{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Classification Sequence Scramble.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCtYCdOtVhdCo2klBLHtFW"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqM52AewG1Ca"
      },
      "source": [
        "# https://www.machinecurve.com/index.php/2021/02/03/how-to-use-k-fold-cross-validation-with-pytorch/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyoY9nCAkqgo",
        "outputId": "71c069e0-b880-4ba3-aabc-a57164fe3b73"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M84SeDz1kwZw",
        "outputId": "e757a8cc-57ed-4a75-8556-dfd575155dc9"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eon5HN5UkzR-",
        "outputId": "1790e529-fb84-46d8-d3fb-66c9b298b7e4"
      },
      "source": [
        "cd /content/gdrive/My Drive/ZFDataset/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/ZFDataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TETUqP6nlK5O"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "import pathlib\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "from matplotlib import cm\n",
        "\n",
        "from scipy import ndimage as ndi\n",
        "from skimage import io, filters, measure, morphology, img_as_ubyte\n",
        "import pandas as pd\n",
        "from sklearn import decomposition, manifold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6qzTEzfapwc"
      },
      "source": [
        "base_path = '/content/gdrive/My Drive/ZFDataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzJsUW-elDe_"
      },
      "source": [
        "# syllable_df_Nest_Total = pd.read_pickle(base_path+Nest_analysis+'_Densenet121.pkl')\n",
        "# syllable_df_Nest_Total1 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest4_Densenet121.pkl')\n",
        "# syllable_df_Nest_Total2 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest5_Densenet121.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj7I3p9kkOnT"
      },
      "source": [
        "# syllable_df_Nest_Total1 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest1_Densenet121.pkl')\n",
        "# syllable_df_Nest_Total1['Nest'] = \"Nest1\"\n",
        "syllable_df_Nest_Total2 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest2_Densenet121.pkl')\n",
        "syllable_df_Nest_Total2['Nest'] = \"Nest2\"\n",
        "syllable_df_Nest_Total3 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest3_Densenet121.pkl')\n",
        "syllable_df_Nest_Total3['Nest'] = \"Nest3\"\n",
        "syllable_df_Nest_Total4 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest4_Densenet121.pkl')\n",
        "syllable_df_Nest_Total4['Nest'] = \"Nest4\"\n",
        "syllable_df_Nest_Total5 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest5_Densenet121.pkl')\n",
        "syllable_df_Nest_Total5['Nest'] = \"Nest5\"\n",
        "syllable_df_Nest_Total6 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest6_Densenet121.pkl')\n",
        "syllable_df_Nest_Total6['Nest'] = \"Nest6\"\n",
        "syllable_df_Nest_Total7 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest7_Densenet121.pkl')\n",
        "syllable_df_Nest_Total7['Nest'] = \"Nest7\"\n",
        "syllable_df_Nest_Total8 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest8_Densenet121.pkl')\n",
        "syllable_df_Nest_Total8['Nest'] = \"Nest8\"\n",
        "syllable_df_Nest_Total9 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest9_Densenet121.pkl')\n",
        "syllable_df_Nest_Total9['Nest'] = \"Nest9\"\n",
        "syllable_df_Nest_Total10 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest10_Densenet121.pkl')\n",
        "syllable_df_Nest_Total10['Nest'] = \"Nest10\"\n",
        "syllable_df_Nest_Total11 = pd.read_pickle('/content/gdrive/My Drive/ZFDataset/Nest11_Densenet121.pkl')\n",
        "syllable_df_Nest_Total11['Nest'] = \"Nest11\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjM1Mg4FFtKO"
      },
      "source": [
        "# syllable_df_Nest_Total = pd.concat([syllable_df_Nest_Total2, syllable_df_Nest_Total3, syllable_df_Nest_Total4, syllable_df_Nest_Total5], ignore_index=True)\n",
        "syllable_df_Nest_Total = pd.concat([syllable_df_Nest_Total2, syllable_df_Nest_Total3, syllable_df_Nest_Total4, syllable_df_Nest_Total5,\n",
        "                                    syllable_df_Nest_Total6, syllable_df_Nest_Total7, syllable_df_Nest_Total8, syllable_df_Nest_Total9, syllable_df_Nest_Total10, syllable_df_Nest_Total11], ignore_index=True)\n",
        "del syllable_df_Nest_Total11, syllable_df_Nest_Total2, syllable_df_Nest_Total3, syllable_df_Nest_Total4, syllable_df_Nest_Total5\n",
        "del syllable_df_Nest_Total6, syllable_df_Nest_Total7, syllable_df_Nest_Total8, syllable_df_Nest_Total9, syllable_df_Nest_Total10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEylmRg5kPf3"
      },
      "source": [
        "syllable_df_Nest_Total.drop(columns=['audio', 'spectrogram'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "p4EdpblylHOI",
        "outputId": "57bdff4d-b712-43e9-d252-b4731b37fd2a"
      },
      "source": [
        "syllable_df_Nest_Total"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>labels</th>\n",
              "      <th>indv</th>\n",
              "      <th>indvi</th>\n",
              "      <th>key</th>\n",
              "      <th>rate</th>\n",
              "      <th>labels_indv</th>\n",
              "      <th>densenet121_features</th>\n",
              "      <th>Nest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.050414</td>\n",
              "      <td>0.097987</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>1</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.00028999924, 0.0064279474, 0.0022861622, 0....</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.508713</td>\n",
              "      <td>0.570935</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>2</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.0002864063, 0.0052835844, 0.002387906, 0.00...</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.644405</td>\n",
              "      <td>0.703089</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>3</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.0002815476, 0.0063230395, 0.002232295, 0.00...</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.810504</td>\n",
              "      <td>0.870799</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>4</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.00028404495, 0.004314999, 0.0023957393, 0.0...</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.938940</td>\n",
              "      <td>1.000845</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>5</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.00026726056, 0.0051532886, 0.0022074692, 0....</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23050</th>\n",
              "      <td>2.372736</td>\n",
              "      <td>2.450990</td>\n",
              "      <td>f</td>\n",
              "      <td>vstd</td>\n",
              "      <td>16</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_f</td>\n",
              "      <td>[0.00024792607, 0.005248108, 0.0019565802, 0.0...</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23051</th>\n",
              "      <td>2.598813</td>\n",
              "      <td>2.651443</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>17</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.00027455005, 0.0042480123, 0.0022447598, 0....</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23052</th>\n",
              "      <td>3.907656</td>\n",
              "      <td>3.982781</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>18</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.0002736851, 0.0052517042, 0.001988696, 0.00...</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23053</th>\n",
              "      <td>4.090015</td>\n",
              "      <td>4.216341</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>19</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.00030207614, 0.0031468559, 0.0016397715, 0....</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23054</th>\n",
              "      <td>5.081715</td>\n",
              "      <td>5.187112</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>20</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.00032343273, 0.003422297, 0.0019693254, 0.0...</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23055 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       start_time  ...    Nest\n",
              "0        0.050414  ...   Nest2\n",
              "1        0.508713  ...   Nest2\n",
              "2        0.644405  ...   Nest2\n",
              "3        0.810504  ...   Nest2\n",
              "4        0.938940  ...   Nest2\n",
              "...           ...  ...     ...\n",
              "23050    2.372736  ...  Nest11\n",
              "23051    2.598813  ...  Nest11\n",
              "23052    3.907656  ...  Nest11\n",
              "23053    4.090015  ...  Nest11\n",
              "23054    5.081715  ...  Nest11\n",
              "\n",
              "[23055 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLOi8uCnkWyC"
      },
      "source": [
        "# Tutor_dataset = syllable_df_Nest_Total[syllable_df_Nest_Total['indv'].isin([\"ivoj\", \"nzen\", \"xsup\", \"gthh\", \"ttog\", \"isab\", \"ixea\", \"ihza\", \"zegf\", \"sjew\"])].reset_index(drop=True)\n",
        "Tutor_dataset = syllable_df_Nest_Total[syllable_df_Nest_Total['indv'].isin([\"ivoj\", \"nzen\", \"xsup\", \"gthh\", \"ttog\", \"isab\", \"ixea\", \"ihza\", \"zegf\", \"sjew\", \"cgby\"])].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5F_Un1Y59Eg"
      },
      "source": [
        "Pupil_dataset = syllable_df_Nest_Total[syllable_df_Nest_Total['indv'].isin([\"hphi\", \"cyea\", \"phpd\", \"cxyc\", \"qfod\", \"nsrn\", \"khxv\", \"oogw\", \"kcos\", \"tbfk\", \"kccr\", \"bbyj\", \"onsu\", \"vusu\", \"kfgj\", \"inji\", \"hsew\", \"sdhp\", \"vstd\"])].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "sHxAcHdjq3av",
        "outputId": "92a28ef9-20c1-4b42-f844-3c2a23d59efc"
      },
      "source": [
        "Tutor_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>labels</th>\n",
              "      <th>indv</th>\n",
              "      <th>indvi</th>\n",
              "      <th>key</th>\n",
              "      <th>rate</th>\n",
              "      <th>labels_indv</th>\n",
              "      <th>densenet121_features</th>\n",
              "      <th>Nest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.141369</td>\n",
              "      <td>0.163840</td>\n",
              "      <td>i</td>\n",
              "      <td>nzen</td>\n",
              "      <td>1</td>\n",
              "      <td>nzen_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>nzen_i</td>\n",
              "      <td>[0.000281047, 0.006896307, 0.0021862306, 0.003...</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.226426</td>\n",
              "      <td>0.290575</td>\n",
              "      <td>i</td>\n",
              "      <td>nzen</td>\n",
              "      <td>2</td>\n",
              "      <td>nzen_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>nzen_i</td>\n",
              "      <td>[0.0003058371, 0.005542181, 0.0023643032, 0.00...</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.388081</td>\n",
              "      <td>0.453342</td>\n",
              "      <td>i</td>\n",
              "      <td>nzen</td>\n",
              "      <td>3</td>\n",
              "      <td>nzen_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>nzen_i</td>\n",
              "      <td>[0.0002870175, 0.0060381475, 0.0023333135, 0.0...</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.487174</td>\n",
              "      <td>0.550757</td>\n",
              "      <td>j</td>\n",
              "      <td>nzen</td>\n",
              "      <td>4</td>\n",
              "      <td>nzen_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>nzen_j</td>\n",
              "      <td>[0.0003228713, 0.0052634007, 0.0023634112, 0.0...</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.579305</td>\n",
              "      <td>0.642185</td>\n",
              "      <td>a</td>\n",
              "      <td>nzen</td>\n",
              "      <td>5</td>\n",
              "      <td>nzen_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>nzen_a</td>\n",
              "      <td>[0.00028934886, 0.0054234248, 0.00228799, 0.00...</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7176</th>\n",
              "      <td>10.182711</td>\n",
              "      <td>10.273732</td>\n",
              "      <td>0</td>\n",
              "      <td>cgby</td>\n",
              "      <td>39</td>\n",
              "      <td>cgby_0032</td>\n",
              "      <td>44100</td>\n",
              "      <td>cgby_0</td>\n",
              "      <td>[0.0003101198, 0.0023758058, 0.00217167, 0.003...</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7177</th>\n",
              "      <td>10.322530</td>\n",
              "      <td>10.421079</td>\n",
              "      <td>0</td>\n",
              "      <td>cgby</td>\n",
              "      <td>40</td>\n",
              "      <td>cgby_0032</td>\n",
              "      <td>44100</td>\n",
              "      <td>cgby_0</td>\n",
              "      <td>[0.00037552853, 0.004450283, 0.0019465615, 0.0...</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7178</th>\n",
              "      <td>10.451782</td>\n",
              "      <td>10.581827</td>\n",
              "      <td>0</td>\n",
              "      <td>cgby</td>\n",
              "      <td>41</td>\n",
              "      <td>cgby_0032</td>\n",
              "      <td>44100</td>\n",
              "      <td>cgby_0</td>\n",
              "      <td>[0.00045851385, 0.0021333802, 0.0020485146, 0....</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7179</th>\n",
              "      <td>10.640036</td>\n",
              "      <td>10.822507</td>\n",
              "      <td>0</td>\n",
              "      <td>cgby</td>\n",
              "      <td>42</td>\n",
              "      <td>cgby_0032</td>\n",
              "      <td>44100</td>\n",
              "      <td>cgby_0</td>\n",
              "      <td>[0.00029902745, 0.0032967748, 0.0025172085, 0....</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7180</th>\n",
              "      <td>10.846702</td>\n",
              "      <td>10.935183</td>\n",
              "      <td>0</td>\n",
              "      <td>cgby</td>\n",
              "      <td>43</td>\n",
              "      <td>cgby_0032</td>\n",
              "      <td>44100</td>\n",
              "      <td>cgby_0</td>\n",
              "      <td>[0.0002637265, 0.0070170346, 0.0019420997, 0.0...</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7181 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      start_time  ...    Nest\n",
              "0       0.141369  ...   Nest2\n",
              "1       0.226426  ...   Nest2\n",
              "2       0.388081  ...   Nest2\n",
              "3       0.487174  ...   Nest2\n",
              "4       0.579305  ...   Nest2\n",
              "...          ...  ...     ...\n",
              "7176   10.182711  ...  Nest11\n",
              "7177   10.322530  ...  Nest11\n",
              "7178   10.451782  ...  Nest11\n",
              "7179   10.640036  ...  Nest11\n",
              "7180   10.846702  ...  Nest11\n",
              "\n",
              "[7181 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "NNnIcVfwu5aj",
        "outputId": "573ec40f-329f-4baf-aad0-c20231243c5b"
      },
      "source": [
        "Pupil_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>labels</th>\n",
              "      <th>indv</th>\n",
              "      <th>indvi</th>\n",
              "      <th>key</th>\n",
              "      <th>rate</th>\n",
              "      <th>labels_indv</th>\n",
              "      <th>densenet121_features</th>\n",
              "      <th>Nest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.050414</td>\n",
              "      <td>0.097987</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>1</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.00028999924, 0.0064279474, 0.0022861622, 0....</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.508713</td>\n",
              "      <td>0.570935</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>2</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.0002864063, 0.0052835844, 0.002387906, 0.00...</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.644405</td>\n",
              "      <td>0.703089</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>3</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.0002815476, 0.0063230395, 0.002232295, 0.00...</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.810504</td>\n",
              "      <td>0.870799</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>4</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.00028404495, 0.004314999, 0.0023957393, 0.0...</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.938940</td>\n",
              "      <td>1.000845</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>5</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.00026726056, 0.0051532886, 0.0022074692, 0....</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15869</th>\n",
              "      <td>2.372736</td>\n",
              "      <td>2.450990</td>\n",
              "      <td>f</td>\n",
              "      <td>vstd</td>\n",
              "      <td>16</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_f</td>\n",
              "      <td>[0.00024792607, 0.005248108, 0.0019565802, 0.0...</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15870</th>\n",
              "      <td>2.598813</td>\n",
              "      <td>2.651443</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>17</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.00027455005, 0.0042480123, 0.0022447598, 0....</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15871</th>\n",
              "      <td>3.907656</td>\n",
              "      <td>3.982781</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>18</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.0002736851, 0.0052517042, 0.001988696, 0.00...</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15872</th>\n",
              "      <td>4.090015</td>\n",
              "      <td>4.216341</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>19</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.00030207614, 0.0031468559, 0.0016397715, 0....</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15873</th>\n",
              "      <td>5.081715</td>\n",
              "      <td>5.187112</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>20</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.00032343273, 0.003422297, 0.0019693254, 0.0...</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15874 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       start_time  ...    Nest\n",
              "0        0.050414  ...   Nest2\n",
              "1        0.508713  ...   Nest2\n",
              "2        0.644405  ...   Nest2\n",
              "3        0.810504  ...   Nest2\n",
              "4        0.938940  ...   Nest2\n",
              "...           ...  ...     ...\n",
              "15869    2.372736  ...  Nest11\n",
              "15870    2.598813  ...  Nest11\n",
              "15871    3.907656  ...  Nest11\n",
              "15872    4.090015  ...  Nest11\n",
              "15873    5.081715  ...  Nest11\n",
              "\n",
              "[15874 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI52AoQelNfO"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import re\n",
        "import spacy\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import string\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNWE6K2pCW0P"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import column_or_1d\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data.dataset import Subset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXJG5JDDCgF7"
      },
      "source": [
        "le = LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CNNQDMpCk1v",
        "outputId": "7eba7a46-10ab-4a20-baf3-c3761b069f95"
      },
      "source": [
        "# le.fit(syllable_df_Nest_Total['indv'].to_list())\n",
        "le.fit(syllable_df_Nest_Total['Nest'].to_list())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAVsMN6cCwQJ"
      },
      "source": [
        "# targets = le.transform(syllable_df_Nest_Total['indv'].to_list())\n",
        "targets = le.transform(syllable_df_Nest_Total['Nest'].to_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui06X-t2C313",
        "outputId": "fd176252-d24d-41c1-aeb8-e9e942ddf666"
      },
      "source": [
        "targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNZ_knrXG6D5",
        "outputId": "ee296d8b-ebda-45d1-9791-b81abd56903a"
      },
      "source": [
        "list(le.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Nest10',\n",
              " 'Nest11',\n",
              " 'Nest2',\n",
              " 'Nest3',\n",
              " 'Nest4',\n",
              " 'Nest5',\n",
              " 'Nest6',\n",
              " 'Nest7',\n",
              " 'Nest8',\n",
              " 'Nest9']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSdI03XNDB9s"
      },
      "source": [
        "syllable_df_Nest_Total['indv_encoded'] = targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5slyQftJDHQq",
        "outputId": "88d72d7d-bba2-480e-ca6d-ccb094508714"
      },
      "source": [
        "syllable_df_Nest_Total"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>labels</th>\n",
              "      <th>indv</th>\n",
              "      <th>indvi</th>\n",
              "      <th>key</th>\n",
              "      <th>rate</th>\n",
              "      <th>labels_indv</th>\n",
              "      <th>densenet121_features</th>\n",
              "      <th>Nest</th>\n",
              "      <th>indv_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.050414</td>\n",
              "      <td>0.097987</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>1</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.00028999924, 0.0064279474, 0.0022861622, 0....</td>\n",
              "      <td>Nest2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.508713</td>\n",
              "      <td>0.570935</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>2</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.0002864063, 0.0052835844, 0.002387906, 0.00...</td>\n",
              "      <td>Nest2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.644405</td>\n",
              "      <td>0.703089</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>3</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.0002815476, 0.0063230395, 0.002232295, 0.00...</td>\n",
              "      <td>Nest2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.810504</td>\n",
              "      <td>0.870799</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>4</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.00028404495, 0.004314999, 0.0023957393, 0.0...</td>\n",
              "      <td>Nest2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.938940</td>\n",
              "      <td>1.000845</td>\n",
              "      <td>i</td>\n",
              "      <td>cxyc</td>\n",
              "      <td>5</td>\n",
              "      <td>cxyc_0000</td>\n",
              "      <td>44100</td>\n",
              "      <td>cxyc_i</td>\n",
              "      <td>[0.00026726056, 0.0051532886, 0.0022074692, 0....</td>\n",
              "      <td>Nest2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23050</th>\n",
              "      <td>2.372736</td>\n",
              "      <td>2.450990</td>\n",
              "      <td>f</td>\n",
              "      <td>vstd</td>\n",
              "      <td>16</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_f</td>\n",
              "      <td>[0.00024792607, 0.005248108, 0.0019565802, 0.0...</td>\n",
              "      <td>Nest11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23051</th>\n",
              "      <td>2.598813</td>\n",
              "      <td>2.651443</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>17</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.00027455005, 0.0042480123, 0.0022447598, 0....</td>\n",
              "      <td>Nest11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23052</th>\n",
              "      <td>3.907656</td>\n",
              "      <td>3.982781</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>18</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.0002736851, 0.0052517042, 0.001988696, 0.00...</td>\n",
              "      <td>Nest11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23053</th>\n",
              "      <td>4.090015</td>\n",
              "      <td>4.216341</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>19</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.00030207614, 0.0031468559, 0.0016397715, 0....</td>\n",
              "      <td>Nest11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23054</th>\n",
              "      <td>5.081715</td>\n",
              "      <td>5.187112</td>\n",
              "      <td>0</td>\n",
              "      <td>vstd</td>\n",
              "      <td>20</td>\n",
              "      <td>vstd_0004</td>\n",
              "      <td>44100</td>\n",
              "      <td>vstd_0</td>\n",
              "      <td>[0.00032343273, 0.003422297, 0.0019693254, 0.0...</td>\n",
              "      <td>Nest11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23055 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       start_time  end_time  ...    Nest indv_encoded\n",
              "0        0.050414  0.097987  ...   Nest2            2\n",
              "1        0.508713  0.570935  ...   Nest2            2\n",
              "2        0.644405  0.703089  ...   Nest2            2\n",
              "3        0.810504  0.870799  ...   Nest2            2\n",
              "4        0.938940  1.000845  ...   Nest2            2\n",
              "...           ...       ...  ...     ...          ...\n",
              "23050    2.372736  2.450990  ...  Nest11            1\n",
              "23051    2.598813  2.651443  ...  Nest11            1\n",
              "23052    3.907656  3.982781  ...  Nest11            1\n",
              "23053    4.090015  4.216341  ...  Nest11            1\n",
              "23054    5.081715  5.187112  ...  Nest11            1\n",
              "\n",
              "[23055 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5JgKLYqwQEs"
      },
      "source": [
        "max_sequence_length = syllable_df_Nest_Total['indvi'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh1pR8Z8KC0u"
      },
      "source": [
        "# current_songfile = syllable_df_Nest_Total.loc[syllable_df_Nest_Total['key']=='cyea_0000']\n",
        "# current_songfile = syllable_df_Nest_Total.loc[syllable_df_Nest_Total['key']=='cxyc_0000']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yrVOqmPm09Y"
      },
      "source": [
        "def create_sequence_feature(syllable_df_Nest_Total, given_key, encoder, label_select='indv'):\n",
        "    current_songfile = syllable_df_Nest_Total.loc[syllable_df_Nest_Total['key']==given_key]\n",
        "    sequence_length = current_songfile['indvi'].values[-1]\n",
        "    temp_list = current_songfile['densenet121_features'].to_list()\n",
        "    label = encoder.transform(current_songfile[label_select].values)[-1]\n",
        "    # for k in range(sequence_length,max_sequence_length):\n",
        "    #   temp_list.append(np.zeros(len(temp_list[0])))\n",
        "    return [temp_list, sequence_length], label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGCWBUpGEo4L"
      },
      "source": [
        "# current_songfile = syllable_df_Nest_Total.loc[syllable_df_Nest_Total['key']=='cyea_0000']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhKNYe8dL528"
      },
      "source": [
        "# unique_indv = syllable_df_Nest_Total.indv.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_cf5pclXd5u"
      },
      "source": [
        "def data_splitting_based_on_sample_size(syllable_df_Nest_Total):\n",
        "  Label_Total = []\n",
        "  Nest_Total = []\n",
        "\n",
        "  for key in syllable_df_Nest_Total.key.unique():\n",
        "    Label_Total.append(syllable_df_Nest_Total.loc[syllable_df_Nest_Total['key']==key]['indv'].values[0])\n",
        "    Nest_Total.append(syllable_df_Nest_Total.loc[syllable_df_Nest_Total['key']==key]['Nest'].values[0])\n",
        "\n",
        "  le = LabelEncoder()\n",
        "  le.fit(Nest_Total)\n",
        "\n",
        "  targets = le.transform(Nest_Total)\n",
        "\n",
        "  encoded_targets = pd.DataFrame({'targets' : targets,\n",
        "        'indvi' : Label_Total,\n",
        "        'key' : syllable_df_Nest_Total.key.unique(),\n",
        "        'Nest' : Nest_Total})\n",
        "\n",
        "  # train_indices, test_indices = train_test_split(np.arange(targets.shape[0]), train_size=train_test_split_ratio, stratify=targets)\n",
        "\n",
        "  # train_keys = encoded_targets.loc[train_indices]['key'].to_list()\n",
        "\n",
        "  # test_keys = encoded_targets.loc[test_indices]['key'].to_list()\n",
        "\n",
        "  # return encoded_targets, train_keys, test_keys, le\n",
        "  return encoded_targets, le"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGBXfIAzY0YW"
      },
      "source": [
        "# Training on Tutor set\n",
        "encoded_targets, le = data_splitting_based_on_sample_size(Tutor_dataset)\n",
        "# Training on Pupil set\n",
        "#encoded_targets, le = data_splitting_based_on_sample_size(Pupil_dataset)\n",
        "# encoded_targets, le = data_splitting_based_on_sample_size(syllable_df_Nest_Total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlKnHWBJi1ob",
        "outputId": "1b431cf6-b8d6-4a2e-9c78-aa9c094a0e1a"
      },
      "source": [
        "le.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Nest10', 'Nest11', 'Nest2', 'Nest3', 'Nest4', 'Nest5', 'Nest6',\n",
              "       'Nest7', 'Nest8', 'Nest9'], dtype='<U6')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "euO6Fph3ZzkU",
        "outputId": "737ca6d0-6010-41f9-b10f-bf0f78cddb14"
      },
      "source": [
        "encoded_targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>targets</th>\n",
              "      <th>indvi</th>\n",
              "      <th>key</th>\n",
              "      <th>Nest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>nzen</td>\n",
              "      <td>nzen_0000</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>nzen</td>\n",
              "      <td>nzen_0001</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>nzen</td>\n",
              "      <td>nzen_0002</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>nzen</td>\n",
              "      <td>nzen_0003</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>nzen</td>\n",
              "      <td>nzen_0004</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>1</td>\n",
              "      <td>cgby</td>\n",
              "      <td>cgby_0026</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>1</td>\n",
              "      <td>cgby</td>\n",
              "      <td>cgby_0048</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>1</td>\n",
              "      <td>cgby</td>\n",
              "      <td>cgby_0022</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>1</td>\n",
              "      <td>cgby</td>\n",
              "      <td>cgby_0012</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>1</td>\n",
              "      <td>cgby</td>\n",
              "      <td>cgby_0032</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>325 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     targets indvi        key    Nest\n",
              "0          2  nzen  nzen_0000   Nest2\n",
              "1          2  nzen  nzen_0001   Nest2\n",
              "2          2  nzen  nzen_0002   Nest2\n",
              "3          2  nzen  nzen_0003   Nest2\n",
              "4          2  nzen  nzen_0004   Nest2\n",
              "..       ...   ...        ...     ...\n",
              "320        1  cgby  cgby_0026  Nest11\n",
              "321        1  cgby  cgby_0048  Nest11\n",
              "322        1  cgby  cgby_0022  Nest11\n",
              "323        1  cgby  cgby_0012  Nest11\n",
              "324        1  cgby  cgby_0032  Nest11\n",
              "\n",
              "[325 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHl6WkEtAmbO"
      },
      "source": [
        "# Shuffling the training dataset\n",
        "encoded_targets = encoded_targets.sample(frac=1, random_state=2021).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "p_i9GZWVAsMW",
        "outputId": "e3be976a-ad64-43fa-fa28-41c537a99b89"
      },
      "source": [
        "encoded_targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>targets</th>\n",
              "      <th>indvi</th>\n",
              "      <th>key</th>\n",
              "      <th>Nest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>ixea</td>\n",
              "      <td>ixea_0001</td>\n",
              "      <td>Nest7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>isab</td>\n",
              "      <td>isab_0028</td>\n",
              "      <td>Nest6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>gthh</td>\n",
              "      <td>gthh_0030</td>\n",
              "      <td>Nest4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>isab</td>\n",
              "      <td>isab_0004</td>\n",
              "      <td>Nest6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>sjew</td>\n",
              "      <td>sjew_0007</td>\n",
              "      <td>Nest10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>3</td>\n",
              "      <td>xsup</td>\n",
              "      <td>xsup_0027</td>\n",
              "      <td>Nest3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>5</td>\n",
              "      <td>ttog</td>\n",
              "      <td>ttog_0023</td>\n",
              "      <td>Nest5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>6</td>\n",
              "      <td>isab</td>\n",
              "      <td>isab_0006</td>\n",
              "      <td>Nest6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>4</td>\n",
              "      <td>gthh</td>\n",
              "      <td>gthh_0033</td>\n",
              "      <td>Nest4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>5</td>\n",
              "      <td>ttog</td>\n",
              "      <td>ttog_0031</td>\n",
              "      <td>Nest5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>325 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     targets indvi        key    Nest\n",
              "0          7  ixea  ixea_0001   Nest7\n",
              "1          6  isab  isab_0028   Nest6\n",
              "2          4  gthh  gthh_0030   Nest4\n",
              "3          6  isab  isab_0004   Nest6\n",
              "4          0  sjew  sjew_0007  Nest10\n",
              "..       ...   ...        ...     ...\n",
              "320        3  xsup  xsup_0027   Nest3\n",
              "321        5  ttog  ttog_0023   Nest5\n",
              "322        6  isab  isab_0006   Nest6\n",
              "323        4  gthh  gthh_0033   Nest4\n",
              "324        5  ttog  ttog_0031   Nest5\n",
              "\n",
              "[325 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGdi7i7oLoHm",
        "outputId": "445c0764-9f8d-4e41-8bdc-ece0d021f52f"
      },
      "source": [
        "# Creating the sequences\n",
        "# X_train = []; X_test =[];\n",
        "# y_train = []; y_test =[];\n",
        "X_total = []; y_total = [];\n",
        "\n",
        "# for key_indv in unique_indv:\n",
        "#   newkeys = syllable_df_Nest_Total[syllable_df_Nest_Total['indv']==key_indv].key.unique()\n",
        "#   for key in newkeys:\n",
        "#     data, label = create_sequence_feature(syllable_df_Nest_Total, key)\n",
        "#     Nest_feature_set_padded.append(data)\n",
        "#     Label_set.append(label)\n",
        "\n",
        "for key in encoded_targets['key'].unique():# [:10]:\n",
        "    print(key)\n",
        "    data, label = create_sequence_feature(Tutor_dataset, key, le, label_select='Nest')\n",
        "    X_total.append(data)\n",
        "    y_total.append(label)\n",
        "    # if key in train_keys:\n",
        "    #   X_train.append(data)\n",
        "    #   y_train.append(label)\n",
        "    # elif key in test_keys:\n",
        "    #   X_test.append(data)\n",
        "    #   y_test.append(label)\n",
        "    # else:\n",
        "    #   print(key, \"Not Found\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ixea_0001\n",
            "isab_0028\n",
            "gthh_0030\n",
            "isab_0004\n",
            "sjew_0007\n",
            "ixea_0008\n",
            "gthh_0024\n",
            "ttog_0016\n",
            "zegf_0000\n",
            "cgby_0021\n",
            "nzen_0001\n",
            "ixea_0025\n",
            "sjew_0000\n",
            "cgby_0002\n",
            "isab_0021\n",
            "gthh_0010\n",
            "nzen_0006\n",
            "ixea_0018\n",
            "gthh_0022\n",
            "xsup_0019\n",
            "xsup_0011\n",
            "xsup_0029\n",
            "ttog_0001\n",
            "ttog_0032\n",
            "isab_0020\n",
            "ttog_0027\n",
            "ihza_0021\n",
            "cgby_0027\n",
            "ttog_0033\n",
            "cgby_0009\n",
            "isab_0018\n",
            "xsup_0031\n",
            "sjew_0019\n",
            "nzen_0009\n",
            "nzen_0002\n",
            "isab_0013\n",
            "isab_0012\n",
            "ttog_0030\n",
            "ttog_0026\n",
            "cgby_0033\n",
            "isab_0011\n",
            "ttog_0000\n",
            "ihza_0006\n",
            "ixea_0024\n",
            "xsup_0005\n",
            "cgby_0014\n",
            "xsup_0024\n",
            "nzen_0015\n",
            "cgby_0031\n",
            "cgby_0025\n",
            "xsup_0025\n",
            "ihza_0005\n",
            "cgby_0007\n",
            "ixea_0034\n",
            "ixea_0002\n",
            "xsup_0020\n",
            "cgby_0019\n",
            "zegf_0005\n",
            "gthh_0007\n",
            "zegf_0007\n",
            "ttog_0010\n",
            "nzen_0008\n",
            "nzen_0014\n",
            "cgby_0010\n",
            "ihza_0017\n",
            "gthh_0028\n",
            "gthh_0032\n",
            "gthh_0015\n",
            "ttog_0005\n",
            "isab_0008\n",
            "ixea_0031\n",
            "xsup_0009\n",
            "ihza_0026\n",
            "gthh_0013\n",
            "sjew_0023\n",
            "cgby_0046\n",
            "ixea_0011\n",
            "zegf_0015\n",
            "isab_0003\n",
            "ihza_0013\n",
            "gthh_0002\n",
            "ttog_0036\n",
            "ixea_0014\n",
            "zegf_0024\n",
            "ixea_0000\n",
            "gthh_0006\n",
            "isab_0009\n",
            "ttog_0011\n",
            "nzen_0013\n",
            "cgby_0012\n",
            "ihza_0016\n",
            "cgby_0015\n",
            "ttog_0002\n",
            "ixea_0028\n",
            "isab_0019\n",
            "gthh_0016\n",
            "zegf_0006\n",
            "gthh_0008\n",
            "nzen_0003\n",
            "isab_0017\n",
            "cgby_0026\n",
            "cgby_0003\n",
            "xsup_0033\n",
            "cgby_0022\n",
            "gthh_0003\n",
            "zegf_0027\n",
            "xsup_0018\n",
            "xsup_0021\n",
            "ttog_0009\n",
            "ixea_0029\n",
            "nzen_0000\n",
            "isab_0024\n",
            "zegf_0021\n",
            "cgby_0041\n",
            "zegf_0017\n",
            "ttog_0018\n",
            "zegf_0022\n",
            "xsup_0015\n",
            "gthh_0005\n",
            "xsup_0001\n",
            "cgby_0008\n",
            "ttog_0021\n",
            "gthh_0012\n",
            "gthh_0031\n",
            "cgby_0028\n",
            "ixea_0030\n",
            "xsup_0007\n",
            "ttog_0019\n",
            "zegf_0010\n",
            "nzen_0010\n",
            "sjew_0021\n",
            "ixea_0007\n",
            "cgby_0011\n",
            "ihza_0018\n",
            "ixea_0003\n",
            "cgby_0047\n",
            "xsup_0026\n",
            "gthh_0011\n",
            "xsup_0006\n",
            "gthh_0026\n",
            "ihza_0014\n",
            "cgby_0048\n",
            "zegf_0030\n",
            "sjew_0022\n",
            "ttog_0029\n",
            "cgby_0038\n",
            "ttog_0012\n",
            "ihza_0022\n",
            "ttog_0034\n",
            "xsup_0034\n",
            "sjew_0011\n",
            "sjew_0013\n",
            "sjew_0024\n",
            "ihza_0011\n",
            "cgby_0001\n",
            "sjew_0012\n",
            "xsup_0036\n",
            "nzen_0016\n",
            "cgby_0013\n",
            "xsup_0017\n",
            "ttog_0006\n",
            "ttog_0015\n",
            "nzen_0004\n",
            "cgby_0040\n",
            "ixea_0021\n",
            "gthh_0014\n",
            "xsup_0035\n",
            "ihza_0025\n",
            "ihza_0009\n",
            "xsup_0028\n",
            "isab_0023\n",
            "zegf_0004\n",
            "isab_0001\n",
            "ixea_0012\n",
            "ihza_0023\n",
            "sjew_0006\n",
            "ihza_0001\n",
            "cgby_0044\n",
            "cgby_0036\n",
            "ixea_0015\n",
            "isab_0016\n",
            "xsup_0038\n",
            "xsup_0014\n",
            "zegf_0032\n",
            "zegf_0025\n",
            "cgby_0000\n",
            "ihza_0007\n",
            "xsup_0037\n",
            "sjew_0005\n",
            "sjew_0015\n",
            "zegf_0019\n",
            "cgby_0039\n",
            "gthh_0023\n",
            "ttog_0014\n",
            "ixea_0019\n",
            "ttog_0024\n",
            "ihza_0029\n",
            "gthh_0021\n",
            "ixea_0033\n",
            "zegf_0001\n",
            "isab_0025\n",
            "isab_0015\n",
            "ihza_0000\n",
            "xsup_0013\n",
            "ihza_0027\n",
            "cgby_0030\n",
            "ihza_0020\n",
            "ihza_0024\n",
            "ttog_0020\n",
            "gthh_0004\n",
            "zegf_0031\n",
            "ihza_0002\n",
            "nzen_0012\n",
            "ixea_0013\n",
            "zegf_0029\n",
            "gthh_0029\n",
            "sjew_0003\n",
            "cgby_0005\n",
            "ttog_0025\n",
            "sjew_0002\n",
            "gthh_0001\n",
            "ixea_0006\n",
            "ixea_0020\n",
            "isab_0026\n",
            "ihza_0010\n",
            "cgby_0037\n",
            "zegf_0028\n",
            "sjew_0026\n",
            "isab_0007\n",
            "isab_0000\n",
            "sjew_0004\n",
            "sjew_0001\n",
            "zegf_0008\n",
            "gthh_0020\n",
            "cgby_0024\n",
            "cgby_0006\n",
            "ihza_0028\n",
            "ixea_0027\n",
            "zegf_0026\n",
            "cgby_0043\n",
            "isab_0027\n",
            "cgby_0042\n",
            "gthh_0009\n",
            "xsup_0022\n",
            "sjew_0010\n",
            "xsup_0012\n",
            "xsup_0030\n",
            "cgby_0032\n",
            "ttog_0003\n",
            "ihza_0015\n",
            "ihza_0003\n",
            "sjew_0014\n",
            "ixea_0022\n",
            "zegf_0018\n",
            "ixea_0017\n",
            "ihza_0004\n",
            "cgby_0023\n",
            "isab_0005\n",
            "zegf_0003\n",
            "cgby_0034\n",
            "ixea_0005\n",
            "cgby_0045\n",
            "cgby_0018\n",
            "sjew_0018\n",
            "xsup_0003\n",
            "ttog_0028\n",
            "ttog_0008\n",
            "zegf_0020\n",
            "gthh_0027\n",
            "cgby_0029\n",
            "isab_0022\n",
            "zegf_0012\n",
            "ixea_0023\n",
            "sjew_0009\n",
            "sjew_0008\n",
            "ixea_0026\n",
            "gthh_0017\n",
            "cgby_0049\n",
            "ttog_0022\n",
            "sjew_0016\n",
            "ttog_0013\n",
            "zegf_0016\n",
            "xsup_0010\n",
            "zegf_0014\n",
            "nzen_0007\n",
            "cgby_0035\n",
            "xsup_0000\n",
            "nzen_0011\n",
            "xsup_0023\n",
            "zegf_0023\n",
            "gthh_0025\n",
            "ixea_0010\n",
            "xsup_0002\n",
            "ixea_0009\n",
            "ttog_0007\n",
            "xsup_0008\n",
            "zegf_0002\n",
            "cgby_0017\n",
            "ixea_0016\n",
            "cgby_0020\n",
            "zegf_0013\n",
            "nzen_0005\n",
            "ttog_0017\n",
            "ixea_0004\n",
            "isab_0002\n",
            "xsup_0032\n",
            "gthh_0000\n",
            "ihza_0012\n",
            "zegf_0009\n",
            "sjew_0025\n",
            "sjew_0020\n",
            "ttog_0004\n",
            "xsup_0016\n",
            "gthh_0019\n",
            "ttog_0035\n",
            "ihza_0019\n",
            "isab_0014\n",
            "xsup_0004\n",
            "ixea_0035\n",
            "cgby_0004\n",
            "xsup_0027\n",
            "ttog_0023\n",
            "isab_0006\n",
            "gthh_0033\n",
            "ttog_0031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-rw-x2a-BBP"
      },
      "source": [
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.y = Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X[idx][0]), self.y[idx], self.X[idx][1]\n",
        "        # return torch.tensor(self.X[idx]), self.y[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpEfyjqtHffy",
        "outputId": "d3d57b71-613d-468b-d3f3-df36649270c4"
      },
      "source": [
        "Counter(y_total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 26, 1: 49, 2: 17, 3: 39, 4: 33, 5: 37, 6: 28, 7: 35, 8: 29, 9: 32})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxg0jdfEt9A0"
      },
      "source": [
        "num_occurences = encoded_targets.groupby(['Nest','targets']).nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "FF4cvBYfvMUV",
        "outputId": "55d6ae18-eb22-4e53-e468-88aa496679f2"
      },
      "source": [
        "num_occurences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>indvi</th>\n",
              "      <th>key</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest</th>\n",
              "      <th>targets</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Nest10</th>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest11</th>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest2</th>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest3</th>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest4</th>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest5</th>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest6</th>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest7</th>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest8</th>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest9</th>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                indvi  key\n",
              "Nest   targets            \n",
              "Nest10 0            1   26\n",
              "Nest11 1            1   49\n",
              "Nest2  2            1   17\n",
              "Nest3  3            1   39\n",
              "Nest4  4            1   33\n",
              "Nest5  5            1   37\n",
              "Nest6  6            1   28\n",
              "Nest7  7            1   35\n",
              "Nest8  8            1   29\n",
              "Nest9  9            1   32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OopZjJMUvZqy"
      },
      "source": [
        "# class_weights = torch.tensor(num_occurences['key'].min()/num_occurences['key'].values, dtype=float)\n",
        "# for i in range(num_occurences.shape[0]):\n",
        "#   class_weights.append(num_occurences['key'][0]/num_occurences['key'].min())\n",
        "class_weights = num_occurences['key'].min()/num_occurences['key'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzjy2XLKwLqK",
        "outputId": "9ac1cec5-f3ef-4265-a78b-fd6cd98b967f"
      },
      "source": [
        "class_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.65384615, 0.34693878, 1.        , 0.43589744, 0.51515152,\n",
              "       0.45945946, 0.60714286, 0.48571429, 0.5862069 , 0.53125   ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY8Ff3OzmRWG",
        "outputId": "64c30e26-7384-4c8f-ff53-2ce3b2cdab61"
      },
      "source": [
        "len(le.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoXMDxoIEy5"
      },
      "source": [
        "class LSTM_fixed_len(torch.nn.Module) :\n",
        "    # def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, num_layers) :\n",
        "        super().__init__()\n",
        "        # self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bias=True)\n",
        "        self.linear = nn.Linear(hidden_dim, output_dim, bias=True) # Bias = true # Try by setting last layer bias to False\n",
        "        # self.dropout = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x = self.embeddings(x)\n",
        "        # x = self.dropout(x)\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\n",
        "        return self.linear(ht[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrKtriKd01Wl"
      },
      "source": [
        "class LSTM_fixed_len_bidir(torch.nn.Module) :\n",
        "    # def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, num_layers) :\n",
        "        super().__init__()\n",
        "        # self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bias=True, bidirectional=True)\n",
        "        self.linear = nn.Linear(hidden_dim, output_dim, bias=True) # Bias = true\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\n",
        "        return self.linear(ht[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgEoa2fRptn_"
      },
      "source": [
        "# model =  LSTM_fixed_len(1024, 16, len(le.classes_), 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj65tK4Rpu7M",
        "outputId": "291bbed9-3ddb-495c-deb0-8c4f528fae06"
      },
      "source": [
        "# model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM_fixed_len(\n",
              "  (lstm): LSTM(1024, 16, num_layers=2, batch_first=True)\n",
              "  (linear): Linear(in_features=16, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4OsE9xGKfVG"
      },
      "source": [
        "def create_sequence_feature_randomize(syllable_df_Nest_Total, given_key, encoder, label_select='indv', random_state=2021):\n",
        "    current_songfile = syllable_df_Nest_Total.loc[syllable_df_Nest_Total['key']==given_key]\n",
        "    current_songfile = current_songfile.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "    sequence_length = current_songfile['indvi'].values[-1]\n",
        "    temp_list = current_songfile['densenet121_features'].to_list()\n",
        "    label = encoder.transform(current_songfile[label_select].values)[-1]\n",
        "    # for k in range(sequence_length,max_sequence_length):\n",
        "    #   temp_list.append(np.zeros(len(temp_list[0])))\n",
        "    return [temp_list, sequence_length], label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeztI6O49YHR",
        "outputId": "00fb9400-1e6f-4026-9e50-b84135b918ec"
      },
      "source": [
        "encoded_targets_test, le_test = data_splitting_based_on_sample_size(Pupil_dataset)\n",
        "# encoded_targets_test, le_test = data_splitting_based_on_sample_size(Tutor_dataset)\n",
        "\n",
        "X_test = []; y_test = [];\n",
        "\n",
        "for key in encoded_targets_test['key'].unique():# [:10]:\n",
        "    print(key)\n",
        "    # data, label = create_sequence_feature(Tutor_dataset, key, le, label_select='Nest')\n",
        "    data, label = create_sequence_feature_randomize(Pupil_dataset, key, le, label_select='Nest', random_state=7857)\n",
        "    X_test.append(data)\n",
        "    y_test.append(label)\n",
        "\n",
        "test_ds = ReviewsDataset(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cxyc_0000\n",
            "cxyc_0001\n",
            "cxyc_0002\n",
            "cxyc_0003\n",
            "cxyc_0004\n",
            "cxyc_0005\n",
            "cxyc_0006\n",
            "cxyc_0007\n",
            "cxyc_0008\n",
            "cxyc_0009\n",
            "cxyc_0010\n",
            "cxyc_0011\n",
            "cxyc_0012\n",
            "cxyc_0013\n",
            "cxyc_0014\n",
            "cxyc_0015\n",
            "cxyc_0016\n",
            "cxyc_0017\n",
            "cxyc_0018\n",
            "cxyc_0019\n",
            "cxyc_0020\n",
            "cxyc_0021\n",
            "cxyc_0022\n",
            "cxyc_0023\n",
            "cxyc_0024\n",
            "cxyc_0025\n",
            "cxyc_0026\n",
            "nsrn_0000\n",
            "nsrn_0001\n",
            "nsrn_0002\n",
            "nsrn_0003\n",
            "nsrn_0004\n",
            "nsrn_0005\n",
            "nsrn_0006\n",
            "nsrn_0007\n",
            "nsrn_0008\n",
            "nsrn_0009\n",
            "nsrn_0010\n",
            "nsrn_0011\n",
            "nsrn_0012\n",
            "nsrn_0013\n",
            "nsrn_0014\n",
            "nsrn_0015\n",
            "nsrn_0016\n",
            "nsrn_0017\n",
            "nsrn_0018\n",
            "nsrn_0019\n",
            "nsrn_0020\n",
            "nsrn_0021\n",
            "nsrn_0022\n",
            "nsrn_0023\n",
            "nsrn_0024\n",
            "nsrn_0025\n",
            "nsrn_0026\n",
            "nsrn_0027\n",
            "nsrn_0028\n",
            "nsrn_0029\n",
            "nsrn_0030\n",
            "nsrn_0031\n",
            "nsrn_0032\n",
            "nsrn_0033\n",
            "nsrn_0034\n",
            "nsrn_0035\n",
            "nsrn_0036\n",
            "nsrn_0037\n",
            "qfod_0000\n",
            "qfod_0001\n",
            "qfod_0002\n",
            "qfod_0003\n",
            "qfod_0004\n",
            "qfod_0005\n",
            "qfod_0006\n",
            "qfod_0007\n",
            "qfod_0008\n",
            "qfod_0009\n",
            "qfod_0010\n",
            "qfod_0011\n",
            "qfod_0012\n",
            "qfod_0013\n",
            "qfod_0014\n",
            "qfod_0015\n",
            "qfod_0016\n",
            "qfod_0017\n",
            "qfod_0018\n",
            "qfod_0019\n",
            "qfod_0020\n",
            "khxv_0000\n",
            "khxv_0001\n",
            "khxv_0002\n",
            "khxv_0003\n",
            "khxv_0004\n",
            "khxv_0005\n",
            "khxv_0006\n",
            "khxv_0007\n",
            "khxv_0008\n",
            "khxv_0009\n",
            "khxv_0010\n",
            "khxv_0011\n",
            "khxv_0012\n",
            "khxv_0013\n",
            "khxv_0014\n",
            "khxv_0015\n",
            "khxv_0016\n",
            "khxv_0017\n",
            "khxv_0018\n",
            "khxv_0019\n",
            "khxv_0020\n",
            "khxv_0021\n",
            "khxv_0022\n",
            "khxv_0023\n",
            "khxv_0024\n",
            "khxv_0025\n",
            "khxv_0026\n",
            "khxv_0027\n",
            "khxv_0028\n",
            "khxv_0029\n",
            "khxv_0030\n",
            "khxv_0031\n",
            "khxv_0032\n",
            "khxv_0033\n",
            "khxv_0034\n",
            "khxv_0035\n",
            "khxv_0036\n",
            "khxv_0037\n",
            "khxv_0038\n",
            "khxv_0039\n",
            "khxv_0040\n",
            "khxv_0041\n",
            "khxv_0042\n",
            "khxv_0043\n",
            "khxv_0044\n",
            "khxv_0045\n",
            "khxv_0046\n",
            "khxv_0047\n",
            "oogw_0000\n",
            "oogw_0001\n",
            "oogw_0002\n",
            "oogw_0003\n",
            "oogw_0004\n",
            "oogw_0005\n",
            "oogw_0006\n",
            "oogw_0007\n",
            "oogw_0008\n",
            "oogw_0009\n",
            "oogw_0010\n",
            "oogw_0011\n",
            "oogw_0012\n",
            "oogw_0013\n",
            "oogw_0014\n",
            "oogw_0015\n",
            "oogw_0016\n",
            "oogw_0017\n",
            "oogw_0018\n",
            "oogw_0019\n",
            "oogw_0020\n",
            "oogw_0021\n",
            "oogw_0022\n",
            "oogw_0023\n",
            "oogw_0024\n",
            "oogw_0025\n",
            "oogw_0026\n",
            "oogw_0027\n",
            "oogw_0028\n",
            "oogw_0029\n",
            "oogw_0030\n",
            "oogw_0031\n",
            "oogw_0032\n",
            "oogw_0033\n",
            "oogw_0034\n",
            "oogw_0035\n",
            "kcos_0022\n",
            "kcos_0016\n",
            "kcos_0002\n",
            "kcos_0014\n",
            "kcos_0003\n",
            "kcos_0007\n",
            "kcos_0012\n",
            "kcos_0004\n",
            "kcos_0010\n",
            "kcos_0009\n",
            "kcos_0029\n",
            "kcos_0000\n",
            "kcos_0024\n",
            "kcos_0001\n",
            "kcos_0026\n",
            "kcos_0021\n",
            "kcos_0028\n",
            "kcos_0011\n",
            "kcos_0006\n",
            "kcos_0023\n",
            "kcos_0015\n",
            "kcos_0027\n",
            "kcos_0005\n",
            "kcos_0017\n",
            "kcos_0013\n",
            "kcos_0018\n",
            "kcos_0031\n",
            "kcos_0008\n",
            "kcos_0020\n",
            "kcos_0025\n",
            "kcos_0019\n",
            "kcos_0030\n",
            "tbfk_0012\n",
            "tbfk_0003\n",
            "tbfk_0029\n",
            "tbfk_0007\n",
            "tbfk_0000\n",
            "tbfk_0011\n",
            "tbfk_0009\n",
            "tbfk_0017\n",
            "tbfk_0039\n",
            "tbfk_0014\n",
            "tbfk_0021\n",
            "tbfk_0028\n",
            "tbfk_0022\n",
            "tbfk_0031\n",
            "tbfk_0023\n",
            "tbfk_0001\n",
            "tbfk_0024\n",
            "tbfk_0033\n",
            "tbfk_0036\n",
            "tbfk_0005\n",
            "tbfk_0004\n",
            "tbfk_0018\n",
            "tbfk_0015\n",
            "tbfk_0006\n",
            "tbfk_0020\n",
            "tbfk_0025\n",
            "tbfk_0038\n",
            "tbfk_0019\n",
            "tbfk_0032\n",
            "tbfk_0030\n",
            "tbfk_0016\n",
            "tbfk_0010\n",
            "tbfk_0037\n",
            "tbfk_0026\n",
            "tbfk_0027\n",
            "tbfk_0008\n",
            "tbfk_0013\n",
            "tbfk_0034\n",
            "tbfk_0035\n",
            "bbyj_0033\n",
            "bbyj_0000\n",
            "bbyj_0019\n",
            "bbyj_0008\n",
            "bbyj_0013\n",
            "bbyj_0040\n",
            "bbyj_0029\n",
            "bbyj_0006\n",
            "bbyj_0036\n",
            "bbyj_0023\n",
            "bbyj_0032\n",
            "bbyj_0017\n",
            "bbyj_0014\n",
            "bbyj_0028\n",
            "bbyj_0031\n",
            "bbyj_0009\n",
            "bbyj_0004\n",
            "bbyj_0043\n",
            "bbyj_0010\n",
            "bbyj_0042\n",
            "bbyj_0034\n",
            "bbyj_0025\n",
            "bbyj_0011\n",
            "bbyj_0037\n",
            "bbyj_0007\n",
            "bbyj_0022\n",
            "bbyj_0044\n",
            "bbyj_0038\n",
            "bbyj_0012\n",
            "bbyj_0026\n",
            "bbyj_0030\n",
            "bbyj_0020\n",
            "bbyj_0035\n",
            "bbyj_0015\n",
            "bbyj_0021\n",
            "bbyj_0024\n",
            "bbyj_0003\n",
            "bbyj_0016\n",
            "bbyj_0002\n",
            "bbyj_0005\n",
            "bbyj_0041\n",
            "bbyj_0001\n",
            "bbyj_0018\n",
            "bbyj_0039\n",
            "kccr_0038\n",
            "kccr_0023\n",
            "kccr_0027\n",
            "kccr_0020\n",
            "kccr_0010\n",
            "kccr_0014\n",
            "kccr_0030\n",
            "kccr_0005\n",
            "kccr_0031\n",
            "kccr_0008\n",
            "kccr_0041\n",
            "kccr_0050\n",
            "kccr_0021\n",
            "kccr_0013\n",
            "kccr_0024\n",
            "kccr_0054\n",
            "kccr_0043\n",
            "kccr_0022\n",
            "kccr_0019\n",
            "kccr_0051\n",
            "kccr_0001\n",
            "kccr_0037\n",
            "kccr_0052\n",
            "kccr_0029\n",
            "kccr_0007\n",
            "kccr_0034\n",
            "kccr_0061\n",
            "kccr_0028\n",
            "kccr_0062\n",
            "kccr_0009\n",
            "kccr_0047\n",
            "kccr_0017\n",
            "kccr_0060\n",
            "kccr_0044\n",
            "kccr_0039\n",
            "kccr_0006\n",
            "kccr_0035\n",
            "kccr_0046\n",
            "kccr_0045\n",
            "kccr_0058\n",
            "kccr_0016\n",
            "kccr_0018\n",
            "kccr_0053\n",
            "kccr_0057\n",
            "kccr_0048\n",
            "kccr_0003\n",
            "kccr_0025\n",
            "kccr_0011\n",
            "kccr_0012\n",
            "kccr_0036\n",
            "kccr_0026\n",
            "kccr_0040\n",
            "kccr_0059\n",
            "kccr_0042\n",
            "kccr_0056\n",
            "kccr_0033\n",
            "kccr_0000\n",
            "kccr_0004\n",
            "kccr_0055\n",
            "kccr_0063\n",
            "kccr_0032\n",
            "kccr_0049\n",
            "kccr_0015\n",
            "onsu_0026\n",
            "onsu_0019\n",
            "onsu_0011\n",
            "onsu_0021\n",
            "onsu_0000\n",
            "onsu_0009\n",
            "onsu_0018\n",
            "onsu_0016\n",
            "onsu_0003\n",
            "onsu_0008\n",
            "onsu_0007\n",
            "onsu_0006\n",
            "onsu_0025\n",
            "onsu_0002\n",
            "onsu_0028\n",
            "onsu_0015\n",
            "onsu_0012\n",
            "onsu_0010\n",
            "onsu_0005\n",
            "onsu_0022\n",
            "onsu_0027\n",
            "onsu_0013\n",
            "onsu_0023\n",
            "onsu_0017\n",
            "onsu_0001\n",
            "onsu_0004\n",
            "onsu_0020\n",
            "onsu_0014\n",
            "vusu_0000\n",
            "vusu_0029\n",
            "vusu_0001\n",
            "vusu_0028\n",
            "vusu_0006\n",
            "vusu_0003\n",
            "vusu_0002\n",
            "vusu_0022\n",
            "vusu_0027\n",
            "vusu_0011\n",
            "vusu_0009\n",
            "vusu_0017\n",
            "vusu_0010\n",
            "vusu_0007\n",
            "vusu_0026\n",
            "vusu_0014\n",
            "vusu_0013\n",
            "vusu_0020\n",
            "vusu_0015\n",
            "vusu_0025\n",
            "vusu_0012\n",
            "vusu_0024\n",
            "vusu_0018\n",
            "vusu_0005\n",
            "vusu_0016\n",
            "vusu_0023\n",
            "vusu_0021\n",
            "vusu_0019\n",
            "vusu_0008\n",
            "kfgj_0020\n",
            "kfgj_0024\n",
            "kfgj_0003\n",
            "kfgj_0002\n",
            "kfgj_0029\n",
            "kfgj_0006\n",
            "kfgj_0030\n",
            "kfgj_0001\n",
            "kfgj_0025\n",
            "kfgj_0005\n",
            "kfgj_0012\n",
            "kfgj_0021\n",
            "kfgj_0013\n",
            "kfgj_0014\n",
            "kfgj_0017\n",
            "kfgj_0028\n",
            "kfgj_0016\n",
            "kfgj_0027\n",
            "kfgj_0023\n",
            "kfgj_0026\n",
            "kfgj_0010\n",
            "kfgj_0009\n",
            "kfgj_0019\n",
            "kfgj_0004\n",
            "kfgj_0015\n",
            "kfgj_0000\n",
            "kfgj_0018\n",
            "kfgj_0022\n",
            "kfgj_0007\n",
            "kfgj_0011\n",
            "inji_0006\n",
            "inji_0009\n",
            "inji_0018\n",
            "inji_0011\n",
            "inji_0016\n",
            "inji_0020\n",
            "inji_0010\n",
            "inji_0001\n",
            "inji_0021\n",
            "inji_0008\n",
            "inji_0014\n",
            "inji_0015\n",
            "inji_0005\n",
            "inji_0003\n",
            "inji_0000\n",
            "inji_0004\n",
            "inji_0002\n",
            "inji_0019\n",
            "inji_0012\n",
            "inji_0007\n",
            "inji_0017\n",
            "hsew_0006\n",
            "hsew_0002\n",
            "hsew_0001\n",
            "hsew_0005\n",
            "hsew_0004\n",
            "hsew_0003\n",
            "hsew_0000\n",
            "sdhp_0020\n",
            "sdhp_0019\n",
            "sdhp_0012\n",
            "sdhp_0025\n",
            "sdhp_0006\n",
            "sdhp_0016\n",
            "sdhp_0010\n",
            "sdhp_0030\n",
            "sdhp_0029\n",
            "sdhp_0003\n",
            "sdhp_0023\n",
            "sdhp_0017\n",
            "sdhp_0018\n",
            "sdhp_0021\n",
            "sdhp_0011\n",
            "sdhp_0008\n",
            "sdhp_0015\n",
            "sdhp_0026\n",
            "sdhp_0005\n",
            "sdhp_0009\n",
            "sdhp_0007\n",
            "sdhp_0000\n",
            "sdhp_0024\n",
            "sdhp_0028\n",
            "sdhp_0022\n",
            "sdhp_0014\n",
            "sdhp_0002\n",
            "sdhp_0027\n",
            "sdhp_0013\n",
            "sdhp_0001\n",
            "vstd_0010\n",
            "vstd_0012\n",
            "vstd_0025\n",
            "vstd_0007\n",
            "vstd_0002\n",
            "vstd_0016\n",
            "vstd_0009\n",
            "vstd_0028\n",
            "vstd_0000\n",
            "vstd_0029\n",
            "vstd_0014\n",
            "vstd_0008\n",
            "vstd_0005\n",
            "vstd_0022\n",
            "vstd_0001\n",
            "vstd_0018\n",
            "vstd_0030\n",
            "vstd_0017\n",
            "vstd_0027\n",
            "vstd_0006\n",
            "vstd_0021\n",
            "vstd_0019\n",
            "vstd_0003\n",
            "vstd_0013\n",
            "vstd_0011\n",
            "vstd_0026\n",
            "vstd_0023\n",
            "vstd_0024\n",
            "vstd_0015\n",
            "sdhp_0004\n",
            "vstd_0004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xo1DeCk9b8J"
      },
      "source": [
        "num_occurences_test = encoded_targets_test.groupby(['Nest','targets']).nunique()\n",
        "\n",
        "class_weights_test = num_occurences_test['key'].min()/num_occurences_test['key'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "RyWor_RniYcg",
        "outputId": "047f6f8e-6501-47c5-a401-6d745c21659b"
      },
      "source": [
        "num_occurences_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>indvi</th>\n",
              "      <th>key</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest</th>\n",
              "      <th>targets</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Nest10</th>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest11</th>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest2</th>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest3</th>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest4</th>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest5</th>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest6</th>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest7</th>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest8</th>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nest9</th>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                indvi  key\n",
              "Nest   targets            \n",
              "Nest10 0            1    7\n",
              "Nest11 1            2   61\n",
              "Nest2  2            3   86\n",
              "Nest3  3            2   84\n",
              "Nest4  4            1   32\n",
              "Nest5  5            1   39\n",
              "Nest6  6            2  107\n",
              "Nest7  7            2   57\n",
              "Nest8  8            1   30\n",
              "Nest9  9            1   21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EL9aQKH9k_X",
        "outputId": "06a87a00-0c71-4e1e-f290-7a38f7742b38"
      },
      "source": [
        "class_weights_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.1147541 , 0.08139535, 0.08333333, 0.21875   ,\n",
              "       0.17948718, 0.06542056, 0.12280702, 0.23333333, 0.33333333])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlS9HyJqC1Ks"
      },
      "source": [
        "kf = KFold(n_splits  = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oXOoERI6R6y"
      },
      "source": [
        "random_number_set = [\n",
        "# 3859,\n",
        "#  7857,\n",
        "#  7980,\n",
        "#  2999,\n",
        "#  3324,\n",
        " 1778,\n",
        " 329,\n",
        " 5689,\n",
        " 2746,\n",
        " 8964,\n",
        " 70,\n",
        " 4786,\n",
        " 2816,\n",
        " 2405,\n",
        " 2681,\n",
        " 5769,\n",
        " 9327,\n",
        " 7867,\n",
        " 4469,\n",
        " 4928,\n",
        " 5730,\n",
        " 858,\n",
        " 6775,\n",
        " 5487,\n",
        " 1464,\n",
        " 7365,\n",
        " 4313,\n",
        " 9324,\n",
        " 8958,\n",
        " 7663,\n",
        " 5362,\n",
        " 299,\n",
        " 4931,\n",
        " 4906,\n",
        " 5007,\n",
        " 5848,\n",
        " 5119,\n",
        " 7172,\n",
        " 6862,\n",
        " 3981,\n",
        " 8262,\n",
        " 5441,\n",
        " 4702,\n",
        " 4177,\n",
        " 2611,\n",
        " 6342,\n",
        " 9402,\n",
        " 5609,\n",
        " 3590,\n",
        " 5397,\n",
        " 7172,\n",
        " 6862,\n",
        " 3981,\n",
        " 8262,\n",
        " 5441,\n",
        " 4702,\n",
        " 4177,\n",
        " 2611,\n",
        " 6342,\n",
        " 9402,\n",
        " 5609,\n",
        " 3590,\n",
        " 5397];"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EptS9sO_41qw",
        "outputId": "2fc73cc9-afa1-46b6-f9ef-268839a04feb"
      },
      "source": [
        "random_number_set = [2020];\n",
        "for iter, current_random_number in enumerate(random_number_set):\n",
        "\n",
        "  encoded_targets, le = data_splitting_based_on_sample_size(Tutor_dataset)\n",
        "  encoded_targets = encoded_targets.sample(frac=1, random_state=current_random_number).reset_index(drop=True)\n",
        "  print(encoded_targets)\n",
        "  X_total = []; y_total = [];\n",
        "\n",
        "  for key in encoded_targets['key'].unique():\n",
        "    data, label = create_sequence_feature(syllable_df_Nest_Total, key, le, label_select='Nest')\n",
        "    X_total.append(data)\n",
        "    y_total.append(label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     targets indvi        key    Nest\n",
            "0          0  sjew  sjew_0009  Nest10\n",
            "1          1  cgby  cgby_0042  Nest11\n",
            "2          6  isab  isab_0011   Nest6\n",
            "3          2  nzen  nzen_0001   Nest2\n",
            "4          7  ixea  ixea_0016   Nest7\n",
            "..       ...   ...        ...     ...\n",
            "320        5  ttog  ttog_0002   Nest5\n",
            "321        5  ttog  ttog_0024   Nest5\n",
            "322        8  ihza  ihza_0014   Nest8\n",
            "323        5  ttog  ttog_0036   Nest5\n",
            "324        1  cgby  cgby_0012  Nest11\n",
            "\n",
            "[325 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJEyUKJUINS0"
      },
      "source": [
        "#  for iter, (x, y, l) in enumerate(train_ds):\n",
        "#    y = torch.tensor(y).long().resize_((1))\n",
        "#    print(x.shape, y.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wRE90k0f4sR"
      },
      "source": [
        "def dataset_shuffling(encoded_targets, syllable_df, encoder, current_random_number):\n",
        "  encoded_targets = encoded_targets.sample(frac=1, random_state=current_random_number).reset_index(drop=True)\n",
        "\n",
        "  X_total = []; y_total = [];\n",
        "\n",
        "  for key in encoded_targets['key'].unique():\n",
        "    data, label = create_sequence_feature(syllable_df, key, encoder, label_select='Nest')\n",
        "    X_total.append(data)\n",
        "    y_total.append(label)\n",
        "\n",
        "  train_ds = ReviewsDataset(X_total, y_total)\n",
        "\n",
        "  return train_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzqld5HGlkN5"
      },
      "source": [
        "encoded_targets, le = data_splitting_based_on_sample_size(Tutor_dataset) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "w-j0hckElraZ",
        "outputId": "60f69e1d-b317-49a6-9fbb-b8970b5a2745"
      },
      "source": [
        "encoded_targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>targets</th>\n",
              "      <th>indvi</th>\n",
              "      <th>key</th>\n",
              "      <th>Nest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>nzen</td>\n",
              "      <td>nzen_0000</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>nzen</td>\n",
              "      <td>nzen_0001</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>nzen</td>\n",
              "      <td>nzen_0002</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>nzen</td>\n",
              "      <td>nzen_0003</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>nzen</td>\n",
              "      <td>nzen_0004</td>\n",
              "      <td>Nest2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>1</td>\n",
              "      <td>cgby</td>\n",
              "      <td>cgby_0026</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>1</td>\n",
              "      <td>cgby</td>\n",
              "      <td>cgby_0048</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>1</td>\n",
              "      <td>cgby</td>\n",
              "      <td>cgby_0022</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>1</td>\n",
              "      <td>cgby</td>\n",
              "      <td>cgby_0012</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>1</td>\n",
              "      <td>cgby</td>\n",
              "      <td>cgby_0032</td>\n",
              "      <td>Nest11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>325 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     targets indvi        key    Nest\n",
              "0          2  nzen  nzen_0000   Nest2\n",
              "1          2  nzen  nzen_0001   Nest2\n",
              "2          2  nzen  nzen_0002   Nest2\n",
              "3          2  nzen  nzen_0003   Nest2\n",
              "4          2  nzen  nzen_0004   Nest2\n",
              "..       ...   ...        ...     ...\n",
              "320        1  cgby  cgby_0026  Nest11\n",
              "321        1  cgby  cgby_0048  Nest11\n",
              "322        1  cgby  cgby_0022  Nest11\n",
              "323        1  cgby  cgby_0012  Nest11\n",
              "324        1  cgby  cgby_0032  Nest11\n",
              "\n",
              "[325 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL5OxbnRlwWC",
        "outputId": "6e4571f3-931e-4c18-caac-21f4873ca066"
      },
      "source": [
        "current_random_number"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2020"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "X597tgvGGhVK",
        "outputId": "f072dbc9-a503-4383-d4ad-11fdc7b08a86"
      },
      "source": [
        "# Final Architecture Set and random seed change\n",
        "# random_number_set_single = [2021];\n",
        "\n",
        "epochs = 20; lr = 0.001;\n",
        "\n",
        "df_loss_accuracy_crossval = pd.DataFrame(columns=['Train Loss', 'Train Accuracy', 'Val Loss', 'Val Accuracy'])\n",
        "overall_df_loss_accuracy_crossval = pd.DataFrame(columns=['Train Accuracy', 'Val Accuracy'])\n",
        "Total_valid_loss = []\n",
        "Total_test_loss = []\n",
        "\n",
        "def validation_metrics (model, valid_dl, class_weights):\n",
        "  model.eval()\n",
        "  test_correct = 0\n",
        "  test_total = 0\n",
        "  test_sum_loss = 0.0\n",
        "  test_sum_rmse = 0.0\n",
        "  actual_label = []\n",
        "  predicted_label = []\n",
        "  for x, y, l in valid_dl:\n",
        "      x = x.float()\n",
        "      x.resize_((1,x.shape[0],x.shape[1]))\n",
        "      #indv_class_weight = class_weights[y]\n",
        "      indv_class_weight = 1\n",
        "      y = torch.tensor(y).long().resize_((1))\n",
        "      # y_hat = model(x, l)\n",
        "      y_hat = model(x)\n",
        "      loss = F.cross_entropy(y_hat, y)\n",
        "      pred = torch.max(y_hat, 1)[1]\n",
        "      # print(y, pred)\n",
        "      test_correct += (pred == y).float().sum()\n",
        "      test_total += y.shape[0]\n",
        "      test_sum_loss += loss.item()*indv_class_weight*y.shape[0]\n",
        "      test_sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
        "      actual_label.extend(y.numpy())\n",
        "      predicted_label.extend(pred.numpy())\n",
        "  conf_mat = confusion_matrix(actual_label, predicted_label)\n",
        "  # print(conf_mat)\n",
        "  return test_sum_loss/test_total, test_correct/test_total, test_sum_rmse/test_total, conf_mat\n",
        "\n",
        "for iter, current_random_number in enumerate(random_number_set[:10]):\n",
        "\n",
        "  print('Random Number', current_random_number)\n",
        "\n",
        "  encoded_targets, le = data_splitting_based_on_sample_size(Tutor_dataset)   ### CHANGE HERE FOR TUTOR OR PUPIL DATASET FOR TRAINING\n",
        "  encoded_targets = encoded_targets.sample(frac=1, random_state=current_random_number).reset_index(drop=True)\n",
        "\n",
        "  ### SHUFFLING OVER \n",
        "  X_total = []; y_total = [];\n",
        "\n",
        "  for key in encoded_targets['key'].unique():\n",
        "    data, label = create_sequence_feature_randomize(Tutor_dataset, key, le, label_select='Nest', random_state=current_random_number) ### CHANGE HERE FOR TUTOR OR PUPIL DATASET FOR TRAINING\n",
        "    X_total.append(data)\n",
        "    y_total.append(label)\n",
        "    # data_scramb, label_scramb = create_sequence_feature_randomize(Tutor_dataset, key, le, label_select='Nest', random_state=current_random_number) ### CHANGE HERE FOR TUTOR OR PUPIL DATASET FOR TRAINING\n",
        "    # X_total_scramble.append(data_scramb)\n",
        "    # y_total_scramble.append(label_scramb)\n",
        "\n",
        "  for _fold, (train_index, val_index) in enumerate(kf.split(range(len(X_total)))):\n",
        "    print(\"Fold \", _fold)\n",
        "    best_model_test_loss = 0\n",
        "    best_model_test_acc = 0\n",
        "    X_train_subset = []; y_train_subset = [];\n",
        "    X_val_subset = []; y_val_subset = [];\n",
        "\n",
        "    for indx in train_index:\n",
        "      X_train_subset.append(X_total[indx])\n",
        "      y_train_subset.append(y_total[indx])\n",
        "    train_ds = ReviewsDataset(X_train_subset, y_train_subset)\n",
        "\n",
        "    for indx in val_index:\n",
        "      X_val_subset.append(X_total[indx])    ## Validation set from the scrambled data\n",
        "      y_val_subset.append(y_total[indx])\n",
        "    valid_ds = ReviewsDataset(X_val_subset, y_val_subset)\n",
        "\n",
        "    model =  LSTM_fixed_len(1024, 512, len(le.classes_), 1)   ## SET MODEL ARCHITECTURE HERE\n",
        "    print(model.eval())\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "    model.train()\n",
        "\n",
        "    epoch_best_loss = 0\n",
        "    epoch_best_acc = 0\n",
        "    epoch_best_val_loss = 0\n",
        "    epoch_best_val_acc = 0\n",
        "    overall_best_model_train_acc = 0\n",
        "\n",
        "    overall_best_model_stats = []\n",
        "    valid_loss_iter = []\n",
        "    test_loss_iter = []\n",
        "\n",
        "    for i in range(epochs):\n",
        "      model.train()\n",
        "      epoch_loss = 0\n",
        "      epoch_acc = 0    \n",
        "      train_correct = 0\n",
        "      train_total = 0\n",
        "      loss = 0\n",
        "      np.random.shuffle(train_index)\n",
        "      X_train_subset = []; y_train_subset = [];\n",
        "\n",
        "      for indx in train_index:\n",
        "        X_train_subset.append(X_total[indx])\n",
        "        y_train_subset.append(y_total[indx])\n",
        "      train_ds = ReviewsDataset(X_train_subset, y_train_subset)\n",
        "      # train_ds = dataset_shuffling(encoded_targets, Tutor_dataset, le, random_number_set[i])   ## CHECK HERE IF ALTERING TRAINING SET\n",
        "      for iter, (x, y, l) in enumerate(train_ds): \n",
        "          x = x.float()\n",
        "          x.resize_((1,x.shape[0],x.shape[1]))\n",
        "          indv_class_weight = class_weights[y]\n",
        "          # indv_class_weight = 1\n",
        "          y = torch.tensor(y).long().resize_((1))\n",
        "          # y_pred = model(x, l)\n",
        "          y_pred = model(x)\n",
        "          optimizer.zero_grad()\n",
        "          loss += F.cross_entropy(y_pred, y)*indv_class_weight\n",
        "          # print(loss, indv_class_weight, loss*indv_class_weight)\n",
        "          # loss.backward()\n",
        "          # optimizer.step()\n",
        "          # epoch_loss += loss.item()*y.shape[0]\n",
        "          train_total += y.shape[0]\n",
        "          pred_train = torch.max(y_pred, 1)[1]\n",
        "          train_correct += (pred_train == y).float().sum()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_loss =  loss.item()*y.shape[0]      \n",
        "      epoch_loss /= (iter + 1)\n",
        "      epoch_acc = train_correct/train_total    \n",
        "\n",
        "      val_epoch_loss, val_accuracy, val_rmse, val_conf_mat = validation_metrics(model, valid_ds, class_weights)\n",
        "      valid_loss_iter.append(val_epoch_loss)\n",
        "\n",
        "      # test_epoch_loss, test_accuracy, test_rmse, test_conf_mat = validation_metrics(model, test_ds, class_weights)\n",
        "      # test_loss_iter.append(test_epoch_loss)\n",
        "      \n",
        "      # print(\"Epoch %d, train loss %.3f, train accuracy %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (i, epoch_loss, epoch_acc, val_loss, val_accuracy, val_rmse))\n",
        "      print(\"Epoch %d, train loss %.3f, train accuracy %.3f, val loss %.3f, val accuracy %.3f\" % (i, epoch_loss, epoch_acc, val_epoch_loss, val_accuracy))\n",
        "\n",
        "      # if epoch_best_val_loss < val_epoch_loss:\n",
        "      #   epoch_best_val_loss = val_epoch_loss\n",
        "\n",
        "      # if epoch_best_loss < epoch_loss:\n",
        "      #   epoch_best_loss = epoch_loss\n",
        "\n",
        "      if epoch_best_acc <= epoch_acc:\n",
        "        if epoch_best_val_acc <= val_accuracy:\n",
        "          epoch_best_val_loss = val_epoch_loss\n",
        "          epoch_best_loss = epoch_loss\n",
        "          epoch_best_acc = epoch_acc\n",
        "          epoch_best_val_acc = val_accuracy\n",
        "          # test_accuracy_temp = test_accuracy\n",
        "          # test_epoch_loss_temp = test_epoch_loss\n",
        "          now = datetime.now() \n",
        "          dt_string = now.strftime(\"%d_%m_%Y_%H_%M\")\n",
        "          best_model = model\n",
        "          print('Saving overall best train val model')\n",
        "          overall_best_model_stats = [epoch_best_acc.numpy(), epoch_best_val_acc.numpy()]\n",
        "          # overall_best_test_conf_matrix = pd.DataFrame(val_conf_mat, index=[class_label+'_True' for class_label in list(le.classes_)], columns=[class_label+'_Pred' for class_label in list(le.classes_)])        \n",
        "          # if best_model_test_acc <= test_accuracy:\n",
        "          #   best_model_test_acc = test_accuracy\n",
        "          #   # best_model_test_loss = test_epoch_loss\n",
        "          #   overall_best_model = model\n",
        "          #   overall_best_model_train_acc = epoch_acc\n",
        "          #   overall_best_model_stats = [ epoch_best_acc.numpy(), epoch_best_val_acc.numpy(), best_model_test_acc.numpy()]\n",
        "          #   overall_best_test_conf_matrix = pd.DataFrame(test_conf_mat, index=[class_label+'_True' for class_label in list(le.classes_)], columns=[class_label+'_Pred' for class_label in list(le.classes_)])\n",
        "          #   print('Saving overall best test model')\n",
        "          # elif overall_best_model_train_acc < epoch_acc:\n",
        "          #   best_model_test_acc = test_accuracy\n",
        "          #   # best_model_test_loss = test_epoch_loss\n",
        "          #   overall_best_model = model\n",
        "          #   overall_best_model_train_acc = epoch_acc\n",
        "          #   overall_best_model_stats = [ epoch_best_acc.numpy(), epoch_best_val_acc.numpy(), best_model_test_acc.numpy()]\n",
        "          #   overall_best_test_conf_matrix = pd.DataFrame(test_conf_mat, index=[class_label+'_True' for class_label in list(le.classes_)], columns=[class_label+'_Pred' for class_label in list(le.classes_)])\n",
        "          #   print('Replacing overall best test model')\n",
        "\n",
        "    Total_valid_loss.append(valid_loss_iter)\n",
        "    # Total_test_loss.append(test_loss_iter)\n",
        "\n",
        "    df_loss_accuracy_crossval = df_loss_accuracy_crossval.append({'Train Loss': epoch_best_loss , 'Train Accuracy': epoch_best_acc.numpy(),  'Val Loss':  epoch_best_val_loss, \n",
        "                                              'Val Accuracy': epoch_best_val_acc.numpy()}, ignore_index=True)\n",
        "\n",
        "    overall_df_loss_accuracy_crossval = overall_df_loss_accuracy_crossval.append(pd.Series(overall_best_model_stats, index=overall_df_loss_accuracy_crossval.columns.values), ignore_index=True)\n",
        "    \n",
        "    # overall_best_test_conf_matrix.to_csv('/content/gdrive/My Drive/ZFDataset/SavedModels/FullDataset/LSTM/'+'Conf_Mat_Test_Random_'+str(current_random_number)+'.csv')\n",
        "    overall_df_loss_accuracy_crossval.to_csv('/content/gdrive/My Drive/ZFDataset/SavedModels/FullDataset/LSTM/'+'Accuracy_Table_Test_Random_'+str(current_random_number)+'.csv')\n",
        "\n",
        "    torch.save(best_model, '/content/gdrive/My Drive/ZFDataset/SavedModels/FullDataset/LSTM/Unidirectional/'+'Fold'+str(_fold)+'_'+dt_string+'_Train_'+str(np.round(epoch_best_acc.numpy(),4))+\n",
        "                                                                                        '_Val_'+str(np.round(epoch_best_val_acc.numpy(),4)))\n",
        "    \n",
        "    # torch.save(overall_best_model, '/content/gdrive/My Drive/ZFDataset/SavedModels/FullDataset/LSTM/Unidirectional/'+'Overall_Fold'+str(_fold)+'_'+dt_string+'_Train_'+str(np.round(epoch_best_acc.numpy(),4))+\n",
        "    #                                                                                     '_Val_'+str(np.round(epoch_best_val_acc.numpy(),4))+'_Test_'+str(np.round(best_model_test_acc.numpy(),4)))\n",
        "    \n",
        "    del model\n",
        "    # return (sum_loss/((_fold+1)*total)), (correct_train/total), (sum_val_loss/(_fold+1)), (sum_val_acc/(_fold+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Number 3859\n",
            "Fold  0\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.210, train accuracy 0.099, val loss 2.246, val accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.105, train accuracy 0.346, val loss 1.994, val accuracy 0.606\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.977, train accuracy 0.784, val loss 1.654, val accuracy 0.697\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.822, train accuracy 0.818, val loss 1.296, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.626, train accuracy 0.918, val loss 0.976, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.461, train accuracy 0.914, val loss 0.890, val accuracy 0.636\n",
            "Epoch 6, train loss 0.414, train accuracy 0.825, val loss 0.524, val accuracy 0.909\n",
            "Epoch 7, train loss 0.292, train accuracy 0.952, val loss 0.433, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.241, train accuracy 0.949, val loss 0.238, val accuracy 1.000\n",
            "Epoch 9, train loss 0.157, train accuracy 0.966, val loss 0.203, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.131, train accuracy 0.976, val loss 0.135, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.100, train accuracy 0.983, val loss 0.098, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.074, train accuracy 0.986, val loss 0.076, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.056, train accuracy 0.986, val loss 0.059, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.047, train accuracy 0.986, val loss 0.059, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.046, train accuracy 0.986, val loss 0.040, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.037, train accuracy 0.993, val loss 0.050, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.033, train accuracy 0.997, val loss 0.035, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.026, train accuracy 0.990, val loss 0.035, val accuracy 1.000\n",
            "Epoch 19, train loss 0.024, train accuracy 0.993, val loss 0.024, val accuracy 1.000\n",
            "Fold  1\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.203, train accuracy 0.147, val loss 2.152, val accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.094, train accuracy 0.349, val loss 1.922, val accuracy 0.606\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.964, train accuracy 0.777, val loss 1.591, val accuracy 0.727\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.791, train accuracy 0.887, val loss 1.239, val accuracy 0.758\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.598, train accuracy 0.870, val loss 0.949, val accuracy 0.848\n",
            "Epoch 5, train loss 0.451, train accuracy 0.925, val loss 0.737, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.386, train accuracy 0.914, val loss 0.651, val accuracy 0.758\n",
            "Epoch 7, train loss 0.317, train accuracy 0.890, val loss 0.397, val accuracy 0.970\n",
            "Epoch 8, train loss 0.198, train accuracy 0.955, val loss 0.303, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.153, train accuracy 0.969, val loss 0.309, val accuracy 0.939\n",
            "Epoch 10, train loss 0.142, train accuracy 0.959, val loss 0.211, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.096, train accuracy 0.983, val loss 0.189, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.073, train accuracy 0.990, val loss 0.221, val accuracy 0.939\n",
            "Epoch 13, train loss 0.066, train accuracy 0.979, val loss 0.191, val accuracy 0.970\n",
            "Epoch 14, train loss 0.044, train accuracy 0.993, val loss 0.191, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.039, train accuracy 0.993, val loss 0.133, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.029, train accuracy 0.997, val loss 0.119, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.021, train accuracy 0.997, val loss 0.116, val accuracy 0.939\n",
            "Epoch 18, train loss 0.019, train accuracy 0.997, val loss 0.086, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.015, train accuracy 0.997, val loss 0.080, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Fold  2\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.203, train accuracy 0.096, val loss 2.218, val accuracy 0.273\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.095, train accuracy 0.384, val loss 1.909, val accuracy 0.727\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.968, train accuracy 0.747, val loss 1.592, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.783, train accuracy 0.863, val loss 1.204, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.578, train accuracy 0.942, val loss 0.927, val accuracy 0.909\n",
            "Epoch 5, train loss 0.439, train accuracy 0.949, val loss 0.950, val accuracy 0.727\n",
            "Epoch 6, train loss 0.466, train accuracy 0.750, val loss 0.682, val accuracy 0.818\n",
            "Epoch 7, train loss 0.361, train accuracy 0.818, val loss 0.603, val accuracy 0.879\n",
            "Epoch 8, train loss 0.287, train accuracy 0.880, val loss 0.437, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.192, train accuracy 0.979, val loss 0.340, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.154, train accuracy 0.973, val loss 0.279, val accuracy 0.970\n",
            "Epoch 11, train loss 0.121, train accuracy 0.976, val loss 0.240, val accuracy 0.970\n",
            "Epoch 12, train loss 0.097, train accuracy 0.983, val loss 0.198, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.075, train accuracy 0.979, val loss 0.167, val accuracy 0.970\n",
            "Epoch 14, train loss 0.059, train accuracy 0.993, val loss 0.149, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.044, train accuracy 0.993, val loss 0.159, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.036, train accuracy 0.997, val loss 0.144, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.029, train accuracy 0.997, val loss 0.126, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.025, train accuracy 0.997, val loss 0.114, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.020, train accuracy 0.997, val loss 0.110, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Fold  3\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.220, train accuracy 0.055, val loss 2.137, val accuracy 0.364\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.110, train accuracy 0.394, val loss 1.818, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.982, train accuracy 0.842, val loss 1.458, val accuracy 0.788\n",
            "Epoch 3, train loss 0.804, train accuracy 0.935, val loss 1.139, val accuracy 0.818\n",
            "Epoch 4, train loss 0.612, train accuracy 0.901, val loss 0.809, val accuracy 0.848\n",
            "Epoch 5, train loss 0.462, train accuracy 0.921, val loss 0.766, val accuracy 0.788\n",
            "Epoch 6, train loss 0.424, train accuracy 0.812, val loss 0.711, val accuracy 0.818\n",
            "Epoch 7, train loss 0.368, train accuracy 0.877, val loss 0.534, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.230, train accuracy 0.945, val loss 0.459, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.192, train accuracy 0.969, val loss 0.363, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.139, train accuracy 0.973, val loss 0.302, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.119, train accuracy 0.973, val loss 0.238, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.093, train accuracy 0.976, val loss 0.185, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.073, train accuracy 0.979, val loss 0.158, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.060, train accuracy 0.983, val loss 0.139, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.049, train accuracy 0.986, val loss 0.136, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.039, train accuracy 0.990, val loss 0.103, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.031, train accuracy 0.997, val loss 0.094, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.035, train accuracy 0.990, val loss 0.057, val accuracy 1.000\n",
            "Epoch 19, train loss 0.025, train accuracy 0.993, val loss 0.084, val accuracy 1.000\n",
            "Fold  4\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.213, train accuracy 0.086, val loss 2.131, val accuracy 0.273\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.102, train accuracy 0.397, val loss 1.840, val accuracy 0.697\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.969, train accuracy 0.829, val loss 1.513, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.787, train accuracy 0.938, val loss 1.139, val accuracy 0.818\n",
            "Epoch 4, train loss 0.595, train accuracy 0.890, val loss 0.836, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.442, train accuracy 0.938, val loss 0.577, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.283, train accuracy 0.976, val loss 0.424, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.210, train accuracy 0.966, val loss 0.415, val accuracy 0.939\n",
            "Epoch 8, train loss 0.175, train accuracy 0.959, val loss 0.504, val accuracy 0.818\n",
            "Epoch 9, train loss 0.240, train accuracy 0.839, val loss 0.254, val accuracy 0.970\n",
            "Epoch 10, train loss 0.120, train accuracy 0.976, val loss 0.312, val accuracy 0.879\n",
            "Epoch 11, train loss 0.152, train accuracy 0.949, val loss 0.241, val accuracy 0.939\n",
            "Epoch 12, train loss 0.099, train accuracy 0.976, val loss 0.264, val accuracy 0.909\n",
            "Epoch 13, train loss 0.109, train accuracy 0.955, val loss 0.124, val accuracy 0.970\n",
            "Epoch 14, train loss 0.068, train accuracy 0.986, val loss 0.162, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.072, train accuracy 0.979, val loss 0.166, val accuracy 0.970\n",
            "Epoch 16, train loss 0.056, train accuracy 0.973, val loss 0.165, val accuracy 0.939\n",
            "Epoch 17, train loss 0.047, train accuracy 0.986, val loss 0.102, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.035, train accuracy 0.990, val loss 0.059, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.028, train accuracy 0.997, val loss 0.046, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  5\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.207, train accuracy 0.126, val loss 2.160, val accuracy 0.062\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.097, train accuracy 0.195, val loss 1.874, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.964, train accuracy 0.843, val loss 1.521, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.779, train accuracy 0.932, val loss 1.112, val accuracy 0.875\n",
            "Epoch 4, train loss 0.593, train accuracy 0.901, val loss 0.936, val accuracy 0.906\n",
            "Epoch 5, train loss 0.464, train accuracy 0.942, val loss 0.695, val accuracy 0.844\n",
            "Epoch 6, train loss 0.341, train accuracy 0.877, val loss 0.484, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.297, train accuracy 0.915, val loss 0.328, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.187, train accuracy 0.973, val loss 0.324, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.182, train accuracy 0.942, val loss 0.252, val accuracy 1.000\n",
            "Epoch 10, train loss 0.155, train accuracy 0.956, val loss 0.366, val accuracy 0.875\n",
            "Epoch 11, train loss 0.155, train accuracy 0.939, val loss 0.201, val accuracy 0.938\n",
            "Epoch 12, train loss 0.105, train accuracy 0.986, val loss 0.183, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.094, train accuracy 0.980, val loss 0.221, val accuracy 0.969\n",
            "Epoch 14, train loss 0.078, train accuracy 0.980, val loss 0.230, val accuracy 0.969\n",
            "Epoch 15, train loss 0.058, train accuracy 0.990, val loss 0.201, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.048, train accuracy 0.990, val loss 0.130, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.037, train accuracy 0.990, val loss 0.095, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.031, train accuracy 0.990, val loss 0.110, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.026, train accuracy 0.997, val loss 0.098, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Fold  6\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.217, train accuracy 0.041, val loss 2.221, val accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.102, train accuracy 0.430, val loss 1.881, val accuracy 0.719\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.975, train accuracy 0.788, val loss 1.561, val accuracy 0.750\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.808, train accuracy 0.884, val loss 1.278, val accuracy 0.719\n",
            "Epoch 4, train loss 0.654, train accuracy 0.860, val loss 1.084, val accuracy 0.688\n",
            "Epoch 5, train loss 0.545, train accuracy 0.799, val loss 0.593, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.353, train accuracy 0.966, val loss 0.405, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.268, train accuracy 0.962, val loss 0.389, val accuracy 0.938\n",
            "Epoch 8, train loss 0.195, train accuracy 0.966, val loss 0.268, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.183, train accuracy 0.956, val loss 0.141, val accuracy 1.000\n",
            "Epoch 10, train loss 0.126, train accuracy 0.966, val loss 0.170, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.096, train accuracy 0.983, val loss 0.115, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.078, train accuracy 0.973, val loss 0.141, val accuracy 0.938\n",
            "Epoch 13, train loss 0.064, train accuracy 0.983, val loss 0.061, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.047, train accuracy 0.990, val loss 0.057, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.043, train accuracy 0.986, val loss 0.081, val accuracy 0.969\n",
            "Epoch 16, train loss 0.033, train accuracy 0.993, val loss 0.058, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.025, train accuracy 0.997, val loss 0.028, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.022, train accuracy 0.993, val loss 0.023, val accuracy 1.000\n",
            "Epoch 19, train loss 0.017, train accuracy 0.997, val loss 0.026, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  7\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.216, train accuracy 0.048, val loss 2.206, val accuracy 0.156\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.116, train accuracy 0.321, val loss 1.918, val accuracy 0.625\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.985, train accuracy 0.686, val loss 1.634, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.835, train accuracy 0.884, val loss 1.284, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.656, train accuracy 0.925, val loss 0.974, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.492, train accuracy 0.952, val loss 0.756, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.361, train accuracy 0.949, val loss 0.547, val accuracy 0.969\n",
            "Epoch 7, train loss 0.308, train accuracy 0.962, val loss 0.576, val accuracy 0.875\n",
            "Epoch 8, train loss 0.229, train accuracy 0.928, val loss 0.397, val accuracy 0.969\n",
            "Epoch 9, train loss 0.189, train accuracy 0.952, val loss 0.254, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.124, train accuracy 0.973, val loss 0.284, val accuracy 0.938\n",
            "Epoch 11, train loss 0.126, train accuracy 0.966, val loss 0.188, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.087, train accuracy 0.973, val loss 0.152, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.087, train accuracy 0.966, val loss 0.138, val accuracy 0.969\n",
            "Epoch 14, train loss 0.063, train accuracy 0.980, val loss 0.224, val accuracy 0.938\n",
            "Epoch 15, train loss 0.063, train accuracy 0.990, val loss 0.191, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.058, train accuracy 0.980, val loss 0.169, val accuracy 0.969\n",
            "Epoch 17, train loss 0.050, train accuracy 0.983, val loss 0.072, val accuracy 1.000\n",
            "Epoch 18, train loss 0.041, train accuracy 0.986, val loss 0.088, val accuracy 0.969\n",
            "Epoch 19, train loss 0.030, train accuracy 0.990, val loss 0.134, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Fold  8\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.209, train accuracy 0.082, val loss 2.206, val accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.099, train accuracy 0.461, val loss 1.824, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.968, train accuracy 0.860, val loss 1.432, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.797, train accuracy 0.925, val loss 1.045, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.598, train accuracy 0.962, val loss 0.678, val accuracy 0.906\n",
            "Epoch 5, train loss 0.414, train accuracy 0.918, val loss 0.536, val accuracy 1.000\n",
            "Epoch 6, train loss 0.365, train accuracy 0.894, val loss 0.509, val accuracy 0.906\n",
            "Epoch 7, train loss 0.265, train accuracy 0.939, val loss 0.409, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.233, train accuracy 0.918, val loss 0.267, val accuracy 1.000\n",
            "Epoch 9, train loss 0.167, train accuracy 0.962, val loss 0.141, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.105, train accuracy 0.969, val loss 0.167, val accuracy 0.969\n",
            "Epoch 11, train loss 0.113, train accuracy 0.952, val loss 0.159, val accuracy 0.969\n",
            "Epoch 12, train loss 0.088, train accuracy 0.973, val loss 0.085, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.068, train accuracy 0.983, val loss 0.056, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.054, train accuracy 0.986, val loss 0.067, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.054, train accuracy 0.990, val loss 0.035, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.035, train accuracy 0.990, val loss 0.057, val accuracy 0.969\n",
            "Epoch 17, train loss 0.037, train accuracy 0.986, val loss 0.085, val accuracy 0.969\n",
            "Epoch 18, train loss 0.051, train accuracy 0.973, val loss 0.109, val accuracy 0.938\n",
            "Epoch 19, train loss 0.035, train accuracy 0.993, val loss 0.104, val accuracy 0.969\n",
            "Fold  9\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.197, train accuracy 0.089, val loss 2.195, val accuracy 0.156\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.082, train accuracy 0.259, val loss 1.896, val accuracy 0.750\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.941, train accuracy 0.877, val loss 1.586, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.758, train accuracy 0.925, val loss 1.334, val accuracy 0.719\n",
            "Epoch 4, train loss 0.575, train accuracy 0.925, val loss 1.162, val accuracy 0.656\n",
            "Epoch 5, train loss 0.490, train accuracy 0.778, val loss 0.852, val accuracy 0.875\n",
            "Epoch 6, train loss 0.303, train accuracy 0.952, val loss 0.845, val accuracy 0.750\n",
            "Epoch 7, train loss 0.306, train accuracy 0.887, val loss 0.678, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.232, train accuracy 0.935, val loss 0.593, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.173, train accuracy 0.966, val loss 0.559, val accuracy 0.906\n",
            "Epoch 10, train loss 0.148, train accuracy 0.959, val loss 0.425, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.099, train accuracy 0.973, val loss 0.449, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.088, train accuracy 0.986, val loss 0.374, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.060, train accuracy 0.993, val loss 0.340, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.046, train accuracy 0.983, val loss 0.306, val accuracy 0.938\n",
            "Epoch 15, train loss 0.037, train accuracy 0.993, val loss 0.303, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.029, train accuracy 0.993, val loss 0.295, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.025, train accuracy 1.000, val loss 0.292, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.021, train accuracy 1.000, val loss 0.281, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.017, train accuracy 1.000, val loss 0.268, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Random Number 7857\n",
            "Fold  0\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.218, train accuracy 0.065, val loss 2.178, val accuracy 0.061\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.122, train accuracy 0.137, val loss 1.856, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.996, train accuracy 0.928, val loss 1.460, val accuracy 0.879\n",
            "Epoch 3, train loss 0.834, train accuracy 0.870, val loss 1.049, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.616, train accuracy 0.942, val loss 0.750, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.445, train accuracy 0.969, val loss 0.714, val accuracy 0.909\n",
            "Epoch 6, train loss 0.383, train accuracy 0.908, val loss 0.567, val accuracy 0.848\n",
            "Epoch 7, train loss 0.391, train accuracy 0.808, val loss 0.326, val accuracy 0.970\n",
            "Epoch 8, train loss 0.207, train accuracy 0.952, val loss 0.404, val accuracy 0.909\n",
            "Epoch 9, train loss 0.187, train accuracy 0.952, val loss 0.329, val accuracy 0.939\n",
            "Epoch 10, train loss 0.140, train accuracy 0.976, val loss 0.236, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.112, train accuracy 0.986, val loss 0.191, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.094, train accuracy 0.976, val loss 0.186, val accuracy 0.939\n",
            "Epoch 13, train loss 0.068, train accuracy 0.983, val loss 0.184, val accuracy 0.939\n",
            "Epoch 14, train loss 0.052, train accuracy 0.990, val loss 0.172, val accuracy 0.939\n",
            "Epoch 15, train loss 0.039, train accuracy 0.990, val loss 0.164, val accuracy 0.939\n",
            "Epoch 16, train loss 0.035, train accuracy 0.986, val loss 0.150, val accuracy 0.939\n",
            "Epoch 17, train loss 0.032, train accuracy 0.993, val loss 0.168, val accuracy 0.939\n",
            "Epoch 18, train loss 0.022, train accuracy 0.993, val loss 0.187, val accuracy 0.939\n",
            "Epoch 19, train loss 0.021, train accuracy 0.990, val loss 0.183, val accuracy 0.939\n",
            "Fold  1\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.205, train accuracy 0.113, val loss 2.231, val accuracy 0.182\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.106, train accuracy 0.387, val loss 1.942, val accuracy 0.697\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.975, train accuracy 0.774, val loss 1.607, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.814, train accuracy 0.904, val loss 1.244, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.614, train accuracy 0.932, val loss 1.022, val accuracy 0.848\n",
            "Epoch 5, train loss 0.494, train accuracy 0.911, val loss 0.638, val accuracy 0.909\n",
            "Epoch 6, train loss 0.317, train accuracy 0.952, val loss 0.580, val accuracy 0.818\n",
            "Epoch 7, train loss 0.274, train accuracy 0.918, val loss 0.571, val accuracy 0.818\n",
            "Epoch 8, train loss 0.269, train accuracy 0.894, val loss 0.459, val accuracy 0.909\n",
            "Epoch 9, train loss 0.157, train accuracy 0.962, val loss 0.410, val accuracy 0.909\n",
            "Epoch 10, train loss 0.142, train accuracy 0.966, val loss 0.260, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.099, train accuracy 0.979, val loss 0.230, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.075, train accuracy 0.990, val loss 0.248, val accuracy 0.939\n",
            "Epoch 13, train loss 0.058, train accuracy 0.990, val loss 0.279, val accuracy 0.939\n",
            "Epoch 14, train loss 0.046, train accuracy 0.986, val loss 0.198, val accuracy 0.939\n",
            "Epoch 15, train loss 0.035, train accuracy 0.997, val loss 0.173, val accuracy 0.939\n",
            "Epoch 16, train loss 0.040, train accuracy 0.979, val loss 0.158, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.028, train accuracy 0.993, val loss 0.145, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.027, train accuracy 0.997, val loss 0.132, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.020, train accuracy 0.997, val loss 0.122, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Fold  2\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.206, train accuracy 0.106, val loss 2.172, val accuracy 0.182\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.093, train accuracy 0.349, val loss 1.825, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.962, train accuracy 0.829, val loss 1.492, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.774, train accuracy 0.911, val loss 1.249, val accuracy 0.818\n",
            "Epoch 4, train loss 0.644, train accuracy 0.836, val loss 0.904, val accuracy 0.818\n",
            "Epoch 5, train loss 0.506, train accuracy 0.884, val loss 0.652, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.377, train accuracy 0.945, val loss 0.466, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.295, train accuracy 0.942, val loss 0.362, val accuracy 1.000\n",
            "Epoch 8, train loss 0.219, train accuracy 0.966, val loss 0.282, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.148, train accuracy 0.976, val loss 0.152, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.113, train accuracy 0.979, val loss 0.137, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.077, train accuracy 0.986, val loss 0.101, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.063, train accuracy 0.983, val loss 0.084, val accuracy 1.000\n",
            "Epoch 13, train loss 0.055, train accuracy 0.986, val loss 0.045, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.034, train accuracy 0.993, val loss 0.045, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.032, train accuracy 0.993, val loss 0.057, val accuracy 0.970\n",
            "Epoch 16, train loss 0.025, train accuracy 1.000, val loss 0.039, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.022, train accuracy 1.000, val loss 0.020, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.014, train accuracy 1.000, val loss 0.012, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  3\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.210, train accuracy 0.034, val loss 2.238, val accuracy 0.182\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.115, train accuracy 0.199, val loss 1.943, val accuracy 0.545\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.984, train accuracy 0.702, val loss 1.612, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.824, train accuracy 0.894, val loss 1.221, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.617, train accuracy 0.921, val loss 0.899, val accuracy 0.818\n",
            "Epoch 5, train loss 0.433, train accuracy 0.942, val loss 0.786, val accuracy 0.879\n",
            "Epoch 6, train loss 0.360, train accuracy 0.932, val loss 0.602, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.256, train accuracy 0.938, val loss 0.409, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.184, train accuracy 0.969, val loss 0.449, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.171, train accuracy 0.938, val loss 0.304, val accuracy 0.970\n",
            "Epoch 10, train loss 0.119, train accuracy 0.962, val loss 0.268, val accuracy 0.970\n",
            "Epoch 11, train loss 0.084, train accuracy 0.979, val loss 0.258, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.057, train accuracy 0.983, val loss 0.313, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.062, train accuracy 0.976, val loss 0.288, val accuracy 0.939\n",
            "Epoch 14, train loss 0.068, train accuracy 0.969, val loss 0.211, val accuracy 0.970\n",
            "Epoch 15, train loss 0.032, train accuracy 0.990, val loss 0.310, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.073, train accuracy 0.952, val loss 0.252, val accuracy 0.939\n",
            "Epoch 17, train loss 0.029, train accuracy 0.990, val loss 0.383, val accuracy 0.909\n",
            "Epoch 18, train loss 0.037, train accuracy 0.986, val loss 0.241, val accuracy 0.970\n",
            "Epoch 19, train loss 0.028, train accuracy 0.993, val loss 0.250, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Fold  4\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.213, train accuracy 0.192, val loss 2.360, val accuracy 0.121\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.115, train accuracy 0.336, val loss 1.967, val accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.984, train accuracy 0.812, val loss 1.572, val accuracy 0.606\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.832, train accuracy 0.818, val loss 1.329, val accuracy 0.636\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.684, train accuracy 0.829, val loss 1.036, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.510, train accuracy 0.932, val loss 0.739, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.373, train accuracy 0.935, val loss 0.500, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.250, train accuracy 0.952, val loss 0.358, val accuracy 0.970\n",
            "Epoch 8, train loss 0.180, train accuracy 0.973, val loss 0.324, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.165, train accuracy 0.973, val loss 0.369, val accuracy 0.939\n",
            "Epoch 10, train loss 0.128, train accuracy 0.959, val loss 0.184, val accuracy 0.970\n",
            "Epoch 11, train loss 0.096, train accuracy 0.966, val loss 0.138, val accuracy 1.000\n",
            "Epoch 12, train loss 0.066, train accuracy 0.983, val loss 0.174, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.061, train accuracy 0.986, val loss 0.101, val accuracy 0.970\n",
            "Epoch 14, train loss 0.054, train accuracy 0.976, val loss 0.107, val accuracy 0.970\n",
            "Epoch 15, train loss 0.046, train accuracy 0.983, val loss 0.109, val accuracy 0.970\n",
            "Epoch 16, train loss 0.033, train accuracy 0.990, val loss 0.089, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.026, train accuracy 0.997, val loss 0.065, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.022, train accuracy 0.997, val loss 0.056, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.018, train accuracy 0.997, val loss 0.050, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  5\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.201, train accuracy 0.116, val loss 2.247, val accuracy 0.062\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.098, train accuracy 0.181, val loss 1.964, val accuracy 0.562\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.973, train accuracy 0.785, val loss 1.659, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.804, train accuracy 0.911, val loss 1.308, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.609, train accuracy 0.904, val loss 1.053, val accuracy 0.812\n",
            "Epoch 5, train loss 0.428, train accuracy 0.939, val loss 0.705, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.329, train accuracy 0.956, val loss 0.799, val accuracy 0.875\n",
            "Epoch 7, train loss 0.264, train accuracy 0.962, val loss 0.628, val accuracy 0.906\n",
            "Epoch 8, train loss 0.211, train accuracy 0.952, val loss 0.292, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.129, train accuracy 0.966, val loss 0.217, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.143, train accuracy 0.935, val loss 0.394, val accuracy 0.844\n",
            "Epoch 11, train loss 0.128, train accuracy 0.922, val loss 0.268, val accuracy 0.906\n",
            "Epoch 12, train loss 0.077, train accuracy 0.973, val loss 0.173, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.073, train accuracy 0.980, val loss 0.118, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.052, train accuracy 0.993, val loss 0.133, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.051, train accuracy 0.983, val loss 0.121, val accuracy 0.969\n",
            "Epoch 16, train loss 0.033, train accuracy 0.997, val loss 0.132, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.029, train accuracy 0.997, val loss 0.109, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.022, train accuracy 0.997, val loss 0.097, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.018, train accuracy 0.997, val loss 0.098, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Fold  6\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.208, train accuracy 0.150, val loss 2.155, val accuracy 0.062\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.104, train accuracy 0.164, val loss 1.821, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.967, train accuracy 0.840, val loss 1.449, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.789, train accuracy 0.922, val loss 1.031, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.585, train accuracy 0.939, val loss 0.757, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.460, train accuracy 0.945, val loss 0.543, val accuracy 0.938\n",
            "Epoch 6, train loss 0.338, train accuracy 0.928, val loss 0.434, val accuracy 0.906\n",
            "Epoch 7, train loss 0.270, train accuracy 0.922, val loss 0.403, val accuracy 0.906\n",
            "Epoch 8, train loss 0.233, train accuracy 0.966, val loss 0.268, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.154, train accuracy 0.969, val loss 0.246, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.127, train accuracy 0.983, val loss 0.170, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.099, train accuracy 0.983, val loss 0.147, val accuracy 0.969\n",
            "Epoch 12, train loss 0.069, train accuracy 0.983, val loss 0.143, val accuracy 0.969\n",
            "Epoch 13, train loss 0.053, train accuracy 0.990, val loss 0.083, val accuracy 0.969\n",
            "Epoch 14, train loss 0.040, train accuracy 0.990, val loss 0.064, val accuracy 0.969\n",
            "Epoch 15, train loss 0.041, train accuracy 0.990, val loss 0.075, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.027, train accuracy 0.997, val loss 0.105, val accuracy 0.969\n",
            "Epoch 17, train loss 0.033, train accuracy 0.980, val loss 0.126, val accuracy 0.969\n",
            "Epoch 18, train loss 0.022, train accuracy 0.997, val loss 0.065, val accuracy 0.969\n",
            "Epoch 19, train loss 0.018, train accuracy 0.997, val loss 0.028, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  7\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.216, train accuracy 0.055, val loss 2.263, val accuracy 0.062\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.118, train accuracy 0.191, val loss 1.914, val accuracy 0.656\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.990, train accuracy 0.802, val loss 1.555, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.833, train accuracy 0.840, val loss 1.160, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.641, train accuracy 0.898, val loss 0.802, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.448, train accuracy 0.949, val loss 0.690, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.356, train accuracy 0.935, val loss 0.557, val accuracy 0.938\n",
            "Epoch 7, train loss 0.260, train accuracy 0.945, val loss 0.372, val accuracy 0.938\n",
            "Epoch 8, train loss 0.202, train accuracy 0.976, val loss 0.257, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.110, train accuracy 0.983, val loss 0.265, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.092, train accuracy 0.969, val loss 0.209, val accuracy 0.938\n",
            "Epoch 11, train loss 0.075, train accuracy 0.983, val loss 0.169, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.062, train accuracy 0.986, val loss 0.169, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.038, train accuracy 0.993, val loss 0.167, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.031, train accuracy 0.997, val loss 0.164, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.023, train accuracy 0.997, val loss 0.165, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.019, train accuracy 0.997, val loss 0.147, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.014, train accuracy 0.997, val loss 0.134, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.011, train accuracy 0.997, val loss 0.245, val accuracy 0.938\n",
            "Epoch 19, train loss 0.017, train accuracy 0.990, val loss 0.154, val accuracy 0.969\n",
            "Fold  8\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.201, train accuracy 0.038, val loss 2.216, val accuracy 0.219\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.100, train accuracy 0.321, val loss 1.939, val accuracy 0.719\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.972, train accuracy 0.799, val loss 1.596, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.797, train accuracy 0.935, val loss 1.235, val accuracy 0.812\n",
            "Epoch 4, train loss 0.604, train accuracy 0.935, val loss 1.250, val accuracy 0.750\n",
            "Epoch 5, train loss 0.587, train accuracy 0.816, val loss 0.740, val accuracy 0.844\n",
            "Epoch 6, train loss 0.343, train accuracy 0.952, val loss 0.700, val accuracy 0.875\n",
            "Epoch 7, train loss 0.331, train accuracy 0.932, val loss 0.470, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.207, train accuracy 0.973, val loss 0.475, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.205, train accuracy 0.942, val loss 0.300, val accuracy 0.969\n",
            "Epoch 10, train loss 0.125, train accuracy 0.980, val loss 0.234, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.111, train accuracy 0.969, val loss 0.174, val accuracy 0.969\n",
            "Epoch 12, train loss 0.087, train accuracy 0.980, val loss 0.153, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.067, train accuracy 0.976, val loss 0.095, val accuracy 0.969\n",
            "Epoch 14, train loss 0.045, train accuracy 0.986, val loss 0.093, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.044, train accuracy 0.990, val loss 0.095, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.033, train accuracy 0.993, val loss 0.112, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.028, train accuracy 0.990, val loss 0.076, val accuracy 0.969\n",
            "Epoch 18, train loss 0.026, train accuracy 0.986, val loss 0.038, val accuracy 1.000\n",
            "Epoch 19, train loss 0.019, train accuracy 0.993, val loss 0.035, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  9\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.216, train accuracy 0.031, val loss 2.310, val accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.113, train accuracy 0.454, val loss 2.013, val accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.989, train accuracy 0.758, val loss 1.658, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.828, train accuracy 0.911, val loss 1.320, val accuracy 0.750\n",
            "Epoch 4, train loss 0.621, train accuracy 0.884, val loss 1.028, val accuracy 0.688\n",
            "Epoch 5, train loss 0.455, train accuracy 0.870, val loss 0.838, val accuracy 0.844\n",
            "Epoch 6, train loss 0.354, train accuracy 0.949, val loss 0.595, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.279, train accuracy 0.956, val loss 0.499, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.252, train accuracy 0.932, val loss 0.450, val accuracy 0.906\n",
            "Epoch 9, train loss 0.207, train accuracy 0.935, val loss 0.314, val accuracy 0.969\n",
            "Epoch 10, train loss 0.161, train accuracy 0.956, val loss 0.229, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.109, train accuracy 0.993, val loss 0.160, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.088, train accuracy 0.980, val loss 0.136, val accuracy 1.000\n",
            "Epoch 13, train loss 0.073, train accuracy 0.980, val loss 0.130, val accuracy 0.969\n",
            "Epoch 14, train loss 0.052, train accuracy 0.990, val loss 0.124, val accuracy 0.969\n",
            "Epoch 15, train loss 0.043, train accuracy 0.990, val loss 0.074, val accuracy 1.000\n",
            "Epoch 16, train loss 0.035, train accuracy 0.990, val loss 0.054, val accuracy 1.000\n",
            "Epoch 17, train loss 0.028, train accuracy 0.993, val loss 0.044, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.024, train accuracy 0.993, val loss 0.032, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.021, train accuracy 0.993, val loss 0.029, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Random Number 7980\n",
            "Fold  0\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.213, train accuracy 0.123, val loss 2.165, val accuracy 0.212\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.114, train accuracy 0.240, val loss 1.856, val accuracy 0.697\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.974, train accuracy 0.705, val loss 1.509, val accuracy 0.758\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.818, train accuracy 0.791, val loss 1.154, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.662, train accuracy 0.887, val loss 0.987, val accuracy 0.788\n",
            "Epoch 5, train loss 0.565, train accuracy 0.764, val loss 0.626, val accuracy 0.909\n",
            "Epoch 6, train loss 0.376, train accuracy 0.901, val loss 0.530, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.332, train accuracy 0.911, val loss 0.285, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.241, train accuracy 0.949, val loss 0.228, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.201, train accuracy 0.942, val loss 0.177, val accuracy 1.000\n",
            "Epoch 10, train loss 0.147, train accuracy 0.959, val loss 0.139, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.111, train accuracy 0.969, val loss 0.127, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.085, train accuracy 0.973, val loss 0.090, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.064, train accuracy 0.986, val loss 0.060, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.049, train accuracy 0.986, val loss 0.047, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.041, train accuracy 0.990, val loss 0.039, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.033, train accuracy 0.990, val loss 0.035, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.026, train accuracy 0.993, val loss 0.033, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.021, train accuracy 0.993, val loss 0.032, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.018, train accuracy 0.997, val loss 0.032, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  1\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.213, train accuracy 0.058, val loss 2.139, val accuracy 0.121\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.114, train accuracy 0.161, val loss 1.837, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.974, train accuracy 0.860, val loss 1.507, val accuracy 0.788\n",
            "Epoch 3, train loss 0.812, train accuracy 0.849, val loss 1.129, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.612, train accuracy 0.932, val loss 0.994, val accuracy 0.758\n",
            "Epoch 5, train loss 0.527, train accuracy 0.829, val loss 0.855, val accuracy 0.818\n",
            "Epoch 6, train loss 0.413, train accuracy 0.873, val loss 0.696, val accuracy 0.818\n",
            "Epoch 7, train loss 0.344, train accuracy 0.873, val loss 0.655, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.289, train accuracy 0.908, val loss 0.556, val accuracy 0.848\n",
            "Epoch 9, train loss 0.220, train accuracy 0.955, val loss 0.451, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.152, train accuracy 0.955, val loss 0.346, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.115, train accuracy 0.979, val loss 0.320, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.093, train accuracy 0.979, val loss 0.305, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.073, train accuracy 0.990, val loss 0.309, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.058, train accuracy 0.986, val loss 0.225, val accuracy 0.939\n",
            "Epoch 15, train loss 0.046, train accuracy 0.993, val loss 0.262, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.039, train accuracy 0.990, val loss 0.250, val accuracy 0.939\n",
            "Epoch 17, train loss 0.030, train accuracy 0.990, val loss 0.226, val accuracy 0.939\n",
            "Epoch 18, train loss 0.025, train accuracy 0.997, val loss 0.208, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.021, train accuracy 0.997, val loss 0.245, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Fold  2\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.201, train accuracy 0.072, val loss 2.196, val accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.094, train accuracy 0.473, val loss 1.928, val accuracy 0.697\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.964, train accuracy 0.771, val loss 1.590, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.795, train accuracy 0.884, val loss 1.302, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.618, train accuracy 0.928, val loss 0.921, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.468, train accuracy 0.938, val loss 0.854, val accuracy 0.879\n",
            "Epoch 6, train loss 0.386, train accuracy 0.884, val loss 0.966, val accuracy 0.727\n",
            "Epoch 7, train loss 0.423, train accuracy 0.815, val loss 0.485, val accuracy 0.939\n",
            "Epoch 8, train loss 0.249, train accuracy 0.932, val loss 0.424, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.207, train accuracy 0.962, val loss 0.303, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.156, train accuracy 0.983, val loss 0.221, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.119, train accuracy 0.986, val loss 0.176, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.094, train accuracy 0.986, val loss 0.176, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.078, train accuracy 0.976, val loss 0.145, val accuracy 0.970\n",
            "Epoch 14, train loss 0.063, train accuracy 0.986, val loss 0.116, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.052, train accuracy 0.986, val loss 0.108, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.045, train accuracy 0.990, val loss 0.101, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.037, train accuracy 0.990, val loss 0.072, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.030, train accuracy 0.993, val loss 0.056, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.025, train accuracy 0.993, val loss 0.046, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  3\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.205, train accuracy 0.116, val loss 2.219, val accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.096, train accuracy 0.394, val loss 1.900, val accuracy 0.545\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.963, train accuracy 0.675, val loss 1.579, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.795, train accuracy 0.911, val loss 1.195, val accuracy 0.788\n",
            "Epoch 4, train loss 0.605, train accuracy 0.866, val loss 0.996, val accuracy 0.818\n",
            "Epoch 5, train loss 0.491, train accuracy 0.894, val loss 0.762, val accuracy 0.818\n",
            "Epoch 6, train loss 0.437, train accuracy 0.812, val loss 0.680, val accuracy 0.818\n",
            "Epoch 7, train loss 0.328, train accuracy 0.908, val loss 0.484, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.218, train accuracy 0.945, val loss 0.347, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.174, train accuracy 0.979, val loss 0.269, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.133, train accuracy 0.976, val loss 0.213, val accuracy 0.939\n",
            "Epoch 11, train loss 0.104, train accuracy 0.969, val loss 0.128, val accuracy 1.000\n",
            "Epoch 12, train loss 0.073, train accuracy 0.983, val loss 0.105, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.069, train accuracy 0.976, val loss 0.080, val accuracy 1.000\n",
            "Epoch 14, train loss 0.050, train accuracy 0.986, val loss 0.075, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.044, train accuracy 0.983, val loss 0.059, val accuracy 1.000\n",
            "Epoch 16, train loss 0.034, train accuracy 0.990, val loss 0.040, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.025, train accuracy 0.997, val loss 0.032, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.022, train accuracy 0.997, val loss 0.026, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.017, train accuracy 0.997, val loss 0.022, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  4\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.200, train accuracy 0.106, val loss 2.226, val accuracy 0.212\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.090, train accuracy 0.363, val loss 1.979, val accuracy 0.545\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.951, train accuracy 0.774, val loss 1.692, val accuracy 0.758\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.780, train accuracy 0.932, val loss 1.436, val accuracy 0.697\n",
            "Epoch 4, train loss 0.587, train accuracy 0.908, val loss 1.110, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.419, train accuracy 0.952, val loss 0.955, val accuracy 0.758\n",
            "Epoch 6, train loss 0.314, train accuracy 0.959, val loss 0.800, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.237, train accuracy 0.945, val loss 0.846, val accuracy 0.697\n",
            "Epoch 8, train loss 0.243, train accuracy 0.894, val loss 0.771, val accuracy 0.758\n",
            "Epoch 9, train loss 0.216, train accuracy 0.904, val loss 0.551, val accuracy 0.879\n",
            "Epoch 10, train loss 0.137, train accuracy 0.942, val loss 0.710, val accuracy 0.818\n",
            "Epoch 11, train loss 0.157, train accuracy 0.932, val loss 0.644, val accuracy 0.758\n",
            "Epoch 12, train loss 0.100, train accuracy 0.976, val loss 0.594, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.095, train accuracy 0.976, val loss 0.556, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.083, train accuracy 0.976, val loss 0.549, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.075, train accuracy 0.976, val loss 0.550, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.061, train accuracy 0.976, val loss 0.503, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.042, train accuracy 0.990, val loss 0.444, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.032, train accuracy 0.993, val loss 0.436, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.027, train accuracy 0.997, val loss 0.450, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Fold  5\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.195, train accuracy 0.167, val loss 2.116, val accuracy 0.188\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.075, train accuracy 0.358, val loss 1.808, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.931, train accuracy 0.829, val loss 1.424, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.734, train accuracy 0.962, val loss 1.052, val accuracy 0.938\n",
            "Epoch 4, train loss 0.535, train accuracy 0.952, val loss 0.704, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.390, train accuracy 0.939, val loss 0.520, val accuracy 1.000\n",
            "Epoch 6, train loss 0.285, train accuracy 0.942, val loss 0.511, val accuracy 0.938\n",
            "Epoch 7, train loss 0.258, train accuracy 0.922, val loss 0.234, val accuracy 1.000\n",
            "Epoch 8, train loss 0.184, train accuracy 0.942, val loss 0.227, val accuracy 1.000\n",
            "Epoch 9, train loss 0.170, train accuracy 0.942, val loss 0.142, val accuracy 1.000\n",
            "Epoch 10, train loss 0.104, train accuracy 0.980, val loss 0.127, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.095, train accuracy 0.980, val loss 0.094, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.070, train accuracy 0.986, val loss 0.048, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.054, train accuracy 0.986, val loss 0.056, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.047, train accuracy 0.986, val loss 0.066, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.042, train accuracy 0.990, val loss 0.043, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.031, train accuracy 0.990, val loss 0.026, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.026, train accuracy 0.993, val loss 0.021, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.022, train accuracy 0.993, val loss 0.036, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.027, train accuracy 0.986, val loss 0.027, val accuracy 1.000\n",
            "Fold  6\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.221, train accuracy 0.099, val loss 2.243, val accuracy 0.219\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.107, train accuracy 0.430, val loss 1.887, val accuracy 0.438\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.974, train accuracy 0.727, val loss 1.502, val accuracy 0.750\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.805, train accuracy 0.877, val loss 1.224, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.634, train accuracy 0.833, val loss 0.957, val accuracy 0.688\n",
            "Epoch 5, train loss 0.492, train accuracy 0.870, val loss 0.821, val accuracy 0.875\n",
            "Epoch 6, train loss 0.407, train accuracy 0.894, val loss 0.679, val accuracy 0.750\n",
            "Epoch 7, train loss 0.396, train accuracy 0.788, val loss 0.445, val accuracy 0.969\n",
            "Epoch 8, train loss 0.238, train accuracy 0.932, val loss 0.460, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.233, train accuracy 0.935, val loss 0.323, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.143, train accuracy 0.980, val loss 0.259, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.114, train accuracy 0.973, val loss 0.198, val accuracy 0.969\n",
            "Epoch 12, train loss 0.080, train accuracy 0.983, val loss 0.261, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.068, train accuracy 0.986, val loss 0.132, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.059, train accuracy 0.986, val loss 0.147, val accuracy 0.938\n",
            "Epoch 15, train loss 0.046, train accuracy 0.990, val loss 0.191, val accuracy 0.938\n",
            "Epoch 16, train loss 0.038, train accuracy 0.990, val loss 0.128, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.029, train accuracy 0.993, val loss 0.149, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.044, train accuracy 0.986, val loss 0.151, val accuracy 0.969\n",
            "Epoch 19, train loss 0.029, train accuracy 0.990, val loss 0.235, val accuracy 0.938\n",
            "Fold  7\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.230, train accuracy 0.109, val loss 2.184, val accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.118, train accuracy 0.413, val loss 1.894, val accuracy 0.688\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.983, train accuracy 0.741, val loss 1.522, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.810, train accuracy 0.945, val loss 1.147, val accuracy 0.906\n",
            "Epoch 4, train loss 0.601, train accuracy 0.884, val loss 0.867, val accuracy 0.938\n",
            "Epoch 5, train loss 0.476, train accuracy 0.922, val loss 0.713, val accuracy 0.938\n",
            "Epoch 6, train loss 0.412, train accuracy 0.870, val loss 0.492, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.278, train accuracy 0.949, val loss 0.383, val accuracy 0.938\n",
            "Epoch 8, train loss 0.242, train accuracy 0.932, val loss 0.380, val accuracy 0.938\n",
            "Epoch 9, train loss 0.266, train accuracy 0.894, val loss 0.274, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.160, train accuracy 0.952, val loss 0.190, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.123, train accuracy 0.966, val loss 0.143, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.123, train accuracy 0.976, val loss 0.114, val accuracy 0.969\n",
            "Epoch 13, train loss 0.086, train accuracy 0.973, val loss 0.113, val accuracy 0.969\n",
            "Epoch 14, train loss 0.067, train accuracy 0.980, val loss 0.126, val accuracy 0.969\n",
            "Epoch 15, train loss 0.071, train accuracy 0.976, val loss 0.117, val accuracy 0.969\n",
            "Epoch 16, train loss 0.057, train accuracy 0.983, val loss 0.097, val accuracy 0.969\n",
            "Epoch 17, train loss 0.046, train accuracy 0.986, val loss 0.081, val accuracy 0.969\n",
            "Epoch 18, train loss 0.039, train accuracy 0.986, val loss 0.043, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.036, train accuracy 0.990, val loss 0.036, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  8\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.213, train accuracy 0.102, val loss 2.104, val accuracy 0.375\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.103, train accuracy 0.314, val loss 1.780, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.964, train accuracy 0.898, val loss 1.421, val accuracy 0.875\n",
            "Epoch 3, train loss 0.786, train accuracy 0.884, val loss 0.953, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.569, train accuracy 0.956, val loss 0.605, val accuracy 0.938\n",
            "Epoch 5, train loss 0.391, train accuracy 0.966, val loss 0.569, val accuracy 0.906\n",
            "Epoch 6, train loss 0.321, train accuracy 0.898, val loss 0.718, val accuracy 0.750\n",
            "Epoch 7, train loss 0.399, train accuracy 0.754, val loss 0.444, val accuracy 0.812\n",
            "Epoch 8, train loss 0.227, train accuracy 0.898, val loss 0.322, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.216, train accuracy 0.925, val loss 0.196, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.151, train accuracy 0.966, val loss 0.153, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.105, train accuracy 0.980, val loss 0.136, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.086, train accuracy 0.983, val loss 0.089, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.067, train accuracy 0.986, val loss 0.073, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.051, train accuracy 0.986, val loss 0.066, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.042, train accuracy 0.986, val loss 0.060, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.035, train accuracy 0.997, val loss 0.054, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.028, train accuracy 0.997, val loss 0.040, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.022, train accuracy 1.000, val loss 0.039, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.019, train accuracy 0.997, val loss 0.030, val accuracy 1.000\n",
            "Fold  9\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.216, train accuracy 0.109, val loss 2.206, val accuracy 0.188\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.106, train accuracy 0.331, val loss 1.893, val accuracy 0.719\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.970, train accuracy 0.768, val loss 1.507, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.803, train accuracy 0.881, val loss 1.162, val accuracy 0.781\n",
            "Epoch 4, train loss 0.638, train accuracy 0.840, val loss 0.878, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.512, train accuracy 0.898, val loss 0.826, val accuracy 0.812\n",
            "Epoch 6, train loss 0.423, train accuracy 0.887, val loss 0.523, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.294, train accuracy 0.952, val loss 0.366, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.221, train accuracy 0.966, val loss 0.255, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.160, train accuracy 0.973, val loss 0.197, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.126, train accuracy 0.976, val loss 0.162, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.088, train accuracy 0.973, val loss 0.179, val accuracy 0.969\n",
            "Epoch 12, train loss 0.071, train accuracy 0.973, val loss 0.213, val accuracy 0.969\n",
            "Epoch 13, train loss 0.059, train accuracy 0.990, val loss 0.193, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.040, train accuracy 0.990, val loss 0.176, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.037, train accuracy 0.993, val loss 0.172, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.028, train accuracy 0.990, val loss 0.170, val accuracy 0.969\n",
            "Epoch 17, train loss 0.024, train accuracy 0.993, val loss 0.164, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.024, train accuracy 0.997, val loss 0.170, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.016, train accuracy 0.997, val loss 0.181, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Random Number 2999\n",
            "Fold  0\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.205, train accuracy 0.123, val loss 2.247, val accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.116, train accuracy 0.390, val loss 1.966, val accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.992, train accuracy 0.668, val loss 1.635, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.850, train accuracy 0.788, val loss 1.321, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.674, train accuracy 0.870, val loss 1.134, val accuracy 0.788\n",
            "Epoch 5, train loss 0.574, train accuracy 0.753, val loss 0.877, val accuracy 0.788\n",
            "Epoch 6, train loss 0.429, train accuracy 0.873, val loss 0.681, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.293, train accuracy 0.945, val loss 0.522, val accuracy 0.879\n",
            "Epoch 8, train loss 0.218, train accuracy 0.945, val loss 0.449, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.181, train accuracy 0.959, val loss 0.336, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.118, train accuracy 0.979, val loss 0.279, val accuracy 0.939\n",
            "Epoch 11, train loss 0.095, train accuracy 0.976, val loss 0.409, val accuracy 0.879\n",
            "Epoch 12, train loss 0.109, train accuracy 0.962, val loss 0.258, val accuracy 0.939\n",
            "Epoch 13, train loss 0.078, train accuracy 0.976, val loss 0.159, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.070, train accuracy 0.983, val loss 0.177, val accuracy 0.970\n",
            "Epoch 15, train loss 0.057, train accuracy 0.983, val loss 0.223, val accuracy 0.909\n",
            "Epoch 16, train loss 0.048, train accuracy 0.976, val loss 0.184, val accuracy 0.970\n",
            "Epoch 17, train loss 0.039, train accuracy 0.983, val loss 0.128, val accuracy 0.970\n",
            "Epoch 18, train loss 0.037, train accuracy 0.986, val loss 0.093, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.022, train accuracy 1.000, val loss 0.106, val accuracy 0.970\n",
            "Fold  1\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.215, train accuracy 0.113, val loss 2.119, val accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.112, train accuracy 0.353, val loss 1.862, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.987, train accuracy 0.798, val loss 1.503, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.821, train accuracy 0.873, val loss 1.104, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.633, train accuracy 0.918, val loss 1.018, val accuracy 0.788\n",
            "Epoch 5, train loss 0.573, train accuracy 0.729, val loss 0.649, val accuracy 0.909\n",
            "Epoch 6, train loss 0.386, train accuracy 0.908, val loss 0.535, val accuracy 0.848\n",
            "Epoch 7, train loss 0.317, train accuracy 0.942, val loss 0.373, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.209, train accuracy 0.962, val loss 0.302, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.206, train accuracy 0.918, val loss 0.205, val accuracy 0.970\n",
            "Epoch 10, train loss 0.155, train accuracy 0.959, val loss 0.179, val accuracy 0.970\n",
            "Epoch 11, train loss 0.121, train accuracy 0.966, val loss 0.138, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.084, train accuracy 0.973, val loss 0.140, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.080, train accuracy 0.973, val loss 0.120, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.062, train accuracy 0.976, val loss 0.064, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.048, train accuracy 0.983, val loss 0.045, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.038, train accuracy 0.993, val loss 0.037, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.030, train accuracy 0.993, val loss 0.036, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.022, train accuracy 0.997, val loss 0.038, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.019, train accuracy 0.997, val loss 0.032, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  2\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.211, train accuracy 0.096, val loss 2.177, val accuracy 0.152\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.100, train accuracy 0.377, val loss 1.858, val accuracy 0.758\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.964, train accuracy 0.846, val loss 1.454, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.787, train accuracy 0.877, val loss 1.019, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.575, train accuracy 0.935, val loss 0.761, val accuracy 0.848\n",
            "Epoch 5, train loss 0.448, train accuracy 0.853, val loss 0.610, val accuracy 0.939\n",
            "Epoch 6, train loss 0.439, train accuracy 0.795, val loss 0.435, val accuracy 0.970\n",
            "Epoch 7, train loss 0.272, train accuracy 0.962, val loss 0.482, val accuracy 0.939\n",
            "Epoch 8, train loss 0.287, train accuracy 0.884, val loss 0.260, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.205, train accuracy 0.938, val loss 0.164, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.148, train accuracy 0.969, val loss 0.135, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.131, train accuracy 0.966, val loss 0.102, val accuracy 1.000\n",
            "Epoch 12, train loss 0.096, train accuracy 0.979, val loss 0.100, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.080, train accuracy 0.979, val loss 0.061, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.059, train accuracy 0.986, val loss 0.053, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.046, train accuracy 0.986, val loss 0.043, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.039, train accuracy 0.997, val loss 0.048, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.029, train accuracy 0.997, val loss 0.025, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.022, train accuracy 0.997, val loss 0.018, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.018, train accuracy 0.997, val loss 0.018, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  3\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.203, train accuracy 0.123, val loss 2.132, val accuracy 0.273\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.086, train accuracy 0.425, val loss 1.782, val accuracy 0.758\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.952, train accuracy 0.832, val loss 1.469, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.780, train accuracy 0.911, val loss 1.123, val accuracy 0.788\n",
            "Epoch 4, train loss 0.621, train accuracy 0.856, val loss 1.209, val accuracy 0.636\n",
            "Epoch 5, train loss 0.589, train accuracy 0.771, val loss 0.659, val accuracy 0.879\n",
            "Epoch 6, train loss 0.364, train accuracy 0.935, val loss 0.552, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.334, train accuracy 0.908, val loss 0.560, val accuracy 0.879\n",
            "Epoch 8, train loss 0.289, train accuracy 0.897, val loss 0.472, val accuracy 0.879\n",
            "Epoch 9, train loss 0.265, train accuracy 0.945, val loss 0.389, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.197, train accuracy 0.945, val loss 0.324, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.179, train accuracy 0.945, val loss 0.192, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.125, train accuracy 0.966, val loss 0.210, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.122, train accuracy 0.959, val loss 0.129, val accuracy 0.970\n",
            "Epoch 14, train loss 0.097, train accuracy 0.969, val loss 0.133, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.079, train accuracy 0.976, val loss 0.125, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.066, train accuracy 0.983, val loss 0.088, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.051, train accuracy 0.986, val loss 0.056, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.043, train accuracy 0.993, val loss 0.038, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.032, train accuracy 0.997, val loss 0.026, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  4\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.204, train accuracy 0.099, val loss 2.150, val accuracy 0.424\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.091, train accuracy 0.462, val loss 1.871, val accuracy 0.667\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.946, train accuracy 0.846, val loss 1.580, val accuracy 0.727\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.774, train accuracy 0.866, val loss 1.205, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.568, train accuracy 0.890, val loss 0.927, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.410, train accuracy 0.949, val loss 0.781, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.304, train accuracy 0.952, val loss 0.771, val accuracy 0.818\n",
            "Epoch 7, train loss 0.261, train accuracy 0.887, val loss 0.655, val accuracy 0.818\n",
            "Epoch 8, train loss 0.181, train accuracy 0.935, val loss 0.611, val accuracy 0.848\n",
            "Epoch 9, train loss 0.176, train accuracy 0.952, val loss 0.495, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.108, train accuracy 0.976, val loss 0.510, val accuracy 0.879\n",
            "Epoch 11, train loss 0.105, train accuracy 0.976, val loss 0.462, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.071, train accuracy 0.976, val loss 0.492, val accuracy 0.879\n",
            "Epoch 13, train loss 0.071, train accuracy 0.983, val loss 0.449, val accuracy 0.879\n",
            "Epoch 14, train loss 0.040, train accuracy 0.993, val loss 0.430, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.038, train accuracy 0.993, val loss 0.426, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.031, train accuracy 0.997, val loss 0.433, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.021, train accuracy 1.000, val loss 0.449, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.017, train accuracy 1.000, val loss 0.448, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.014, train accuracy 1.000, val loss 0.427, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Fold  5\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.217, train accuracy 0.055, val loss 2.199, val accuracy 0.219\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.108, train accuracy 0.218, val loss 1.853, val accuracy 0.719\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.977, train accuracy 0.778, val loss 1.453, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.809, train accuracy 0.891, val loss 1.078, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.606, train accuracy 0.945, val loss 0.837, val accuracy 0.938\n",
            "Epoch 5, train loss 0.470, train accuracy 0.915, val loss 0.799, val accuracy 0.844\n",
            "Epoch 6, train loss 0.528, train accuracy 0.741, val loss 0.427, val accuracy 0.969\n",
            "Epoch 7, train loss 0.287, train accuracy 0.969, val loss 0.496, val accuracy 0.938\n",
            "Epoch 8, train loss 0.316, train accuracy 0.860, val loss 0.365, val accuracy 0.969\n",
            "Epoch 9, train loss 0.206, train accuracy 0.973, val loss 0.307, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.178, train accuracy 0.969, val loss 0.212, val accuracy 0.969\n",
            "Epoch 11, train loss 0.139, train accuracy 0.976, val loss 0.176, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.124, train accuracy 0.976, val loss 0.142, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.087, train accuracy 0.983, val loss 0.134, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.070, train accuracy 0.983, val loss 0.116, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.053, train accuracy 0.993, val loss 0.096, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.039, train accuracy 0.997, val loss 0.076, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.030, train accuracy 0.997, val loss 0.059, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.022, train accuracy 0.997, val loss 0.049, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.019, train accuracy 0.997, val loss 0.043, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Fold  6\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.216, train accuracy 0.123, val loss 2.156, val accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.100, train accuracy 0.498, val loss 1.846, val accuracy 0.750\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.964, train accuracy 0.863, val loss 1.492, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.787, train accuracy 0.925, val loss 1.148, val accuracy 0.812\n",
            "Epoch 4, train loss 0.590, train accuracy 0.915, val loss 0.727, val accuracy 0.906\n",
            "Epoch 5, train loss 0.410, train accuracy 0.928, val loss 0.461, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.261, train accuracy 0.973, val loss 0.430, val accuracy 0.844\n",
            "Epoch 7, train loss 0.194, train accuracy 0.956, val loss 0.197, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.156, train accuracy 0.949, val loss 0.494, val accuracy 0.875\n",
            "Epoch 9, train loss 0.204, train accuracy 0.908, val loss 0.224, val accuracy 0.938\n",
            "Epoch 10, train loss 0.134, train accuracy 0.959, val loss 0.294, val accuracy 0.906\n",
            "Epoch 11, train loss 0.113, train accuracy 0.956, val loss 0.264, val accuracy 0.938\n",
            "Epoch 12, train loss 0.103, train accuracy 0.962, val loss 0.267, val accuracy 0.938\n",
            "Epoch 13, train loss 0.076, train accuracy 0.986, val loss 0.154, val accuracy 0.969\n",
            "Epoch 14, train loss 0.059, train accuracy 0.993, val loss 0.115, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.060, train accuracy 0.983, val loss 0.082, val accuracy 1.000\n",
            "Epoch 16, train loss 0.038, train accuracy 0.990, val loss 0.093, val accuracy 0.969\n",
            "Epoch 17, train loss 0.026, train accuracy 0.993, val loss 0.148, val accuracy 0.938\n",
            "Epoch 18, train loss 0.026, train accuracy 0.993, val loss 0.184, val accuracy 0.938\n",
            "Epoch 19, train loss 0.023, train accuracy 1.000, val loss 0.184, val accuracy 0.938\n",
            "Fold  7\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.203, train accuracy 0.092, val loss 2.100, val accuracy 0.438\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.083, train accuracy 0.573, val loss 1.830, val accuracy 0.750\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.935, train accuracy 0.860, val loss 1.476, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.746, train accuracy 0.870, val loss 1.160, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.575, train accuracy 0.891, val loss 1.031, val accuracy 0.781\n",
            "Epoch 5, train loss 0.559, train accuracy 0.771, val loss 0.844, val accuracy 0.812\n",
            "Epoch 6, train loss 0.399, train accuracy 0.915, val loss 0.629, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.320, train accuracy 0.942, val loss 0.450, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.214, train accuracy 0.966, val loss 0.368, val accuracy 0.906\n",
            "Epoch 9, train loss 0.148, train accuracy 0.969, val loss 0.260, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.127, train accuracy 0.962, val loss 0.281, val accuracy 0.906\n",
            "Epoch 11, train loss 0.095, train accuracy 0.983, val loss 0.146, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.071, train accuracy 0.973, val loss 0.169, val accuracy 0.969\n",
            "Epoch 13, train loss 0.067, train accuracy 0.986, val loss 0.153, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.051, train accuracy 0.997, val loss 0.121, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.041, train accuracy 0.990, val loss 0.129, val accuracy 0.969\n",
            "Epoch 16, train loss 0.032, train accuracy 0.997, val loss 0.068, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.031, train accuracy 0.986, val loss 0.106, val accuracy 0.969\n",
            "Epoch 18, train loss 0.021, train accuracy 0.993, val loss 0.048, val accuracy 1.000\n",
            "Epoch 19, train loss 0.015, train accuracy 1.000, val loss 0.042, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  8\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.187, train accuracy 0.106, val loss 2.203, val accuracy 0.438\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.071, train accuracy 0.604, val loss 1.900, val accuracy 0.562\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.921, train accuracy 0.833, val loss 1.561, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.731, train accuracy 0.922, val loss 1.182, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.534, train accuracy 0.898, val loss 0.931, val accuracy 0.875\n",
            "Epoch 5, train loss 0.394, train accuracy 0.918, val loss 0.774, val accuracy 0.812\n",
            "Epoch 6, train loss 0.323, train accuracy 0.928, val loss 0.744, val accuracy 0.812\n",
            "Epoch 7, train loss 0.260, train accuracy 0.922, val loss 0.451, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.236, train accuracy 0.904, val loss 0.839, val accuracy 0.625\n",
            "Epoch 9, train loss 0.316, train accuracy 0.802, val loss 0.297, val accuracy 0.938\n",
            "Epoch 10, train loss 0.144, train accuracy 0.956, val loss 0.341, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.160, train accuracy 0.935, val loss 0.358, val accuracy 0.938\n",
            "Epoch 12, train loss 0.151, train accuracy 0.956, val loss 0.263, val accuracy 0.938\n",
            "Epoch 13, train loss 0.101, train accuracy 0.962, val loss 0.197, val accuracy 0.938\n",
            "Epoch 14, train loss 0.081, train accuracy 0.976, val loss 0.177, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.078, train accuracy 0.966, val loss 0.154, val accuracy 1.000\n",
            "Epoch 16, train loss 0.065, train accuracy 0.986, val loss 0.126, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.050, train accuracy 0.990, val loss 0.099, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.040, train accuracy 0.983, val loss 0.083, val accuracy 1.000\n",
            "Epoch 19, train loss 0.033, train accuracy 0.990, val loss 0.067, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  9\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.217, train accuracy 0.130, val loss 2.253, val accuracy 0.062\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.116, train accuracy 0.174, val loss 1.929, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.983, train accuracy 0.836, val loss 1.555, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.821, train accuracy 0.802, val loss 1.237, val accuracy 0.938\n",
            "Epoch 4, train loss 0.641, train accuracy 0.932, val loss 0.862, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.509, train accuracy 0.853, val loss 0.817, val accuracy 0.906\n",
            "Epoch 6, train loss 0.383, train accuracy 0.925, val loss 0.658, val accuracy 0.938\n",
            "Epoch 7, train loss 0.292, train accuracy 0.973, val loss 0.393, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.221, train accuracy 0.952, val loss 0.327, val accuracy 0.969\n",
            "Epoch 9, train loss 0.157, train accuracy 0.959, val loss 0.381, val accuracy 0.906\n",
            "Epoch 10, train loss 0.137, train accuracy 0.956, val loss 0.267, val accuracy 0.969\n",
            "Epoch 11, train loss 0.101, train accuracy 0.976, val loss 0.246, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.094, train accuracy 0.980, val loss 0.205, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.061, train accuracy 0.990, val loss 0.223, val accuracy 0.875\n",
            "Epoch 14, train loss 0.055, train accuracy 0.986, val loss 0.140, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.047, train accuracy 0.983, val loss 0.131, val accuracy 0.969\n",
            "Epoch 16, train loss 0.033, train accuracy 0.993, val loss 0.199, val accuracy 0.938\n",
            "Epoch 17, train loss 0.029, train accuracy 0.993, val loss 0.186, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.020, train accuracy 0.997, val loss 0.155, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.021, train accuracy 0.993, val loss 0.163, val accuracy 0.938\n",
            "Random Number 3324\n",
            "Fold  0\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.206, train accuracy 0.096, val loss 2.124, val accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.090, train accuracy 0.305, val loss 1.824, val accuracy 0.636\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.962, train accuracy 0.784, val loss 1.497, val accuracy 0.606\n",
            "Epoch 3, train loss 0.794, train accuracy 0.825, val loss 1.109, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.614, train accuracy 0.945, val loss 0.938, val accuracy 0.697\n",
            "Epoch 5, train loss 0.502, train accuracy 0.829, val loss 0.900, val accuracy 0.818\n",
            "Epoch 6, train loss 0.498, train accuracy 0.795, val loss 0.587, val accuracy 0.879\n",
            "Epoch 7, train loss 0.364, train accuracy 0.846, val loss 0.490, val accuracy 0.848\n",
            "Epoch 8, train loss 0.318, train accuracy 0.884, val loss 0.360, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.180, train accuracy 0.966, val loss 0.361, val accuracy 0.909\n",
            "Epoch 10, train loss 0.170, train accuracy 0.959, val loss 0.293, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.133, train accuracy 0.976, val loss 0.215, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.099, train accuracy 0.986, val loss 0.192, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.078, train accuracy 0.983, val loss 0.172, val accuracy 0.939\n",
            "Epoch 14, train loss 0.061, train accuracy 0.993, val loss 0.141, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.054, train accuracy 0.990, val loss 0.175, val accuracy 0.939\n",
            "Epoch 16, train loss 0.041, train accuracy 0.986, val loss 0.118, val accuracy 0.970\n",
            "Epoch 17, train loss 0.036, train accuracy 0.997, val loss 0.110, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.031, train accuracy 0.997, val loss 0.107, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.023, train accuracy 0.997, val loss 0.119, val accuracy 0.939\n",
            "Fold  1\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.210, train accuracy 0.123, val loss 2.169, val accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.099, train accuracy 0.284, val loss 1.813, val accuracy 0.606\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.972, train accuracy 0.788, val loss 1.507, val accuracy 0.636\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.809, train accuracy 0.818, val loss 1.132, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.607, train accuracy 0.921, val loss 0.837, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.465, train accuracy 0.908, val loss 0.592, val accuracy 0.848\n",
            "Epoch 6, train loss 0.354, train accuracy 0.856, val loss 0.475, val accuracy 1.000\n",
            "Epoch 7, train loss 0.263, train accuracy 0.918, val loss 0.402, val accuracy 0.879\n",
            "Epoch 8, train loss 0.231, train accuracy 0.887, val loss 0.238, val accuracy 1.000\n",
            "Epoch 9, train loss 0.142, train accuracy 0.983, val loss 0.125, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.102, train accuracy 0.966, val loss 0.123, val accuracy 1.000\n",
            "Epoch 11, train loss 0.088, train accuracy 0.976, val loss 0.101, val accuracy 1.000\n",
            "Epoch 12, train loss 0.070, train accuracy 0.983, val loss 0.068, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.049, train accuracy 0.990, val loss 0.065, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.041, train accuracy 0.990, val loss 0.048, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.036, train accuracy 0.983, val loss 0.053, val accuracy 1.000\n",
            "Epoch 16, train loss 0.030, train accuracy 0.993, val loss 0.034, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.019, train accuracy 1.000, val loss 0.037, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.020, train accuracy 0.993, val loss 0.025, val accuracy 1.000\n",
            "Epoch 19, train loss 0.012, train accuracy 1.000, val loss 0.037, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  2\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.221, train accuracy 0.106, val loss 2.289, val accuracy 0.061\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.123, train accuracy 0.164, val loss 1.932, val accuracy 0.727\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.996, train accuracy 0.798, val loss 1.538, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.855, train accuracy 0.788, val loss 1.240, val accuracy 0.879\n",
            "Epoch 4, train loss 0.681, train accuracy 0.825, val loss 1.025, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.559, train accuracy 0.873, val loss 0.983, val accuracy 0.667\n",
            "Epoch 6, train loss 0.479, train accuracy 0.818, val loss 0.712, val accuracy 0.848\n",
            "Epoch 7, train loss 0.349, train accuracy 0.932, val loss 0.524, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.288, train accuracy 0.890, val loss 0.515, val accuracy 0.909\n",
            "Epoch 9, train loss 0.206, train accuracy 0.959, val loss 0.473, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.167, train accuracy 0.959, val loss 0.315, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.130, train accuracy 0.969, val loss 0.225, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.090, train accuracy 0.979, val loss 0.157, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.079, train accuracy 0.973, val loss 0.154, val accuracy 0.970\n",
            "Epoch 14, train loss 0.052, train accuracy 0.979, val loss 0.160, val accuracy 0.970\n",
            "Epoch 15, train loss 0.042, train accuracy 0.986, val loss 0.149, val accuracy 0.970\n",
            "Epoch 16, train loss 0.034, train accuracy 0.997, val loss 0.131, val accuracy 0.970\n",
            "Epoch 17, train loss 0.033, train accuracy 0.990, val loss 0.150, val accuracy 0.970\n",
            "Epoch 18, train loss 0.023, train accuracy 0.997, val loss 0.171, val accuracy 0.970\n",
            "Epoch 19, train loss 0.023, train accuracy 0.990, val loss 0.145, val accuracy 0.970\n",
            "Fold  3\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.209, train accuracy 0.103, val loss 2.093, val accuracy 0.333\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.093, train accuracy 0.394, val loss 1.751, val accuracy 0.727\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.960, train accuracy 0.719, val loss 1.369, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.778, train accuracy 0.884, val loss 0.981, val accuracy 0.818\n",
            "Epoch 4, train loss 0.621, train accuracy 0.836, val loss 1.024, val accuracy 0.758\n",
            "Epoch 5, train loss 0.582, train accuracy 0.860, val loss 0.639, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.409, train accuracy 0.932, val loss 0.408, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.327, train accuracy 0.928, val loss 0.336, val accuracy 0.939\n",
            "Epoch 8, train loss 0.286, train accuracy 0.908, val loss 0.250, val accuracy 1.000\n",
            "Epoch 9, train loss 0.189, train accuracy 0.983, val loss 0.222, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.156, train accuracy 0.983, val loss 0.120, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.110, train accuracy 0.969, val loss 0.082, val accuracy 1.000\n",
            "Epoch 12, train loss 0.081, train accuracy 0.979, val loss 0.068, val accuracy 1.000\n",
            "Epoch 13, train loss 0.062, train accuracy 0.986, val loss 0.045, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.047, train accuracy 0.993, val loss 0.038, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.040, train accuracy 0.986, val loss 0.027, val accuracy 1.000\n",
            "Epoch 16, train loss 0.029, train accuracy 0.993, val loss 0.021, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.023, train accuracy 0.990, val loss 0.058, val accuracy 0.970\n",
            "Epoch 18, train loss 0.032, train accuracy 0.979, val loss 0.014, val accuracy 1.000\n",
            "Epoch 19, train loss 0.018, train accuracy 0.997, val loss 0.012, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  4\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.199, train accuracy 0.151, val loss 2.206, val accuracy 0.182\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.093, train accuracy 0.404, val loss 1.868, val accuracy 0.667\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.950, train accuracy 0.784, val loss 1.533, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.787, train accuracy 0.863, val loss 1.199, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.599, train accuracy 0.873, val loss 1.034, val accuracy 0.758\n",
            "Epoch 5, train loss 0.498, train accuracy 0.832, val loss 0.757, val accuracy 0.848\n",
            "Epoch 6, train loss 0.384, train accuracy 0.863, val loss 0.543, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.271, train accuracy 0.962, val loss 0.318, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.181, train accuracy 0.973, val loss 0.236, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.129, train accuracy 0.969, val loss 0.200, val accuracy 0.970\n",
            "Epoch 10, train loss 0.097, train accuracy 0.973, val loss 0.152, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.076, train accuracy 0.976, val loss 0.135, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.057, train accuracy 0.986, val loss 0.094, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.044, train accuracy 0.986, val loss 0.079, val accuracy 0.970\n",
            "Epoch 14, train loss 0.035, train accuracy 0.990, val loss 0.116, val accuracy 0.939\n",
            "Epoch 15, train loss 0.028, train accuracy 0.993, val loss 0.065, val accuracy 0.970\n",
            "Epoch 16, train loss 0.020, train accuracy 1.000, val loss 0.076, val accuracy 0.970\n",
            "Epoch 17, train loss 0.017, train accuracy 0.997, val loss 0.062, val accuracy 0.970\n",
            "Epoch 18, train loss 0.012, train accuracy 1.000, val loss 0.073, val accuracy 0.970\n",
            "Epoch 19, train loss 0.010, train accuracy 1.000, val loss 0.058, val accuracy 0.970\n",
            "Fold  5\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.193, train accuracy 0.119, val loss 2.133, val accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.078, train accuracy 0.515, val loss 1.925, val accuracy 0.562\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.946, train accuracy 0.775, val loss 1.638, val accuracy 0.688\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.776, train accuracy 0.833, val loss 1.316, val accuracy 0.719\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.600, train accuracy 0.846, val loss 0.986, val accuracy 0.750\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.458, train accuracy 0.877, val loss 0.952, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.427, train accuracy 0.816, val loss 0.601, val accuracy 0.969\n",
            "Epoch 7, train loss 0.275, train accuracy 0.980, val loss 0.497, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.231, train accuracy 0.952, val loss 0.358, val accuracy 0.969\n",
            "Epoch 9, train loss 0.160, train accuracy 0.973, val loss 0.238, val accuracy 1.000\n",
            "Epoch 10, train loss 0.108, train accuracy 0.990, val loss 0.191, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.093, train accuracy 0.976, val loss 0.150, val accuracy 0.969\n",
            "Epoch 12, train loss 0.063, train accuracy 0.993, val loss 0.143, val accuracy 0.969\n",
            "Epoch 13, train loss 0.053, train accuracy 0.980, val loss 0.065, val accuracy 1.000\n",
            "Epoch 14, train loss 0.051, train accuracy 0.980, val loss 0.073, val accuracy 0.969\n",
            "Epoch 15, train loss 0.033, train accuracy 0.990, val loss 0.101, val accuracy 0.969\n",
            "Epoch 16, train loss 0.033, train accuracy 0.993, val loss 0.024, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.023, train accuracy 0.990, val loss 0.025, val accuracy 1.000\n",
            "Epoch 18, train loss 0.018, train accuracy 0.997, val loss 0.052, val accuracy 0.969\n",
            "Epoch 19, train loss 0.016, train accuracy 0.997, val loss 0.080, val accuracy 0.969\n",
            "Fold  6\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.205, train accuracy 0.096, val loss 2.105, val accuracy 0.375\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.092, train accuracy 0.420, val loss 1.841, val accuracy 0.688\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.958, train accuracy 0.747, val loss 1.477, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.790, train accuracy 0.788, val loss 1.140, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.604, train accuracy 0.853, val loss 0.912, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.541, train accuracy 0.846, val loss 0.621, val accuracy 0.844\n",
            "Epoch 6, train loss 0.356, train accuracy 0.949, val loss 0.564, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.275, train accuracy 0.962, val loss 0.284, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.215, train accuracy 0.969, val loss 0.216, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.159, train accuracy 0.959, val loss 0.175, val accuracy 1.000\n",
            "Epoch 10, train loss 0.110, train accuracy 0.980, val loss 0.174, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.092, train accuracy 0.990, val loss 0.124, val accuracy 0.969\n",
            "Epoch 12, train loss 0.059, train accuracy 0.993, val loss 0.055, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.046, train accuracy 0.990, val loss 0.174, val accuracy 0.938\n",
            "Epoch 14, train loss 0.052, train accuracy 0.980, val loss 0.052, val accuracy 1.000\n",
            "Epoch 15, train loss 0.035, train accuracy 0.993, val loss 0.036, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.030, train accuracy 0.993, val loss 0.058, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.023, train accuracy 0.997, val loss 0.121, val accuracy 0.938\n",
            "Epoch 18, train loss 0.027, train accuracy 0.990, val loss 0.033, val accuracy 1.000\n",
            "Epoch 19, train loss 0.014, train accuracy 0.997, val loss 0.013, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  7\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.204, train accuracy 0.089, val loss 2.158, val accuracy 0.219\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.083, train accuracy 0.457, val loss 1.844, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.943, train accuracy 0.812, val loss 1.490, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.757, train accuracy 0.887, val loss 1.127, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.567, train accuracy 0.911, val loss 0.972, val accuracy 0.656\n",
            "Epoch 5, train loss 0.473, train accuracy 0.741, val loss 0.598, val accuracy 0.938\n",
            "Epoch 6, train loss 0.300, train accuracy 0.973, val loss 0.489, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.238, train accuracy 0.952, val loss 0.336, val accuracy 0.938\n",
            "Epoch 8, train loss 0.166, train accuracy 0.962, val loss 0.352, val accuracy 0.906\n",
            "Epoch 9, train loss 0.151, train accuracy 0.935, val loss 0.166, val accuracy 0.969\n",
            "Epoch 10, train loss 0.080, train accuracy 0.990, val loss 0.128, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.071, train accuracy 0.983, val loss 0.118, val accuracy 1.000\n",
            "Epoch 12, train loss 0.050, train accuracy 0.990, val loss 0.113, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.037, train accuracy 0.993, val loss 0.102, val accuracy 0.969\n",
            "Epoch 14, train loss 0.035, train accuracy 0.997, val loss 0.107, val accuracy 0.969\n",
            "Epoch 15, train loss 0.032, train accuracy 0.990, val loss 0.128, val accuracy 0.969\n",
            "Epoch 16, train loss 0.027, train accuracy 0.993, val loss 0.094, val accuracy 0.969\n",
            "Epoch 17, train loss 0.020, train accuracy 0.993, val loss 0.047, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.015, train accuracy 1.000, val loss 0.052, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.013, train accuracy 1.000, val loss 0.061, val accuracy 0.969\n",
            "Fold  8\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.207, train accuracy 0.109, val loss 2.264, val accuracy 0.156\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.105, train accuracy 0.235, val loss 1.917, val accuracy 0.656\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.972, train accuracy 0.792, val loss 1.555, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.819, train accuracy 0.782, val loss 1.279, val accuracy 0.844\n",
            "Epoch 4, train loss 0.641, train accuracy 0.887, val loss 1.147, val accuracy 0.781\n",
            "Epoch 5, train loss 0.498, train accuracy 0.925, val loss 0.906, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.384, train accuracy 0.935, val loss 0.806, val accuracy 0.812\n",
            "Epoch 7, train loss 0.270, train accuracy 0.945, val loss 0.618, val accuracy 0.875\n",
            "Epoch 8, train loss 0.196, train accuracy 0.976, val loss 0.514, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.138, train accuracy 0.976, val loss 0.423, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.097, train accuracy 0.983, val loss 0.511, val accuracy 0.875\n",
            "Epoch 11, train loss 0.098, train accuracy 0.973, val loss 0.463, val accuracy 0.875\n",
            "Epoch 12, train loss 0.085, train accuracy 0.962, val loss 0.320, val accuracy 0.969\n",
            "Epoch 13, train loss 0.048, train accuracy 0.993, val loss 0.336, val accuracy 0.906\n",
            "Epoch 14, train loss 0.045, train accuracy 0.983, val loss 0.304, val accuracy 0.938\n",
            "Epoch 15, train loss 0.030, train accuracy 0.997, val loss 0.275, val accuracy 0.938\n",
            "Epoch 16, train loss 0.022, train accuracy 0.997, val loss 0.276, val accuracy 0.938\n",
            "Epoch 17, train loss 0.018, train accuracy 1.000, val loss 0.286, val accuracy 0.906\n",
            "Epoch 18, train loss 0.014, train accuracy 1.000, val loss 0.277, val accuracy 0.938\n",
            "Epoch 19, train loss 0.011, train accuracy 1.000, val loss 0.273, val accuracy 0.938\n",
            "Fold  9\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.223, train accuracy 0.072, val loss 2.247, val accuracy 0.375\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.121, train accuracy 0.502, val loss 2.018, val accuracy 0.438\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 1.007, train accuracy 0.642, val loss 1.713, val accuracy 0.688\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.864, train accuracy 0.819, val loss 1.397, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.688, train accuracy 0.867, val loss 1.132, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.532, train accuracy 0.911, val loss 1.100, val accuracy 0.719\n",
            "Epoch 6, train loss 0.488, train accuracy 0.816, val loss 0.713, val accuracy 0.875\n",
            "Epoch 7, train loss 0.317, train accuracy 0.925, val loss 0.594, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.289, train accuracy 0.962, val loss 0.458, val accuracy 0.938\n",
            "Epoch 9, train loss 0.195, train accuracy 0.962, val loss 0.418, val accuracy 0.938\n",
            "Epoch 10, train loss 0.151, train accuracy 0.973, val loss 0.328, val accuracy 0.938\n",
            "Epoch 11, train loss 0.105, train accuracy 0.983, val loss 0.261, val accuracy 0.938\n",
            "Epoch 12, train loss 0.069, train accuracy 0.993, val loss 0.196, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.051, train accuracy 0.993, val loss 0.197, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.035, train accuracy 0.993, val loss 0.230, val accuracy 0.938\n",
            "Epoch 15, train loss 0.028, train accuracy 0.993, val loss 0.267, val accuracy 0.938\n",
            "Epoch 16, train loss 0.021, train accuracy 0.997, val loss 0.274, val accuracy 0.938\n",
            "Epoch 17, train loss 0.017, train accuracy 0.997, val loss 0.297, val accuracy 0.906\n",
            "Epoch 18, train loss 0.021, train accuracy 0.997, val loss 0.269, val accuracy 0.906\n",
            "Epoch 19, train loss 0.011, train accuracy 1.000, val loss 0.228, val accuracy 0.906\n",
            "Random Number 1778\n",
            "Fold  0\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.213, train accuracy 0.123, val loss 2.157, val accuracy 0.212\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.092, train accuracy 0.486, val loss 1.795, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.949, train accuracy 0.842, val loss 1.362, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.772, train accuracy 0.914, val loss 1.039, val accuracy 0.879\n",
            "Epoch 4, train loss 0.591, train accuracy 0.897, val loss 0.754, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.463, train accuracy 0.935, val loss 0.508, val accuracy 0.939\n",
            "Epoch 6, train loss 0.311, train accuracy 0.959, val loss 0.372, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.224, train accuracy 0.952, val loss 0.286, val accuracy 1.000\n",
            "Epoch 8, train loss 0.159, train accuracy 0.976, val loss 0.219, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.157, train accuracy 0.949, val loss 0.331, val accuracy 0.909\n",
            "Epoch 10, train loss 0.212, train accuracy 0.870, val loss 0.098, val accuracy 1.000\n",
            "Epoch 11, train loss 0.085, train accuracy 0.976, val loss 0.139, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.144, train accuracy 0.925, val loss 0.092, val accuracy 0.970\n",
            "Epoch 13, train loss 0.071, train accuracy 0.979, val loss 0.097, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.064, train accuracy 0.983, val loss 0.092, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.062, train accuracy 0.979, val loss 0.070, val accuracy 1.000\n",
            "Epoch 16, train loss 0.052, train accuracy 0.986, val loss 0.060, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.042, train accuracy 0.986, val loss 0.060, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.035, train accuracy 0.993, val loss 0.047, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.029, train accuracy 0.997, val loss 0.029, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  1\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.201, train accuracy 0.185, val loss 2.159, val accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.089, train accuracy 0.462, val loss 1.795, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.941, train accuracy 0.870, val loss 1.401, val accuracy 0.879\n",
            "Epoch 3, train loss 0.758, train accuracy 0.846, val loss 0.968, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.548, train accuracy 0.949, val loss 0.728, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.422, train accuracy 0.914, val loss 0.639, val accuracy 0.758\n",
            "Epoch 6, train loss 0.335, train accuracy 0.894, val loss 0.491, val accuracy 0.879\n",
            "Epoch 7, train loss 0.295, train accuracy 0.894, val loss 0.478, val accuracy 0.879\n",
            "Epoch 8, train loss 0.245, train accuracy 0.925, val loss 0.519, val accuracy 0.848\n",
            "Epoch 9, train loss 0.331, train accuracy 0.853, val loss 0.351, val accuracy 0.939\n",
            "Epoch 10, train loss 0.185, train accuracy 0.962, val loss 0.317, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.187, train accuracy 0.962, val loss 0.236, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.140, train accuracy 0.976, val loss 0.168, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.108, train accuracy 0.969, val loss 0.162, val accuracy 0.970\n",
            "Epoch 14, train loss 0.099, train accuracy 0.966, val loss 0.165, val accuracy 0.970\n",
            "Epoch 15, train loss 0.072, train accuracy 0.990, val loss 0.214, val accuracy 0.939\n",
            "Epoch 16, train loss 0.082, train accuracy 0.979, val loss 0.129, val accuracy 0.970\n",
            "Epoch 17, train loss 0.054, train accuracy 0.993, val loss 0.172, val accuracy 0.939\n",
            "Epoch 18, train loss 0.058, train accuracy 0.983, val loss 0.159, val accuracy 0.970\n",
            "Epoch 19, train loss 0.041, train accuracy 0.993, val loss 0.163, val accuracy 0.970\n",
            "Fold  2\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.211, train accuracy 0.147, val loss 2.129, val accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.104, train accuracy 0.312, val loss 1.814, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.964, train accuracy 0.901, val loss 1.410, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.793, train accuracy 0.914, val loss 1.133, val accuracy 0.758\n",
            "Epoch 4, train loss 0.626, train accuracy 0.863, val loss 0.894, val accuracy 0.879\n",
            "Epoch 5, train loss 0.611, train accuracy 0.767, val loss 0.527, val accuracy 1.000\n",
            "Epoch 6, train loss 0.339, train accuracy 0.973, val loss 0.538, val accuracy 0.879\n",
            "Epoch 7, train loss 0.322, train accuracy 0.901, val loss 0.251, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.193, train accuracy 0.973, val loss 0.221, val accuracy 0.970\n",
            "Epoch 9, train loss 0.174, train accuracy 0.955, val loss 0.136, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.117, train accuracy 0.973, val loss 0.130, val accuracy 0.970\n",
            "Epoch 11, train loss 0.104, train accuracy 0.983, val loss 0.096, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.116, train accuracy 0.959, val loss 0.134, val accuracy 0.970\n",
            "Epoch 13, train loss 0.086, train accuracy 0.962, val loss 0.144, val accuracy 0.970\n",
            "Epoch 14, train loss 0.071, train accuracy 0.969, val loss 0.078, val accuracy 0.970\n",
            "Epoch 15, train loss 0.046, train accuracy 0.990, val loss 0.050, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.048, train accuracy 0.979, val loss 0.060, val accuracy 0.970\n",
            "Epoch 17, train loss 0.029, train accuracy 0.997, val loss 0.064, val accuracy 0.970\n",
            "Epoch 18, train loss 0.024, train accuracy 0.997, val loss 0.063, val accuracy 0.970\n",
            "Epoch 19, train loss 0.021, train accuracy 0.997, val loss 0.058, val accuracy 0.970\n",
            "Fold  3\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.199, train accuracy 0.113, val loss 2.096, val accuracy 0.394\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.081, train accuracy 0.503, val loss 1.818, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.946, train accuracy 0.836, val loss 1.490, val accuracy 0.758\n",
            "Epoch 3, train loss 0.775, train accuracy 0.822, val loss 1.101, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.579, train accuracy 0.955, val loss 0.876, val accuracy 0.909\n",
            "Epoch 5, train loss 0.422, train accuracy 0.928, val loss 0.622, val accuracy 0.879\n",
            "Epoch 6, train loss 0.378, train accuracy 0.863, val loss 0.662, val accuracy 0.818\n",
            "Epoch 7, train loss 0.268, train accuracy 0.904, val loss 0.525, val accuracy 0.909\n",
            "Epoch 8, train loss 0.212, train accuracy 0.962, val loss 0.332, val accuracy 0.909\n",
            "Epoch 9, train loss 0.151, train accuracy 0.976, val loss 0.210, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.117, train accuracy 0.993, val loss 0.209, val accuracy 0.939\n",
            "Epoch 11, train loss 0.094, train accuracy 0.983, val loss 0.145, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.072, train accuracy 0.986, val loss 0.149, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.059, train accuracy 0.990, val loss 0.100, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.049, train accuracy 0.993, val loss 0.175, val accuracy 0.939\n",
            "Epoch 15, train loss 0.045, train accuracy 0.990, val loss 0.168, val accuracy 0.939\n",
            "Epoch 16, train loss 0.035, train accuracy 0.990, val loss 0.089, val accuracy 0.970\n",
            "Epoch 17, train loss 0.028, train accuracy 0.997, val loss 0.063, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.025, train accuracy 0.997, val loss 0.073, val accuracy 0.970\n",
            "Epoch 19, train loss 0.021, train accuracy 0.997, val loss 0.062, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  4\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.199, train accuracy 0.120, val loss 2.242, val accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.103, train accuracy 0.370, val loss 1.997, val accuracy 0.455\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.973, train accuracy 0.723, val loss 1.668, val accuracy 0.727\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.814, train accuracy 0.901, val loss 1.341, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.623, train accuracy 0.908, val loss 1.009, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.448, train accuracy 0.938, val loss 0.904, val accuracy 0.788\n",
            "Epoch 6, train loss 0.393, train accuracy 0.808, val loss 0.527, val accuracy 0.848\n",
            "Epoch 7, train loss 0.250, train accuracy 0.962, val loss 0.529, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.239, train accuracy 0.925, val loss 0.450, val accuracy 0.939\n",
            "Epoch 9, train loss 0.172, train accuracy 0.973, val loss 0.317, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.123, train accuracy 0.979, val loss 0.295, val accuracy 0.909\n",
            "Epoch 11, train loss 0.095, train accuracy 0.976, val loss 0.395, val accuracy 0.909\n",
            "Epoch 12, train loss 0.094, train accuracy 0.976, val loss 0.223, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.070, train accuracy 0.979, val loss 0.194, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.050, train accuracy 0.990, val loss 0.223, val accuracy 0.939\n",
            "Epoch 15, train loss 0.051, train accuracy 0.983, val loss 0.196, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.038, train accuracy 0.993, val loss 0.172, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.027, train accuracy 0.997, val loss 0.191, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.027, train accuracy 0.993, val loss 0.220, val accuracy 0.909\n",
            "Epoch 19, train loss 0.029, train accuracy 0.993, val loss 0.179, val accuracy 0.970\n",
            "Fold  5\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.223, train accuracy 0.089, val loss 2.314, val accuracy 0.469\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.114, train accuracy 0.549, val loss 2.006, val accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.976, train accuracy 0.700, val loss 1.588, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.807, train accuracy 0.891, val loss 1.285, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.620, train accuracy 0.891, val loss 1.090, val accuracy 0.656\n",
            "Epoch 5, train loss 0.528, train accuracy 0.843, val loss 0.849, val accuracy 0.906\n",
            "Epoch 6, train loss 0.450, train accuracy 0.853, val loss 0.710, val accuracy 0.875\n",
            "Epoch 7, train loss 0.335, train accuracy 0.877, val loss 0.739, val accuracy 0.812\n",
            "Epoch 8, train loss 0.267, train accuracy 0.932, val loss 0.452, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.202, train accuracy 0.969, val loss 0.278, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.148, train accuracy 0.966, val loss 0.243, val accuracy 1.000\n",
            "Epoch 11, train loss 0.128, train accuracy 0.969, val loss 0.181, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.092, train accuracy 0.980, val loss 0.149, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.064, train accuracy 0.990, val loss 0.139, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.049, train accuracy 0.993, val loss 0.112, val accuracy 0.969\n",
            "Epoch 15, train loss 0.042, train accuracy 0.997, val loss 0.175, val accuracy 0.969\n",
            "Epoch 16, train loss 0.049, train accuracy 0.976, val loss 0.061, val accuracy 1.000\n",
            "Epoch 17, train loss 0.036, train accuracy 0.983, val loss 0.036, val accuracy 1.000\n",
            "Epoch 18, train loss 0.020, train accuracy 0.997, val loss 0.042, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.022, train accuracy 0.986, val loss 0.031, val accuracy 1.000\n",
            "Fold  6\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.209, train accuracy 0.072, val loss 2.177, val accuracy 0.125\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.089, train accuracy 0.150, val loss 1.804, val accuracy 0.656\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.955, train accuracy 0.785, val loss 1.454, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.774, train accuracy 0.918, val loss 1.056, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.562, train accuracy 0.935, val loss 0.777, val accuracy 0.938\n",
            "Epoch 5, train loss 0.409, train accuracy 0.942, val loss 0.759, val accuracy 0.719\n",
            "Epoch 6, train loss 0.358, train accuracy 0.792, val loss 0.676, val accuracy 0.875\n",
            "Epoch 7, train loss 0.316, train accuracy 0.867, val loss 0.358, val accuracy 0.969\n",
            "Epoch 8, train loss 0.207, train accuracy 0.959, val loss 0.286, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.169, train accuracy 0.962, val loss 0.259, val accuracy 0.938\n",
            "Epoch 10, train loss 0.125, train accuracy 0.973, val loss 0.196, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.094, train accuracy 0.980, val loss 0.138, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.069, train accuracy 0.990, val loss 0.092, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.060, train accuracy 0.993, val loss 0.123, val accuracy 0.969\n",
            "Epoch 14, train loss 0.061, train accuracy 0.983, val loss 0.095, val accuracy 0.969\n",
            "Epoch 15, train loss 0.045, train accuracy 0.983, val loss 0.061, val accuracy 0.969\n",
            "Epoch 16, train loss 0.030, train accuracy 0.990, val loss 0.056, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.033, train accuracy 0.983, val loss 0.028, val accuracy 1.000\n",
            "Epoch 18, train loss 0.017, train accuracy 0.997, val loss 0.040, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.020, train accuracy 0.993, val loss 0.068, val accuracy 0.969\n",
            "Fold  7\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.211, train accuracy 0.044, val loss 2.092, val accuracy 0.562\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.094, train accuracy 0.580, val loss 1.830, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.957, train accuracy 0.925, val loss 1.473, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.780, train accuracy 0.956, val loss 1.118, val accuracy 0.812\n",
            "Epoch 4, train loss 0.601, train accuracy 0.898, val loss 0.818, val accuracy 0.906\n",
            "Epoch 5, train loss 0.468, train accuracy 0.887, val loss 0.692, val accuracy 0.812\n",
            "Epoch 6, train loss 0.384, train accuracy 0.863, val loss 0.522, val accuracy 0.969\n",
            "Epoch 7, train loss 0.283, train accuracy 0.969, val loss 0.342, val accuracy 0.938\n",
            "Epoch 8, train loss 0.201, train accuracy 0.969, val loss 0.295, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.155, train accuracy 0.973, val loss 0.236, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.176, train accuracy 0.959, val loss 0.161, val accuracy 0.969\n",
            "Epoch 11, train loss 0.117, train accuracy 0.976, val loss 0.129, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.083, train accuracy 0.986, val loss 0.146, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.081, train accuracy 0.973, val loss 0.091, val accuracy 0.969\n",
            "Epoch 14, train loss 0.051, train accuracy 0.983, val loss 0.086, val accuracy 0.969\n",
            "Epoch 15, train loss 0.051, train accuracy 0.980, val loss 0.088, val accuracy 0.969\n",
            "Epoch 16, train loss 0.042, train accuracy 0.993, val loss 0.080, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.034, train accuracy 0.993, val loss 0.064, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.026, train accuracy 0.997, val loss 0.054, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.023, train accuracy 0.997, val loss 0.045, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  8\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.209, train accuracy 0.096, val loss 2.234, val accuracy 0.094\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.096, train accuracy 0.294, val loss 1.896, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.957, train accuracy 0.874, val loss 1.541, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.779, train accuracy 0.898, val loss 1.185, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.562, train accuracy 0.942, val loss 0.847, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.455, train accuracy 0.887, val loss 0.819, val accuracy 0.844\n",
            "Epoch 6, train loss 0.441, train accuracy 0.840, val loss 0.566, val accuracy 0.969\n",
            "Epoch 7, train loss 0.288, train accuracy 0.952, val loss 0.606, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.272, train accuracy 0.918, val loss 0.419, val accuracy 0.938\n",
            "Epoch 9, train loss 0.178, train accuracy 0.969, val loss 0.356, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.149, train accuracy 0.983, val loss 0.316, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.109, train accuracy 0.976, val loss 0.272, val accuracy 0.938\n",
            "Epoch 12, train loss 0.085, train accuracy 0.980, val loss 0.226, val accuracy 0.938\n",
            "Epoch 13, train loss 0.064, train accuracy 0.993, val loss 0.210, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.045, train accuracy 0.993, val loss 0.209, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.037, train accuracy 0.993, val loss 0.181, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.034, train accuracy 0.980, val loss 0.200, val accuracy 0.938\n",
            "Epoch 17, train loss 0.033, train accuracy 0.983, val loss 0.174, val accuracy 0.938\n",
            "Epoch 18, train loss 0.026, train accuracy 0.993, val loss 0.120, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.067, train accuracy 0.959, val loss 0.153, val accuracy 0.938\n",
            "Fold  9\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.201, train accuracy 0.116, val loss 2.257, val accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.088, train accuracy 0.573, val loss 1.970, val accuracy 0.594\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.950, train accuracy 0.761, val loss 1.635, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.770, train accuracy 0.908, val loss 1.288, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.560, train accuracy 0.925, val loss 1.005, val accuracy 0.812\n",
            "Epoch 5, train loss 0.396, train accuracy 0.918, val loss 1.047, val accuracy 0.656\n",
            "Epoch 6, train loss 0.370, train accuracy 0.870, val loss 0.915, val accuracy 0.719\n",
            "Epoch 7, train loss 0.338, train accuracy 0.833, val loss 0.741, val accuracy 0.719\n",
            "Epoch 8, train loss 0.242, train accuracy 0.935, val loss 0.611, val accuracy 0.812\n",
            "Epoch 9, train loss 0.176, train accuracy 0.959, val loss 0.516, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.134, train accuracy 0.976, val loss 0.514, val accuracy 0.938\n",
            "Epoch 11, train loss 0.122, train accuracy 0.976, val loss 0.455, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.083, train accuracy 0.980, val loss 0.460, val accuracy 0.938\n",
            "Epoch 13, train loss 0.073, train accuracy 0.973, val loss 0.449, val accuracy 0.906\n",
            "Epoch 14, train loss 0.056, train accuracy 0.973, val loss 0.387, val accuracy 0.906\n",
            "Epoch 15, train loss 0.046, train accuracy 0.997, val loss 0.348, val accuracy 0.938\n",
            "Epoch 16, train loss 0.037, train accuracy 1.000, val loss 0.340, val accuracy 0.938\n",
            "Epoch 17, train loss 0.029, train accuracy 1.000, val loss 0.335, val accuracy 0.938\n",
            "Epoch 18, train loss 0.021, train accuracy 1.000, val loss 0.333, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.021, train accuracy 0.997, val loss 0.361, val accuracy 0.938\n",
            "Random Number 329\n",
            "Fold  0\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.206, train accuracy 0.116, val loss 2.135, val accuracy 0.364\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.106, train accuracy 0.373, val loss 1.876, val accuracy 0.727\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.978, train accuracy 0.866, val loss 1.571, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.825, train accuracy 0.877, val loss 1.232, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.629, train accuracy 0.935, val loss 0.898, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.449, train accuracy 0.973, val loss 0.963, val accuracy 0.788\n",
            "Epoch 6, train loss 0.461, train accuracy 0.846, val loss 0.557, val accuracy 0.939\n",
            "Epoch 7, train loss 0.271, train accuracy 0.969, val loss 0.459, val accuracy 0.879\n",
            "Epoch 8, train loss 0.199, train accuracy 0.962, val loss 0.380, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.148, train accuracy 0.966, val loss 0.429, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.136, train accuracy 0.969, val loss 0.231, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.073, train accuracy 0.986, val loss 0.228, val accuracy 0.939\n",
            "Epoch 12, train loss 0.068, train accuracy 0.986, val loss 0.208, val accuracy 0.939\n",
            "Epoch 13, train loss 0.052, train accuracy 0.993, val loss 0.196, val accuracy 0.939\n",
            "Epoch 14, train loss 0.040, train accuracy 0.993, val loss 0.216, val accuracy 0.939\n",
            "Epoch 15, train loss 0.028, train accuracy 0.997, val loss 0.276, val accuracy 0.939\n",
            "Epoch 16, train loss 0.025, train accuracy 0.997, val loss 0.278, val accuracy 0.909\n",
            "Epoch 17, train loss 0.023, train accuracy 0.997, val loss 0.384, val accuracy 0.879\n",
            "Epoch 18, train loss 0.038, train accuracy 0.986, val loss 0.273, val accuracy 0.909\n",
            "Epoch 19, train loss 0.014, train accuracy 0.997, val loss 0.229, val accuracy 0.909\n",
            "Fold  1\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.195, train accuracy 0.134, val loss 2.102, val accuracy 0.394\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.087, train accuracy 0.466, val loss 1.858, val accuracy 0.636\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.952, train accuracy 0.764, val loss 1.543, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.779, train accuracy 0.870, val loss 1.171, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.576, train accuracy 0.904, val loss 0.834, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.425, train accuracy 0.952, val loss 0.916, val accuracy 0.758\n",
            "Epoch 6, train loss 0.367, train accuracy 0.890, val loss 0.764, val accuracy 0.848\n",
            "Epoch 7, train loss 0.317, train accuracy 0.884, val loss 0.693, val accuracy 0.818\n",
            "Epoch 8, train loss 0.315, train accuracy 0.863, val loss 0.451, val accuracy 0.939\n",
            "Epoch 9, train loss 0.191, train accuracy 0.966, val loss 0.455, val accuracy 0.848\n",
            "Epoch 10, train loss 0.179, train accuracy 0.952, val loss 0.254, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.123, train accuracy 0.979, val loss 0.302, val accuracy 0.909\n",
            "Epoch 12, train loss 0.111, train accuracy 0.976, val loss 0.229, val accuracy 0.939\n",
            "Epoch 13, train loss 0.091, train accuracy 0.976, val loss 0.204, val accuracy 0.939\n",
            "Epoch 14, train loss 0.071, train accuracy 0.986, val loss 0.181, val accuracy 0.939\n",
            "Epoch 15, train loss 0.054, train accuracy 0.986, val loss 0.174, val accuracy 0.939\n",
            "Epoch 16, train loss 0.046, train accuracy 0.990, val loss 0.146, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.041, train accuracy 0.993, val loss 0.108, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.032, train accuracy 0.997, val loss 0.082, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.025, train accuracy 0.997, val loss 0.064, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  2\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.209, train accuracy 0.106, val loss 2.136, val accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.099, train accuracy 0.428, val loss 1.859, val accuracy 0.697\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.962, train accuracy 0.825, val loss 1.524, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.793, train accuracy 0.918, val loss 1.154, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.607, train accuracy 0.914, val loss 1.070, val accuracy 0.788\n",
            "Epoch 5, train loss 0.564, train accuracy 0.774, val loss 0.712, val accuracy 0.939\n",
            "Epoch 6, train loss 0.365, train accuracy 0.962, val loss 0.711, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.323, train accuracy 0.932, val loss 0.425, val accuracy 0.970\n",
            "Epoch 8, train loss 0.205, train accuracy 0.976, val loss 0.338, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.159, train accuracy 0.979, val loss 0.230, val accuracy 0.970\n",
            "Epoch 10, train loss 0.105, train accuracy 0.983, val loss 0.178, val accuracy 0.970\n",
            "Epoch 11, train loss 0.080, train accuracy 0.983, val loss 0.130, val accuracy 0.970\n",
            "Epoch 12, train loss 0.062, train accuracy 0.990, val loss 0.109, val accuracy 0.970\n",
            "Epoch 13, train loss 0.044, train accuracy 0.990, val loss 0.091, val accuracy 0.970\n",
            "Epoch 14, train loss 0.032, train accuracy 0.997, val loss 0.078, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.027, train accuracy 0.997, val loss 0.123, val accuracy 0.970\n",
            "Epoch 16, train loss 0.027, train accuracy 0.993, val loss 0.116, val accuracy 0.970\n",
            "Epoch 17, train loss 0.021, train accuracy 0.993, val loss 0.139, val accuracy 0.939\n",
            "Epoch 18, train loss 0.039, train accuracy 0.979, val loss 0.115, val accuracy 0.939\n",
            "Epoch 19, train loss 0.029, train accuracy 0.983, val loss 0.075, val accuracy 0.970\n",
            "Fold  3\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.217, train accuracy 0.082, val loss 2.092, val accuracy 0.576\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.101, train accuracy 0.630, val loss 1.915, val accuracy 0.606\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.968, train accuracy 0.781, val loss 1.519, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.783, train accuracy 0.901, val loss 1.110, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.571, train accuracy 0.921, val loss 0.835, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.429, train accuracy 0.935, val loss 0.576, val accuracy 0.879\n",
            "Epoch 6, train loss 0.317, train accuracy 0.911, val loss 0.658, val accuracy 0.758\n",
            "Epoch 7, train loss 0.305, train accuracy 0.815, val loss 0.373, val accuracy 0.970\n",
            "Epoch 8, train loss 0.194, train accuracy 0.955, val loss 0.266, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.164, train accuracy 0.952, val loss 0.193, val accuracy 1.000\n",
            "Epoch 10, train loss 0.134, train accuracy 0.962, val loss 0.128, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.089, train accuracy 0.983, val loss 0.139, val accuracy 0.970\n",
            "Epoch 12, train loss 0.083, train accuracy 0.979, val loss 0.102, val accuracy 0.970\n",
            "Epoch 13, train loss 0.056, train accuracy 0.983, val loss 0.052, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.038, train accuracy 0.993, val loss 0.038, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.037, train accuracy 0.993, val loss 0.023, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.029, train accuracy 0.993, val loss 0.019, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.021, train accuracy 0.997, val loss 0.017, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.016, train accuracy 0.997, val loss 0.015, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.014, train accuracy 0.997, val loss 0.013, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  4\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.218, train accuracy 0.075, val loss 2.231, val accuracy 0.455\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.118, train accuracy 0.596, val loss 2.010, val accuracy 0.485\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.992, train accuracy 0.688, val loss 1.708, val accuracy 0.636\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.850, train accuracy 0.842, val loss 1.437, val accuracy 0.697\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.689, train accuracy 0.870, val loss 1.042, val accuracy 0.758\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.493, train accuracy 0.932, val loss 0.807, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.354, train accuracy 0.949, val loss 0.511, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.260, train accuracy 0.966, val loss 0.432, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.210, train accuracy 0.962, val loss 0.286, val accuracy 0.970\n",
            "Epoch 9, train loss 0.141, train accuracy 0.976, val loss 0.210, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.120, train accuracy 0.979, val loss 0.145, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.072, train accuracy 0.997, val loss 0.188, val accuracy 0.970\n",
            "Epoch 12, train loss 0.060, train accuracy 0.986, val loss 0.136, val accuracy 0.970\n",
            "Epoch 13, train loss 0.053, train accuracy 0.976, val loss 0.093, val accuracy 1.000\n",
            "Epoch 14, train loss 0.029, train accuracy 0.993, val loss 0.179, val accuracy 0.970\n",
            "Epoch 15, train loss 0.032, train accuracy 0.993, val loss 0.061, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.020, train accuracy 0.997, val loss 0.084, val accuracy 0.970\n",
            "Epoch 17, train loss 0.018, train accuracy 0.993, val loss 0.089, val accuracy 0.970\n",
            "Epoch 18, train loss 0.012, train accuracy 0.997, val loss 0.116, val accuracy 0.939\n",
            "Epoch 19, train loss 0.012, train accuracy 0.997, val loss 0.067, val accuracy 0.970\n",
            "Fold  5\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.204, train accuracy 0.137, val loss 2.148, val accuracy 0.188\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.097, train accuracy 0.307, val loss 1.843, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.970, train accuracy 0.853, val loss 1.505, val accuracy 0.906\n",
            "Epoch 3, train loss 0.812, train accuracy 0.877, val loss 1.165, val accuracy 0.906\n",
            "Epoch 4, train loss 0.626, train accuracy 0.809, val loss 0.929, val accuracy 0.875\n",
            "Epoch 5, train loss 0.530, train accuracy 0.826, val loss 0.650, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.375, train accuracy 0.939, val loss 0.463, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.294, train accuracy 0.939, val loss 0.441, val accuracy 0.938\n",
            "Epoch 8, train loss 0.272, train accuracy 0.928, val loss 0.224, val accuracy 1.000\n",
            "Epoch 9, train loss 0.176, train accuracy 0.969, val loss 0.150, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.130, train accuracy 0.966, val loss 0.135, val accuracy 1.000\n",
            "Epoch 11, train loss 0.094, train accuracy 0.980, val loss 0.113, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.085, train accuracy 0.976, val loss 0.073, val accuracy 1.000\n",
            "Epoch 13, train loss 0.055, train accuracy 0.990, val loss 0.049, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.047, train accuracy 0.993, val loss 0.069, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.043, train accuracy 0.990, val loss 0.039, val accuracy 1.000\n",
            "Epoch 16, train loss 0.042, train accuracy 0.980, val loss 0.131, val accuracy 0.969\n",
            "Epoch 17, train loss 0.043, train accuracy 0.986, val loss 0.036, val accuracy 1.000\n",
            "Epoch 18, train loss 0.028, train accuracy 0.990, val loss 0.028, val accuracy 1.000\n",
            "Epoch 19, train loss 0.028, train accuracy 0.983, val loss 0.031, val accuracy 1.000\n",
            "Fold  6\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.210, train accuracy 0.106, val loss 2.220, val accuracy 0.312\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.100, train accuracy 0.461, val loss 1.886, val accuracy 0.625\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.965, train accuracy 0.706, val loss 1.495, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.785, train accuracy 0.850, val loss 1.149, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.588, train accuracy 0.932, val loss 0.951, val accuracy 0.719\n",
            "Epoch 5, train loss 0.484, train accuracy 0.805, val loss 0.698, val accuracy 0.812\n",
            "Epoch 6, train loss 0.432, train accuracy 0.788, val loss 0.880, val accuracy 0.781\n",
            "Epoch 7, train loss 0.455, train accuracy 0.819, val loss 0.568, val accuracy 0.844\n",
            "Epoch 8, train loss 0.256, train accuracy 0.918, val loss 0.516, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.267, train accuracy 0.935, val loss 0.486, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.224, train accuracy 0.949, val loss 0.327, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.150, train accuracy 0.980, val loss 0.253, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.108, train accuracy 0.986, val loss 0.209, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.083, train accuracy 0.986, val loss 0.176, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.070, train accuracy 0.986, val loss 0.125, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.053, train accuracy 0.990, val loss 0.095, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.045, train accuracy 0.993, val loss 0.081, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.037, train accuracy 0.993, val loss 0.076, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.031, train accuracy 0.997, val loss 0.073, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.026, train accuracy 0.997, val loss 0.070, val accuracy 0.969\n",
            "Fold  7\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.217, train accuracy 0.119, val loss 2.249, val accuracy 0.312\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.120, train accuracy 0.461, val loss 1.958, val accuracy 0.625\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 1.001, train accuracy 0.706, val loss 1.560, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.862, train accuracy 0.857, val loss 1.205, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.699, train accuracy 0.867, val loss 0.901, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.551, train accuracy 0.945, val loss 0.635, val accuracy 0.906\n",
            "Epoch 6, train loss 0.385, train accuracy 0.928, val loss 0.453, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.292, train accuracy 0.969, val loss 0.324, val accuracy 0.938\n",
            "Epoch 8, train loss 0.209, train accuracy 0.962, val loss 0.206, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.180, train accuracy 0.939, val loss 0.165, val accuracy 0.969\n",
            "Epoch 10, train loss 0.097, train accuracy 0.986, val loss 0.147, val accuracy 0.938\n",
            "Epoch 11, train loss 0.085, train accuracy 0.976, val loss 0.093, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.061, train accuracy 0.990, val loss 0.095, val accuracy 0.969\n",
            "Epoch 13, train loss 0.047, train accuracy 0.990, val loss 0.138, val accuracy 0.969\n",
            "Epoch 14, train loss 0.046, train accuracy 0.986, val loss 0.121, val accuracy 0.969\n",
            "Epoch 15, train loss 0.052, train accuracy 0.973, val loss 0.106, val accuracy 0.969\n",
            "Epoch 16, train loss 0.039, train accuracy 0.973, val loss 0.110, val accuracy 0.969\n",
            "Epoch 17, train loss 0.035, train accuracy 0.993, val loss 0.137, val accuracy 0.969\n",
            "Epoch 18, train loss 0.027, train accuracy 0.997, val loss 0.137, val accuracy 0.969\n",
            "Epoch 19, train loss 0.020, train accuracy 0.993, val loss 0.134, val accuracy 0.969\n",
            "Fold  8\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.208, train accuracy 0.123, val loss 2.201, val accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.103, train accuracy 0.389, val loss 1.949, val accuracy 0.656\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.972, train accuracy 0.765, val loss 1.641, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.813, train accuracy 0.863, val loss 1.310, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.628, train accuracy 0.870, val loss 0.996, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.458, train accuracy 0.932, val loss 0.919, val accuracy 0.781\n",
            "Epoch 6, train loss 0.375, train accuracy 0.898, val loss 0.662, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.239, train accuracy 0.966, val loss 0.777, val accuracy 0.781\n",
            "Epoch 8, train loss 0.305, train accuracy 0.829, val loss 0.479, val accuracy 0.906\n",
            "Epoch 9, train loss 0.161, train accuracy 0.956, val loss 0.615, val accuracy 0.875\n",
            "Epoch 10, train loss 0.173, train accuracy 0.915, val loss 0.510, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.104, train accuracy 0.983, val loss 0.420, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.076, train accuracy 0.986, val loss 0.386, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.060, train accuracy 0.990, val loss 0.396, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.056, train accuracy 0.983, val loss 0.366, val accuracy 0.938\n",
            "Epoch 15, train loss 0.047, train accuracy 0.976, val loss 0.399, val accuracy 0.906\n",
            "Epoch 16, train loss 0.038, train accuracy 0.997, val loss 0.413, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.035, train accuracy 0.990, val loss 0.356, val accuracy 0.938\n",
            "Epoch 18, train loss 0.029, train accuracy 0.983, val loss 0.348, val accuracy 0.938\n",
            "Epoch 19, train loss 0.020, train accuracy 0.997, val loss 0.382, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Fold  9\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.207, train accuracy 0.130, val loss 2.210, val accuracy 0.156\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.102, train accuracy 0.307, val loss 1.958, val accuracy 0.562\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.978, train accuracy 0.782, val loss 1.581, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.817, train accuracy 0.877, val loss 1.267, val accuracy 0.812\n",
            "Epoch 4, train loss 0.629, train accuracy 0.874, val loss 1.197, val accuracy 0.625\n",
            "Epoch 5, train loss 0.618, train accuracy 0.765, val loss 0.776, val accuracy 0.875\n",
            "Epoch 6, train loss 0.404, train accuracy 0.932, val loss 0.677, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.360, train accuracy 0.942, val loss 0.377, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.221, train accuracy 0.973, val loss 0.326, val accuracy 0.969\n",
            "Epoch 9, train loss 0.187, train accuracy 0.966, val loss 0.250, val accuracy 0.969\n",
            "Epoch 10, train loss 0.132, train accuracy 0.976, val loss 0.198, val accuracy 0.969\n",
            "Epoch 11, train loss 0.109, train accuracy 0.973, val loss 0.140, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.119, train accuracy 0.966, val loss 0.087, val accuracy 1.000\n",
            "Epoch 13, train loss 0.074, train accuracy 0.973, val loss 0.096, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.066, train accuracy 0.983, val loss 0.096, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.052, train accuracy 0.993, val loss 0.106, val accuracy 0.938\n",
            "Epoch 16, train loss 0.048, train accuracy 0.993, val loss 0.069, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.035, train accuracy 0.986, val loss 0.051, val accuracy 1.000\n",
            "Epoch 18, train loss 0.030, train accuracy 0.997, val loss 0.043, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.021, train accuracy 0.997, val loss 0.034, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Random Number 5689\n",
            "Fold  0\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.207, train accuracy 0.099, val loss 2.176, val accuracy 0.424\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.108, train accuracy 0.469, val loss 1.883, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.979, train accuracy 0.825, val loss 1.553, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.816, train accuracy 0.856, val loss 1.199, val accuracy 0.848\n",
            "Epoch 4, train loss 0.629, train accuracy 0.887, val loss 0.962, val accuracy 0.848\n",
            "Epoch 5, train loss 0.541, train accuracy 0.767, val loss 0.791, val accuracy 0.788\n",
            "Epoch 6, train loss 0.418, train accuracy 0.839, val loss 0.532, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.299, train accuracy 0.966, val loss 0.443, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.272, train accuracy 0.955, val loss 0.269, val accuracy 1.000\n",
            "Epoch 9, train loss 0.164, train accuracy 0.962, val loss 0.257, val accuracy 1.000\n",
            "Epoch 10, train loss 0.138, train accuracy 0.979, val loss 0.185, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.100, train accuracy 0.986, val loss 0.111, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.083, train accuracy 0.979, val loss 0.079, val accuracy 1.000\n",
            "Epoch 13, train loss 0.053, train accuracy 0.993, val loss 0.084, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.047, train accuracy 0.990, val loss 0.066, val accuracy 1.000\n",
            "Epoch 15, train loss 0.041, train accuracy 0.990, val loss 0.129, val accuracy 0.939\n",
            "Epoch 16, train loss 0.032, train accuracy 0.990, val loss 0.030, val accuracy 1.000\n",
            "Epoch 17, train loss 0.023, train accuracy 0.993, val loss 0.028, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.018, train accuracy 0.997, val loss 0.030, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.015, train accuracy 0.997, val loss 0.029, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  1\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.204, train accuracy 0.144, val loss 2.075, val accuracy 0.576\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.093, train accuracy 0.555, val loss 1.812, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.954, train accuracy 0.825, val loss 1.457, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.768, train accuracy 0.853, val loss 1.020, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.563, train accuracy 0.911, val loss 0.714, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.414, train accuracy 0.925, val loss 0.669, val accuracy 0.879\n",
            "Epoch 6, train loss 0.404, train accuracy 0.829, val loss 0.412, val accuracy 1.000\n",
            "Epoch 7, train loss 0.263, train accuracy 0.952, val loss 0.348, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.229, train accuracy 0.935, val loss 0.334, val accuracy 0.939\n",
            "Epoch 9, train loss 0.181, train accuracy 0.952, val loss 0.261, val accuracy 0.909\n",
            "Epoch 10, train loss 0.116, train accuracy 0.979, val loss 0.162, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.098, train accuracy 0.976, val loss 0.105, val accuracy 1.000\n",
            "Epoch 12, train loss 0.080, train accuracy 0.969, val loss 0.101, val accuracy 1.000\n",
            "Epoch 13, train loss 0.066, train accuracy 0.979, val loss 0.075, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.044, train accuracy 0.990, val loss 0.069, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.033, train accuracy 0.993, val loss 0.069, val accuracy 0.970\n",
            "Epoch 16, train loss 0.029, train accuracy 0.993, val loss 0.063, val accuracy 0.970\n",
            "Epoch 17, train loss 0.022, train accuracy 0.997, val loss 0.047, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.017, train accuracy 0.997, val loss 0.036, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.014, train accuracy 0.997, val loss 0.029, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  2\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.204, train accuracy 0.113, val loss 2.167, val accuracy 0.364\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.095, train accuracy 0.445, val loss 1.873, val accuracy 0.697\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.958, train accuracy 0.798, val loss 1.483, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.785, train accuracy 0.860, val loss 1.177, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.605, train accuracy 0.877, val loss 0.909, val accuracy 0.818\n",
            "Epoch 5, train loss 0.504, train accuracy 0.887, val loss 0.695, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.344, train accuracy 0.928, val loss 0.573, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.282, train accuracy 0.966, val loss 0.398, val accuracy 0.970\n",
            "Epoch 8, train loss 0.223, train accuracy 0.949, val loss 0.254, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.156, train accuracy 0.962, val loss 0.203, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.129, train accuracy 0.973, val loss 0.113, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.091, train accuracy 0.973, val loss 0.093, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.070, train accuracy 0.986, val loss 0.054, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.049, train accuracy 0.990, val loss 0.036, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.040, train accuracy 0.986, val loss 0.041, val accuracy 1.000\n",
            "Epoch 15, train loss 0.034, train accuracy 0.986, val loss 0.046, val accuracy 1.000\n",
            "Epoch 16, train loss 0.036, train accuracy 0.986, val loss 0.022, val accuracy 1.000\n",
            "Epoch 17, train loss 0.019, train accuracy 0.993, val loss 0.068, val accuracy 0.970\n",
            "Epoch 18, train loss 0.027, train accuracy 0.997, val loss 0.018, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.014, train accuracy 1.000, val loss 0.031, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  3\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.203, train accuracy 0.089, val loss 2.161, val accuracy 0.273\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.102, train accuracy 0.353, val loss 1.874, val accuracy 0.636\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.967, train accuracy 0.805, val loss 1.552, val accuracy 0.758\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.799, train accuracy 0.781, val loss 1.156, val accuracy 0.879\n",
            "Epoch 4, train loss 0.601, train accuracy 0.856, val loss 0.856, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.430, train accuracy 0.966, val loss 0.589, val accuracy 0.909\n",
            "Epoch 6, train loss 0.316, train accuracy 0.938, val loss 0.443, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.237, train accuracy 0.952, val loss 0.357, val accuracy 0.939\n",
            "Epoch 8, train loss 0.202, train accuracy 0.938, val loss 0.344, val accuracy 0.939\n",
            "Epoch 9, train loss 0.147, train accuracy 0.942, val loss 0.200, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.101, train accuracy 0.983, val loss 0.123, val accuracy 0.970\n",
            "Epoch 11, train loss 0.083, train accuracy 0.973, val loss 0.081, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.055, train accuracy 0.990, val loss 0.074, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.047, train accuracy 0.990, val loss 0.055, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.033, train accuracy 0.990, val loss 0.066, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.033, train accuracy 0.993, val loss 0.031, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.020, train accuracy 0.997, val loss 0.024, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.016, train accuracy 0.997, val loss 0.022, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.013, train accuracy 0.997, val loss 0.021, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.011, train accuracy 1.000, val loss 0.014, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  4\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.201, train accuracy 0.086, val loss 2.302, val accuracy 0.121\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.107, train accuracy 0.312, val loss 1.919, val accuracy 0.667\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.971, train accuracy 0.774, val loss 1.527, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.809, train accuracy 0.832, val loss 1.136, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.597, train accuracy 0.938, val loss 0.930, val accuracy 0.848\n",
            "Epoch 5, train loss 0.436, train accuracy 0.908, val loss 0.927, val accuracy 0.788\n",
            "Epoch 6, train loss 0.517, train accuracy 0.760, val loss 0.588, val accuracy 0.909\n",
            "Epoch 7, train loss 0.273, train accuracy 0.962, val loss 0.619, val accuracy 0.818\n",
            "Epoch 8, train loss 0.249, train accuracy 0.925, val loss 0.410, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.183, train accuracy 0.973, val loss 0.297, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.127, train accuracy 0.973, val loss 0.219, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.105, train accuracy 0.979, val loss 0.171, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.079, train accuracy 0.983, val loss 0.138, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.059, train accuracy 0.986, val loss 0.138, val accuracy 0.939\n",
            "Epoch 14, train loss 0.045, train accuracy 0.990, val loss 0.125, val accuracy 0.939\n",
            "Epoch 15, train loss 0.037, train accuracy 0.993, val loss 0.117, val accuracy 0.939\n",
            "Epoch 16, train loss 0.028, train accuracy 0.993, val loss 0.092, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.021, train accuracy 0.993, val loss 0.060, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.018, train accuracy 0.997, val loss 0.138, val accuracy 0.939\n",
            "Epoch 19, train loss 0.015, train accuracy 0.990, val loss 0.083, val accuracy 0.970\n",
            "Fold  5\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.208, train accuracy 0.072, val loss 2.305, val accuracy 0.125\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.119, train accuracy 0.235, val loss 1.987, val accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.999, train accuracy 0.662, val loss 1.660, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.852, train accuracy 0.809, val loss 1.283, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.667, train accuracy 0.887, val loss 1.084, val accuracy 0.781\n",
            "Epoch 5, train loss 0.526, train accuracy 0.823, val loss 0.894, val accuracy 0.875\n",
            "Epoch 6, train loss 0.434, train accuracy 0.881, val loss 0.576, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.284, train accuracy 0.966, val loss 0.455, val accuracy 0.938\n",
            "Epoch 8, train loss 0.221, train accuracy 0.969, val loss 0.285, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.147, train accuracy 0.976, val loss 0.212, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.103, train accuracy 0.986, val loss 0.148, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.077, train accuracy 0.983, val loss 0.169, val accuracy 1.000\n",
            "Epoch 12, train loss 0.068, train accuracy 0.973, val loss 0.089, val accuracy 1.000\n",
            "Epoch 13, train loss 0.060, train accuracy 0.973, val loss 0.064, val accuracy 1.000\n",
            "Epoch 14, train loss 0.037, train accuracy 0.990, val loss 0.102, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.033, train accuracy 0.997, val loss 0.045, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.024, train accuracy 1.000, val loss 0.032, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.018, train accuracy 0.997, val loss 0.029, val accuracy 1.000\n",
            "Epoch 18, train loss 0.015, train accuracy 1.000, val loss 0.024, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.011, train accuracy 1.000, val loss 0.019, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  6\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.212, train accuracy 0.123, val loss 2.243, val accuracy 0.188\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.122, train accuracy 0.300, val loss 1.964, val accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.991, train accuracy 0.717, val loss 1.637, val accuracy 0.656\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.834, train accuracy 0.843, val loss 1.307, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.649, train accuracy 0.877, val loss 1.101, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.526, train accuracy 0.846, val loss 0.950, val accuracy 0.719\n",
            "Epoch 6, train loss 0.492, train accuracy 0.771, val loss 0.736, val accuracy 0.781\n",
            "Epoch 7, train loss 0.361, train accuracy 0.881, val loss 0.581, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.277, train accuracy 0.932, val loss 0.392, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.205, train accuracy 0.983, val loss 0.274, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.156, train accuracy 0.973, val loss 0.285, val accuracy 0.938\n",
            "Epoch 11, train loss 0.131, train accuracy 0.976, val loss 0.195, val accuracy 0.938\n",
            "Epoch 12, train loss 0.090, train accuracy 0.976, val loss 0.162, val accuracy 0.969\n",
            "Epoch 13, train loss 0.074, train accuracy 0.980, val loss 0.186, val accuracy 0.938\n",
            "Epoch 14, train loss 0.078, train accuracy 0.986, val loss 0.096, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.056, train accuracy 0.990, val loss 0.086, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.042, train accuracy 0.993, val loss 0.085, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.033, train accuracy 0.993, val loss 0.078, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.026, train accuracy 0.997, val loss 0.054, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.020, train accuracy 0.997, val loss 0.037, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  7\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.209, train accuracy 0.143, val loss 2.267, val accuracy 0.156\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.116, train accuracy 0.263, val loss 2.005, val accuracy 0.688\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.984, train accuracy 0.867, val loss 1.734, val accuracy 0.656\n",
            "Epoch 3, train loss 0.826, train accuracy 0.860, val loss 1.366, val accuracy 0.719\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.628, train accuracy 0.904, val loss 1.215, val accuracy 0.719\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.474, train accuracy 0.887, val loss 0.993, val accuracy 0.719\n",
            "Epoch 6, train loss 0.404, train accuracy 0.867, val loss 0.915, val accuracy 0.688\n",
            "Epoch 7, train loss 0.303, train accuracy 0.925, val loss 0.832, val accuracy 0.750\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.243, train accuracy 0.959, val loss 0.754, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.184, train accuracy 0.973, val loss 0.614, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.143, train accuracy 0.980, val loss 0.507, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.098, train accuracy 0.990, val loss 0.422, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.080, train accuracy 0.997, val loss 0.418, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.053, train accuracy 0.993, val loss 0.408, val accuracy 0.875\n",
            "Epoch 14, train loss 0.042, train accuracy 0.997, val loss 0.382, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.033, train accuracy 0.997, val loss 0.376, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.024, train accuracy 0.997, val loss 0.428, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.020, train accuracy 0.997, val loss 0.371, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.015, train accuracy 0.997, val loss 0.388, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.011, train accuracy 0.997, val loss 0.418, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Fold  8\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.211, train accuracy 0.092, val loss 2.164, val accuracy 0.219\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.118, train accuracy 0.362, val loss 1.828, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.982, train accuracy 0.857, val loss 1.461, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.823, train accuracy 0.843, val loss 1.043, val accuracy 0.938\n",
            "Epoch 4, train loss 0.619, train accuracy 0.904, val loss 0.702, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.439, train accuracy 0.949, val loss 0.592, val accuracy 0.938\n",
            "Epoch 6, train loss 0.412, train accuracy 0.911, val loss 0.301, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.224, train accuracy 0.973, val loss 0.351, val accuracy 0.938\n",
            "Epoch 8, train loss 0.241, train accuracy 0.874, val loss 0.136, val accuracy 1.000\n",
            "Epoch 9, train loss 0.155, train accuracy 0.959, val loss 0.176, val accuracy 0.969\n",
            "Epoch 10, train loss 0.142, train accuracy 0.945, val loss 0.242, val accuracy 0.906\n",
            "Epoch 11, train loss 0.109, train accuracy 0.966, val loss 0.106, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.084, train accuracy 0.966, val loss 0.066, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.063, train accuracy 0.983, val loss 0.045, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.048, train accuracy 0.986, val loss 0.048, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.048, train accuracy 0.980, val loss 0.040, val accuracy 1.000\n",
            "Epoch 16, train loss 0.036, train accuracy 0.990, val loss 0.037, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.029, train accuracy 0.990, val loss 0.031, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.025, train accuracy 0.993, val loss 0.027, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.017, train accuracy 0.993, val loss 0.022, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  9\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.211, train accuracy 0.065, val loss 2.150, val accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.098, train accuracy 0.522, val loss 1.886, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.961, train accuracy 0.799, val loss 1.525, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.766, train accuracy 0.901, val loss 1.259, val accuracy 0.812\n",
            "Epoch 4, train loss 0.587, train accuracy 0.908, val loss 0.849, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.418, train accuracy 0.935, val loss 0.747, val accuracy 0.875\n",
            "Epoch 6, train loss 0.360, train accuracy 0.887, val loss 0.545, val accuracy 0.938\n",
            "Epoch 7, train loss 0.233, train accuracy 0.959, val loss 0.463, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.166, train accuracy 0.980, val loss 0.352, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.124, train accuracy 0.969, val loss 0.310, val accuracy 0.969\n",
            "Epoch 10, train loss 0.092, train accuracy 0.986, val loss 0.286, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.063, train accuracy 0.986, val loss 0.315, val accuracy 0.938\n",
            "Epoch 12, train loss 0.048, train accuracy 0.990, val loss 0.273, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.036, train accuracy 0.993, val loss 0.334, val accuracy 0.938\n",
            "Epoch 14, train loss 0.035, train accuracy 0.993, val loss 0.247, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.030, train accuracy 0.990, val loss 0.303, val accuracy 0.938\n",
            "Epoch 16, train loss 0.025, train accuracy 0.990, val loss 0.272, val accuracy 0.969\n",
            "Epoch 17, train loss 0.021, train accuracy 0.993, val loss 0.262, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.015, train accuracy 1.000, val loss 0.250, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.011, train accuracy 1.000, val loss 0.238, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Random Number 2746\n",
            "Fold  0\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.192, train accuracy 0.134, val loss 2.156, val accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.074, train accuracy 0.408, val loss 1.852, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.928, train accuracy 0.866, val loss 1.507, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.723, train accuracy 0.945, val loss 1.109, val accuracy 0.848\n",
            "Epoch 4, train loss 0.505, train accuracy 0.938, val loss 0.857, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.353, train accuracy 0.949, val loss 0.713, val accuracy 0.848\n",
            "Epoch 6, train loss 0.346, train accuracy 0.863, val loss 0.746, val accuracy 0.818\n",
            "Epoch 7, train loss 0.409, train accuracy 0.849, val loss 0.684, val accuracy 0.788\n",
            "Epoch 8, train loss 0.362, train accuracy 0.849, val loss 0.643, val accuracy 0.818\n",
            "Epoch 9, train loss 0.270, train accuracy 0.901, val loss 0.523, val accuracy 0.939\n",
            "Epoch 10, train loss 0.218, train accuracy 0.969, val loss 0.424, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.171, train accuracy 0.962, val loss 0.266, val accuracy 1.000\n",
            "Epoch 12, train loss 0.119, train accuracy 0.976, val loss 0.238, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.100, train accuracy 0.979, val loss 0.177, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.085, train accuracy 0.983, val loss 0.147, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.065, train accuracy 0.990, val loss 0.119, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.055, train accuracy 0.986, val loss 0.099, val accuracy 1.000\n",
            "Epoch 17, train loss 0.054, train accuracy 0.983, val loss 0.086, val accuracy 1.000\n",
            "Epoch 18, train loss 0.040, train accuracy 0.990, val loss 0.112, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.042, train accuracy 0.993, val loss 0.070, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  1\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.206, train accuracy 0.041, val loss 2.181, val accuracy 0.182\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.082, train accuracy 0.432, val loss 1.866, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.938, train accuracy 0.880, val loss 1.495, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.748, train accuracy 0.928, val loss 1.080, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.538, train accuracy 0.955, val loss 0.872, val accuracy 0.879\n",
            "Epoch 5, train loss 0.394, train accuracy 0.918, val loss 0.634, val accuracy 0.909\n",
            "Epoch 6, train loss 0.331, train accuracy 0.918, val loss 0.642, val accuracy 0.818\n",
            "Epoch 7, train loss 0.304, train accuracy 0.839, val loss 0.428, val accuracy 0.970\n",
            "Epoch 8, train loss 0.214, train accuracy 0.969, val loss 0.711, val accuracy 0.758\n",
            "Epoch 9, train loss 0.268, train accuracy 0.839, val loss 0.232, val accuracy 1.000\n",
            "Epoch 10, train loss 0.129, train accuracy 0.969, val loss 0.193, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.151, train accuracy 0.952, val loss 0.186, val accuracy 0.970\n",
            "Epoch 12, train loss 0.121, train accuracy 0.969, val loss 0.204, val accuracy 0.970\n",
            "Epoch 13, train loss 0.106, train accuracy 0.969, val loss 0.186, val accuracy 0.970\n",
            "Epoch 14, train loss 0.083, train accuracy 0.962, val loss 0.162, val accuracy 1.000\n",
            "Epoch 15, train loss 0.071, train accuracy 0.990, val loss 0.115, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.056, train accuracy 0.990, val loss 0.094, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.047, train accuracy 0.990, val loss 0.082, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.039, train accuracy 0.993, val loss 0.073, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.032, train accuracy 0.993, val loss 0.067, val accuracy 0.970\n",
            "Fold  2\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.199, train accuracy 0.089, val loss 2.196, val accuracy 0.394\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.089, train accuracy 0.603, val loss 1.888, val accuracy 0.606\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.952, train accuracy 0.729, val loss 1.541, val accuracy 0.758\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.787, train accuracy 0.918, val loss 1.113, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.585, train accuracy 0.949, val loss 0.835, val accuracy 0.909\n",
            "Epoch 5, train loss 0.427, train accuracy 0.921, val loss 0.713, val accuracy 0.788\n",
            "Epoch 6, train loss 0.401, train accuracy 0.829, val loss 0.505, val accuracy 0.970\n",
            "Epoch 7, train loss 0.252, train accuracy 0.942, val loss 0.375, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.220, train accuracy 0.932, val loss 0.240, val accuracy 1.000\n",
            "Epoch 9, train loss 0.150, train accuracy 0.969, val loss 0.170, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.124, train accuracy 0.979, val loss 0.123, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.090, train accuracy 0.983, val loss 0.085, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.079, train accuracy 0.969, val loss 0.114, val accuracy 1.000\n",
            "Epoch 13, train loss 0.071, train accuracy 0.983, val loss 0.074, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.055, train accuracy 0.990, val loss 0.051, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.041, train accuracy 0.990, val loss 0.050, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.032, train accuracy 0.993, val loss 0.040, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.025, train accuracy 0.993, val loss 0.030, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.022, train accuracy 0.997, val loss 0.022, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.016, train accuracy 0.997, val loss 0.019, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  3\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.197, train accuracy 0.110, val loss 2.203, val accuracy 0.212\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.082, train accuracy 0.408, val loss 1.887, val accuracy 0.545\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.939, train accuracy 0.784, val loss 1.573, val accuracy 0.667\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.764, train accuracy 0.757, val loss 1.202, val accuracy 0.818\n",
            "Epoch 4, train loss 0.552, train accuracy 0.959, val loss 0.961, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.389, train accuracy 0.918, val loss 1.038, val accuracy 0.667\n",
            "Epoch 6, train loss 0.380, train accuracy 0.815, val loss 0.738, val accuracy 0.818\n",
            "Epoch 7, train loss 0.273, train accuracy 0.928, val loss 0.708, val accuracy 0.848\n",
            "Epoch 8, train loss 0.242, train accuracy 0.942, val loss 0.689, val accuracy 0.818\n",
            "Epoch 9, train loss 0.192, train accuracy 0.938, val loss 0.611, val accuracy 0.879\n",
            "Epoch 10, train loss 0.164, train accuracy 0.955, val loss 0.582, val accuracy 0.879\n",
            "Epoch 11, train loss 0.120, train accuracy 0.979, val loss 0.579, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.095, train accuracy 0.983, val loss 0.516, val accuracy 0.879\n",
            "Epoch 13, train loss 0.066, train accuracy 0.993, val loss 0.503, val accuracy 0.848\n",
            "Epoch 14, train loss 0.054, train accuracy 1.000, val loss 0.506, val accuracy 0.879\n",
            "Epoch 15, train loss 0.036, train accuracy 1.000, val loss 0.529, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.028, train accuracy 1.000, val loss 0.537, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.026, train accuracy 1.000, val loss 0.551, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.020, train accuracy 1.000, val loss 0.565, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.017, train accuracy 1.000, val loss 0.555, val accuracy 0.879\n",
            "Fold  4\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.220, train accuracy 0.113, val loss 2.144, val accuracy 0.424\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.101, train accuracy 0.589, val loss 1.873, val accuracy 0.788\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.972, train accuracy 0.832, val loss 1.492, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.790, train accuracy 0.921, val loss 1.108, val accuracy 0.848\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.592, train accuracy 0.932, val loss 0.799, val accuracy 0.879\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.454, train accuracy 0.932, val loss 0.540, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.298, train accuracy 0.955, val loss 0.460, val accuracy 0.909\n",
            "Epoch 7, train loss 0.263, train accuracy 0.921, val loss 0.527, val accuracy 0.879\n",
            "Epoch 8, train loss 0.374, train accuracy 0.815, val loss 0.563, val accuracy 0.879\n",
            "Epoch 9, train loss 0.290, train accuracy 0.887, val loss 0.349, val accuracy 0.939\n",
            "Epoch 10, train loss 0.185, train accuracy 0.952, val loss 0.259, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.149, train accuracy 0.969, val loss 0.212, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.149, train accuracy 0.966, val loss 0.187, val accuracy 0.970\n",
            "Epoch 13, train loss 0.094, train accuracy 0.976, val loss 0.178, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.076, train accuracy 0.983, val loss 0.126, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.071, train accuracy 0.983, val loss 0.094, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.055, train accuracy 0.990, val loss 0.074, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.043, train accuracy 0.997, val loss 0.066, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.040, train accuracy 0.997, val loss 0.058, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.034, train accuracy 0.993, val loss 0.045, val accuracy 1.000\n",
            "Fold  5\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.215, train accuracy 0.092, val loss 2.277, val accuracy 0.156\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.098, train accuracy 0.430, val loss 1.924, val accuracy 0.562\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.959, train accuracy 0.802, val loss 1.540, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.784, train accuracy 0.918, val loss 1.165, val accuracy 0.906\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.586, train accuracy 0.908, val loss 1.011, val accuracy 0.781\n",
            "Epoch 5, train loss 0.508, train accuracy 0.816, val loss 0.666, val accuracy 0.969\n",
            "Epoch 6, train loss 0.352, train accuracy 0.932, val loss 0.590, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.259, train accuracy 0.956, val loss 0.362, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.217, train accuracy 0.952, val loss 0.383, val accuracy 0.938\n",
            "Epoch 9, train loss 0.172, train accuracy 0.952, val loss 0.263, val accuracy 0.969\n",
            "Epoch 10, train loss 0.120, train accuracy 0.983, val loss 0.234, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.115, train accuracy 0.969, val loss 0.240, val accuracy 0.969\n",
            "Epoch 12, train loss 0.096, train accuracy 0.973, val loss 0.173, val accuracy 0.969\n",
            "Epoch 13, train loss 0.072, train accuracy 0.980, val loss 0.097, val accuracy 0.969\n",
            "Epoch 14, train loss 0.062, train accuracy 0.976, val loss 0.067, val accuracy 1.000\n",
            "Epoch 15, train loss 0.046, train accuracy 0.990, val loss 0.078, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.043, train accuracy 0.986, val loss 0.072, val accuracy 0.969\n",
            "Epoch 17, train loss 0.029, train accuracy 0.986, val loss 0.102, val accuracy 0.969\n",
            "Epoch 18, train loss 0.025, train accuracy 0.990, val loss 0.126, val accuracy 0.969\n",
            "Epoch 19, train loss 0.023, train accuracy 0.997, val loss 0.128, val accuracy 0.969\n",
            "Fold  6\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.201, train accuracy 0.078, val loss 2.203, val accuracy 0.188\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.086, train accuracy 0.454, val loss 1.913, val accuracy 0.594\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.945, train accuracy 0.754, val loss 1.540, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.764, train accuracy 0.935, val loss 1.138, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.555, train accuracy 0.959, val loss 0.956, val accuracy 0.844\n",
            "Epoch 5, train loss 0.416, train accuracy 0.932, val loss 0.659, val accuracy 0.938\n",
            "Epoch 6, train loss 0.311, train accuracy 0.935, val loss 0.733, val accuracy 0.781\n",
            "Epoch 7, train loss 0.294, train accuracy 0.887, val loss 0.430, val accuracy 0.938\n",
            "Epoch 8, train loss 0.234, train accuracy 0.911, val loss 0.350, val accuracy 0.969\n",
            "Epoch 9, train loss 0.183, train accuracy 0.956, val loss 0.348, val accuracy 0.938\n",
            "Epoch 10, train loss 0.140, train accuracy 0.962, val loss 0.221, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.106, train accuracy 0.969, val loss 0.188, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.090, train accuracy 0.976, val loss 0.134, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.073, train accuracy 0.980, val loss 0.083, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.052, train accuracy 0.986, val loss 0.102, val accuracy 0.969\n",
            "Epoch 15, train loss 0.040, train accuracy 0.986, val loss 0.091, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.033, train accuracy 0.990, val loss 0.058, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.025, train accuracy 0.990, val loss 0.043, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.020, train accuracy 1.000, val loss 0.033, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.017, train accuracy 1.000, val loss 0.025, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  7\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.220, train accuracy 0.068, val loss 2.173, val accuracy 0.219\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.096, train accuracy 0.430, val loss 1.832, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.957, train accuracy 0.922, val loss 1.452, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.761, train accuracy 0.925, val loss 1.008, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.558, train accuracy 0.949, val loss 0.812, val accuracy 0.938\n",
            "Epoch 5, train loss 0.433, train accuracy 0.887, val loss 0.620, val accuracy 0.875\n",
            "Epoch 6, train loss 0.383, train accuracy 0.884, val loss 0.398, val accuracy 1.000\n",
            "Epoch 7, train loss 0.316, train accuracy 0.942, val loss 0.473, val accuracy 0.906\n",
            "Epoch 8, train loss 0.322, train accuracy 0.853, val loss 0.267, val accuracy 0.969\n",
            "Epoch 9, train loss 0.168, train accuracy 0.966, val loss 0.297, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.143, train accuracy 0.969, val loss 0.240, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.115, train accuracy 0.973, val loss 0.150, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.085, train accuracy 0.976, val loss 0.127, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.068, train accuracy 0.986, val loss 0.107, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.052, train accuracy 0.993, val loss 0.093, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.043, train accuracy 0.990, val loss 0.099, val accuracy 1.000\n",
            "Epoch 16, train loss 0.049, train accuracy 0.980, val loss 0.072, val accuracy 1.000\n",
            "Epoch 17, train loss 0.059, train accuracy 0.983, val loss 0.058, val accuracy 1.000\n",
            "Epoch 18, train loss 0.051, train accuracy 0.980, val loss 0.053, val accuracy 1.000\n",
            "Epoch 19, train loss 0.041, train accuracy 0.986, val loss 0.058, val accuracy 1.000\n",
            "Fold  8\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.210, train accuracy 0.092, val loss 2.146, val accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.104, train accuracy 0.543, val loss 1.843, val accuracy 0.688\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.972, train accuracy 0.737, val loss 1.490, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.808, train accuracy 0.925, val loss 1.085, val accuracy 0.938\n",
            "Epoch 4, train loss 0.599, train accuracy 0.935, val loss 0.700, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 5, train loss 0.410, train accuracy 0.952, val loss 0.604, val accuracy 0.875\n",
            "Epoch 6, train loss 0.372, train accuracy 0.884, val loss 0.427, val accuracy 0.969\n",
            "Epoch 7, train loss 0.255, train accuracy 0.928, val loss 0.313, val accuracy 0.969\n",
            "Epoch 8, train loss 0.209, train accuracy 0.949, val loss 0.325, val accuracy 0.938\n",
            "Epoch 9, train loss 0.281, train accuracy 0.860, val loss 0.294, val accuracy 0.906\n",
            "Epoch 10, train loss 0.159, train accuracy 0.952, val loss 0.242, val accuracy 0.938\n",
            "Epoch 11, train loss 0.150, train accuracy 0.952, val loss 0.160, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.110, train accuracy 0.976, val loss 0.120, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.088, train accuracy 0.983, val loss 0.073, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.064, train accuracy 0.990, val loss 0.058, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.053, train accuracy 0.986, val loss 0.095, val accuracy 0.969\n",
            "Epoch 16, train loss 0.047, train accuracy 0.986, val loss 0.097, val accuracy 0.969\n",
            "Epoch 17, train loss 0.046, train accuracy 0.980, val loss 0.045, val accuracy 1.000\n",
            "Epoch 18, train loss 0.030, train accuracy 0.997, val loss 0.085, val accuracy 0.969\n",
            "Epoch 19, train loss 0.029, train accuracy 0.990, val loss 0.031, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  9\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.207, train accuracy 0.126, val loss 2.090, val accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.087, train accuracy 0.519, val loss 1.817, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.945, train accuracy 0.874, val loss 1.468, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.774, train accuracy 0.922, val loss 1.077, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.576, train accuracy 0.932, val loss 0.856, val accuracy 0.875\n",
            "Epoch 5, train loss 0.443, train accuracy 0.915, val loss 0.861, val accuracy 0.875\n",
            "Epoch 6, train loss 0.487, train accuracy 0.819, val loss 0.469, val accuracy 0.969\n",
            "Epoch 7, train loss 0.259, train accuracy 0.973, val loss 0.490, val accuracy 0.906\n",
            "Epoch 8, train loss 0.234, train accuracy 0.928, val loss 0.290, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.169, train accuracy 0.952, val loss 0.205, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.128, train accuracy 0.969, val loss 0.365, val accuracy 0.875\n",
            "Epoch 11, train loss 0.150, train accuracy 0.935, val loss 0.155, val accuracy 0.969\n",
            "Epoch 12, train loss 0.125, train accuracy 0.962, val loss 0.131, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.107, train accuracy 0.962, val loss 0.135, val accuracy 0.969\n",
            "Epoch 14, train loss 0.088, train accuracy 0.966, val loss 0.092, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.060, train accuracy 0.983, val loss 0.097, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.051, train accuracy 0.993, val loss 0.096, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.038, train accuracy 0.993, val loss 0.064, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.030, train accuracy 0.997, val loss 0.035, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.027, train accuracy 0.993, val loss 0.033, val accuracy 1.000\n",
            "Random Number 8964\n",
            "Fold  0\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.204, train accuracy 0.086, val loss 2.230, val accuracy 0.212\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.094, train accuracy 0.373, val loss 1.935, val accuracy 0.576\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.958, train accuracy 0.729, val loss 1.585, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.793, train accuracy 0.914, val loss 1.232, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.602, train accuracy 0.921, val loss 1.023, val accuracy 0.818\n",
            "Epoch 5, train loss 0.489, train accuracy 0.842, val loss 1.023, val accuracy 0.636\n",
            "Epoch 6, train loss 0.547, train accuracy 0.702, val loss 0.554, val accuracy 1.000\n",
            "Epoch 7, train loss 0.307, train accuracy 0.962, val loss 0.549, val accuracy 0.909\n",
            "Epoch 8, train loss 0.328, train accuracy 0.901, val loss 0.435, val accuracy 0.939\n",
            "Epoch 9, train loss 0.256, train accuracy 0.925, val loss 0.337, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.198, train accuracy 0.962, val loss 0.230, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.153, train accuracy 0.966, val loss 0.199, val accuracy 0.970\n",
            "Epoch 12, train loss 0.120, train accuracy 0.973, val loss 0.113, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.090, train accuracy 0.986, val loss 0.069, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.069, train accuracy 0.986, val loss 0.053, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.059, train accuracy 0.983, val loss 0.037, val accuracy 1.000\n",
            "Epoch 16, train loss 0.046, train accuracy 0.986, val loss 0.024, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.033, train accuracy 0.993, val loss 0.018, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.027, train accuracy 0.993, val loss 0.016, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.021, train accuracy 1.000, val loss 0.013, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  1\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.209, train accuracy 0.068, val loss 2.265, val accuracy 0.394\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.118, train accuracy 0.551, val loss 1.953, val accuracy 0.606\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.987, train accuracy 0.771, val loss 1.568, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.838, train accuracy 0.897, val loss 1.197, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.644, train accuracy 0.921, val loss 0.876, val accuracy 0.848\n",
            "Epoch 5, train loss 0.475, train accuracy 0.925, val loss 0.854, val accuracy 0.758\n",
            "Epoch 6, train loss 0.405, train accuracy 0.873, val loss 0.598, val accuracy 0.909\n",
            "Epoch 7, train loss 0.307, train accuracy 0.949, val loss 0.566, val accuracy 0.848\n",
            "Epoch 8, train loss 0.297, train accuracy 0.897, val loss 0.392, val accuracy 0.818\n",
            "Epoch 9, train loss 0.202, train accuracy 0.908, val loss 0.296, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.163, train accuracy 0.979, val loss 0.239, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.129, train accuracy 0.976, val loss 0.176, val accuracy 0.970\n",
            "Epoch 12, train loss 0.094, train accuracy 0.976, val loss 0.133, val accuracy 1.000\n",
            "Epoch 13, train loss 0.078, train accuracy 0.983, val loss 0.104, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.063, train accuracy 0.986, val loss 0.098, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.053, train accuracy 0.983, val loss 0.061, val accuracy 1.000\n",
            "Epoch 16, train loss 0.040, train accuracy 0.986, val loss 0.045, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.032, train accuracy 0.993, val loss 0.068, val accuracy 0.970\n",
            "Epoch 18, train loss 0.026, train accuracy 0.993, val loss 0.086, val accuracy 0.970\n",
            "Epoch 19, train loss 0.020, train accuracy 0.993, val loss 0.021, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  2\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.210, train accuracy 0.144, val loss 2.277, val accuracy 0.152\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.108, train accuracy 0.435, val loss 1.894, val accuracy 0.667\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.980, train accuracy 0.757, val loss 1.502, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.821, train accuracy 0.932, val loss 1.127, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.635, train accuracy 0.969, val loss 0.906, val accuracy 0.848\n",
            "Epoch 5, train loss 0.505, train accuracy 0.866, val loss 0.743, val accuracy 0.879\n",
            "Epoch 6, train loss 0.469, train accuracy 0.863, val loss 0.528, val accuracy 0.970\n",
            "Epoch 7, train loss 0.293, train accuracy 0.928, val loss 0.397, val accuracy 0.909\n",
            "Epoch 8, train loss 0.232, train accuracy 0.962, val loss 0.296, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.164, train accuracy 0.976, val loss 0.222, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.130, train accuracy 0.990, val loss 0.170, val accuracy 0.970\n",
            "Epoch 11, train loss 0.091, train accuracy 0.983, val loss 0.167, val accuracy 0.970\n",
            "Epoch 12, train loss 0.070, train accuracy 0.979, val loss 0.145, val accuracy 0.970\n",
            "Epoch 13, train loss 0.051, train accuracy 0.990, val loss 0.120, val accuracy 0.970\n",
            "Epoch 14, train loss 0.040, train accuracy 0.993, val loss 0.107, val accuracy 0.970\n",
            "Epoch 15, train loss 0.031, train accuracy 0.993, val loss 0.090, val accuracy 0.970\n",
            "Epoch 16, train loss 0.023, train accuracy 0.997, val loss 0.072, val accuracy 0.970\n",
            "Epoch 17, train loss 0.019, train accuracy 0.997, val loss 0.095, val accuracy 0.970\n",
            "Epoch 18, train loss 0.014, train accuracy 0.997, val loss 0.129, val accuracy 0.939\n",
            "Epoch 19, train loss 0.012, train accuracy 1.000, val loss 0.095, val accuracy 0.970\n",
            "Fold  3\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.190, train accuracy 0.158, val loss 2.130, val accuracy 0.364\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.082, train accuracy 0.473, val loss 1.829, val accuracy 0.606\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.951, train accuracy 0.750, val loss 1.493, val accuracy 0.909\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.788, train accuracy 0.921, val loss 1.103, val accuracy 0.818\n",
            "Epoch 4, train loss 0.592, train accuracy 0.849, val loss 0.914, val accuracy 0.848\n",
            "Epoch 5, train loss 0.501, train accuracy 0.877, val loss 0.681, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.339, train accuracy 0.935, val loss 0.499, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.244, train accuracy 0.962, val loss 0.386, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.167, train accuracy 0.969, val loss 0.332, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.146, train accuracy 0.983, val loss 0.250, val accuracy 0.939\n",
            "Epoch 10, train loss 0.109, train accuracy 0.962, val loss 0.211, val accuracy 0.970\n",
            "Epoch 11, train loss 0.080, train accuracy 0.969, val loss 0.180, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.060, train accuracy 0.986, val loss 0.205, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.053, train accuracy 0.993, val loss 0.218, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.046, train accuracy 0.983, val loss 0.168, val accuracy 0.970\n",
            "Epoch 15, train loss 0.029, train accuracy 0.997, val loss 0.164, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.025, train accuracy 0.997, val loss 0.187, val accuracy 0.970\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.020, train accuracy 0.993, val loss 0.240, val accuracy 0.909\n",
            "Epoch 18, train loss 0.016, train accuracy 0.997, val loss 0.222, val accuracy 0.939\n",
            "Epoch 19, train loss 0.015, train accuracy 0.997, val loss 0.168, val accuracy 0.939\n",
            "Fold  4\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.194, train accuracy 0.185, val loss 2.184, val accuracy 0.061\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.087, train accuracy 0.229, val loss 1.836, val accuracy 0.818\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.951, train accuracy 0.825, val loss 1.550, val accuracy 0.788\n",
            "Epoch 3, train loss 0.798, train accuracy 0.849, val loss 1.235, val accuracy 0.606\n",
            "Epoch 4, train loss 0.661, train accuracy 0.685, val loss 1.036, val accuracy 0.758\n",
            "Epoch 5, train loss 0.509, train accuracy 0.880, val loss 0.853, val accuracy 0.939\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.432, train accuracy 0.955, val loss 0.543, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.275, train accuracy 0.973, val loss 0.487, val accuracy 0.909\n",
            "Epoch 8, train loss 0.229, train accuracy 0.969, val loss 0.605, val accuracy 0.848\n",
            "Epoch 9, train loss 0.195, train accuracy 0.945, val loss 0.297, val accuracy 0.970\n",
            "Epoch 10, train loss 0.154, train accuracy 0.966, val loss 0.193, val accuracy 0.970\n",
            "Epoch 11, train loss 0.098, train accuracy 0.976, val loss 0.202, val accuracy 0.970\n",
            "Epoch 12, train loss 0.075, train accuracy 0.986, val loss 0.189, val accuracy 0.970\n",
            "Epoch 13, train loss 0.058, train accuracy 0.990, val loss 0.150, val accuracy 0.970\n",
            "Epoch 14, train loss 0.041, train accuracy 0.990, val loss 0.164, val accuracy 0.970\n",
            "Epoch 15, train loss 0.033, train accuracy 0.993, val loss 0.183, val accuracy 0.939\n",
            "Epoch 16, train loss 0.028, train accuracy 0.993, val loss 0.199, val accuracy 0.909\n",
            "Epoch 17, train loss 0.023, train accuracy 0.993, val loss 0.170, val accuracy 0.939\n",
            "Epoch 18, train loss 0.018, train accuracy 0.993, val loss 0.163, val accuracy 0.939\n",
            "Epoch 19, train loss 0.014, train accuracy 0.993, val loss 0.161, val accuracy 0.939\n",
            "Fold  5\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.210, train accuracy 0.137, val loss 2.159, val accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.106, train accuracy 0.365, val loss 1.892, val accuracy 0.562\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.978, train accuracy 0.724, val loss 1.546, val accuracy 0.781\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.807, train accuracy 0.870, val loss 1.191, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.612, train accuracy 0.952, val loss 0.915, val accuracy 0.844\n",
            "Epoch 5, train loss 0.427, train accuracy 0.922, val loss 0.597, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.296, train accuracy 0.956, val loss 0.511, val accuracy 0.938\n",
            "Epoch 7, train loss 0.247, train accuracy 0.939, val loss 0.310, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.170, train accuracy 0.949, val loss 0.411, val accuracy 0.938\n",
            "Epoch 9, train loss 0.305, train accuracy 0.867, val loss 0.240, val accuracy 0.969\n",
            "Epoch 10, train loss 0.150, train accuracy 0.949, val loss 0.187, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.108, train accuracy 0.959, val loss 0.196, val accuracy 0.938\n",
            "Epoch 12, train loss 0.112, train accuracy 0.949, val loss 0.136, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.073, train accuracy 0.973, val loss 0.112, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.060, train accuracy 0.990, val loss 0.107, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.051, train accuracy 0.990, val loss 0.093, val accuracy 0.938\n",
            "Epoch 16, train loss 0.044, train accuracy 0.993, val loss 0.064, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.033, train accuracy 0.997, val loss 0.047, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.025, train accuracy 0.997, val loss 0.043, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.021, train accuracy 0.997, val loss 0.041, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  6\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.211, train accuracy 0.096, val loss 2.191, val accuracy 0.125\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.099, train accuracy 0.304, val loss 1.874, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.963, train accuracy 0.850, val loss 1.569, val accuracy 0.844\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.789, train accuracy 0.935, val loss 1.193, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.594, train accuracy 0.956, val loss 1.106, val accuracy 0.781\n",
            "Epoch 5, train loss 0.496, train accuracy 0.836, val loss 1.222, val accuracy 0.562\n",
            "Epoch 6, train loss 0.554, train accuracy 0.689, val loss 0.599, val accuracy 0.938\n",
            "Epoch 7, train loss 0.292, train accuracy 0.966, val loss 0.643, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.286, train accuracy 0.959, val loss 0.532, val accuracy 0.969\n",
            "Epoch 9, train loss 0.214, train accuracy 0.962, val loss 0.413, val accuracy 0.969\n",
            "Epoch 10, train loss 0.141, train accuracy 0.976, val loss 0.353, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.108, train accuracy 0.983, val loss 0.343, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.088, train accuracy 0.986, val loss 0.279, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.061, train accuracy 0.993, val loss 0.256, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.053, train accuracy 0.980, val loss 0.331, val accuracy 0.938\n",
            "Epoch 15, train loss 0.050, train accuracy 0.993, val loss 0.298, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.037, train accuracy 1.000, val loss 0.255, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.027, train accuracy 1.000, val loss 0.250, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.021, train accuracy 1.000, val loss 0.251, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.015, train accuracy 1.000, val loss 0.250, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Fold  7\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.216, train accuracy 0.116, val loss 2.352, val accuracy 0.125\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.126, train accuracy 0.177, val loss 1.987, val accuracy 0.375\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 1.008, train accuracy 0.614, val loss 1.625, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.865, train accuracy 0.874, val loss 1.295, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.685, train accuracy 0.915, val loss 1.094, val accuracy 0.719\n",
            "Epoch 5, train loss 0.539, train accuracy 0.894, val loss 0.865, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 6, train loss 0.437, train accuracy 0.908, val loss 0.641, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 7, train loss 0.283, train accuracy 0.962, val loss 0.483, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.209, train accuracy 0.973, val loss 0.380, val accuracy 0.938\n",
            "Epoch 9, train loss 0.142, train accuracy 0.966, val loss 0.211, val accuracy 0.938\n",
            "Epoch 10, train loss 0.114, train accuracy 0.973, val loss 0.213, val accuracy 0.938\n",
            "Epoch 11, train loss 0.081, train accuracy 0.976, val loss 0.141, val accuracy 0.938\n",
            "Epoch 12, train loss 0.059, train accuracy 0.983, val loss 0.105, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.053, train accuracy 0.986, val loss 0.248, val accuracy 0.938\n",
            "Epoch 14, train loss 0.062, train accuracy 0.976, val loss 0.199, val accuracy 0.969\n",
            "Epoch 15, train loss 0.038, train accuracy 0.990, val loss 0.191, val accuracy 0.938\n",
            "Epoch 16, train loss 0.028, train accuracy 0.997, val loss 0.187, val accuracy 0.938\n",
            "Epoch 17, train loss 0.028, train accuracy 0.993, val loss 0.180, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.019, train accuracy 0.997, val loss 0.185, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.017, train accuracy 1.000, val loss 0.192, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Fold  8\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.212, train accuracy 0.092, val loss 2.172, val accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.096, train accuracy 0.498, val loss 1.846, val accuracy 0.750\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 0.953, train accuracy 0.884, val loss 1.459, val accuracy 0.812\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.771, train accuracy 0.935, val loss 1.199, val accuracy 0.750\n",
            "Epoch 4, train loss 0.621, train accuracy 0.857, val loss 0.972, val accuracy 0.875\n",
            "Epoch 5, train loss 0.564, train accuracy 0.860, val loss 0.687, val accuracy 0.969\n",
            "Epoch 6, train loss 0.406, train accuracy 0.925, val loss 0.664, val accuracy 0.781\n",
            "Epoch 7, train loss 0.318, train accuracy 0.911, val loss 0.433, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.228, train accuracy 0.969, val loss 0.332, val accuracy 0.938\n",
            "Epoch 9, train loss 0.163, train accuracy 0.969, val loss 0.289, val accuracy 0.938\n",
            "Epoch 10, train loss 0.115, train accuracy 0.969, val loss 0.205, val accuracy 0.969\n",
            "Epoch 11, train loss 0.087, train accuracy 0.976, val loss 0.182, val accuracy 0.969\n",
            "Epoch 12, train loss 0.072, train accuracy 0.980, val loss 0.136, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.052, train accuracy 0.983, val loss 0.104, val accuracy 0.969\n",
            "Epoch 14, train loss 0.040, train accuracy 0.990, val loss 0.073, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 15, train loss 0.032, train accuracy 0.997, val loss 0.050, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.025, train accuracy 0.997, val loss 0.036, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.020, train accuracy 0.997, val loss 0.027, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.018, train accuracy 0.997, val loss 0.023, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.012, train accuracy 1.000, val loss 0.019, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Fold  9\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 512, batch_first=True)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Epoch 0, train loss 1.216, train accuracy 0.055, val loss 2.267, val accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Epoch 1, train loss 1.118, train accuracy 0.433, val loss 1.989, val accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 2, train loss 1.003, train accuracy 0.706, val loss 1.646, val accuracy 0.875\n",
            "Saving overall best train val model\n",
            "Epoch 3, train loss 0.858, train accuracy 0.901, val loss 1.337, val accuracy 0.938\n",
            "Saving overall best train val model\n",
            "Epoch 4, train loss 0.683, train accuracy 0.915, val loss 1.083, val accuracy 0.844\n",
            "Epoch 5, train loss 0.573, train accuracy 0.863, val loss 0.901, val accuracy 0.938\n",
            "Epoch 6, train loss 0.449, train accuracy 0.898, val loss 0.632, val accuracy 0.969\n",
            "Epoch 7, train loss 0.361, train accuracy 0.932, val loss 0.387, val accuracy 0.969\n",
            "Saving overall best train val model\n",
            "Epoch 8, train loss 0.246, train accuracy 0.959, val loss 0.336, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 9, train loss 0.190, train accuracy 0.962, val loss 0.215, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 10, train loss 0.135, train accuracy 0.966, val loss 0.146, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 11, train loss 0.103, train accuracy 0.973, val loss 0.102, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 12, train loss 0.084, train accuracy 0.969, val loss 0.105, val accuracy 1.000\n",
            "Epoch 13, train loss 0.083, train accuracy 0.983, val loss 0.066, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 14, train loss 0.059, train accuracy 0.976, val loss 0.055, val accuracy 1.000\n",
            "Epoch 15, train loss 0.054, train accuracy 0.973, val loss 0.047, val accuracy 1.000\n",
            "Epoch 16, train loss 0.039, train accuracy 0.986, val loss 0.044, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 17, train loss 0.037, train accuracy 0.990, val loss 0.035, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.026, train accuracy 0.990, val loss 0.029, val accuracy 1.000\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.021, train accuracy 0.997, val loss 0.021, val accuracy 1.000\n",
            "Saving overall best train val model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "kUsob3X-ruD7",
        "outputId": "b3096e11-1d18-42c9-a9c5-22c33963a92b"
      },
      "source": [
        "overall_df_loss_accuracy_crossval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Val Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5650685</td>\n",
              "      <td>0.33333334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.56164384</td>\n",
              "      <td>0.3939394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6164383</td>\n",
              "      <td>0.36363637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.6609589</td>\n",
              "      <td>0.57575756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.59931505</td>\n",
              "      <td>0.36363637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.51877135</td>\n",
              "      <td>0.34375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.54266214</td>\n",
              "      <td>0.65625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.5699659</td>\n",
              "      <td>0.3125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.6518771</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.48122868</td>\n",
              "      <td>0.28125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Train Accuracy Val Accuracy\n",
              "0      0.5650685   0.33333334\n",
              "1     0.56164384    0.3939394\n",
              "2      0.6164383   0.36363637\n",
              "3      0.6609589   0.57575756\n",
              "4     0.59931505   0.36363637\n",
              "5     0.51877135      0.34375\n",
              "6     0.54266214      0.65625\n",
              "7      0.5699659       0.3125\n",
              "8      0.6518771          0.5\n",
              "9     0.48122868      0.28125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YmjHSEcoxN7u"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CoWsblN6lHll",
        "outputId": "fcdf65fa-e1f8-48c1-f572-6d1790e77a41"
      },
      "source": [
        "fig, axs = plt.subplots(5, 2, figsize=(20, 10))\n",
        "for i in range(0,10):\n",
        "  if i < int(10/2):\n",
        "    axs[i, 0].plot(Total_valid_loss[i])\n",
        "    axs[i, 0].plot(Total_test_loss[i])\n",
        "  else:\n",
        "    axs[i-int(10/2), 1].plot(Total_valid_loss[i])\n",
        "    axs[i-int(10/2), 1].plot(Total_test_loss[i])\n",
        "plt.legend(['Train Loss','Test Loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-921b1945610f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTotal_valid_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTotal_test_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTotal_valid_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "UO9jo5o2xDFS",
        "outputId": "d18e57d8-045d-46f5-d109-118a14863b2c"
      },
      "source": [
        "df_loss_accuracy_crossval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Loss</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Val Loss</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Test Loss</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000027</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000614</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.386951</td>\n",
              "      <td>0.36514524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000129</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000188</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.838575</td>\n",
              "      <td>0.4813278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000028</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.075721</td>\n",
              "      <td>0.373444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.028092</td>\n",
              "      <td>0.99115044</td>\n",
              "      <td>0.066905</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.920424</td>\n",
              "      <td>0.37759337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000022</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.745028</td>\n",
              "      <td>0.41493776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000034</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.867160</td>\n",
              "      <td>0.49377593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000022</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.948827</td>\n",
              "      <td>0.48547718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.047629</td>\n",
              "      <td>0.9649123</td>\n",
              "      <td>0.063618</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.703324</td>\n",
              "      <td>0.3153527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000014</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.698461</td>\n",
              "      <td>0.9166667</td>\n",
              "      <td>3.154973</td>\n",
              "      <td>0.34024897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000024</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.283157</td>\n",
              "      <td>0.9166667</td>\n",
              "      <td>3.038667</td>\n",
              "      <td>0.40248963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Train Loss Train Accuracy  Val Loss Val Accuracy  Test Loss Test Accuracy\n",
              "0    0.000027            1.0  0.000614          1.0   3.386951    0.36514524\n",
              "1    0.000129            1.0  0.000188          1.0   2.838575     0.4813278\n",
              "2    0.000028            1.0  0.000025          1.0   4.075721      0.373444\n",
              "3    0.028092     0.99115044  0.066905          1.0   1.920424    0.37759337\n",
              "4    0.000022            1.0  0.000022          1.0   3.745028    0.41493776\n",
              "5    0.000034            1.0  0.000043          1.0   2.867160    0.49377593\n",
              "6    0.000022            1.0  0.000016          1.0   2.948827    0.48547718\n",
              "7    0.047629      0.9649123  0.063618          1.0   1.703324     0.3153527\n",
              "8    0.000014            1.0  0.698461    0.9166667   3.154973    0.34024897\n",
              "9    0.000024            1.0  0.283157    0.9166667   3.038667    0.40248963"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "9evoqDksxLUI",
        "outputId": "940853b8-43ea-4a8e-e34b-da5883969d59"
      },
      "source": [
        "overall_df_loss_accuracy_crossval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.38589212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.48547718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.373444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.99115044</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.37759337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.48962656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.49377593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.48547718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.9649123</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3153527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9166667</td>\n",
              "      <td>0.35684648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9166667</td>\n",
              "      <td>0.406639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Train Accuracy Val Accuracy Test Accuracy\n",
              "0            1.0          1.0    0.38589212\n",
              "1            1.0          1.0    0.48547718\n",
              "2            1.0          1.0      0.373444\n",
              "3     0.99115044          1.0    0.37759337\n",
              "4            1.0          1.0    0.48962656\n",
              "5            1.0          1.0    0.49377593\n",
              "6            1.0          1.0    0.48547718\n",
              "7      0.9649123          1.0     0.3153527\n",
              "8            1.0    0.9166667    0.35684648\n",
              "9            1.0    0.9166667      0.406639"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5__863jNowD",
        "outputId": "de079be2-0176-4fdf-8526-ac3fffd69567"
      },
      "source": [
        "overall_df_loss_accuracy_crossval.mean(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Train Accuracy    0.999425\n",
              "Val Accuracy      0.992308\n",
              "Test Accuracy     0.690226\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24AE11WsuOnk",
        "outputId": "f0dd3fe0-15fb-4889-f112-8557f32ba5b8"
      },
      "source": [
        "epochs = 150; lr = 0.00001;\n",
        "current_random_number = 2021\n",
        "\n",
        "# df_loss_accuracy_crossval = pd.DataFrame(columns=['Train Loss', 'Train Accuracy', 'Val Loss', 'Val Accuracy', 'Test Loss', 'Test Accuracy'])\n",
        "# overall_df_loss_accuracy_crossval = pd.DataFrame(columns=['Train Accuracy', 'Val Accuracy', 'Test Accuracy', 'Test Accuracy Equal Weight'])\n",
        "Total_valid_loss = []\n",
        "Total_test_loss = []\n",
        "\n",
        "def validation_metrics (model, valid_dl, class_weights):\n",
        "  model.eval()\n",
        "  test_correct = 0\n",
        "  test_total = 0\n",
        "  test_sum_loss = 0.0\n",
        "  test_sum_rmse = 0.0\n",
        "  actual_label = []\n",
        "  predicted_label = []\n",
        "  for x, y, l in valid_dl:\n",
        "      x = x.float()\n",
        "      x.resize_((1,x.shape[0],x.shape[1]))\n",
        "      indv_class_weight = class_weights[y]\n",
        "      # indv_class_weight = 1\n",
        "      y = torch.tensor(y).long().resize_((1))\n",
        "      # y_hat = model(x, l)\n",
        "      y_hat = model(x)\n",
        "      loss = F.cross_entropy(y_hat, y)\n",
        "      pred = torch.max(y_hat, 1)[1]\n",
        "      # print(y, pred)\n",
        "      test_correct += (pred == y).float().sum()\n",
        "      test_total += y.shape[0]\n",
        "      test_sum_loss += loss.item()*indv_class_weight*y.shape[0]\n",
        "      test_sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
        "      actual_label.extend(y.numpy())\n",
        "      predicted_label.extend(pred.numpy())\n",
        "  conf_mat = confusion_matrix(actual_label, predicted_label)\n",
        "  Equal_Weight_Nest_Acc = Nest_Equal_weight_accuracy(conf_mat)\n",
        "  # print(conf_mat)\n",
        "  return test_sum_loss/test_total, test_correct/test_total, test_sum_rmse/test_total, conf_mat, Equal_Weight_Nest_Acc\n",
        "\n",
        "def Nest_Equal_weight_accuracy(confusion_matrix):\n",
        "  Nest_sum = confusion_matrix.sum(axis=1)\n",
        "  Indv_Nest_Acc = [];\n",
        "  for i in range(0, Nest_sum.shape[0]):\n",
        "    Indv_Nest_Acc.append(confusion_matrix[i, i]/Nest_sum[i])\n",
        "    # print(confusion_matrix[i, i]/Nest_sum[i])\n",
        "  return np.mean(Indv_Nest_Acc)\n",
        "\n",
        "encoded_targets, le = data_splitting_based_on_sample_size(Tutor_dataset)        ###  CHANGE HERE FOR TUTOR OR PUPIL DATASET TRAINING\n",
        "encoded_targets = encoded_targets.sample(frac=1, random_state=current_random_number).reset_index(drop=True)\n",
        "\n",
        "X_total = []; y_total = [];\n",
        "\n",
        "for key in encoded_targets['key'].unique():\n",
        "  data, label = create_sequence_feature(syllable_df_Nest_Total, key, le, label_select='Nest')\n",
        "  X_total.append(data)\n",
        "  y_total.append(label)\n",
        "\n",
        "train_ds = ReviewsDataset(X_total, y_total)\n",
        "\n",
        "for current_random_number in random_number_set[:15]:\n",
        "  print(current_random_number)\n",
        "\n",
        "  model =  LSTM_fixed_len(1024, 64, len(le.classes_), 1)   ### SET MODEL ARCHITECTURE HERE\n",
        "  # model =  LSTM_fixed_len_bidir(1024, 512, len(le.classes_), 2)\n",
        "  print(model.eval())\n",
        "  parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "  optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "  model.train()\n",
        "\n",
        "  epoch_best_loss = 0\n",
        "  epoch_best_acc = 0\n",
        "  epoch_best_val_loss = 0\n",
        "  epoch_best_val_acc = 0\n",
        "  overall_best_model_train_acc = 0\n",
        "  best_model_test_acc = 0\n",
        "  best_model_test_acc = 0\n",
        "  best_model_test_acc_equal_weight = 0\n",
        "\n",
        "  overall_best_model_stats = []\n",
        "  valid_loss_iter = []\n",
        "  test_loss_iter = []\n",
        "\n",
        "  encoded_targets_test, le_test = data_splitting_based_on_sample_size(Pupil_dataset)\n",
        "  # encoded_targets_test, le_test = data_splitting_based_on_sample_size(Tutor_dataset)\n",
        "\n",
        "  X_test = []; y_test = [];\n",
        "  \n",
        "  print('Scrambling test sequence')\n",
        "  for key in encoded_targets_test['key'].unique():# [:10]:\n",
        "      # print(key)\n",
        "      # data, label = create_sequence_feature(Tutor_dataset, key, le, label_select='Nest')\n",
        "      data, label = create_sequence_feature_randomize(Pupil_dataset, key, le, label_select='Nest', random_state=current_random_number)\n",
        "      X_test.append(data)\n",
        "      y_test.append(label)\n",
        "\n",
        "  test_ds = ReviewsDataset(X_test, y_test)\n",
        "\n",
        "  for i in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0    \n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    for iter, (x, y, l) in enumerate(train_ds):\n",
        "        x = x.float()\n",
        "        x.resize_((1,x.shape[0],x.shape[1]))\n",
        "        indv_class_weight = class_weights[y]\n",
        "        # indv_class_weight = 1\n",
        "        y = torch.tensor(y).long().resize_((1))\n",
        "        # y_pred = model(x, l)\n",
        "        y_pred = model(x)\n",
        "        optimizer.zero_grad()\n",
        "        loss = F.cross_entropy(y_pred, y)*indv_class_weight\n",
        "        # print(loss, indv_class_weight, loss*indv_class_weight)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()*y.shape[0]\n",
        "        train_total += y.shape[0]\n",
        "        pred_train = torch.max(y_pred, 1)[1]\n",
        "        train_correct += (pred_train == y).float().sum()          \n",
        "    epoch_loss /= (iter + 1)\n",
        "    epoch_acc = train_correct/train_total  \n",
        "    val_epoch_loss, val_accuracy, val_rmse, val_conf_mat, val_acuracy_equal_weight = validation_metrics(model, train_ds, class_weights)\n",
        "    valid_loss_iter.append(val_epoch_loss)\n",
        "\n",
        "    test_epoch_loss, test_accuracy, test_rmse, test_conf_mat, test_accuracy_equal_weight = validation_metrics(model, test_ds, class_weights)\n",
        "    test_loss_iter.append(test_epoch_loss)\n",
        "  \n",
        "    print(\"Epoch %d, train loss %.3f, train accuracy %.3f, val loss %.3f, val accuracy %.3f, test loss %.3f, test accuracy %.3f\" % (i, epoch_loss, epoch_acc, val_epoch_loss, val_accuracy, test_epoch_loss, test_accuracy))\n",
        "\n",
        "    if epoch_best_acc <= epoch_acc:\n",
        "      if epoch_best_val_acc <= val_accuracy:\n",
        "        epoch_best_val_loss = val_epoch_loss\n",
        "        epoch_best_loss = epoch_loss\n",
        "        epoch_best_acc = epoch_acc\n",
        "        epoch_best_val_acc = val_accuracy\n",
        "        epoch_best_val_acc_equal_weight = val_acuracy_equal_weight\n",
        "        test_accuracy_temp = test_accuracy\n",
        "        test_accuracy_temp_equal_weight = test_accuracy_equal_weight\n",
        "        test_epoch_loss_temp = test_epoch_loss\n",
        "        now = datetime.now() \n",
        "        dt_string = now.strftime(\"%d_%m_%Y_%H_%M\")\n",
        "        best_model = model\n",
        "        print('Saving overall best train val model')        \n",
        "        if best_model_test_acc <= test_accuracy:\n",
        "          best_model_test_acc = test_accuracy\n",
        "          best_model_test_acc_equal_weight = test_accuracy_equal_weight\n",
        "          best_model_test_loss = test_epoch_loss\n",
        "          overall_best_model = model\n",
        "          overall_best_model_train_acc = epoch_acc\n",
        "          overall_best_model_stats = [ epoch_best_acc.numpy(), epoch_best_val_acc.numpy(), best_model_test_acc.numpy(), best_model_test_acc_equal_weight]\n",
        "          overall_best_test_conf_matrix = pd.DataFrame(test_conf_mat, index=[class_label+'_True' for class_label in list(le.classes_)], columns=[class_label+'_Pred' for class_label in list(le.classes_)])\n",
        "          overall_best_valid_conf_matrix = pd.DataFrame(val_conf_mat, index=[class_label+'_True' for class_label in list(le.classes_)], columns=[class_label+'_Pred' for class_label in list(le.classes_)])\n",
        "          print('Saving overall best test model')\n",
        "        elif overall_best_model_train_acc < epoch_acc:\n",
        "          best_model_test_acc = test_accuracy\n",
        "          best_model_test_acc_equal_weight = test_accuracy_equal_weight\n",
        "          best_model_test_loss = test_epoch_loss\n",
        "          overall_best_model = model\n",
        "          overall_best_model_train_acc = epoch_acc\n",
        "          overall_best_model_stats = [ epoch_best_acc.numpy(), epoch_best_val_acc.numpy(), best_model_test_acc.numpy(), best_model_test_acc_equal_weight]\n",
        "          overall_best_test_conf_matrix = pd.DataFrame(test_conf_mat, index=[class_label+'_True' for class_label in list(le.classes_)], columns=[class_label+'_Pred' for class_label in list(le.classes_)])\n",
        "          overall_best_valid_conf_matrix = pd.DataFrame(val_conf_mat, index=[class_label+'_True' for class_label in list(le.classes_)], columns=[class_label+'_Pred' for class_label in list(le.classes_)])\n",
        "          print('Replacing overall best test model')\n",
        "\n",
        "  Total_valid_loss.append(valid_loss_iter)\n",
        "  Total_test_loss.append(test_loss_iter)\n",
        "\n",
        "  actual_label = []\n",
        "  predicted_label = []\n",
        "  predicted_label_name = []\n",
        "\n",
        "  for x, y, l in test_ds:\n",
        "    x = x.float()\n",
        "    x.resize_((1,x.shape[0],x.shape[1]))\n",
        "    # indv_class_weight = class_weights[y]\n",
        "    y = torch.tensor(y).long().resize_((1))\n",
        "    y_hat = model(x)\n",
        "    pred = torch.max(y_hat, 1)[1]\n",
        "    actual_label.extend(y.numpy())\n",
        "    predicted_label.extend(pred.numpy())\n",
        "    # print(y.numpy(), pred.numpy())\n",
        "    predicted_label_name.extend(le.inverse_transform(pred.numpy()).tolist())\n",
        "  conf_mat = confusion_matrix(actual_label, predicted_label)\n",
        "\n",
        "  encoded_targets_test[\"Nest Pred\"] = predicted_label_name\n",
        "\n",
        "  PupilID_Nest = np.zeros(shape=(len(encoded_targets_test['indvi'].unique()), len(encoded_targets_test['Nest'].unique())), dtype=int )\n",
        "\n",
        "  counter = 0;\n",
        "  PupilID_Nest_Names = []\n",
        "  for indvi in encoded_targets_test['indvi'].unique():\n",
        "    current_Bird = encoded_targets_test.loc[encoded_targets_test['indvi']==indvi]\n",
        "    PupilID_Nest_Names.extend([str(indvi)+'_'+str(current_Bird['Nest'].values[-1])])\n",
        "    # print(counter, [str(indvi)+'_'+str(current_Bird['Nest'].values[-1])], len(current_Bird['key']))\n",
        "    for key in current_Bird['key'].unique():\n",
        "      # print(key, counter, int(le.transform(current_Bird['Nest Pred'].loc[current_Bird['key']==key].values)) , PupilID_Nest[counter][int(le.transform(current_Bird['Nest Pred'].loc[current_Bird['key']==key].values))])\n",
        "      PupilID_Nest[counter][int(le.transform(current_Bird['Nest Pred'].loc[current_Bird['key']==key].values))] += 1\n",
        "    counter += 1\n",
        "\n",
        "  PupilID_Nest_df = pd.DataFrame(PupilID_Nest, index=PupilID_Nest_Names, columns=[class_label+'_Pred' for class_label in list(le.classes_)])\n",
        "\n",
        "  df_loss_accuracy_crossval = df_loss_accuracy_crossval.append({'Train Loss': epoch_best_loss , 'Train Accuracy': epoch_best_acc.numpy(),  'Val Loss':  epoch_best_val_loss, \n",
        "                                          'Val Accuracy': epoch_best_val_acc.numpy(), 'Test Loss': test_epoch_loss_temp, 'Test Accuracy': test_accuracy_temp.numpy()}, ignore_index=True)\n",
        "\n",
        "  overall_df_loss_accuracy_crossval = overall_df_loss_accuracy_crossval.append(pd.Series(overall_best_model_stats, index=overall_df_loss_accuracy_crossval.columns.values), ignore_index=True)\n",
        "\n",
        "  print('Saving PupilID Nest for seq', str(current_random_number))\n",
        "  PupilID_Nest_df.to_csv('/content/gdrive/My Drive/ZFDataset/SavedModels/FullDataset/LSTM/Unidirectional/Randomize/'+'PupilID_Nest_'+str(current_random_number)+'.csv')\n",
        "overall_df_loss_accuracy_crossval.to_csv('/content/gdrive/My Drive/ZFDataset/SavedModels/FullDataset/LSTM/Unidirectional/Randomize/'+'ScrambleSeq'+'.csv')\n",
        "\n",
        "  # torch.save(model, '/content/gdrive/My Drive/ZFDataset/SavedModels/FullDataset/LSTM/Unidirectional/Randomize/'+'Total'+dt_string+'_Train_'+str(np.round(epoch_best_acc.numpy(),4))+\n",
        "  #                                                                                    '_Val_'+str(np.round(epoch_best_val_acc.numpy(),4))+'_Test_'+str(np.round(best_model_test_acc.numpy(),4)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.748, test accuracy 0.532\n",
            "Saving overall best train val model\n",
            "Epoch 107, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.748, test accuracy 0.532\n",
            "Saving overall best train val model\n",
            "Epoch 108, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.749, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 109, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.746, test accuracy 0.532\n",
            "Saving overall best train val model\n",
            "Epoch 110, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.746, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Epoch 111, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.744, test accuracy 0.538\n",
            "Saving overall best train val model\n",
            "Epoch 112, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.743, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 113, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.740, test accuracy 0.542\n",
            "Saving overall best train val model\n",
            "Epoch 114, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.741, test accuracy 0.546\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 115, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.739, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Epoch 116, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.735, test accuracy 0.542\n",
            "Saving overall best train val model\n",
            "Epoch 117, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.737, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Epoch 118, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.732, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 119, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.731, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Epoch 120, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.730, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Epoch 121, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.724, test accuracy 0.555\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 122, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.735, test accuracy 0.561\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 123, train loss 0.005, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.725, test accuracy 0.555\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.735, test accuracy 0.561\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 125, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.727, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 126, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.724, test accuracy 0.563\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 127, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.732, test accuracy 0.557\n",
            "Saving overall best train val model\n",
            "Epoch 128, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.730, test accuracy 0.555\n",
            "Saving overall best train val model\n",
            "Epoch 129, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.726, test accuracy 0.563\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 130, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.727, test accuracy 0.553\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.727, test accuracy 0.569\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 132, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.723, test accuracy 0.559\n",
            "Saving overall best train val model\n",
            "Epoch 133, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.724, test accuracy 0.563\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.718, test accuracy 0.555\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.731, test accuracy 0.563\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.726, test accuracy 0.563\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.723, test accuracy 0.559\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.717, test accuracy 0.561\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.731, test accuracy 0.557\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.725, test accuracy 0.559\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.728, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.724, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.739, test accuracy 0.542\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.730, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.738, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 146, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.734, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Epoch 147, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.730, test accuracy 0.557\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.735, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 149, train loss 0.002, train accuracy 1.000, val loss 0.001, val accuracy 1.000, test loss 0.738, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 329\n",
            "5689\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.201, train accuracy 0.095, val loss 1.184, val accuracy 0.129, test loss 1.306, test accuracy 0.128\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.169, train accuracy 0.182, val loss 1.149, val accuracy 0.249, test loss 1.299, test accuracy 0.101\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 2, train loss 1.130, train accuracy 0.314, val loss 1.104, val accuracy 0.415, test loss 1.290, test accuracy 0.135\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.081, train accuracy 0.514, val loss 1.051, val accuracy 0.671, test loss 1.278, test accuracy 0.176\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.026, train accuracy 0.714, val loss 0.997, val accuracy 0.822, test loss 1.263, test accuracy 0.208\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 5, train loss 0.973, train accuracy 0.849, val loss 0.944, val accuracy 0.895, test loss 1.244, test accuracy 0.229\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.921, train accuracy 0.908, val loss 0.894, val accuracy 0.917, test loss 1.224, test accuracy 0.261\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 7, train loss 0.872, train accuracy 0.942, val loss 0.844, val accuracy 0.938, test loss 1.205, test accuracy 0.277\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 8, train loss 0.823, train accuracy 0.945, val loss 0.796, val accuracy 0.966, test loss 1.186, test accuracy 0.313\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.776, train accuracy 0.966, val loss 0.751, val accuracy 0.966, test loss 1.171, test accuracy 0.332\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.734, train accuracy 0.972, val loss 0.713, val accuracy 0.969, test loss 1.155, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 11, train loss 0.698, train accuracy 0.972, val loss 0.678, val accuracy 0.972, test loss 1.141, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 12, train loss 0.665, train accuracy 0.975, val loss 0.647, val accuracy 0.975, test loss 1.127, test accuracy 0.380\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 13, train loss 0.635, train accuracy 0.978, val loss 0.618, val accuracy 0.978, test loss 1.115, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 14, train loss 0.607, train accuracy 0.982, val loss 0.591, val accuracy 0.982, test loss 1.102, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 15, train loss 0.581, train accuracy 0.982, val loss 0.566, val accuracy 0.985, test loss 1.090, test accuracy 0.403\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 16, train loss 0.556, train accuracy 0.982, val loss 0.542, val accuracy 0.985, test loss 1.077, test accuracy 0.414\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.532, train accuracy 0.982, val loss 0.518, val accuracy 0.985, test loss 1.064, test accuracy 0.424\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 18, train loss 0.509, train accuracy 0.982, val loss 0.495, val accuracy 0.982, test loss 1.055, test accuracy 0.437\n",
            "Epoch 19, train loss 0.486, train accuracy 0.985, val loss 0.473, val accuracy 0.985, test loss 1.051, test accuracy 0.433\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 20, train loss 0.464, train accuracy 0.982, val loss 0.452, val accuracy 0.982, test loss 1.044, test accuracy 0.439\n",
            "Epoch 21, train loss 0.444, train accuracy 0.982, val loss 0.433, val accuracy 0.985, test loss 1.036, test accuracy 0.443\n",
            "Epoch 22, train loss 0.425, train accuracy 0.982, val loss 0.414, val accuracy 0.985, test loss 1.027, test accuracy 0.452\n",
            "Epoch 23, train loss 0.406, train accuracy 0.982, val loss 0.396, val accuracy 0.985, test loss 1.020, test accuracy 0.456\n",
            "Epoch 24, train loss 0.388, train accuracy 0.982, val loss 0.378, val accuracy 0.985, test loss 1.012, test accuracy 0.450\n",
            "Epoch 25, train loss 0.372, train accuracy 0.985, val loss 0.362, val accuracy 0.985, test loss 1.006, test accuracy 0.447\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 26, train loss 0.356, train accuracy 0.985, val loss 0.347, val accuracy 0.985, test loss 0.999, test accuracy 0.450\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 27, train loss 0.341, train accuracy 0.985, val loss 0.333, val accuracy 0.985, test loss 0.993, test accuracy 0.456\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 28, train loss 0.327, train accuracy 0.985, val loss 0.319, val accuracy 0.985, test loss 0.987, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 29, train loss 0.313, train accuracy 0.985, val loss 0.306, val accuracy 0.985, test loss 0.981, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 30, train loss 0.300, train accuracy 0.988, val loss 0.293, val accuracy 0.988, test loss 0.976, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 31, train loss 0.288, train accuracy 0.988, val loss 0.281, val accuracy 0.988, test loss 0.972, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Epoch 32, train loss 0.276, train accuracy 0.988, val loss 0.270, val accuracy 0.991, test loss 0.967, test accuracy 0.479\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 33, train loss 0.265, train accuracy 0.991, val loss 0.259, val accuracy 0.991, test loss 0.963, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 34, train loss 0.254, train accuracy 0.991, val loss 0.248, val accuracy 0.991, test loss 0.958, test accuracy 0.473\n",
            "Saving overall best train val model\n",
            "Epoch 35, train loss 0.244, train accuracy 0.991, val loss 0.238, val accuracy 0.991, test loss 0.954, test accuracy 0.473\n",
            "Saving overall best train val model\n",
            "Epoch 36, train loss 0.234, train accuracy 0.991, val loss 0.229, val accuracy 0.991, test loss 0.949, test accuracy 0.471\n",
            "Saving overall best train val model\n",
            "Epoch 37, train loss 0.225, train accuracy 0.991, val loss 0.220, val accuracy 0.991, test loss 0.945, test accuracy 0.471\n",
            "Saving overall best train val model\n",
            "Epoch 38, train loss 0.216, train accuracy 0.991, val loss 0.211, val accuracy 0.991, test loss 0.941, test accuracy 0.473\n",
            "Saving overall best train val model\n",
            "Epoch 39, train loss 0.207, train accuracy 0.991, val loss 0.202, val accuracy 0.994, test loss 0.937, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 40, train loss 0.199, train accuracy 0.991, val loss 0.194, val accuracy 0.994, test loss 0.934, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 41, train loss 0.191, train accuracy 0.994, val loss 0.186, val accuracy 0.994, test loss 0.931, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 42, train loss 0.183, train accuracy 0.994, val loss 0.179, val accuracy 0.994, test loss 0.928, test accuracy 0.468\n",
            "Saving overall best train val model\n",
            "Epoch 43, train loss 0.176, train accuracy 0.994, val loss 0.172, val accuracy 0.994, test loss 0.925, test accuracy 0.468\n",
            "Saving overall best train val model\n",
            "Epoch 44, train loss 0.169, train accuracy 0.994, val loss 0.165, val accuracy 0.994, test loss 0.922, test accuracy 0.466\n",
            "Saving overall best train val model\n",
            "Epoch 45, train loss 0.162, train accuracy 0.994, val loss 0.158, val accuracy 0.994, test loss 0.920, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Epoch 46, train loss 0.156, train accuracy 0.994, val loss 0.152, val accuracy 0.994, test loss 0.917, test accuracy 0.464\n",
            "Saving overall best train val model\n",
            "Epoch 47, train loss 0.150, train accuracy 0.994, val loss 0.146, val accuracy 0.994, test loss 0.915, test accuracy 0.468\n",
            "Saving overall best train val model\n",
            "Epoch 48, train loss 0.144, train accuracy 0.994, val loss 0.141, val accuracy 0.994, test loss 0.912, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Epoch 49, train loss 0.139, train accuracy 0.994, val loss 0.135, val accuracy 0.994, test loss 0.909, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Epoch 50, train loss 0.133, train accuracy 0.994, val loss 0.130, val accuracy 0.994, test loss 0.906, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 51, train loss 0.128, train accuracy 0.994, val loss 0.125, val accuracy 0.994, test loss 0.903, test accuracy 0.479\n",
            "Saving overall best train val model\n",
            "Epoch 52, train loss 0.124, train accuracy 0.994, val loss 0.121, val accuracy 0.994, test loss 0.900, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Epoch 53, train loss 0.119, train accuracy 0.994, val loss 0.116, val accuracy 0.994, test loss 0.896, test accuracy 0.483\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 54, train loss 0.115, train accuracy 0.994, val loss 0.112, val accuracy 0.994, test loss 0.893, test accuracy 0.487\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 55, train loss 0.110, train accuracy 0.994, val loss 0.108, val accuracy 0.997, test loss 0.890, test accuracy 0.490\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 56, train loss 0.106, train accuracy 0.994, val loss 0.104, val accuracy 0.997, test loss 0.887, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 57, train loss 0.102, train accuracy 0.997, val loss 0.100, val accuracy 0.997, test loss 0.884, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 58, train loss 0.099, train accuracy 0.997, val loss 0.096, val accuracy 0.997, test loss 0.881, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 59, train loss 0.095, train accuracy 0.997, val loss 0.093, val accuracy 0.997, test loss 0.878, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 60, train loss 0.091, train accuracy 0.997, val loss 0.089, val accuracy 0.997, test loss 0.874, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 61, train loss 0.088, train accuracy 0.997, val loss 0.086, val accuracy 0.997, test loss 0.872, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 62, train loss 0.085, train accuracy 0.997, val loss 0.083, val accuracy 0.997, test loss 0.870, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Epoch 63, train loss 0.082, train accuracy 0.997, val loss 0.080, val accuracy 0.997, test loss 0.867, test accuracy 0.506\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 64, train loss 0.079, train accuracy 0.997, val loss 0.077, val accuracy 0.997, test loss 0.864, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 65, train loss 0.076, train accuracy 0.997, val loss 0.075, val accuracy 0.997, test loss 0.861, test accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 66, train loss 0.074, train accuracy 0.997, val loss 0.072, val accuracy 0.997, test loss 0.858, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 67, train loss 0.071, train accuracy 0.997, val loss 0.070, val accuracy 0.997, test loss 0.856, test accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 68, train loss 0.069, train accuracy 0.997, val loss 0.067, val accuracy 0.997, test loss 0.853, test accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 69, train loss 0.066, train accuracy 0.997, val loss 0.065, val accuracy 0.997, test loss 0.849, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 70, train loss 0.064, train accuracy 0.997, val loss 0.063, val accuracy 0.997, test loss 0.845, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 71, train loss 0.062, train accuracy 0.997, val loss 0.060, val accuracy 0.997, test loss 0.842, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 72, train loss 0.060, train accuracy 0.997, val loss 0.058, val accuracy 0.997, test loss 0.839, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 73, train loss 0.058, train accuracy 0.997, val loss 0.056, val accuracy 0.997, test loss 0.837, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Epoch 74, train loss 0.056, train accuracy 0.997, val loss 0.054, val accuracy 0.997, test loss 0.835, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Epoch 75, train loss 0.054, train accuracy 0.997, val loss 0.053, val accuracy 0.997, test loss 0.832, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 76, train loss 0.052, train accuracy 0.997, val loss 0.051, val accuracy 0.997, test loss 0.830, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 77, train loss 0.050, train accuracy 0.997, val loss 0.049, val accuracy 0.997, test loss 0.828, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 78, train loss 0.049, train accuracy 0.997, val loss 0.047, val accuracy 0.997, test loss 0.828, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 79, train loss 0.047, train accuracy 0.997, val loss 0.046, val accuracy 0.997, test loss 0.824, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 80, train loss 0.045, train accuracy 0.997, val loss 0.044, val accuracy 0.997, test loss 0.819, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 81, train loss 0.044, train accuracy 0.997, val loss 0.043, val accuracy 0.997, test loss 0.818, test accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 82, train loss 0.042, train accuracy 0.997, val loss 0.041, val accuracy 0.997, test loss 0.814, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 83, train loss 0.041, train accuracy 0.997, val loss 0.040, val accuracy 0.997, test loss 0.814, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.040, train accuracy 0.997, val loss 0.039, val accuracy 0.997, test loss 0.813, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Epoch 85, train loss 0.038, train accuracy 0.997, val loss 0.037, val accuracy 0.997, test loss 0.813, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Epoch 86, train loss 0.037, train accuracy 0.997, val loss 0.036, val accuracy 0.997, test loss 0.812, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 87, train loss 0.036, train accuracy 0.997, val loss 0.035, val accuracy 0.997, test loss 0.811, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 88, train loss 0.035, train accuracy 0.997, val loss 0.034, val accuracy 0.997, test loss 0.811, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Epoch 89, train loss 0.033, train accuracy 0.997, val loss 0.033, val accuracy 0.997, test loss 0.812, test accuracy 0.525\n",
            "Saving overall best train val model\n",
            "Epoch 90, train loss 0.032, train accuracy 0.997, val loss 0.031, val accuracy 0.997, test loss 0.810, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 91, train loss 0.031, train accuracy 0.997, val loss 0.030, val accuracy 0.997, test loss 0.811, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Epoch 92, train loss 0.030, train accuracy 0.997, val loss 0.029, val accuracy 0.997, test loss 0.812, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Epoch 93, train loss 0.029, train accuracy 0.997, val loss 0.028, val accuracy 0.997, test loss 0.813, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 94, train loss 0.028, train accuracy 0.997, val loss 0.027, val accuracy 0.997, test loss 0.814, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 95, train loss 0.027, train accuracy 0.997, val loss 0.026, val accuracy 0.997, test loss 0.821, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 96, train loss 0.026, train accuracy 0.997, val loss 0.025, val accuracy 0.997, test loss 0.830, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 97, train loss 0.025, train accuracy 0.997, val loss 0.024, val accuracy 0.997, test loss 0.823, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 98, train loss 0.024, train accuracy 0.997, val loss 0.024, val accuracy 0.997, test loss 0.822, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 99, train loss 0.023, train accuracy 0.997, val loss 0.023, val accuracy 0.997, test loss 0.824, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 100, train loss 0.023, train accuracy 0.997, val loss 0.023, val accuracy 0.997, test loss 0.824, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Epoch 101, train loss 0.022, train accuracy 0.997, val loss 0.022, val accuracy 0.997, test loss 0.823, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Epoch 102, train loss 0.021, train accuracy 0.997, val loss 0.021, val accuracy 0.997, test loss 0.820, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 103, train loss 0.021, train accuracy 0.997, val loss 0.020, val accuracy 0.997, test loss 0.820, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Epoch 104, train loss 0.020, train accuracy 0.997, val loss 0.020, val accuracy 0.997, test loss 0.819, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 105, train loss 0.019, train accuracy 0.997, val loss 0.019, val accuracy 0.997, test loss 0.818, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.019, train accuracy 0.997, val loss 0.018, val accuracy 0.997, test loss 0.817, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 107, train loss 0.018, train accuracy 0.997, val loss 0.018, val accuracy 0.997, test loss 0.816, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 108, train loss 0.018, train accuracy 0.997, val loss 0.017, val accuracy 0.997, test loss 0.828, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 109, train loss 0.017, train accuracy 0.997, val loss 0.017, val accuracy 0.997, test loss 0.818, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 110, train loss 0.016, train accuracy 0.997, val loss 0.016, val accuracy 0.997, test loss 0.820, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 111, train loss 0.016, train accuracy 0.997, val loss 0.016, val accuracy 0.997, test loss 0.819, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 112, train loss 0.015, train accuracy 0.997, val loss 0.015, val accuracy 0.997, test loss 0.817, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 113, train loss 0.015, train accuracy 0.997, val loss 0.015, val accuracy 0.997, test loss 0.817, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 114, train loss 0.014, train accuracy 0.997, val loss 0.014, val accuracy 0.997, test loss 0.817, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 115, train loss 0.014, train accuracy 0.997, val loss 0.014, val accuracy 0.997, test loss 0.817, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 116, train loss 0.014, train accuracy 0.997, val loss 0.013, val accuracy 0.997, test loss 0.817, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Epoch 117, train loss 0.013, train accuracy 0.997, val loss 0.013, val accuracy 0.997, test loss 0.817, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Epoch 118, train loss 0.013, train accuracy 0.997, val loss 0.012, val accuracy 0.997, test loss 0.816, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 119, train loss 0.012, train accuracy 0.997, val loss 0.012, val accuracy 0.997, test loss 0.818, test accuracy 0.506\n",
            "Saving overall best train val model\n",
            "Epoch 120, train loss 0.012, train accuracy 0.997, val loss 0.012, val accuracy 0.997, test loss 0.817, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 121, train loss 0.012, train accuracy 0.997, val loss 0.011, val accuracy 0.997, test loss 0.812, test accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 122, train loss 0.011, train accuracy 0.997, val loss 0.011, val accuracy 0.997, test loss 0.818, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 123, train loss 0.011, train accuracy 0.997, val loss 0.011, val accuracy 0.997, test loss 0.849, test accuracy 0.468\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.010, train accuracy 0.997, val loss 0.010, val accuracy 0.997, test loss 0.810, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 125, train loss 0.010, train accuracy 0.997, val loss 0.010, val accuracy 0.997, test loss 0.807, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Epoch 126, train loss 0.010, train accuracy 0.997, val loss 0.010, val accuracy 0.997, test loss 0.807, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Epoch 127, train loss 0.010, train accuracy 0.997, val loss 0.009, val accuracy 0.997, test loss 0.808, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 128, train loss 0.009, train accuracy 0.997, val loss 0.009, val accuracy 0.997, test loss 0.805, test accuracy 0.536\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 129, train loss 0.009, train accuracy 0.997, val loss 0.009, val accuracy 1.000, test loss 0.818, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 130, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 0.997, test loss 0.807, test accuracy 0.534\n",
            "Epoch 131, train loss 0.008, train accuracy 0.997, val loss 0.008, val accuracy 1.000, test loss 0.811, test accuracy 0.525\n",
            "Saving overall best train val model\n",
            "Epoch 132, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.816, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 133, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.814, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.819, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 135, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.817, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.821, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.819, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 138, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.823, test accuracy 0.525\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.821, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.827, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.825, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.828, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.834, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.835, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.849, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 146, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.829, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Epoch 147, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.839, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.841, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Epoch 149, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.839, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 5689\n",
            "2746\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.201, train accuracy 0.166, val loss 1.184, val accuracy 0.185, test loss 1.362, test accuracy 0.053\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.168, train accuracy 0.203, val loss 1.149, val accuracy 0.212, test loss 1.354, test accuracy 0.065\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 2, train loss 1.134, train accuracy 0.258, val loss 1.114, val accuracy 0.298, test loss 1.348, test accuracy 0.080\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.099, train accuracy 0.354, val loss 1.078, val accuracy 0.406, test loss 1.342, test accuracy 0.101\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.060, train accuracy 0.495, val loss 1.037, val accuracy 0.535, test loss 1.336, test accuracy 0.116\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 5, train loss 1.017, train accuracy 0.652, val loss 0.990, val accuracy 0.708, test loss 1.332, test accuracy 0.181\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.968, train accuracy 0.800, val loss 0.940, val accuracy 0.855, test loss 1.329, test accuracy 0.216\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 7, train loss 0.920, train accuracy 0.889, val loss 0.895, val accuracy 0.911, test loss 1.320, test accuracy 0.240\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 8, train loss 0.876, train accuracy 0.942, val loss 0.851, val accuracy 0.954, test loss 1.308, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.833, train accuracy 0.957, val loss 0.808, val accuracy 0.963, test loss 1.297, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.791, train accuracy 0.963, val loss 0.767, val accuracy 0.963, test loss 1.285, test accuracy 0.294\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 11, train loss 0.750, train accuracy 0.972, val loss 0.727, val accuracy 0.972, test loss 1.273, test accuracy 0.311\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 12, train loss 0.710, train accuracy 0.972, val loss 0.687, val accuracy 0.982, test loss 1.263, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 13, train loss 0.672, train accuracy 0.978, val loss 0.650, val accuracy 0.975, test loss 1.254, test accuracy 0.332\n",
            "Epoch 14, train loss 0.636, train accuracy 0.978, val loss 0.616, val accuracy 0.975, test loss 1.247, test accuracy 0.321\n",
            "Epoch 15, train loss 0.604, train accuracy 0.978, val loss 0.585, val accuracy 0.972, test loss 1.239, test accuracy 0.324\n",
            "Epoch 16, train loss 0.573, train accuracy 0.978, val loss 0.555, val accuracy 0.972, test loss 1.232, test accuracy 0.321\n",
            "Epoch 17, train loss 0.545, train accuracy 0.978, val loss 0.528, val accuracy 0.972, test loss 1.225, test accuracy 0.323\n",
            "Epoch 18, train loss 0.518, train accuracy 0.975, val loss 0.501, val accuracy 0.972, test loss 1.218, test accuracy 0.323\n",
            "Epoch 19, train loss 0.492, train accuracy 0.978, val loss 0.477, val accuracy 0.975, test loss 1.211, test accuracy 0.328\n",
            "Epoch 20, train loss 0.468, train accuracy 0.978, val loss 0.453, val accuracy 0.978, test loss 1.206, test accuracy 0.328\n",
            "Epoch 21, train loss 0.445, train accuracy 0.988, val loss 0.431, val accuracy 0.978, test loss 1.200, test accuracy 0.334\n",
            "Epoch 22, train loss 0.423, train accuracy 0.988, val loss 0.411, val accuracy 0.985, test loss 1.196, test accuracy 0.326\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 23, train loss 0.403, train accuracy 0.988, val loss 0.391, val accuracy 0.988, test loss 1.193, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 24, train loss 0.384, train accuracy 0.991, val loss 0.373, val accuracy 0.988, test loss 1.189, test accuracy 0.326\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 25, train loss 0.367, train accuracy 0.991, val loss 0.356, val accuracy 0.991, test loss 1.186, test accuracy 0.330\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 26, train loss 0.350, train accuracy 0.994, val loss 0.340, val accuracy 0.991, test loss 1.182, test accuracy 0.326\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 27, train loss 0.335, train accuracy 0.994, val loss 0.326, val accuracy 0.991, test loss 1.178, test accuracy 0.336\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 28, train loss 0.320, train accuracy 0.994, val loss 0.312, val accuracy 0.991, test loss 1.176, test accuracy 0.336\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 29, train loss 0.307, train accuracy 0.994, val loss 0.299, val accuracy 0.991, test loss 1.173, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Epoch 30, train loss 0.294, train accuracy 0.994, val loss 0.287, val accuracy 0.991, test loss 1.170, test accuracy 0.326\n",
            "Saving overall best train val model\n",
            "Epoch 31, train loss 0.282, train accuracy 0.994, val loss 0.275, val accuracy 0.991, test loss 1.166, test accuracy 0.326\n",
            "Saving overall best train val model\n",
            "Epoch 32, train loss 0.270, train accuracy 0.994, val loss 0.264, val accuracy 0.991, test loss 1.163, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Epoch 33, train loss 0.259, train accuracy 0.997, val loss 0.253, val accuracy 0.997, test loss 1.159, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 34, train loss 0.249, train accuracy 0.997, val loss 0.243, val accuracy 0.997, test loss 1.156, test accuracy 0.326\n",
            "Saving overall best train val model\n",
            "Epoch 35, train loss 0.239, train accuracy 0.997, val loss 0.233, val accuracy 0.997, test loss 1.153, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Epoch 36, train loss 0.230, train accuracy 0.997, val loss 0.224, val accuracy 0.997, test loss 1.149, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Epoch 37, train loss 0.221, train accuracy 0.997, val loss 0.215, val accuracy 0.997, test loss 1.145, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Epoch 38, train loss 0.214, train accuracy 0.997, val loss 0.208, val accuracy 0.997, test loss 1.141, test accuracy 0.315\n",
            "Saving overall best train val model\n",
            "Epoch 39, train loss 0.205, train accuracy 0.997, val loss 0.198, val accuracy 0.997, test loss 1.132, test accuracy 0.317\n",
            "Saving overall best train val model\n",
            "Epoch 40, train loss 0.196, train accuracy 0.997, val loss 0.191, val accuracy 0.997, test loss 1.134, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Epoch 41, train loss 0.189, train accuracy 0.997, val loss 0.183, val accuracy 0.997, test loss 1.130, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Epoch 42, train loss 0.181, train accuracy 0.997, val loss 0.176, val accuracy 0.997, test loss 1.127, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Epoch 43, train loss 0.174, train accuracy 0.997, val loss 0.169, val accuracy 0.997, test loss 1.125, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Epoch 44, train loss 0.167, train accuracy 0.997, val loss 0.162, val accuracy 0.997, test loss 1.121, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Epoch 45, train loss 0.161, train accuracy 0.997, val loss 0.156, val accuracy 0.997, test loss 1.118, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Epoch 46, train loss 0.154, train accuracy 0.997, val loss 0.149, val accuracy 0.997, test loss 1.115, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Epoch 47, train loss 0.148, train accuracy 0.997, val loss 0.143, val accuracy 0.997, test loss 1.112, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Epoch 48, train loss 0.142, train accuracy 0.997, val loss 0.138, val accuracy 0.997, test loss 1.109, test accuracy 0.315\n",
            "Saving overall best train val model\n",
            "Epoch 49, train loss 0.138, train accuracy 0.997, val loss 0.132, val accuracy 0.997, test loss 1.105, test accuracy 0.326\n",
            "Saving overall best train val model\n",
            "Epoch 50, train loss 0.131, train accuracy 0.997, val loss 0.127, val accuracy 0.997, test loss 1.104, test accuracy 0.323\n",
            "Saving overall best train val model\n",
            "Epoch 51, train loss 0.126, train accuracy 0.997, val loss 0.122, val accuracy 1.000, test loss 1.099, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 52, train loss 0.121, train accuracy 0.997, val loss 0.117, val accuracy 1.000, test loss 1.095, test accuracy 0.326\n",
            "Saving overall best train val model\n",
            "Epoch 53, train loss 0.116, train accuracy 0.997, val loss 0.113, val accuracy 1.000, test loss 1.091, test accuracy 0.326\n",
            "Saving overall best train val model\n",
            "Epoch 54, train loss 0.112, train accuracy 0.997, val loss 0.108, val accuracy 1.000, test loss 1.088, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Epoch 55, train loss 0.107, train accuracy 1.000, val loss 0.104, val accuracy 1.000, test loss 1.085, test accuracy 0.330\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 56, train loss 0.103, train accuracy 1.000, val loss 0.100, val accuracy 1.000, test loss 1.081, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 57, train loss 0.099, train accuracy 1.000, val loss 0.096, val accuracy 1.000, test loss 1.078, test accuracy 0.336\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 58, train loss 0.095, train accuracy 1.000, val loss 0.092, val accuracy 1.000, test loss 1.074, test accuracy 0.340\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 59, train loss 0.091, train accuracy 1.000, val loss 0.088, val accuracy 1.000, test loss 1.071, test accuracy 0.340\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 60, train loss 0.087, train accuracy 1.000, val loss 0.085, val accuracy 1.000, test loss 1.068, test accuracy 0.340\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 61, train loss 0.084, train accuracy 1.000, val loss 0.081, val accuracy 1.000, test loss 1.065, test accuracy 0.338\n",
            "Saving overall best train val model\n",
            "Epoch 62, train loss 0.081, train accuracy 1.000, val loss 0.078, val accuracy 1.000, test loss 1.063, test accuracy 0.340\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 63, train loss 0.077, train accuracy 1.000, val loss 0.075, val accuracy 1.000, test loss 1.061, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 64, train loss 0.074, train accuracy 1.000, val loss 0.072, val accuracy 1.000, test loss 1.058, test accuracy 0.345\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 65, train loss 0.071, train accuracy 1.000, val loss 0.069, val accuracy 1.000, test loss 1.056, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 66, train loss 0.068, train accuracy 1.000, val loss 0.066, val accuracy 1.000, test loss 1.054, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 67, train loss 0.066, train accuracy 1.000, val loss 0.063, val accuracy 1.000, test loss 1.051, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 68, train loss 0.063, train accuracy 1.000, val loss 0.061, val accuracy 1.000, test loss 1.050, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 69, train loss 0.061, train accuracy 1.000, val loss 0.058, val accuracy 1.000, test loss 1.048, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 70, train loss 0.058, train accuracy 1.000, val loss 0.056, val accuracy 1.000, test loss 1.047, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 71, train loss 0.056, train accuracy 1.000, val loss 0.054, val accuracy 1.000, test loss 1.045, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 72, train loss 0.054, train accuracy 1.000, val loss 0.052, val accuracy 1.000, test loss 1.044, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 73, train loss 0.051, train accuracy 1.000, val loss 0.050, val accuracy 1.000, test loss 1.044, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 74, train loss 0.049, train accuracy 1.000, val loss 0.047, val accuracy 1.000, test loss 1.043, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 75, train loss 0.047, train accuracy 1.000, val loss 0.046, val accuracy 1.000, test loss 1.043, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 76, train loss 0.045, train accuracy 1.000, val loss 0.044, val accuracy 1.000, test loss 1.042, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 77, train loss 0.043, train accuracy 1.000, val loss 0.042, val accuracy 1.000, test loss 1.042, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 78, train loss 0.042, train accuracy 1.000, val loss 0.040, val accuracy 1.000, test loss 1.041, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 79, train loss 0.040, train accuracy 1.000, val loss 0.038, val accuracy 1.000, test loss 1.040, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 80, train loss 0.038, train accuracy 1.000, val loss 0.037, val accuracy 1.000, test loss 1.038, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 81, train loss 0.036, train accuracy 1.000, val loss 0.035, val accuracy 1.000, test loss 1.037, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 82, train loss 0.035, train accuracy 1.000, val loss 0.034, val accuracy 1.000, test loss 1.034, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 83, train loss 0.033, train accuracy 1.000, val loss 0.032, val accuracy 1.000, test loss 1.032, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.032, train accuracy 1.000, val loss 0.031, val accuracy 1.000, test loss 1.031, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 85, train loss 0.031, train accuracy 1.000, val loss 0.030, val accuracy 1.000, test loss 1.030, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 86, train loss 0.029, train accuracy 1.000, val loss 0.028, val accuracy 1.000, test loss 1.029, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 87, train loss 0.028, train accuracy 1.000, val loss 0.027, val accuracy 1.000, test loss 1.029, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 88, train loss 0.027, train accuracy 1.000, val loss 0.026, val accuracy 1.000, test loss 1.029, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 89, train loss 0.026, train accuracy 1.000, val loss 0.025, val accuracy 1.000, test loss 1.028, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 90, train loss 0.025, train accuracy 1.000, val loss 0.024, val accuracy 1.000, test loss 1.028, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 91, train loss 0.024, train accuracy 1.000, val loss 0.023, val accuracy 1.000, test loss 1.028, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 92, train loss 0.022, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 1.027, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 93, train loss 0.022, train accuracy 1.000, val loss 0.021, val accuracy 1.000, test loss 1.026, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 94, train loss 0.021, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 1.027, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 95, train loss 0.020, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 1.030, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 96, train loss 0.019, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 1.029, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 97, train loss 0.018, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 1.034, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Epoch 98, train loss 0.017, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 1.032, test accuracy 0.374\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 99, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 1.037, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 100, train loss 0.016, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 1.038, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 101, train loss 0.015, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 1.042, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 102, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 1.045, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Epoch 103, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 1.049, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Epoch 104, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 1.051, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 105, train loss 0.013, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.064, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.057, test accuracy 0.374\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 107, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.059, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 108, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.058, test accuracy 0.374\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 109, train loss 0.011, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.064, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Epoch 110, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.062, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Epoch 111, train loss 0.010, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.067, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 112, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.068, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 113, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.073, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 114, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.074, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 115, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.080, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 116, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.080, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 117, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.085, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 118, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.088, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 119, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.091, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 120, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.098, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Epoch 121, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.097, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 122, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.107, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 123, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.105, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.116, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 125, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.114, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 126, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.122, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 127, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.120, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 128, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.130, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 129, train loss 0.005, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.126, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 130, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.137, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.121, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 132, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.137, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 133, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.139, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.130, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.147, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.142, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.148, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.144, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.161, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.162, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.149, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.150, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.157, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.003, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 1.162, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 1.166, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 146, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 1.169, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 147, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 1.171, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 1.174, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 149, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 1.177, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 2746\n",
            "8964\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.188, train accuracy 0.200, val loss 1.167, val accuracy 0.240, test loss 1.357, test accuracy 0.069\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.148, train accuracy 0.255, val loss 1.124, val accuracy 0.302, test loss 1.344, test accuracy 0.076\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 2, train loss 1.104, train accuracy 0.378, val loss 1.080, val accuracy 0.508, test loss 1.330, test accuracy 0.090\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.060, train accuracy 0.597, val loss 1.035, val accuracy 0.683, test loss 1.316, test accuracy 0.135\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.016, train accuracy 0.754, val loss 0.992, val accuracy 0.800, test loss 1.303, test accuracy 0.168\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 5, train loss 0.972, train accuracy 0.828, val loss 0.948, val accuracy 0.846, test loss 1.290, test accuracy 0.185\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.929, train accuracy 0.862, val loss 0.905, val accuracy 0.898, test loss 1.278, test accuracy 0.197\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 7, train loss 0.887, train accuracy 0.908, val loss 0.863, val accuracy 0.917, test loss 1.266, test accuracy 0.204\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 8, train loss 0.845, train accuracy 0.923, val loss 0.822, val accuracy 0.935, test loss 1.255, test accuracy 0.221\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.804, train accuracy 0.932, val loss 0.782, val accuracy 0.948, test loss 1.244, test accuracy 0.223\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.766, train accuracy 0.948, val loss 0.744, val accuracy 0.957, test loss 1.232, test accuracy 0.223\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 11, train loss 0.730, train accuracy 0.951, val loss 0.710, val accuracy 0.963, test loss 1.219, test accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 12, train loss 0.696, train accuracy 0.966, val loss 0.678, val accuracy 0.963, test loss 1.215, test accuracy 0.248\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 13, train loss 0.665, train accuracy 0.966, val loss 0.647, val accuracy 0.966, test loss 1.205, test accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 14, train loss 0.636, train accuracy 0.969, val loss 0.619, val accuracy 0.966, test loss 1.197, test accuracy 0.258\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 15, train loss 0.610, train accuracy 0.975, val loss 0.597, val accuracy 0.972, test loss 1.194, test accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 16, train loss 0.587, train accuracy 0.978, val loss 0.572, val accuracy 0.975, test loss 1.185, test accuracy 0.252\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.564, train accuracy 0.978, val loss 0.550, val accuracy 0.978, test loss 1.179, test accuracy 0.256\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 18, train loss 0.543, train accuracy 0.982, val loss 0.530, val accuracy 0.978, test loss 1.174, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 19, train loss 0.523, train accuracy 0.982, val loss 0.510, val accuracy 0.982, test loss 1.169, test accuracy 0.261\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 20, train loss 0.504, train accuracy 0.985, val loss 0.491, val accuracy 0.988, test loss 1.164, test accuracy 0.267\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 21, train loss 0.485, train accuracy 0.988, val loss 0.473, val accuracy 0.988, test loss 1.160, test accuracy 0.261\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 22, train loss 0.467, train accuracy 0.988, val loss 0.456, val accuracy 0.988, test loss 1.156, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 23, train loss 0.450, train accuracy 0.988, val loss 0.440, val accuracy 0.988, test loss 1.153, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Epoch 24, train loss 0.434, train accuracy 0.985, val loss 0.423, val accuracy 0.988, test loss 1.150, test accuracy 0.258\n",
            "Epoch 25, train loss 0.418, train accuracy 0.985, val loss 0.407, val accuracy 0.988, test loss 1.148, test accuracy 0.258\n",
            "Epoch 26, train loss 0.402, train accuracy 0.985, val loss 0.392, val accuracy 0.988, test loss 1.146, test accuracy 0.260\n",
            "Epoch 27, train loss 0.386, train accuracy 0.985, val loss 0.377, val accuracy 0.988, test loss 1.143, test accuracy 0.254\n",
            "Epoch 28, train loss 0.371, train accuracy 0.988, val loss 0.362, val accuracy 0.988, test loss 1.142, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Epoch 29, train loss 0.357, train accuracy 0.988, val loss 0.347, val accuracy 0.988, test loss 1.141, test accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Epoch 30, train loss 0.343, train accuracy 0.988, val loss 0.334, val accuracy 0.988, test loss 1.137, test accuracy 0.256\n",
            "Saving overall best train val model\n",
            "Epoch 31, train loss 0.329, train accuracy 0.988, val loss 0.320, val accuracy 0.988, test loss 1.133, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Epoch 32, train loss 0.315, train accuracy 0.988, val loss 0.306, val accuracy 0.991, test loss 1.129, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Epoch 33, train loss 0.307, train accuracy 0.988, val loss 0.294, val accuracy 0.991, test loss 1.119, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Epoch 34, train loss 0.290, train accuracy 0.991, val loss 0.283, val accuracy 0.991, test loss 1.116, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 35, train loss 0.280, train accuracy 0.991, val loss 0.273, val accuracy 0.991, test loss 1.113, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 36, train loss 0.269, train accuracy 0.991, val loss 0.263, val accuracy 0.991, test loss 1.108, test accuracy 0.261\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 37, train loss 0.259, train accuracy 0.991, val loss 0.253, val accuracy 0.991, test loss 1.104, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 38, train loss 0.250, train accuracy 0.991, val loss 0.244, val accuracy 0.991, test loss 1.099, test accuracy 0.267\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 39, train loss 0.240, train accuracy 0.991, val loss 0.234, val accuracy 0.991, test loss 1.095, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Epoch 40, train loss 0.231, train accuracy 0.991, val loss 0.229, val accuracy 0.991, test loss 1.094, test accuracy 0.267\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 41, train loss 0.223, train accuracy 0.991, val loss 0.216, val accuracy 0.991, test loss 1.088, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Epoch 42, train loss 0.216, train accuracy 0.991, val loss 0.209, val accuracy 0.991, test loss 1.091, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 43, train loss 0.206, train accuracy 0.991, val loss 0.201, val accuracy 0.991, test loss 1.084, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Epoch 44, train loss 0.198, train accuracy 0.991, val loss 0.193, val accuracy 0.991, test loss 1.078, test accuracy 0.267\n",
            "Saving overall best train val model\n",
            "Epoch 45, train loss 0.191, train accuracy 0.991, val loss 0.186, val accuracy 0.991, test loss 1.075, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 46, train loss 0.183, train accuracy 0.991, val loss 0.179, val accuracy 0.991, test loss 1.071, test accuracy 0.271\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 47, train loss 0.176, train accuracy 0.994, val loss 0.172, val accuracy 0.991, test loss 1.068, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 48, train loss 0.170, train accuracy 0.994, val loss 0.165, val accuracy 0.991, test loss 1.062, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Epoch 49, train loss 0.163, train accuracy 0.994, val loss 0.159, val accuracy 0.991, test loss 1.060, test accuracy 0.261\n",
            "Saving overall best train val model\n",
            "Epoch 50, train loss 0.157, train accuracy 0.994, val loss 0.153, val accuracy 0.991, test loss 1.056, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Epoch 51, train loss 0.151, train accuracy 0.994, val loss 0.147, val accuracy 0.991, test loss 1.053, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Epoch 52, train loss 0.144, train accuracy 0.994, val loss 0.141, val accuracy 0.991, test loss 1.050, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Epoch 53, train loss 0.139, train accuracy 0.994, val loss 0.137, val accuracy 0.991, test loss 1.053, test accuracy 0.271\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 54, train loss 0.134, train accuracy 0.994, val loss 0.130, val accuracy 0.991, test loss 1.045, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Epoch 55, train loss 0.129, train accuracy 0.994, val loss 0.125, val accuracy 0.991, test loss 1.041, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Epoch 56, train loss 0.124, train accuracy 0.994, val loss 0.120, val accuracy 0.991, test loss 1.040, test accuracy 0.261\n",
            "Saving overall best train val model\n",
            "Epoch 57, train loss 0.119, train accuracy 0.994, val loss 0.116, val accuracy 0.994, test loss 1.039, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Epoch 58, train loss 0.114, train accuracy 0.994, val loss 0.111, val accuracy 0.997, test loss 1.037, test accuracy 0.267\n",
            "Saving overall best train val model\n",
            "Epoch 59, train loss 0.110, train accuracy 0.997, val loss 0.107, val accuracy 0.997, test loss 1.035, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 60, train loss 0.106, train accuracy 0.997, val loss 0.103, val accuracy 0.997, test loss 1.033, test accuracy 0.273\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 61, train loss 0.102, train accuracy 0.997, val loss 0.099, val accuracy 0.997, test loss 1.031, test accuracy 0.279\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 62, train loss 0.098, train accuracy 0.997, val loss 0.095, val accuracy 0.997, test loss 1.030, test accuracy 0.273\n",
            "Saving overall best train val model\n",
            "Epoch 63, train loss 0.094, train accuracy 0.997, val loss 0.092, val accuracy 0.997, test loss 1.025, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 64, train loss 0.090, train accuracy 0.997, val loss 0.088, val accuracy 0.997, test loss 1.026, test accuracy 0.275\n",
            "Saving overall best train val model\n",
            "Epoch 65, train loss 0.087, train accuracy 0.997, val loss 0.085, val accuracy 0.997, test loss 1.021, test accuracy 0.286\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 66, train loss 0.083, train accuracy 0.997, val loss 0.081, val accuracy 0.997, test loss 1.024, test accuracy 0.282\n",
            "Saving overall best train val model\n",
            "Epoch 67, train loss 0.080, train accuracy 0.997, val loss 0.083, val accuracy 0.997, test loss 1.046, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Epoch 68, train loss 0.079, train accuracy 0.997, val loss 0.076, val accuracy 0.997, test loss 1.022, test accuracy 0.282\n",
            "Saving overall best train val model\n",
            "Epoch 69, train loss 0.075, train accuracy 0.997, val loss 0.073, val accuracy 0.997, test loss 1.016, test accuracy 0.292\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 70, train loss 0.072, train accuracy 0.997, val loss 0.069, val accuracy 0.997, test loss 1.019, test accuracy 0.282\n",
            "Saving overall best train val model\n",
            "Epoch 71, train loss 0.069, train accuracy 0.997, val loss 0.067, val accuracy 0.997, test loss 1.020, test accuracy 0.275\n",
            "Saving overall best train val model\n",
            "Epoch 72, train loss 0.066, train accuracy 0.997, val loss 0.064, val accuracy 0.997, test loss 1.022, test accuracy 0.279\n",
            "Saving overall best train val model\n",
            "Epoch 73, train loss 0.064, train accuracy 0.997, val loss 0.062, val accuracy 0.997, test loss 1.024, test accuracy 0.279\n",
            "Saving overall best train val model\n",
            "Epoch 74, train loss 0.061, train accuracy 0.997, val loss 0.060, val accuracy 0.997, test loss 1.027, test accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 75, train loss 0.059, train accuracy 0.997, val loss 0.057, val accuracy 0.997, test loss 1.029, test accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 76, train loss 0.057, train accuracy 0.997, val loss 0.055, val accuracy 0.997, test loss 1.030, test accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 77, train loss 0.055, train accuracy 0.997, val loss 0.053, val accuracy 0.997, test loss 1.031, test accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 78, train loss 0.052, train accuracy 0.997, val loss 0.051, val accuracy 0.997, test loss 1.033, test accuracy 0.282\n",
            "Saving overall best train val model\n",
            "Epoch 79, train loss 0.050, train accuracy 0.997, val loss 0.049, val accuracy 0.997, test loss 1.035, test accuracy 0.282\n",
            "Saving overall best train val model\n",
            "Epoch 80, train loss 0.049, train accuracy 0.997, val loss 0.047, val accuracy 0.997, test loss 1.037, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Epoch 81, train loss 0.047, train accuracy 0.997, val loss 0.045, val accuracy 0.997, test loss 1.039, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Epoch 82, train loss 0.045, train accuracy 0.997, val loss 0.044, val accuracy 1.000, test loss 1.040, test accuracy 0.286\n",
            "Saving overall best train val model\n",
            "Epoch 83, train loss 0.043, train accuracy 0.997, val loss 0.042, val accuracy 1.000, test loss 1.041, test accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.042, train accuracy 0.997, val loss 0.040, val accuracy 1.000, test loss 1.042, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Epoch 85, train loss 0.040, train accuracy 0.997, val loss 0.039, val accuracy 1.000, test loss 1.042, test accuracy 0.286\n",
            "Saving overall best train val model\n",
            "Epoch 86, train loss 0.038, train accuracy 1.000, val loss 0.037, val accuracy 1.000, test loss 1.042, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 87, train loss 0.037, train accuracy 1.000, val loss 0.036, val accuracy 1.000, test loss 1.042, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 88, train loss 0.035, train accuracy 1.000, val loss 0.035, val accuracy 1.000, test loss 1.042, test accuracy 0.286\n",
            "Saving overall best train val model\n",
            "Epoch 89, train loss 0.034, train accuracy 1.000, val loss 0.033, val accuracy 1.000, test loss 1.043, test accuracy 0.286\n",
            "Saving overall best train val model\n",
            "Epoch 90, train loss 0.033, train accuracy 1.000, val loss 0.032, val accuracy 1.000, test loss 1.043, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 91, train loss 0.032, train accuracy 1.000, val loss 0.031, val accuracy 1.000, test loss 1.043, test accuracy 0.294\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 92, train loss 0.030, train accuracy 1.000, val loss 0.030, val accuracy 1.000, test loss 1.043, test accuracy 0.298\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 93, train loss 0.029, train accuracy 1.000, val loss 0.028, val accuracy 1.000, test loss 1.044, test accuracy 0.305\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 94, train loss 0.028, train accuracy 1.000, val loss 0.029, val accuracy 1.000, test loss 1.016, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 95, train loss 0.027, train accuracy 1.000, val loss 0.026, val accuracy 1.000, test loss 1.043, test accuracy 0.313\n",
            "Saving overall best train val model\n",
            "Epoch 96, train loss 0.026, train accuracy 1.000, val loss 0.025, val accuracy 1.000, test loss 1.040, test accuracy 0.317\n",
            "Saving overall best train val model\n",
            "Epoch 97, train loss 0.025, train accuracy 1.000, val loss 0.024, val accuracy 1.000, test loss 1.043, test accuracy 0.313\n",
            "Saving overall best train val model\n",
            "Epoch 98, train loss 0.024, train accuracy 1.000, val loss 0.024, val accuracy 1.000, test loss 1.070, test accuracy 0.315\n",
            "Saving overall best train val model\n",
            "Epoch 99, train loss 0.023, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 1.042, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Epoch 100, train loss 0.022, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 1.048, test accuracy 0.305\n",
            "Saving overall best train val model\n",
            "Epoch 101, train loss 0.022, train accuracy 1.000, val loss 0.023, val accuracy 1.000, test loss 1.025, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 102, train loss 0.021, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 1.068, test accuracy 0.313\n",
            "Saving overall best train val model\n",
            "Epoch 103, train loss 0.020, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 1.043, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Epoch 104, train loss 0.019, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 1.046, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Epoch 105, train loss 0.018, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 1.045, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.018, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 1.042, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Epoch 107, train loss 0.017, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 1.043, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Epoch 108, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 1.044, test accuracy 0.332\n",
            "Saving overall best train val model\n",
            "Epoch 109, train loss 0.016, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 1.045, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 110, train loss 0.015, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 1.047, test accuracy 0.336\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 111, train loss 0.015, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 1.049, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 112, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 1.050, test accuracy 0.340\n",
            "Saving overall best train val model\n",
            "Epoch 113, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 1.052, test accuracy 0.340\n",
            "Saving overall best train val model\n",
            "Epoch 114, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 1.054, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 115, train loss 0.013, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.056, test accuracy 0.345\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 116, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.058, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 117, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.059, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 118, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.061, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 119, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.062, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 120, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.067, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 121, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.073, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 122, train loss 0.010, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.076, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 123, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.079, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.082, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 125, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.085, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Epoch 126, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.088, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 127, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.091, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 128, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.040, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 129, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.082, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 130, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.078, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.080, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Epoch 132, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.086, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Epoch 133, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.092, test accuracy 0.376\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.097, test accuracy 0.374\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.102, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.107, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.111, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.114, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.118, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.122, test accuracy 0.374\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.126, test accuracy 0.378\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.130, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.133, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.136, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.138, test accuracy 0.391\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 146, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.142, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 147, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.147, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 148, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.153, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 149, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.158, test accuracy 0.391\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 8964\n",
            "70\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.187, train accuracy 0.151, val loss 1.165, val accuracy 0.197, test loss 1.343, test accuracy 0.111\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.147, train accuracy 0.274, val loss 1.125, val accuracy 0.434, test loss 1.338, test accuracy 0.137\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 2, train loss 1.109, train accuracy 0.514, val loss 1.089, val accuracy 0.674, test loss 1.330, test accuracy 0.139\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.073, train accuracy 0.695, val loss 1.051, val accuracy 0.803, test loss 1.319, test accuracy 0.153\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.033, train accuracy 0.818, val loss 1.009, val accuracy 0.883, test loss 1.306, test accuracy 0.156\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 5, train loss 0.988, train accuracy 0.892, val loss 0.960, val accuracy 0.917, test loss 1.289, test accuracy 0.158\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.937, train accuracy 0.908, val loss 0.906, val accuracy 0.935, test loss 1.273, test accuracy 0.189\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 7, train loss 0.882, train accuracy 0.945, val loss 0.852, val accuracy 0.948, test loss 1.259, test accuracy 0.210\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 8, train loss 0.830, train accuracy 0.954, val loss 0.801, val accuracy 0.960, test loss 1.242, test accuracy 0.233\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.781, train accuracy 0.951, val loss 0.753, val accuracy 0.963, test loss 1.223, test accuracy 0.277\n",
            "Epoch 10, train loss 0.734, train accuracy 0.963, val loss 0.707, val accuracy 0.960, test loss 1.200, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 11, train loss 0.689, train accuracy 0.960, val loss 0.664, val accuracy 0.966, test loss 1.178, test accuracy 0.349\n",
            "Epoch 12, train loss 0.647, train accuracy 0.963, val loss 0.623, val accuracy 0.966, test loss 1.158, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 13, train loss 0.608, train accuracy 0.966, val loss 0.587, val accuracy 0.966, test loss 1.144, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 14, train loss 0.574, train accuracy 0.972, val loss 0.555, val accuracy 0.966, test loss 1.132, test accuracy 0.376\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 15, train loss 0.544, train accuracy 0.972, val loss 0.527, val accuracy 0.972, test loss 1.118, test accuracy 0.380\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 16, train loss 0.518, train accuracy 0.972, val loss 0.503, val accuracy 0.972, test loss 1.108, test accuracy 0.382\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.494, train accuracy 0.972, val loss 0.480, val accuracy 0.975, test loss 1.099, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 18, train loss 0.472, train accuracy 0.972, val loss 0.462, val accuracy 0.972, test loss 1.104, test accuracy 0.370\n",
            "Epoch 19, train loss 0.451, train accuracy 0.972, val loss 0.438, val accuracy 0.972, test loss 1.090, test accuracy 0.359\n",
            "Epoch 20, train loss 0.432, train accuracy 0.972, val loss 0.419, val accuracy 0.972, test loss 1.084, test accuracy 0.355\n",
            "Epoch 21, train loss 0.413, train accuracy 0.975, val loss 0.402, val accuracy 0.975, test loss 1.078, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 22, train loss 0.396, train accuracy 0.975, val loss 0.385, val accuracy 0.975, test loss 1.072, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 23, train loss 0.380, train accuracy 0.975, val loss 0.369, val accuracy 0.978, test loss 1.066, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 24, train loss 0.365, train accuracy 0.978, val loss 0.354, val accuracy 0.982, test loss 1.059, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 25, train loss 0.350, train accuracy 0.982, val loss 0.340, val accuracy 0.982, test loss 1.053, test accuracy 0.376\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 26, train loss 0.336, train accuracy 0.982, val loss 0.326, val accuracy 0.982, test loss 1.047, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 27, train loss 0.322, train accuracy 0.982, val loss 0.313, val accuracy 0.982, test loss 1.042, test accuracy 0.395\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 28, train loss 0.309, train accuracy 0.982, val loss 0.301, val accuracy 0.988, test loss 1.036, test accuracy 0.403\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 29, train loss 0.297, train accuracy 0.985, val loss 0.290, val accuracy 0.988, test loss 1.034, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 30, train loss 0.285, train accuracy 0.988, val loss 0.278, val accuracy 0.988, test loss 1.023, test accuracy 0.405\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 31, train loss 0.275, train accuracy 0.985, val loss 0.273, val accuracy 0.988, test loss 1.032, test accuracy 0.389\n",
            "Epoch 32, train loss 0.264, train accuracy 0.988, val loss 0.256, val accuracy 0.988, test loss 1.012, test accuracy 0.399\n",
            "Saving overall best train val model\n",
            "Epoch 33, train loss 0.253, train accuracy 0.988, val loss 0.246, val accuracy 0.988, test loss 1.007, test accuracy 0.405\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 34, train loss 0.243, train accuracy 0.988, val loss 0.237, val accuracy 0.988, test loss 1.002, test accuracy 0.408\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 35, train loss 0.234, train accuracy 0.988, val loss 0.228, val accuracy 0.988, test loss 0.996, test accuracy 0.410\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 36, train loss 0.225, train accuracy 0.988, val loss 0.219, val accuracy 0.988, test loss 0.991, test accuracy 0.410\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 37, train loss 0.216, train accuracy 0.988, val loss 0.210, val accuracy 0.988, test loss 0.987, test accuracy 0.408\n",
            "Saving overall best train val model\n",
            "Epoch 38, train loss 0.208, train accuracy 0.988, val loss 0.202, val accuracy 0.988, test loss 0.982, test accuracy 0.414\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 39, train loss 0.200, train accuracy 0.988, val loss 0.195, val accuracy 0.988, test loss 0.977, test accuracy 0.418\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 40, train loss 0.193, train accuracy 0.988, val loss 0.187, val accuracy 0.988, test loss 0.972, test accuracy 0.420\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 41, train loss 0.185, train accuracy 0.988, val loss 0.180, val accuracy 0.988, test loss 0.969, test accuracy 0.420\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 42, train loss 0.178, train accuracy 0.988, val loss 0.173, val accuracy 0.988, test loss 0.965, test accuracy 0.424\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 43, train loss 0.171, train accuracy 0.988, val loss 0.167, val accuracy 0.994, test loss 0.963, test accuracy 0.424\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 44, train loss 0.165, train accuracy 0.994, val loss 0.160, val accuracy 0.994, test loss 0.959, test accuracy 0.426\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 45, train loss 0.159, train accuracy 0.994, val loss 0.154, val accuracy 0.994, test loss 0.956, test accuracy 0.416\n",
            "Saving overall best train val model\n",
            "Epoch 46, train loss 0.153, train accuracy 0.994, val loss 0.148, val accuracy 0.994, test loss 0.952, test accuracy 0.418\n",
            "Saving overall best train val model\n",
            "Epoch 47, train loss 0.147, train accuracy 0.994, val loss 0.143, val accuracy 0.994, test loss 0.948, test accuracy 0.420\n",
            "Saving overall best train val model\n",
            "Epoch 48, train loss 0.141, train accuracy 0.994, val loss 0.137, val accuracy 0.994, test loss 0.943, test accuracy 0.427\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 49, train loss 0.136, train accuracy 0.994, val loss 0.132, val accuracy 0.994, test loss 0.940, test accuracy 0.435\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 50, train loss 0.131, train accuracy 0.994, val loss 0.127, val accuracy 0.994, test loss 0.935, test accuracy 0.433\n",
            "Saving overall best train val model\n",
            "Epoch 51, train loss 0.125, train accuracy 0.994, val loss 0.122, val accuracy 0.994, test loss 0.934, test accuracy 0.437\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 52, train loss 0.121, train accuracy 0.994, val loss 0.117, val accuracy 0.994, test loss 0.929, test accuracy 0.445\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 53, train loss 0.116, train accuracy 0.997, val loss 0.112, val accuracy 0.997, test loss 0.924, test accuracy 0.452\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 54, train loss 0.111, train accuracy 0.997, val loss 0.108, val accuracy 0.997, test loss 0.919, test accuracy 0.456\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 55, train loss 0.107, train accuracy 0.997, val loss 0.104, val accuracy 0.997, test loss 0.916, test accuracy 0.458\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 56, train loss 0.103, train accuracy 0.997, val loss 0.100, val accuracy 0.997, test loss 0.912, test accuracy 0.458\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 57, train loss 0.099, train accuracy 0.997, val loss 0.096, val accuracy 0.997, test loss 0.908, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 58, train loss 0.095, train accuracy 0.997, val loss 0.092, val accuracy 0.997, test loss 0.903, test accuracy 0.458\n",
            "Saving overall best train val model\n",
            "Epoch 59, train loss 0.092, train accuracy 0.997, val loss 0.089, val accuracy 0.997, test loss 0.900, test accuracy 0.460\n",
            "Saving overall best train val model\n",
            "Epoch 60, train loss 0.088, train accuracy 0.997, val loss 0.085, val accuracy 0.997, test loss 0.896, test accuracy 0.464\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 61, train loss 0.085, train accuracy 0.997, val loss 0.082, val accuracy 0.997, test loss 0.892, test accuracy 0.466\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 62, train loss 0.081, train accuracy 0.997, val loss 0.079, val accuracy 0.997, test loss 0.888, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Epoch 63, train loss 0.078, train accuracy 0.997, val loss 0.076, val accuracy 0.997, test loss 0.885, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Epoch 64, train loss 0.075, train accuracy 0.997, val loss 0.073, val accuracy 0.997, test loss 0.881, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Epoch 65, train loss 0.072, train accuracy 0.997, val loss 0.070, val accuracy 0.997, test loss 0.880, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Epoch 66, train loss 0.070, train accuracy 0.997, val loss 0.068, val accuracy 0.997, test loss 0.877, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Epoch 67, train loss 0.067, train accuracy 0.997, val loss 0.065, val accuracy 0.997, test loss 0.876, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Epoch 68, train loss 0.065, train accuracy 0.997, val loss 0.063, val accuracy 0.997, test loss 0.873, test accuracy 0.466\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 69, train loss 0.062, train accuracy 0.997, val loss 0.060, val accuracy 0.997, test loss 0.871, test accuracy 0.468\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 70, train loss 0.060, train accuracy 0.997, val loss 0.058, val accuracy 0.997, test loss 0.871, test accuracy 0.466\n",
            "Saving overall best train val model\n",
            "Epoch 71, train loss 0.058, train accuracy 0.997, val loss 0.056, val accuracy 0.997, test loss 0.872, test accuracy 0.471\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 72, train loss 0.055, train accuracy 0.997, val loss 0.054, val accuracy 0.997, test loss 0.864, test accuracy 0.468\n",
            "Saving overall best train val model\n",
            "Epoch 73, train loss 0.053, train accuracy 0.997, val loss 0.052, val accuracy 0.997, test loss 0.860, test accuracy 0.469\n",
            "Saving overall best train val model\n",
            "Epoch 74, train loss 0.051, train accuracy 0.997, val loss 0.050, val accuracy 0.997, test loss 0.857, test accuracy 0.469\n",
            "Saving overall best train val model\n",
            "Epoch 75, train loss 0.049, train accuracy 0.997, val loss 0.048, val accuracy 0.997, test loss 0.854, test accuracy 0.469\n",
            "Saving overall best train val model\n",
            "Epoch 76, train loss 0.048, train accuracy 0.997, val loss 0.046, val accuracy 0.997, test loss 0.853, test accuracy 0.464\n",
            "Saving overall best train val model\n",
            "Epoch 77, train loss 0.046, train accuracy 0.997, val loss 0.045, val accuracy 0.997, test loss 0.851, test accuracy 0.469\n",
            "Saving overall best train val model\n",
            "Epoch 78, train loss 0.044, train accuracy 0.997, val loss 0.043, val accuracy 0.997, test loss 0.849, test accuracy 0.471\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 79, train loss 0.042, train accuracy 0.997, val loss 0.041, val accuracy 0.997, test loss 0.847, test accuracy 0.471\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 80, train loss 0.041, train accuracy 0.997, val loss 0.040, val accuracy 0.997, test loss 0.845, test accuracy 0.471\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 81, train loss 0.039, train accuracy 0.997, val loss 0.038, val accuracy 0.997, test loss 0.844, test accuracy 0.473\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 82, train loss 0.038, train accuracy 0.997, val loss 0.037, val accuracy 0.997, test loss 0.842, test accuracy 0.473\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 83, train loss 0.037, train accuracy 0.997, val loss 0.036, val accuracy 0.997, test loss 0.841, test accuracy 0.469\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.035, train accuracy 0.997, val loss 0.034, val accuracy 0.997, test loss 0.839, test accuracy 0.471\n",
            "Saving overall best train val model\n",
            "Epoch 85, train loss 0.034, train accuracy 0.997, val loss 0.033, val accuracy 0.997, test loss 0.837, test accuracy 0.479\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 86, train loss 0.033, train accuracy 0.997, val loss 0.032, val accuracy 0.997, test loss 0.836, test accuracy 0.483\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 87, train loss 0.032, train accuracy 0.997, val loss 0.031, val accuracy 0.997, test loss 0.833, test accuracy 0.485\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 88, train loss 0.031, train accuracy 0.997, val loss 0.030, val accuracy 0.997, test loss 0.833, test accuracy 0.483\n",
            "Saving overall best train val model\n",
            "Epoch 89, train loss 0.029, train accuracy 0.997, val loss 0.028, val accuracy 0.997, test loss 0.828, test accuracy 0.485\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 90, train loss 0.028, train accuracy 0.997, val loss 0.027, val accuracy 0.997, test loss 0.824, test accuracy 0.489\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 91, train loss 0.027, train accuracy 0.997, val loss 0.026, val accuracy 0.997, test loss 0.820, test accuracy 0.489\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 92, train loss 0.026, train accuracy 0.997, val loss 0.025, val accuracy 0.997, test loss 0.819, test accuracy 0.490\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 93, train loss 0.025, train accuracy 0.997, val loss 0.024, val accuracy 0.997, test loss 0.821, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 94, train loss 0.024, train accuracy 0.997, val loss 0.024, val accuracy 0.997, test loss 0.821, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 95, train loss 0.023, train accuracy 0.997, val loss 0.023, val accuracy 0.997, test loss 0.820, test accuracy 0.506\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 96, train loss 0.023, train accuracy 0.997, val loss 0.022, val accuracy 1.000, test loss 0.820, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 97, train loss 0.022, train accuracy 1.000, val loss 0.021, val accuracy 1.000, test loss 0.819, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 98, train loss 0.021, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 0.819, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 99, train loss 0.020, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 0.819, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 100, train loss 0.020, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 0.819, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 101, train loss 0.019, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 0.819, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Epoch 102, train loss 0.018, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 0.819, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 103, train loss 0.018, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 0.820, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 104, train loss 0.017, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 0.822, test accuracy 0.506\n",
            "Saving overall best train val model\n",
            "Epoch 105, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 0.823, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 0.816, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Epoch 107, train loss 0.015, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 0.816, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 108, train loss 0.015, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 0.813, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 109, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 0.815, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 110, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.812, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 111, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.808, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 112, train loss 0.013, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.818, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 113, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.805, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 114, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.814, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 115, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.809, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 116, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.815, test accuracy 0.525\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 117, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.814, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 118, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.815, test accuracy 0.525\n",
            "Saving overall best train val model\n",
            "Epoch 119, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.819, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 120, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.821, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Epoch 121, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.824, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 122, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.826, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 123, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.829, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.829, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 125, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.832, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 126, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.836, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 127, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.838, test accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 128, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.840, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 129, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.843, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Epoch 130, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.845, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.849, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Epoch 132, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.849, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 133, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.853, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.857, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.858, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.860, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.861, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.866, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.864, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.867, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.853, test accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.856, test accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.858, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.857, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.005, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.857, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 146, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.860, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 147, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.861, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.864, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 149, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.865, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 70\n",
            "4786\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.194, train accuracy 0.129, val loss 1.175, val accuracy 0.206, test loss 1.369, test accuracy 0.059\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.159, train accuracy 0.292, val loss 1.139, val accuracy 0.363, test loss 1.360, test accuracy 0.095\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 2, train loss 1.122, train accuracy 0.418, val loss 1.101, val accuracy 0.474, test loss 1.351, test accuracy 0.118\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.082, train accuracy 0.520, val loss 1.058, val accuracy 0.578, test loss 1.340, test accuracy 0.130\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.037, train accuracy 0.665, val loss 1.010, val accuracy 0.708, test loss 1.328, test accuracy 0.145\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 5, train loss 0.986, train accuracy 0.742, val loss 0.955, val accuracy 0.757, test loss 1.318, test accuracy 0.153\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.930, train accuracy 0.782, val loss 0.899, val accuracy 0.803, test loss 1.317, test accuracy 0.141\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 7, train loss 0.875, train accuracy 0.815, val loss 0.845, val accuracy 0.837, test loss 1.315, test accuracy 0.132\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 8, train loss 0.822, train accuracy 0.846, val loss 0.793, val accuracy 0.880, test loss 1.313, test accuracy 0.124\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 9, train loss 0.770, train accuracy 0.905, val loss 0.741, val accuracy 0.914, test loss 1.309, test accuracy 0.128\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.720, train accuracy 0.917, val loss 0.694, val accuracy 0.923, test loss 1.305, test accuracy 0.132\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 11, train loss 0.676, train accuracy 0.932, val loss 0.652, val accuracy 0.935, test loss 1.301, test accuracy 0.130\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 12, train loss 0.636, train accuracy 0.938, val loss 0.614, val accuracy 0.945, test loss 1.298, test accuracy 0.126\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 13, train loss 0.600, train accuracy 0.945, val loss 0.581, val accuracy 0.951, test loss 1.296, test accuracy 0.122\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 14, train loss 0.568, train accuracy 0.963, val loss 0.551, val accuracy 0.963, test loss 1.294, test accuracy 0.118\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 15, train loss 0.539, train accuracy 0.969, val loss 0.523, val accuracy 0.972, test loss 1.292, test accuracy 0.120\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 16, train loss 0.513, train accuracy 0.978, val loss 0.498, val accuracy 0.978, test loss 1.290, test accuracy 0.120\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.488, train accuracy 0.982, val loss 0.473, val accuracy 0.982, test loss 1.286, test accuracy 0.122\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 18, train loss 0.464, train accuracy 0.982, val loss 0.452, val accuracy 0.988, test loss 1.280, test accuracy 0.135\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 19, train loss 0.443, train accuracy 0.988, val loss 0.430, val accuracy 0.991, test loss 1.276, test accuracy 0.145\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 20, train loss 0.422, train accuracy 0.988, val loss 0.411, val accuracy 0.991, test loss 1.270, test accuracy 0.151\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 21, train loss 0.403, train accuracy 0.991, val loss 0.392, val accuracy 0.991, test loss 1.266, test accuracy 0.153\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 22, train loss 0.385, train accuracy 0.991, val loss 0.374, val accuracy 0.991, test loss 1.261, test accuracy 0.153\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 23, train loss 0.367, train accuracy 0.991, val loss 0.356, val accuracy 0.991, test loss 1.257, test accuracy 0.156\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 24, train loss 0.350, train accuracy 0.991, val loss 0.339, val accuracy 0.991, test loss 1.252, test accuracy 0.158\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 25, train loss 0.334, train accuracy 0.991, val loss 0.323, val accuracy 0.991, test loss 1.245, test accuracy 0.166\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 26, train loss 0.318, train accuracy 0.991, val loss 0.308, val accuracy 0.991, test loss 1.238, test accuracy 0.170\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 27, train loss 0.303, train accuracy 0.991, val loss 0.294, val accuracy 0.991, test loss 1.230, test accuracy 0.174\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 28, train loss 0.289, train accuracy 0.991, val loss 0.280, val accuracy 0.991, test loss 1.222, test accuracy 0.170\n",
            "Saving overall best train val model\n",
            "Epoch 29, train loss 0.275, train accuracy 0.991, val loss 0.267, val accuracy 0.994, test loss 1.214, test accuracy 0.179\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 30, train loss 0.263, train accuracy 0.994, val loss 0.255, val accuracy 0.994, test loss 1.208, test accuracy 0.179\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 31, train loss 0.251, train accuracy 0.994, val loss 0.243, val accuracy 0.994, test loss 1.205, test accuracy 0.176\n",
            "Saving overall best train val model\n",
            "Epoch 32, train loss 0.240, train accuracy 0.994, val loss 0.233, val accuracy 0.994, test loss 1.199, test accuracy 0.177\n",
            "Saving overall best train val model\n",
            "Epoch 33, train loss 0.229, train accuracy 0.994, val loss 0.223, val accuracy 0.994, test loss 1.195, test accuracy 0.181\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 34, train loss 0.220, train accuracy 0.994, val loss 0.214, val accuracy 0.994, test loss 1.194, test accuracy 0.179\n",
            "Saving overall best train val model\n",
            "Epoch 35, train loss 0.210, train accuracy 0.994, val loss 0.204, val accuracy 0.994, test loss 1.190, test accuracy 0.176\n",
            "Saving overall best train val model\n",
            "Epoch 36, train loss 0.201, train accuracy 0.994, val loss 0.195, val accuracy 0.994, test loss 1.185, test accuracy 0.181\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 37, train loss 0.194, train accuracy 0.994, val loss 0.191, val accuracy 0.994, test loss 1.192, test accuracy 0.185\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 38, train loss 0.185, train accuracy 0.994, val loss 0.179, val accuracy 0.994, test loss 1.180, test accuracy 0.189\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 39, train loss 0.177, train accuracy 0.994, val loss 0.172, val accuracy 0.994, test loss 1.179, test accuracy 0.195\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 40, train loss 0.170, train accuracy 0.994, val loss 0.166, val accuracy 0.994, test loss 1.181, test accuracy 0.191\n",
            "Saving overall best train val model\n",
            "Epoch 41, train loss 0.163, train accuracy 0.994, val loss 0.158, val accuracy 0.994, test loss 1.176, test accuracy 0.198\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 42, train loss 0.156, train accuracy 0.994, val loss 0.152, val accuracy 0.994, test loss 1.176, test accuracy 0.198\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 43, train loss 0.150, train accuracy 0.994, val loss 0.145, val accuracy 0.994, test loss 1.173, test accuracy 0.202\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 44, train loss 0.144, train accuracy 0.994, val loss 0.142, val accuracy 0.994, test loss 1.177, test accuracy 0.208\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 45, train loss 0.138, train accuracy 0.994, val loss 0.133, val accuracy 0.997, test loss 1.168, test accuracy 0.198\n",
            "Saving overall best train val model\n",
            "Epoch 46, train loss 0.131, train accuracy 0.997, val loss 0.128, val accuracy 0.997, test loss 1.168, test accuracy 0.204\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 47, train loss 0.126, train accuracy 0.997, val loss 0.122, val accuracy 0.997, test loss 1.168, test accuracy 0.210\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 48, train loss 0.121, train accuracy 0.997, val loss 0.117, val accuracy 0.997, test loss 1.165, test accuracy 0.214\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 49, train loss 0.116, train accuracy 0.997, val loss 0.116, val accuracy 0.997, test loss 1.173, test accuracy 0.218\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 50, train loss 0.112, train accuracy 0.997, val loss 0.108, val accuracy 0.997, test loss 1.163, test accuracy 0.219\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 51, train loss 0.106, train accuracy 0.997, val loss 0.104, val accuracy 0.997, test loss 1.163, test accuracy 0.223\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 52, train loss 0.102, train accuracy 0.997, val loss 0.099, val accuracy 0.997, test loss 1.160, test accuracy 0.225\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 53, train loss 0.098, train accuracy 0.997, val loss 0.095, val accuracy 0.997, test loss 1.159, test accuracy 0.227\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 54, train loss 0.094, train accuracy 0.997, val loss 0.091, val accuracy 0.997, test loss 1.157, test accuracy 0.233\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 55, train loss 0.090, train accuracy 0.997, val loss 0.087, val accuracy 0.997, test loss 1.157, test accuracy 0.229\n",
            "Saving overall best train val model\n",
            "Epoch 56, train loss 0.087, train accuracy 0.997, val loss 0.087, val accuracy 0.997, test loss 1.170, test accuracy 0.229\n",
            "Saving overall best train val model\n",
            "Epoch 57, train loss 0.083, train accuracy 0.997, val loss 0.081, val accuracy 0.997, test loss 1.157, test accuracy 0.233\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 58, train loss 0.080, train accuracy 0.997, val loss 0.078, val accuracy 0.997, test loss 1.150, test accuracy 0.233\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 59, train loss 0.076, train accuracy 0.997, val loss 0.074, val accuracy 0.997, test loss 1.151, test accuracy 0.231\n",
            "Saving overall best train val model\n",
            "Epoch 60, train loss 0.073, train accuracy 0.997, val loss 0.071, val accuracy 0.997, test loss 1.153, test accuracy 0.235\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 61, train loss 0.070, train accuracy 0.997, val loss 0.068, val accuracy 0.997, test loss 1.154, test accuracy 0.235\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 62, train loss 0.067, train accuracy 0.997, val loss 0.065, val accuracy 0.997, test loss 1.155, test accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 63, train loss 0.064, train accuracy 0.997, val loss 0.063, val accuracy 0.997, test loss 1.156, test accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 64, train loss 0.061, train accuracy 0.997, val loss 0.060, val accuracy 0.997, test loss 1.157, test accuracy 0.246\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 65, train loss 0.059, train accuracy 0.997, val loss 0.057, val accuracy 0.997, test loss 1.159, test accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Epoch 66, train loss 0.056, train accuracy 0.997, val loss 0.056, val accuracy 0.997, test loss 1.161, test accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Epoch 67, train loss 0.055, train accuracy 0.997, val loss 0.056, val accuracy 0.997, test loss 1.173, test accuracy 0.235\n",
            "Saving overall best train val model\n",
            "Epoch 68, train loss 0.053, train accuracy 0.997, val loss 0.051, val accuracy 0.997, test loss 1.156, test accuracy 0.246\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 69, train loss 0.050, train accuracy 0.997, val loss 0.050, val accuracy 0.997, test loss 1.171, test accuracy 0.231\n",
            "Saving overall best train val model\n",
            "Epoch 70, train loss 0.048, train accuracy 0.997, val loss 0.047, val accuracy 0.997, test loss 1.156, test accuracy 0.252\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 71, train loss 0.046, train accuracy 0.997, val loss 0.045, val accuracy 0.997, test loss 1.153, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 72, train loss 0.044, train accuracy 0.997, val loss 0.043, val accuracy 0.997, test loss 1.155, test accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Epoch 73, train loss 0.042, train accuracy 0.997, val loss 0.042, val accuracy 0.997, test loss 1.157, test accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Epoch 74, train loss 0.041, train accuracy 0.997, val loss 0.040, val accuracy 0.997, test loss 1.156, test accuracy 0.248\n",
            "Saving overall best train val model\n",
            "Epoch 75, train loss 0.039, train accuracy 0.997, val loss 0.039, val accuracy 0.997, test loss 1.156, test accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Epoch 76, train loss 0.038, train accuracy 0.997, val loss 0.037, val accuracy 0.997, test loss 1.157, test accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Epoch 77, train loss 0.036, train accuracy 0.997, val loss 0.036, val accuracy 0.997, test loss 1.157, test accuracy 0.252\n",
            "Saving overall best train val model\n",
            "Epoch 78, train loss 0.035, train accuracy 0.997, val loss 0.034, val accuracy 0.997, test loss 1.156, test accuracy 0.256\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 79, train loss 0.033, train accuracy 0.997, val loss 0.032, val accuracy 0.997, test loss 1.155, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 80, train loss 0.032, train accuracy 0.997, val loss 0.031, val accuracy 0.997, test loss 1.156, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 81, train loss 0.031, train accuracy 0.997, val loss 0.030, val accuracy 0.997, test loss 1.155, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Epoch 82, train loss 0.030, train accuracy 0.997, val loss 0.032, val accuracy 0.994, test loss 1.139, test accuracy 0.271\n",
            "Epoch 83, train loss 0.029, train accuracy 0.997, val loss 0.028, val accuracy 0.997, test loss 1.162, test accuracy 0.267\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 84, train loss 0.030, train accuracy 0.994, val loss 0.029, val accuracy 0.997, test loss 1.180, test accuracy 0.265\n",
            "Epoch 85, train loss 0.027, train accuracy 0.997, val loss 0.026, val accuracy 0.997, test loss 1.165, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Epoch 86, train loss 0.025, train accuracy 0.997, val loss 0.025, val accuracy 0.997, test loss 1.149, test accuracy 0.267\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 87, train loss 0.024, train accuracy 0.997, val loss 0.024, val accuracy 0.997, test loss 1.171, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 88, train loss 0.023, train accuracy 0.997, val loss 0.023, val accuracy 0.997, test loss 1.168, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 89, train loss 0.023, train accuracy 0.997, val loss 0.022, val accuracy 0.997, test loss 1.172, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Epoch 90, train loss 0.022, train accuracy 0.997, val loss 0.021, val accuracy 0.997, test loss 1.164, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 91, train loss 0.021, train accuracy 0.997, val loss 0.020, val accuracy 0.997, test loss 1.170, test accuracy 0.279\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 92, train loss 0.020, train accuracy 0.997, val loss 0.020, val accuracy 0.997, test loss 1.169, test accuracy 0.277\n",
            "Saving overall best train val model\n",
            "Epoch 93, train loss 0.019, train accuracy 0.997, val loss 0.019, val accuracy 0.997, test loss 1.177, test accuracy 0.273\n",
            "Saving overall best train val model\n",
            "Epoch 94, train loss 0.019, train accuracy 0.997, val loss 0.018, val accuracy 0.997, test loss 1.175, test accuracy 0.277\n",
            "Saving overall best train val model\n",
            "Epoch 95, train loss 0.018, train accuracy 0.997, val loss 0.017, val accuracy 0.997, test loss 1.180, test accuracy 0.275\n",
            "Saving overall best train val model\n",
            "Epoch 96, train loss 0.017, train accuracy 0.997, val loss 0.017, val accuracy 0.997, test loss 1.180, test accuracy 0.279\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 97, train loss 0.016, train accuracy 0.997, val loss 0.016, val accuracy 1.000, test loss 1.178, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 98, train loss 0.016, train accuracy 0.997, val loss 0.016, val accuracy 1.000, test loss 1.180, test accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 99, train loss 0.015, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 1.173, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 100, train loss 0.015, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 1.192, test accuracy 0.271\n",
            "Saving overall best train val model\n",
            "Epoch 101, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 1.176, test accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 102, train loss 0.014, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 1.268, test accuracy 0.275\n",
            "Saving overall best train val model\n",
            "Epoch 103, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 1.202, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Epoch 104, train loss 0.013, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.192, test accuracy 0.277\n",
            "Saving overall best train val model\n",
            "Epoch 105, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.191, test accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.188, test accuracy 0.286\n",
            "Saving overall best train val model\n",
            "Epoch 107, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.184, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 108, train loss 0.011, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.186, test accuracy 0.292\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 109, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.186, test accuracy 0.292\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 110, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.188, test accuracy 0.292\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 111, train loss 0.010, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.191, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Epoch 112, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.194, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Epoch 113, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.196, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Epoch 114, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.196, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Epoch 115, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.199, test accuracy 0.286\n",
            "Saving overall best train val model\n",
            "Epoch 116, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.200, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Epoch 117, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.194, test accuracy 0.300\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 118, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.218, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Epoch 119, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.211, test accuracy 0.294\n",
            "Saving overall best train val model\n",
            "Epoch 120, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.196, test accuracy 0.313\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 121, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.197, test accuracy 0.305\n",
            "Saving overall best train val model\n",
            "Epoch 122, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.220, test accuracy 0.298\n",
            "Saving overall best train val model\n",
            "Epoch 123, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.217, test accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.229, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Epoch 125, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.229, test accuracy 0.298\n",
            "Saving overall best train val model\n",
            "Epoch 126, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.220, test accuracy 0.307\n",
            "Saving overall best train val model\n",
            "Epoch 127, train loss 0.005, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.397, test accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Epoch 128, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.289, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Epoch 129, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.262, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Epoch 130, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.256, test accuracy 0.286\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.005, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.252, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Epoch 132, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.254, test accuracy 0.292\n",
            "Saving overall best train val model\n",
            "Epoch 133, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.256, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.252, test accuracy 0.298\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.250, test accuracy 0.302\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.248, test accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.249, test accuracy 0.305\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.004, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.253, test accuracy 0.307\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.256, test accuracy 0.307\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.258, test accuracy 0.309\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.261, test accuracy 0.313\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 142, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.266, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 143, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.263, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 144, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.270, test accuracy 0.317\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.267, test accuracy 0.323\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 146, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.268, test accuracy 0.326\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 147, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.280, test accuracy 0.317\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.003, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 1.279, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 149, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 1.278, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Saving PupilID Nest for seq 4786\n",
            "2816\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.188, train accuracy 0.160, val loss 1.170, val accuracy 0.185, test loss 1.336, test accuracy 0.177\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.157, train accuracy 0.240, val loss 1.140, val accuracy 0.298, test loss 1.330, test accuracy 0.204\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 2, train loss 1.126, train accuracy 0.372, val loss 1.107, val accuracy 0.465, test loss 1.325, test accuracy 0.214\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.091, train accuracy 0.542, val loss 1.069, val accuracy 0.612, test loss 1.321, test accuracy 0.246\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.050, train accuracy 0.680, val loss 1.026, val accuracy 0.729, test loss 1.316, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 5, train loss 1.006, train accuracy 0.748, val loss 0.982, val accuracy 0.782, test loss 1.307, test accuracy 0.281\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.965, train accuracy 0.794, val loss 0.943, val accuracy 0.809, test loss 1.297, test accuracy 0.275\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 7, train loss 0.926, train accuracy 0.834, val loss 0.905, val accuracy 0.868, test loss 1.286, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 8, train loss 0.889, train accuracy 0.865, val loss 0.868, val accuracy 0.908, test loss 1.274, test accuracy 0.296\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.852, train accuracy 0.905, val loss 0.831, val accuracy 0.929, test loss 1.260, test accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.815, train accuracy 0.935, val loss 0.793, val accuracy 0.942, test loss 1.245, test accuracy 0.311\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 11, train loss 0.778, train accuracy 0.938, val loss 0.756, val accuracy 0.954, test loss 1.227, test accuracy 0.315\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 12, train loss 0.742, train accuracy 0.945, val loss 0.722, val accuracy 0.957, test loss 1.209, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 13, train loss 0.708, train accuracy 0.951, val loss 0.689, val accuracy 0.960, test loss 1.192, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 14, train loss 0.676, train accuracy 0.954, val loss 0.658, val accuracy 0.966, test loss 1.174, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 15, train loss 0.646, train accuracy 0.957, val loss 0.629, val accuracy 0.966, test loss 1.158, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 16, train loss 0.618, train accuracy 0.957, val loss 0.601, val accuracy 0.969, test loss 1.143, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.591, train accuracy 0.957, val loss 0.575, val accuracy 0.969, test loss 1.129, test accuracy 0.403\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 18, train loss 0.565, train accuracy 0.963, val loss 0.550, val accuracy 0.969, test loss 1.115, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 19, train loss 0.542, train accuracy 0.969, val loss 0.527, val accuracy 0.982, test loss 1.101, test accuracy 0.416\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 20, train loss 0.519, train accuracy 0.969, val loss 0.506, val accuracy 0.982, test loss 1.088, test accuracy 0.429\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 21, train loss 0.498, train accuracy 0.975, val loss 0.485, val accuracy 0.982, test loss 1.076, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 22, train loss 0.477, train accuracy 0.982, val loss 0.465, val accuracy 0.982, test loss 1.065, test accuracy 0.466\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 23, train loss 0.458, train accuracy 0.985, val loss 0.446, val accuracy 0.988, test loss 1.056, test accuracy 0.485\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 24, train loss 0.440, train accuracy 0.985, val loss 0.429, val accuracy 0.988, test loss 1.048, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 25, train loss 0.423, train accuracy 0.985, val loss 0.412, val accuracy 0.988, test loss 1.041, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 26, train loss 0.406, train accuracy 0.988, val loss 0.396, val accuracy 0.988, test loss 1.034, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 27, train loss 0.391, train accuracy 0.988, val loss 0.381, val accuracy 0.988, test loss 1.027, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 28, train loss 0.376, train accuracy 0.988, val loss 0.366, val accuracy 0.988, test loss 1.021, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 29, train loss 0.361, train accuracy 0.991, val loss 0.351, val accuracy 0.991, test loss 1.014, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 30, train loss 0.346, train accuracy 0.991, val loss 0.337, val accuracy 0.991, test loss 1.008, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 31, train loss 0.332, train accuracy 0.991, val loss 0.323, val accuracy 0.991, test loss 1.003, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 32, train loss 0.319, train accuracy 0.991, val loss 0.309, val accuracy 0.991, test loss 0.997, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 33, train loss 0.305, train accuracy 0.991, val loss 0.296, val accuracy 0.991, test loss 0.992, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 34, train loss 0.292, train accuracy 0.991, val loss 0.284, val accuracy 0.991, test loss 0.986, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 35, train loss 0.280, train accuracy 0.991, val loss 0.272, val accuracy 0.991, test loss 0.979, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 36, train loss 0.268, train accuracy 0.991, val loss 0.261, val accuracy 0.991, test loss 0.973, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 37, train loss 0.257, train accuracy 0.991, val loss 0.250, val accuracy 0.991, test loss 0.969, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 38, train loss 0.247, train accuracy 0.991, val loss 0.240, val accuracy 0.991, test loss 0.964, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Epoch 39, train loss 0.237, train accuracy 0.991, val loss 0.230, val accuracy 0.991, test loss 0.960, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Epoch 40, train loss 0.228, train accuracy 0.991, val loss 0.221, val accuracy 0.991, test loss 0.957, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Epoch 41, train loss 0.219, train accuracy 0.991, val loss 0.212, val accuracy 0.991, test loss 0.953, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Epoch 42, train loss 0.210, train accuracy 0.991, val loss 0.204, val accuracy 0.991, test loss 0.949, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 43, train loss 0.202, train accuracy 0.991, val loss 0.196, val accuracy 0.991, test loss 0.945, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Epoch 44, train loss 0.194, train accuracy 0.991, val loss 0.188, val accuracy 0.994, test loss 0.941, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Epoch 45, train loss 0.186, train accuracy 0.991, val loss 0.181, val accuracy 0.994, test loss 0.936, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 46, train loss 0.179, train accuracy 0.991, val loss 0.174, val accuracy 0.994, test loss 0.932, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 47, train loss 0.172, train accuracy 0.994, val loss 0.167, val accuracy 0.994, test loss 0.929, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 48, train loss 0.165, train accuracy 0.994, val loss 0.161, val accuracy 0.994, test loss 0.926, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 49, train loss 0.159, train accuracy 0.994, val loss 0.155, val accuracy 0.994, test loss 0.923, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 50, train loss 0.153, train accuracy 0.994, val loss 0.149, val accuracy 0.994, test loss 0.920, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 51, train loss 0.147, train accuracy 0.994, val loss 0.143, val accuracy 0.994, test loss 0.916, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 52, train loss 0.142, train accuracy 0.994, val loss 0.138, val accuracy 0.997, test loss 0.911, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Epoch 53, train loss 0.136, train accuracy 0.997, val loss 0.132, val accuracy 0.997, test loss 0.906, test accuracy 0.511\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 54, train loss 0.131, train accuracy 0.997, val loss 0.128, val accuracy 0.997, test loss 0.903, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 55, train loss 0.126, train accuracy 0.997, val loss 0.123, val accuracy 0.997, test loss 0.901, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 56, train loss 0.121, train accuracy 0.997, val loss 0.118, val accuracy 0.997, test loss 0.898, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 57, train loss 0.117, train accuracy 0.997, val loss 0.114, val accuracy 0.997, test loss 0.895, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 58, train loss 0.112, train accuracy 0.997, val loss 0.110, val accuracy 0.997, test loss 0.892, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 59, train loss 0.108, train accuracy 0.997, val loss 0.105, val accuracy 0.997, test loss 0.888, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 60, train loss 0.104, train accuracy 0.997, val loss 0.102, val accuracy 0.997, test loss 0.885, test accuracy 0.538\n",
            "Saving overall best train val model\n",
            "Epoch 61, train loss 0.100, train accuracy 0.997, val loss 0.098, val accuracy 0.997, test loss 0.881, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 62, train loss 0.097, train accuracy 0.997, val loss 0.094, val accuracy 0.997, test loss 0.878, test accuracy 0.538\n",
            "Saving overall best train val model\n",
            "Epoch 63, train loss 0.093, train accuracy 0.997, val loss 0.091, val accuracy 0.997, test loss 0.874, test accuracy 0.538\n",
            "Saving overall best train val model\n",
            "Epoch 64, train loss 0.090, train accuracy 0.997, val loss 0.087, val accuracy 0.997, test loss 0.869, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 65, train loss 0.086, train accuracy 0.997, val loss 0.084, val accuracy 0.997, test loss 0.864, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 66, train loss 0.083, train accuracy 0.997, val loss 0.081, val accuracy 0.997, test loss 0.860, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 67, train loss 0.080, train accuracy 0.997, val loss 0.077, val accuracy 0.997, test loss 0.857, test accuracy 0.546\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 68, train loss 0.077, train accuracy 0.997, val loss 0.075, val accuracy 0.997, test loss 0.852, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 69, train loss 0.074, train accuracy 0.997, val loss 0.072, val accuracy 0.997, test loss 0.849, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 70, train loss 0.071, train accuracy 0.997, val loss 0.069, val accuracy 0.997, test loss 0.847, test accuracy 0.553\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 71, train loss 0.068, train accuracy 0.997, val loss 0.067, val accuracy 0.997, test loss 0.845, test accuracy 0.555\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 72, train loss 0.066, train accuracy 0.997, val loss 0.064, val accuracy 0.997, test loss 0.841, test accuracy 0.557\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 73, train loss 0.063, train accuracy 0.997, val loss 0.062, val accuracy 0.997, test loss 0.838, test accuracy 0.557\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 74, train loss 0.061, train accuracy 0.997, val loss 0.060, val accuracy 0.997, test loss 0.836, test accuracy 0.559\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 75, train loss 0.059, train accuracy 0.997, val loss 0.057, val accuracy 0.997, test loss 0.833, test accuracy 0.561\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 76, train loss 0.057, train accuracy 0.997, val loss 0.055, val accuracy 1.000, test loss 0.829, test accuracy 0.559\n",
            "Saving overall best train val model\n",
            "Epoch 77, train loss 0.054, train accuracy 0.997, val loss 0.053, val accuracy 1.000, test loss 0.826, test accuracy 0.559\n",
            "Saving overall best train val model\n",
            "Epoch 78, train loss 0.052, train accuracy 0.997, val loss 0.051, val accuracy 1.000, test loss 0.823, test accuracy 0.557\n",
            "Saving overall best train val model\n",
            "Epoch 79, train loss 0.051, train accuracy 1.000, val loss 0.049, val accuracy 1.000, test loss 0.820, test accuracy 0.561\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 80, train loss 0.049, train accuracy 1.000, val loss 0.047, val accuracy 1.000, test loss 0.821, test accuracy 0.563\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 81, train loss 0.047, train accuracy 1.000, val loss 0.046, val accuracy 1.000, test loss 0.820, test accuracy 0.563\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 82, train loss 0.045, train accuracy 1.000, val loss 0.044, val accuracy 1.000, test loss 0.818, test accuracy 0.557\n",
            "Saving overall best train val model\n",
            "Epoch 83, train loss 0.043, train accuracy 1.000, val loss 0.042, val accuracy 1.000, test loss 0.816, test accuracy 0.559\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.042, train accuracy 1.000, val loss 0.041, val accuracy 1.000, test loss 0.815, test accuracy 0.557\n",
            "Saving overall best train val model\n",
            "Epoch 85, train loss 0.040, train accuracy 1.000, val loss 0.039, val accuracy 1.000, test loss 0.814, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 86, train loss 0.039, train accuracy 1.000, val loss 0.038, val accuracy 1.000, test loss 0.814, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Epoch 87, train loss 0.037, train accuracy 1.000, val loss 0.036, val accuracy 1.000, test loss 0.814, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Epoch 88, train loss 0.036, train accuracy 1.000, val loss 0.035, val accuracy 1.000, test loss 0.814, test accuracy 0.542\n",
            "Saving overall best train val model\n",
            "Epoch 89, train loss 0.035, train accuracy 1.000, val loss 0.034, val accuracy 1.000, test loss 0.813, test accuracy 0.546\n",
            "Saving overall best train val model\n",
            "Epoch 90, train loss 0.033, train accuracy 1.000, val loss 0.032, val accuracy 1.000, test loss 0.812, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 91, train loss 0.032, train accuracy 1.000, val loss 0.031, val accuracy 1.000, test loss 0.812, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 92, train loss 0.031, train accuracy 1.000, val loss 0.030, val accuracy 1.000, test loss 0.812, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Epoch 93, train loss 0.030, train accuracy 1.000, val loss 0.029, val accuracy 1.000, test loss 0.811, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 94, train loss 0.029, train accuracy 1.000, val loss 0.028, val accuracy 1.000, test loss 0.811, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 95, train loss 0.028, train accuracy 1.000, val loss 0.027, val accuracy 1.000, test loss 0.811, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 96, train loss 0.027, train accuracy 1.000, val loss 0.026, val accuracy 1.000, test loss 0.811, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Epoch 97, train loss 0.026, train accuracy 1.000, val loss 0.025, val accuracy 1.000, test loss 0.811, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 98, train loss 0.025, train accuracy 1.000, val loss 0.024, val accuracy 1.000, test loss 0.811, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Epoch 99, train loss 0.024, train accuracy 1.000, val loss 0.023, val accuracy 1.000, test loss 0.810, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 100, train loss 0.023, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 0.811, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Epoch 101, train loss 0.022, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 0.809, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 102, train loss 0.021, train accuracy 1.000, val loss 0.021, val accuracy 1.000, test loss 0.810, test accuracy 0.553\n",
            "Saving overall best train val model\n",
            "Epoch 103, train loss 0.021, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 0.809, test accuracy 0.546\n",
            "Saving overall best train val model\n",
            "Epoch 104, train loss 0.020, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 0.809, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 105, train loss 0.019, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 0.811, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.018, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 0.809, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Epoch 107, train loss 0.018, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 0.812, test accuracy 0.536\n",
            "Saving overall best train val model\n",
            "Epoch 108, train loss 0.017, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 0.807, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Epoch 109, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 0.811, test accuracy 0.538\n",
            "Saving overall best train val model\n",
            "Epoch 110, train loss 0.016, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 0.807, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Epoch 111, train loss 0.015, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 0.810, test accuracy 0.542\n",
            "Saving overall best train val model\n",
            "Epoch 112, train loss 0.015, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 0.809, test accuracy 0.542\n",
            "Saving overall best train val model\n",
            "Epoch 113, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 0.811, test accuracy 0.548\n",
            "Saving overall best train val model\n",
            "Epoch 114, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.812, test accuracy 0.546\n",
            "Saving overall best train val model\n",
            "Epoch 115, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.813, test accuracy 0.546\n",
            "Saving overall best train val model\n",
            "Epoch 116, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.814, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Epoch 117, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.817, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 118, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.812, test accuracy 0.546\n",
            "Saving overall best train val model\n",
            "Epoch 119, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.818, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Epoch 120, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.816, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Epoch 121, train loss 0.011, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.819, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Epoch 122, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.819, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Epoch 123, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.820, test accuracy 0.542\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.010, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.822, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Epoch 125, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.826, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Epoch 126, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.827, test accuracy 0.536\n",
            "Saving overall best train val model\n",
            "Epoch 127, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.823, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Epoch 128, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.823, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Epoch 129, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.823, test accuracy 0.546\n",
            "Saving overall best train val model\n",
            "Epoch 130, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.824, test accuracy 0.546\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.824, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 132, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.824, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 133, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.823, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.824, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.824, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.825, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.825, test accuracy 0.553\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.825, test accuracy 0.553\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.826, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.827, test accuracy 0.550\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.829, test accuracy 0.553\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.831, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.832, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.833, test accuracy 0.552\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.835, test accuracy 0.553\n",
            "Saving overall best train val model\n",
            "Epoch 146, train loss 0.005, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.836, test accuracy 0.555\n",
            "Saving overall best train val model\n",
            "Epoch 147, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.837, test accuracy 0.555\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.839, test accuracy 0.557\n",
            "Saving overall best train val model\n",
            "Epoch 149, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.842, test accuracy 0.555\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 2816\n",
            "2405\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.200, train accuracy 0.111, val loss 1.180, val accuracy 0.132, test loss 1.385, test accuracy 0.069\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.165, train accuracy 0.166, val loss 1.145, val accuracy 0.240, test loss 1.367, test accuracy 0.063\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 2, train loss 1.127, train accuracy 0.277, val loss 1.104, val accuracy 0.354, test loss 1.350, test accuracy 0.065\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.083, train accuracy 0.434, val loss 1.057, val accuracy 0.551, test loss 1.331, test accuracy 0.078\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.035, train accuracy 0.603, val loss 1.008, val accuracy 0.695, test loss 1.311, test accuracy 0.092\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 5, train loss 0.986, train accuracy 0.732, val loss 0.958, val accuracy 0.785, test loss 1.292, test accuracy 0.128\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.935, train accuracy 0.822, val loss 0.907, val accuracy 0.858, test loss 1.274, test accuracy 0.158\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 7, train loss 0.885, train accuracy 0.889, val loss 0.856, val accuracy 0.895, test loss 1.259, test accuracy 0.181\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 8, train loss 0.836, train accuracy 0.908, val loss 0.809, val accuracy 0.902, test loss 1.246, test accuracy 0.197\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.790, train accuracy 0.908, val loss 0.766, val accuracy 0.908, test loss 1.232, test accuracy 0.200\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.749, train accuracy 0.920, val loss 0.727, val accuracy 0.932, test loss 1.216, test accuracy 0.212\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 11, train loss 0.712, train accuracy 0.938, val loss 0.691, val accuracy 0.938, test loss 1.199, test accuracy 0.227\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 12, train loss 0.678, train accuracy 0.948, val loss 0.658, val accuracy 0.942, test loss 1.184, test accuracy 0.237\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 13, train loss 0.646, train accuracy 0.948, val loss 0.628, val accuracy 0.945, test loss 1.170, test accuracy 0.246\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 14, train loss 0.616, train accuracy 0.960, val loss 0.599, val accuracy 0.954, test loss 1.159, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 15, train loss 0.589, train accuracy 0.960, val loss 0.573, val accuracy 0.963, test loss 1.149, test accuracy 0.273\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 16, train loss 0.564, train accuracy 0.963, val loss 0.549, val accuracy 0.966, test loss 1.140, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.540, train accuracy 0.963, val loss 0.526, val accuracy 0.963, test loss 1.131, test accuracy 0.290\n",
            "Epoch 18, train loss 0.518, train accuracy 0.966, val loss 0.504, val accuracy 0.966, test loss 1.124, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 19, train loss 0.497, train accuracy 0.966, val loss 0.484, val accuracy 0.966, test loss 1.115, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 20, train loss 0.478, train accuracy 0.966, val loss 0.465, val accuracy 0.966, test loss 1.107, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 21, train loss 0.459, train accuracy 0.966, val loss 0.447, val accuracy 0.966, test loss 1.100, test accuracy 0.294\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 22, train loss 0.441, train accuracy 0.966, val loss 0.429, val accuracy 0.966, test loss 1.092, test accuracy 0.300\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 23, train loss 0.424, train accuracy 0.966, val loss 0.413, val accuracy 0.966, test loss 1.084, test accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 24, train loss 0.408, train accuracy 0.966, val loss 0.397, val accuracy 0.966, test loss 1.078, test accuracy 0.302\n",
            "Saving overall best train val model\n",
            "Epoch 25, train loss 0.392, train accuracy 0.966, val loss 0.382, val accuracy 0.969, test loss 1.071, test accuracy 0.294\n",
            "Saving overall best train val model\n",
            "Epoch 26, train loss 0.378, train accuracy 0.966, val loss 0.368, val accuracy 0.969, test loss 1.065, test accuracy 0.296\n",
            "Saving overall best train val model\n",
            "Epoch 27, train loss 0.364, train accuracy 0.966, val loss 0.355, val accuracy 0.969, test loss 1.059, test accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 28, train loss 0.350, train accuracy 0.966, val loss 0.342, val accuracy 0.969, test loss 1.053, test accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 29, train loss 0.338, train accuracy 0.969, val loss 0.329, val accuracy 0.972, test loss 1.046, test accuracy 0.307\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 30, train loss 0.325, train accuracy 0.972, val loss 0.316, val accuracy 0.972, test loss 1.040, test accuracy 0.315\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 31, train loss 0.313, train accuracy 0.972, val loss 0.304, val accuracy 0.972, test loss 1.033, test accuracy 0.323\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 32, train loss 0.301, train accuracy 0.972, val loss 0.292, val accuracy 0.972, test loss 1.027, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 33, train loss 0.289, train accuracy 0.972, val loss 0.280, val accuracy 0.978, test loss 1.021, test accuracy 0.336\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 34, train loss 0.277, train accuracy 0.972, val loss 0.269, val accuracy 0.982, test loss 1.016, test accuracy 0.340\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 35, train loss 0.265, train accuracy 0.972, val loss 0.258, val accuracy 0.982, test loss 1.012, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 36, train loss 0.255, train accuracy 0.978, val loss 0.248, val accuracy 0.982, test loss 1.009, test accuracy 0.345\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 37, train loss 0.245, train accuracy 0.982, val loss 0.238, val accuracy 0.982, test loss 1.005, test accuracy 0.349\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 38, train loss 0.236, train accuracy 0.982, val loss 0.229, val accuracy 0.982, test loss 1.001, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 39, train loss 0.227, train accuracy 0.982, val loss 0.221, val accuracy 0.982, test loss 0.997, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 40, train loss 0.219, train accuracy 0.982, val loss 0.213, val accuracy 0.982, test loss 0.996, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 41, train loss 0.213, train accuracy 0.982, val loss 0.206, val accuracy 0.982, test loss 0.984, test accuracy 0.382\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 42, train loss 0.204, train accuracy 0.982, val loss 0.198, val accuracy 0.982, test loss 0.984, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 43, train loss 0.197, train accuracy 0.982, val loss 0.192, val accuracy 0.982, test loss 0.983, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 44, train loss 0.190, train accuracy 0.982, val loss 0.185, val accuracy 0.982, test loss 0.979, test accuracy 0.395\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 45, train loss 0.183, train accuracy 0.982, val loss 0.180, val accuracy 0.985, test loss 0.976, test accuracy 0.405\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 46, train loss 0.177, train accuracy 0.985, val loss 0.172, val accuracy 0.991, test loss 0.968, test accuracy 0.414\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 47, train loss 0.171, train accuracy 0.988, val loss 0.168, val accuracy 0.991, test loss 0.968, test accuracy 0.418\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 48, train loss 0.165, train accuracy 0.991, val loss 0.160, val accuracy 0.994, test loss 0.961, test accuracy 0.429\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 49, train loss 0.159, train accuracy 0.988, val loss 0.155, val accuracy 0.994, test loss 0.958, test accuracy 0.429\n",
            "Epoch 50, train loss 0.153, train accuracy 0.991, val loss 0.149, val accuracy 0.994, test loss 0.954, test accuracy 0.431\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 51, train loss 0.147, train accuracy 0.991, val loss 0.144, val accuracy 0.994, test loss 0.952, test accuracy 0.435\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 52, train loss 0.142, train accuracy 0.991, val loss 0.138, val accuracy 0.994, test loss 0.950, test accuracy 0.435\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 53, train loss 0.137, train accuracy 0.994, val loss 0.133, val accuracy 0.994, test loss 0.949, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 54, train loss 0.132, train accuracy 0.994, val loss 0.128, val accuracy 0.994, test loss 0.946, test accuracy 0.437\n",
            "Saving overall best train val model\n",
            "Epoch 55, train loss 0.127, train accuracy 0.994, val loss 0.123, val accuracy 0.994, test loss 0.944, test accuracy 0.443\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 56, train loss 0.122, train accuracy 0.994, val loss 0.119, val accuracy 0.997, test loss 0.942, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Epoch 57, train loss 0.118, train accuracy 1.000, val loss 0.114, val accuracy 1.000, test loss 0.942, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 58, train loss 0.113, train accuracy 1.000, val loss 0.109, val accuracy 1.000, test loss 0.942, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 59, train loss 0.108, train accuracy 1.000, val loss 0.105, val accuracy 1.000, test loss 0.939, test accuracy 0.439\n",
            "Saving overall best train val model\n",
            "Epoch 60, train loss 0.104, train accuracy 1.000, val loss 0.101, val accuracy 1.000, test loss 0.933, test accuracy 0.443\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 61, train loss 0.100, train accuracy 1.000, val loss 0.097, val accuracy 1.000, test loss 0.931, test accuracy 0.445\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 62, train loss 0.096, train accuracy 1.000, val loss 0.093, val accuracy 1.000, test loss 0.929, test accuracy 0.447\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 63, train loss 0.093, train accuracy 1.000, val loss 0.090, val accuracy 1.000, test loss 0.926, test accuracy 0.447\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 64, train loss 0.089, train accuracy 1.000, val loss 0.086, val accuracy 1.000, test loss 0.923, test accuracy 0.452\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 65, train loss 0.086, train accuracy 1.000, val loss 0.083, val accuracy 1.000, test loss 0.921, test accuracy 0.454\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 66, train loss 0.082, train accuracy 1.000, val loss 0.080, val accuracy 1.000, test loss 0.917, test accuracy 0.454\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 67, train loss 0.079, train accuracy 1.000, val loss 0.077, val accuracy 1.000, test loss 0.916, test accuracy 0.456\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 68, train loss 0.076, train accuracy 1.000, val loss 0.074, val accuracy 1.000, test loss 0.912, test accuracy 0.464\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 69, train loss 0.073, train accuracy 1.000, val loss 0.071, val accuracy 1.000, test loss 0.912, test accuracy 0.468\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 70, train loss 0.070, train accuracy 1.000, val loss 0.068, val accuracy 1.000, test loss 0.908, test accuracy 0.469\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 71, train loss 0.067, train accuracy 1.000, val loss 0.065, val accuracy 1.000, test loss 0.905, test accuracy 0.473\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 72, train loss 0.065, train accuracy 1.000, val loss 0.063, val accuracy 1.000, test loss 0.903, test accuracy 0.479\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 73, train loss 0.062, train accuracy 1.000, val loss 0.061, val accuracy 1.000, test loss 0.901, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 74, train loss 0.060, train accuracy 1.000, val loss 0.058, val accuracy 1.000, test loss 0.899, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Epoch 75, train loss 0.058, train accuracy 1.000, val loss 0.056, val accuracy 1.000, test loss 0.898, test accuracy 0.473\n",
            "Saving overall best train val model\n",
            "Epoch 76, train loss 0.056, train accuracy 1.000, val loss 0.054, val accuracy 1.000, test loss 0.895, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Epoch 77, train loss 0.053, train accuracy 1.000, val loss 0.052, val accuracy 1.000, test loss 0.893, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 78, train loss 0.051, train accuracy 1.000, val loss 0.050, val accuracy 1.000, test loss 0.891, test accuracy 0.487\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 79, train loss 0.050, train accuracy 1.000, val loss 0.048, val accuracy 1.000, test loss 0.890, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 80, train loss 0.048, train accuracy 1.000, val loss 0.046, val accuracy 1.000, test loss 0.887, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 81, train loss 0.046, train accuracy 1.000, val loss 0.045, val accuracy 1.000, test loss 0.885, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 82, train loss 0.044, train accuracy 1.000, val loss 0.043, val accuracy 1.000, test loss 0.884, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 83, train loss 0.042, train accuracy 1.000, val loss 0.041, val accuracy 1.000, test loss 0.884, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.041, train accuracy 1.000, val loss 0.040, val accuracy 1.000, test loss 0.886, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Epoch 85, train loss 0.039, train accuracy 1.000, val loss 0.038, val accuracy 1.000, test loss 0.886, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 86, train loss 0.038, train accuracy 1.000, val loss 0.037, val accuracy 1.000, test loss 0.884, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 87, train loss 0.036, train accuracy 1.000, val loss 0.035, val accuracy 1.000, test loss 0.883, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 88, train loss 0.035, train accuracy 1.000, val loss 0.034, val accuracy 1.000, test loss 0.882, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 89, train loss 0.034, train accuracy 1.000, val loss 0.033, val accuracy 1.000, test loss 0.881, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 90, train loss 0.032, train accuracy 1.000, val loss 0.031, val accuracy 1.000, test loss 0.879, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 91, train loss 0.031, train accuracy 1.000, val loss 0.030, val accuracy 1.000, test loss 0.879, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 92, train loss 0.030, train accuracy 1.000, val loss 0.029, val accuracy 1.000, test loss 0.878, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 93, train loss 0.029, train accuracy 1.000, val loss 0.028, val accuracy 1.000, test loss 0.876, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 94, train loss 0.028, train accuracy 1.000, val loss 0.027, val accuracy 1.000, test loss 0.874, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 95, train loss 0.027, train accuracy 1.000, val loss 0.026, val accuracy 1.000, test loss 0.881, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 96, train loss 0.026, train accuracy 1.000, val loss 0.025, val accuracy 1.000, test loss 0.878, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 97, train loss 0.025, train accuracy 1.000, val loss 0.024, val accuracy 1.000, test loss 0.880, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 98, train loss 0.024, train accuracy 1.000, val loss 0.023, val accuracy 1.000, test loss 0.882, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 99, train loss 0.023, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 0.885, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 100, train loss 0.022, train accuracy 1.000, val loss 0.021, val accuracy 1.000, test loss 0.897, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Epoch 101, train loss 0.021, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 0.895, test accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 102, train loss 0.020, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 0.888, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 103, train loss 0.019, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 0.889, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 104, train loss 0.019, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 0.884, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 105, train loss 0.018, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 0.881, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.017, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 0.879, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 107, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 0.876, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 108, train loss 0.016, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 0.874, test accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 109, train loss 0.015, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 0.873, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 110, train loss 0.015, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 0.871, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Epoch 111, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 0.870, test accuracy 0.515\n",
            "Saving overall best train val model\n",
            "Epoch 112, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.869, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 113, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.869, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 114, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.868, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 115, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.860, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 116, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.858, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 117, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.857, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 118, train loss 0.011, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.856, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 119, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.855, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 120, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.854, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 121, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.852, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 122, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.850, test accuracy 0.536\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 123, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.846, test accuracy 0.536\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 124, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.840, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Epoch 125, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.833, test accuracy 0.536\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 126, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.831, test accuracy 0.536\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 127, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.840, test accuracy 0.536\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 128, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.842, test accuracy 0.542\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 129, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.842, test accuracy 0.538\n",
            "Saving overall best train val model\n",
            "Epoch 130, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.833, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.846, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Epoch 132, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.839, test accuracy 0.544\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 133, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.856, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.843, test accuracy 0.540\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.810, test accuracy 0.536\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.867, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.842, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.840, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.842, test accuracy 0.538\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.845, test accuracy 0.538\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.848, test accuracy 0.538\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.854, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.824, test accuracy 0.532\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.906, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.865, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 146, train loss 0.004, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.869, test accuracy 0.525\n",
            "Saving overall best train val model\n",
            "Epoch 147, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.873, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.881, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Epoch 149, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.885, test accuracy 0.525\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 2405\n",
            "2681\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.217, train accuracy 0.111, val loss 1.198, val accuracy 0.123, test loss 1.370, test accuracy 0.143\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.182, train accuracy 0.129, val loss 1.161, val accuracy 0.160, test loss 1.353, test accuracy 0.160\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 2, train loss 1.142, train accuracy 0.206, val loss 1.118, val accuracy 0.249, test loss 1.336, test accuracy 0.177\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.097, train accuracy 0.323, val loss 1.070, val accuracy 0.455, test loss 1.320, test accuracy 0.187\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.049, train accuracy 0.554, val loss 1.022, val accuracy 0.634, test loss 1.303, test accuracy 0.183\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 5, train loss 1.000, train accuracy 0.717, val loss 0.973, val accuracy 0.797, test loss 1.285, test accuracy 0.189\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.951, train accuracy 0.831, val loss 0.924, val accuracy 0.874, test loss 1.268, test accuracy 0.176\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 7, train loss 0.904, train accuracy 0.892, val loss 0.878, val accuracy 0.917, test loss 1.252, test accuracy 0.164\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 8, train loss 0.858, train accuracy 0.932, val loss 0.833, val accuracy 0.948, test loss 1.236, test accuracy 0.187\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.816, train accuracy 0.954, val loss 0.792, val accuracy 0.957, test loss 1.224, test accuracy 0.197\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.775, train accuracy 0.960, val loss 0.752, val accuracy 0.960, test loss 1.214, test accuracy 0.210\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 11, train loss 0.737, train accuracy 0.963, val loss 0.715, val accuracy 0.960, test loss 1.208, test accuracy 0.231\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 12, train loss 0.700, train accuracy 0.963, val loss 0.679, val accuracy 0.966, test loss 1.201, test accuracy 0.246\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 13, train loss 0.665, train accuracy 0.963, val loss 0.646, val accuracy 0.966, test loss 1.195, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 14, train loss 0.633, train accuracy 0.963, val loss 0.614, val accuracy 0.966, test loss 1.189, test accuracy 0.258\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 15, train loss 0.603, train accuracy 0.963, val loss 0.586, val accuracy 0.966, test loss 1.183, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.575, train accuracy 0.966, val loss 0.559, val accuracy 0.969, test loss 1.178, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.549, train accuracy 0.966, val loss 0.535, val accuracy 0.969, test loss 1.172, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.526, train accuracy 0.969, val loss 0.512, val accuracy 0.969, test loss 1.166, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 19, train loss 0.504, train accuracy 0.972, val loss 0.491, val accuracy 0.972, test loss 1.160, test accuracy 0.256\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 20, train loss 0.483, train accuracy 0.972, val loss 0.471, val accuracy 0.972, test loss 1.153, test accuracy 0.258\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 21, train loss 0.464, train accuracy 0.972, val loss 0.453, val accuracy 0.972, test loss 1.143, test accuracy 0.271\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 22, train loss 0.446, train accuracy 0.972, val loss 0.438, val accuracy 0.972, test loss 1.132, test accuracy 0.275\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 23, train loss 0.428, train accuracy 0.972, val loss 0.419, val accuracy 0.972, test loss 1.133, test accuracy 0.271\n",
            "Saving overall best train val model\n",
            "Epoch 24, train loss 0.411, train accuracy 0.972, val loss 0.402, val accuracy 0.972, test loss 1.134, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Epoch 25, train loss 0.395, train accuracy 0.972, val loss 0.386, val accuracy 0.972, test loss 1.129, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Epoch 26, train loss 0.380, train accuracy 0.972, val loss 0.371, val accuracy 0.972, test loss 1.125, test accuracy 0.261\n",
            "Saving overall best train val model\n",
            "Epoch 27, train loss 0.365, train accuracy 0.972, val loss 0.356, val accuracy 0.972, test loss 1.121, test accuracy 0.248\n",
            "Saving overall best train val model\n",
            "Epoch 28, train loss 0.351, train accuracy 0.972, val loss 0.342, val accuracy 0.972, test loss 1.115, test accuracy 0.246\n",
            "Saving overall best train val model\n",
            "Epoch 29, train loss 0.337, train accuracy 0.972, val loss 0.329, val accuracy 0.975, test loss 1.110, test accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Epoch 30, train loss 0.323, train accuracy 0.975, val loss 0.317, val accuracy 0.975, test loss 1.106, test accuracy 0.235\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 31, train loss 0.311, train accuracy 0.975, val loss 0.304, val accuracy 0.975, test loss 1.103, test accuracy 0.240\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 32, train loss 0.300, train accuracy 0.975, val loss 0.293, val accuracy 0.975, test loss 1.099, test accuracy 0.237\n",
            "Saving overall best train val model\n",
            "Epoch 33, train loss 0.288, train accuracy 0.975, val loss 0.282, val accuracy 0.975, test loss 1.095, test accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 34, train loss 0.278, train accuracy 0.975, val loss 0.271, val accuracy 0.975, test loss 1.092, test accuracy 0.239\n",
            "Saving overall best train val model\n",
            "Epoch 35, train loss 0.268, train accuracy 0.975, val loss 0.261, val accuracy 0.975, test loss 1.089, test accuracy 0.240\n",
            "Saving overall best train val model\n",
            "Epoch 36, train loss 0.258, train accuracy 0.975, val loss 0.252, val accuracy 0.975, test loss 1.083, test accuracy 0.248\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 37, train loss 0.249, train accuracy 0.975, val loss 0.243, val accuracy 0.975, test loss 1.081, test accuracy 0.248\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 38, train loss 0.240, train accuracy 0.975, val loss 0.234, val accuracy 0.975, test loss 1.078, test accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 39, train loss 0.232, train accuracy 0.975, val loss 0.226, val accuracy 0.975, test loss 1.073, test accuracy 0.252\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 40, train loss 0.223, train accuracy 0.975, val loss 0.217, val accuracy 0.975, test loss 1.070, test accuracy 0.252\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 41, train loss 0.215, train accuracy 0.978, val loss 0.210, val accuracy 0.975, test loss 1.067, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 42, train loss 0.208, train accuracy 0.978, val loss 0.202, val accuracy 0.978, test loss 1.064, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 43, train loss 0.200, train accuracy 0.978, val loss 0.195, val accuracy 0.982, test loss 1.061, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 44, train loss 0.193, train accuracy 0.978, val loss 0.188, val accuracy 0.982, test loss 1.058, test accuracy 0.256\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 45, train loss 0.186, train accuracy 0.978, val loss 0.181, val accuracy 0.985, test loss 1.054, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 46, train loss 0.180, train accuracy 0.982, val loss 0.175, val accuracy 0.985, test loss 1.051, test accuracy 0.261\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 47, train loss 0.173, train accuracy 0.988, val loss 0.168, val accuracy 0.988, test loss 1.047, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 48, train loss 0.167, train accuracy 0.991, val loss 0.162, val accuracy 0.991, test loss 1.045, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 49, train loss 0.161, train accuracy 0.991, val loss 0.157, val accuracy 0.991, test loss 1.042, test accuracy 0.275\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 50, train loss 0.156, train accuracy 0.991, val loss 0.151, val accuracy 0.991, test loss 1.039, test accuracy 0.277\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 51, train loss 0.150, train accuracy 0.991, val loss 0.146, val accuracy 0.997, test loss 1.036, test accuracy 0.279\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 52, train loss 0.145, train accuracy 0.997, val loss 0.140, val accuracy 0.997, test loss 1.034, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 53, train loss 0.140, train accuracy 0.997, val loss 0.135, val accuracy 0.997, test loss 1.031, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 54, train loss 0.135, train accuracy 0.997, val loss 0.131, val accuracy 0.997, test loss 1.029, test accuracy 0.292\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 55, train loss 0.130, train accuracy 0.997, val loss 0.126, val accuracy 0.997, test loss 1.027, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Epoch 56, train loss 0.125, train accuracy 0.997, val loss 0.122, val accuracy 0.997, test loss 1.024, test accuracy 0.286\n",
            "Saving overall best train val model\n",
            "Epoch 57, train loss 0.121, train accuracy 0.997, val loss 0.117, val accuracy 0.997, test loss 1.021, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Epoch 58, train loss 0.116, train accuracy 0.997, val loss 0.113, val accuracy 0.997, test loss 1.018, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Epoch 59, train loss 0.112, train accuracy 0.997, val loss 0.109, val accuracy 0.997, test loss 1.016, test accuracy 0.292\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 60, train loss 0.108, train accuracy 0.997, val loss 0.105, val accuracy 0.997, test loss 1.014, test accuracy 0.296\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 61, train loss 0.104, train accuracy 0.997, val loss 0.102, val accuracy 0.997, test loss 1.012, test accuracy 0.296\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 62, train loss 0.100, train accuracy 0.997, val loss 0.098, val accuracy 0.997, test loss 1.012, test accuracy 0.298\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 63, train loss 0.097, train accuracy 0.997, val loss 0.094, val accuracy 0.997, test loss 1.011, test accuracy 0.302\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 64, train loss 0.093, train accuracy 0.997, val loss 0.091, val accuracy 0.997, test loss 1.011, test accuracy 0.305\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 65, train loss 0.090, train accuracy 0.997, val loss 0.088, val accuracy 0.997, test loss 1.009, test accuracy 0.307\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 66, train loss 0.087, train accuracy 0.997, val loss 0.084, val accuracy 0.997, test loss 1.008, test accuracy 0.307\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 67, train loss 0.083, train accuracy 0.997, val loss 0.081, val accuracy 0.997, test loss 1.008, test accuracy 0.307\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 68, train loss 0.080, train accuracy 0.997, val loss 0.078, val accuracy 0.997, test loss 1.007, test accuracy 0.311\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 69, train loss 0.077, train accuracy 0.997, val loss 0.075, val accuracy 0.997, test loss 1.006, test accuracy 0.315\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 70, train loss 0.074, train accuracy 0.997, val loss 0.073, val accuracy 0.997, test loss 1.006, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 71, train loss 0.072, train accuracy 0.997, val loss 0.070, val accuracy 0.997, test loss 1.004, test accuracy 0.323\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 72, train loss 0.069, train accuracy 0.997, val loss 0.067, val accuracy 1.000, test loss 1.004, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Epoch 73, train loss 0.066, train accuracy 0.997, val loss 0.065, val accuracy 1.000, test loss 1.004, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 74, train loss 0.064, train accuracy 1.000, val loss 0.062, val accuracy 1.000, test loss 1.004, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 75, train loss 0.063, train accuracy 1.000, val loss 0.060, val accuracy 1.000, test loss 1.007, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Epoch 76, train loss 0.060, train accuracy 1.000, val loss 0.058, val accuracy 1.000, test loss 1.006, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 77, train loss 0.058, train accuracy 1.000, val loss 0.056, val accuracy 1.000, test loss 1.006, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Epoch 78, train loss 0.055, train accuracy 1.000, val loss 0.054, val accuracy 1.000, test loss 1.005, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Epoch 79, train loss 0.053, train accuracy 1.000, val loss 0.052, val accuracy 1.000, test loss 1.008, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 80, train loss 0.051, train accuracy 1.000, val loss 0.050, val accuracy 1.000, test loss 1.007, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Epoch 81, train loss 0.050, train accuracy 1.000, val loss 0.052, val accuracy 1.000, test loss 1.035, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Epoch 82, train loss 0.049, train accuracy 1.000, val loss 0.047, val accuracy 1.000, test loss 1.017, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 83, train loss 0.047, train accuracy 1.000, val loss 0.045, val accuracy 1.000, test loss 1.004, test accuracy 0.326\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.045, train accuracy 1.000, val loss 0.043, val accuracy 1.000, test loss 1.003, test accuracy 0.317\n",
            "Saving overall best train val model\n",
            "Epoch 85, train loss 0.043, train accuracy 1.000, val loss 0.042, val accuracy 1.000, test loss 1.004, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Epoch 86, train loss 0.042, train accuracy 1.000, val loss 0.040, val accuracy 1.000, test loss 1.008, test accuracy 0.317\n",
            "Saving overall best train val model\n",
            "Epoch 87, train loss 0.040, train accuracy 1.000, val loss 0.039, val accuracy 1.000, test loss 1.008, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Epoch 88, train loss 0.039, train accuracy 1.000, val loss 0.038, val accuracy 1.000, test loss 1.010, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 89, train loss 0.037, train accuracy 1.000, val loss 0.036, val accuracy 1.000, test loss 1.010, test accuracy 0.332\n",
            "Saving overall best train val model\n",
            "Epoch 90, train loss 0.036, train accuracy 1.000, val loss 0.035, val accuracy 1.000, test loss 1.012, test accuracy 0.336\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 91, train loss 0.035, train accuracy 1.000, val loss 0.034, val accuracy 1.000, test loss 1.013, test accuracy 0.340\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 92, train loss 0.033, train accuracy 1.000, val loss 0.032, val accuracy 1.000, test loss 1.014, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 93, train loss 0.032, train accuracy 1.000, val loss 0.031, val accuracy 1.000, test loss 1.022, test accuracy 0.338\n",
            "Saving overall best train val model\n",
            "Epoch 94, train loss 0.031, train accuracy 1.000, val loss 0.030, val accuracy 1.000, test loss 1.011, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 95, train loss 0.030, train accuracy 1.000, val loss 0.030, val accuracy 1.000, test loss 1.043, test accuracy 0.345\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 96, train loss 0.029, train accuracy 1.000, val loss 0.028, val accuracy 1.000, test loss 1.012, test accuracy 0.340\n",
            "Saving overall best train val model\n",
            "Epoch 97, train loss 0.028, train accuracy 1.000, val loss 0.027, val accuracy 1.000, test loss 1.010, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 98, train loss 0.026, train accuracy 1.000, val loss 0.026, val accuracy 1.000, test loss 1.017, test accuracy 0.349\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 99, train loss 0.025, train accuracy 1.000, val loss 0.025, val accuracy 1.000, test loss 1.019, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 100, train loss 0.024, train accuracy 1.000, val loss 0.024, val accuracy 1.000, test loss 1.027, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 101, train loss 0.023, train accuracy 1.000, val loss 0.023, val accuracy 1.000, test loss 1.025, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 102, train loss 0.022, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 1.026, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 103, train loss 0.022, train accuracy 1.000, val loss 0.021, val accuracy 1.000, test loss 1.028, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 104, train loss 0.021, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 1.031, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 105, train loss 0.020, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 1.033, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 106, train loss 0.019, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 1.034, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 107, train loss 0.018, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 1.032, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 108, train loss 0.018, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 1.031, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 109, train loss 0.017, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 1.034, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 110, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 1.036, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 111, train loss 0.015, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 1.039, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 112, train loss 0.015, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 1.051, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 113, train loss 0.015, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 1.031, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 114, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 1.034, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 115, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 1.036, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 116, train loss 0.013, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.037, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 117, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.040, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Epoch 118, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.042, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 119, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.044, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 120, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.046, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 121, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.047, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 122, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.049, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Epoch 123, train loss 0.010, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.052, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.055, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 125, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.059, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Epoch 126, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.063, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 127, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.065, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 128, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.063, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Epoch 129, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.066, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 130, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.075, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.079, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 132, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.084, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Epoch 133, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.091, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.095, test accuracy 0.349\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.103, test accuracy 0.345\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.108, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.110, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.121, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.110, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.111, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.117, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.123, test accuracy 0.340\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.120, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.123, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.124, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Epoch 146, train loss 0.004, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.129, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Epoch 147, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.132, test accuracy 0.349\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.130, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Epoch 149, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.133, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 2681\n",
            "5769\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.183, train accuracy 0.308, val loss 1.164, val accuracy 0.372, test loss 1.380, test accuracy 0.084\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.149, train accuracy 0.422, val loss 1.129, val accuracy 0.465, test loss 1.370, test accuracy 0.074\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 2, train loss 1.114, train accuracy 0.480, val loss 1.094, val accuracy 0.523, test loss 1.361, test accuracy 0.092\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.077, train accuracy 0.535, val loss 1.055, val accuracy 0.609, test loss 1.353, test accuracy 0.099\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.036, train accuracy 0.655, val loss 1.011, val accuracy 0.729, test loss 1.345, test accuracy 0.094\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 5, train loss 0.990, train accuracy 0.763, val loss 0.963, val accuracy 0.797, test loss 1.336, test accuracy 0.109\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.942, train accuracy 0.815, val loss 0.915, val accuracy 0.828, test loss 1.326, test accuracy 0.124\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 7, train loss 0.895, train accuracy 0.862, val loss 0.870, val accuracy 0.871, test loss 1.310, test accuracy 0.139\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 8, train loss 0.852, train accuracy 0.889, val loss 0.828, val accuracy 0.898, test loss 1.298, test accuracy 0.143\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.812, train accuracy 0.908, val loss 0.789, val accuracy 0.914, test loss 1.286, test accuracy 0.149\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.774, train accuracy 0.920, val loss 0.751, val accuracy 0.935, test loss 1.275, test accuracy 0.160\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 11, train loss 0.735, train accuracy 0.935, val loss 0.712, val accuracy 0.945, test loss 1.263, test accuracy 0.168\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 12, train loss 0.697, train accuracy 0.951, val loss 0.674, val accuracy 0.951, test loss 1.252, test accuracy 0.174\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 13, train loss 0.659, train accuracy 0.954, val loss 0.637, val accuracy 0.960, test loss 1.241, test accuracy 0.185\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 14, train loss 0.624, train accuracy 0.963, val loss 0.604, val accuracy 0.966, test loss 1.229, test accuracy 0.195\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 15, train loss 0.591, train accuracy 0.963, val loss 0.572, val accuracy 0.966, test loss 1.214, test accuracy 0.218\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 16, train loss 0.560, train accuracy 0.963, val loss 0.541, val accuracy 0.972, test loss 1.199, test accuracy 0.221\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.531, train accuracy 0.963, val loss 0.515, val accuracy 0.972, test loss 1.188, test accuracy 0.231\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 18, train loss 0.506, train accuracy 0.972, val loss 0.490, val accuracy 0.978, test loss 1.178, test accuracy 0.233\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 19, train loss 0.481, train accuracy 0.978, val loss 0.466, val accuracy 0.978, test loss 1.169, test accuracy 0.242\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 20, train loss 0.459, train accuracy 0.978, val loss 0.444, val accuracy 0.978, test loss 1.161, test accuracy 0.250\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 21, train loss 0.437, train accuracy 0.978, val loss 0.423, val accuracy 0.975, test loss 1.160, test accuracy 0.246\n",
            "Epoch 22, train loss 0.416, train accuracy 0.978, val loss 0.403, val accuracy 0.975, test loss 1.153, test accuracy 0.261\n",
            "Epoch 23, train loss 0.397, train accuracy 0.978, val loss 0.385, val accuracy 0.978, test loss 1.146, test accuracy 0.275\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 24, train loss 0.379, train accuracy 0.982, val loss 0.368, val accuracy 0.978, test loss 1.141, test accuracy 0.286\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 25, train loss 0.362, train accuracy 0.982, val loss 0.352, val accuracy 0.982, test loss 1.136, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 26, train loss 0.347, train accuracy 0.982, val loss 0.337, val accuracy 0.982, test loss 1.131, test accuracy 0.300\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 27, train loss 0.332, train accuracy 0.982, val loss 0.323, val accuracy 0.982, test loss 1.129, test accuracy 0.298\n",
            "Saving overall best train val model\n",
            "Epoch 28, train loss 0.318, train accuracy 0.982, val loss 0.310, val accuracy 0.982, test loss 1.124, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Epoch 29, train loss 0.306, train accuracy 0.982, val loss 0.298, val accuracy 0.978, test loss 1.137, test accuracy 0.284\n",
            "Epoch 30, train loss 0.293, train accuracy 0.982, val loss 0.285, val accuracy 0.982, test loss 1.123, test accuracy 0.292\n",
            "Saving overall best train val model\n",
            "Epoch 31, train loss 0.281, train accuracy 0.985, val loss 0.273, val accuracy 0.985, test loss 1.122, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 32, train loss 0.269, train accuracy 0.988, val loss 0.262, val accuracy 0.991, test loss 1.123, test accuracy 0.284\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 33, train loss 0.259, train accuracy 0.994, val loss 0.253, val accuracy 0.991, test loss 1.123, test accuracy 0.303\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 34, train loss 0.248, train accuracy 0.991, val loss 0.241, val accuracy 0.994, test loss 1.118, test accuracy 0.290\n",
            "Epoch 35, train loss 0.239, train accuracy 0.994, val loss 0.232, val accuracy 0.994, test loss 1.114, test accuracy 0.294\n",
            "Saving overall best train val model\n",
            "Epoch 36, train loss 0.229, train accuracy 0.994, val loss 0.223, val accuracy 0.994, test loss 1.113, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Epoch 37, train loss 0.221, train accuracy 0.994, val loss 0.217, val accuracy 0.994, test loss 1.112, test accuracy 0.305\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 38, train loss 0.212, train accuracy 0.994, val loss 0.206, val accuracy 0.994, test loss 1.108, test accuracy 0.288\n",
            "Saving overall best train val model\n",
            "Epoch 39, train loss 0.203, train accuracy 0.994, val loss 0.199, val accuracy 0.994, test loss 1.107, test accuracy 0.292\n",
            "Saving overall best train val model\n",
            "Epoch 40, train loss 0.196, train accuracy 0.994, val loss 0.192, val accuracy 0.994, test loss 1.103, test accuracy 0.296\n",
            "Saving overall best train val model\n",
            "Epoch 41, train loss 0.188, train accuracy 0.994, val loss 0.183, val accuracy 0.997, test loss 1.101, test accuracy 0.307\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 42, train loss 0.181, train accuracy 0.994, val loss 0.176, val accuracy 0.997, test loss 1.101, test accuracy 0.307\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 43, train loss 0.174, train accuracy 0.994, val loss 0.169, val accuracy 0.997, test loss 1.099, test accuracy 0.305\n",
            "Saving overall best train val model\n",
            "Epoch 44, train loss 0.168, train accuracy 0.997, val loss 0.163, val accuracy 0.997, test loss 1.102, test accuracy 0.294\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 45, train loss 0.161, train accuracy 1.000, val loss 0.156, val accuracy 1.000, test loss 1.091, test accuracy 0.313\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 46, train loss 0.154, train accuracy 1.000, val loss 0.150, val accuracy 1.000, test loss 1.091, test accuracy 0.309\n",
            "Saving overall best train val model\n",
            "Epoch 47, train loss 0.148, train accuracy 1.000, val loss 0.144, val accuracy 1.000, test loss 1.089, test accuracy 0.313\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 48, train loss 0.143, train accuracy 1.000, val loss 0.139, val accuracy 1.000, test loss 1.096, test accuracy 0.298\n",
            "Saving overall best train val model\n",
            "Epoch 49, train loss 0.137, train accuracy 1.000, val loss 0.133, val accuracy 1.000, test loss 1.084, test accuracy 0.317\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 50, train loss 0.132, train accuracy 1.000, val loss 0.128, val accuracy 1.000, test loss 1.081, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 51, train loss 0.127, train accuracy 1.000, val loss 0.123, val accuracy 1.000, test loss 1.077, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 52, train loss 0.122, train accuracy 1.000, val loss 0.118, val accuracy 1.000, test loss 1.079, test accuracy 0.315\n",
            "Saving overall best train val model\n",
            "Epoch 53, train loss 0.117, train accuracy 1.000, val loss 0.114, val accuracy 1.000, test loss 1.077, test accuracy 0.311\n",
            "Saving overall best train val model\n",
            "Epoch 54, train loss 0.113, train accuracy 1.000, val loss 0.109, val accuracy 1.000, test loss 1.076, test accuracy 0.311\n",
            "Saving overall best train val model\n",
            "Epoch 55, train loss 0.108, train accuracy 1.000, val loss 0.105, val accuracy 1.000, test loss 1.074, test accuracy 0.317\n",
            "Saving overall best train val model\n",
            "Epoch 56, train loss 0.104, train accuracy 1.000, val loss 0.101, val accuracy 1.000, test loss 1.073, test accuracy 0.321\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 57, train loss 0.100, train accuracy 1.000, val loss 0.097, val accuracy 1.000, test loss 1.071, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 58, train loss 0.096, train accuracy 1.000, val loss 0.093, val accuracy 1.000, test loss 1.069, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 59, train loss 0.092, train accuracy 1.000, val loss 0.090, val accuracy 1.000, test loss 1.066, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 60, train loss 0.089, train accuracy 1.000, val loss 0.086, val accuracy 1.000, test loss 1.065, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 61, train loss 0.085, train accuracy 1.000, val loss 0.083, val accuracy 1.000, test loss 1.063, test accuracy 0.330\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 62, train loss 0.082, train accuracy 1.000, val loss 0.080, val accuracy 1.000, test loss 1.062, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Epoch 63, train loss 0.079, train accuracy 1.000, val loss 0.076, val accuracy 1.000, test loss 1.060, test accuracy 0.330\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 64, train loss 0.076, train accuracy 1.000, val loss 0.073, val accuracy 1.000, test loss 1.059, test accuracy 0.330\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 65, train loss 0.073, train accuracy 1.000, val loss 0.070, val accuracy 1.000, test loss 1.058, test accuracy 0.332\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 66, train loss 0.070, train accuracy 1.000, val loss 0.068, val accuracy 1.000, test loss 1.056, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 67, train loss 0.067, train accuracy 1.000, val loss 0.065, val accuracy 1.000, test loss 1.054, test accuracy 0.336\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 68, train loss 0.064, train accuracy 1.000, val loss 0.062, val accuracy 1.000, test loss 1.054, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Epoch 69, train loss 0.062, train accuracy 1.000, val loss 0.060, val accuracy 1.000, test loss 1.053, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 70, train loss 0.059, train accuracy 1.000, val loss 0.058, val accuracy 1.000, test loss 1.051, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 71, train loss 0.057, train accuracy 1.000, val loss 0.055, val accuracy 1.000, test loss 1.050, test accuracy 0.345\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 72, train loss 0.055, train accuracy 1.000, val loss 0.053, val accuracy 1.000, test loss 1.050, test accuracy 0.345\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 73, train loss 0.053, train accuracy 1.000, val loss 0.051, val accuracy 1.000, test loss 1.049, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 74, train loss 0.051, train accuracy 1.000, val loss 0.049, val accuracy 1.000, test loss 1.049, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 75, train loss 0.049, train accuracy 1.000, val loss 0.047, val accuracy 1.000, test loss 1.048, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 76, train loss 0.047, train accuracy 1.000, val loss 0.045, val accuracy 1.000, test loss 1.047, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 77, train loss 0.045, train accuracy 1.000, val loss 0.043, val accuracy 1.000, test loss 1.048, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 78, train loss 0.043, train accuracy 1.000, val loss 0.042, val accuracy 1.000, test loss 1.048, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Epoch 79, train loss 0.041, train accuracy 1.000, val loss 0.040, val accuracy 1.000, test loss 1.049, test accuracy 0.338\n",
            "Saving overall best train val model\n",
            "Epoch 80, train loss 0.040, train accuracy 1.000, val loss 0.038, val accuracy 1.000, test loss 1.048, test accuracy 0.336\n",
            "Saving overall best train val model\n",
            "Epoch 81, train loss 0.038, train accuracy 1.000, val loss 0.037, val accuracy 1.000, test loss 1.048, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Epoch 82, train loss 0.037, train accuracy 1.000, val loss 0.035, val accuracy 1.000, test loss 1.048, test accuracy 0.338\n",
            "Saving overall best train val model\n",
            "Epoch 83, train loss 0.035, train accuracy 1.000, val loss 0.034, val accuracy 1.000, test loss 1.047, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.034, train accuracy 1.000, val loss 0.033, val accuracy 1.000, test loss 1.047, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Epoch 85, train loss 0.032, train accuracy 1.000, val loss 0.031, val accuracy 1.000, test loss 1.047, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Epoch 86, train loss 0.031, train accuracy 1.000, val loss 0.030, val accuracy 1.000, test loss 1.047, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 87, train loss 0.030, train accuracy 1.000, val loss 0.029, val accuracy 1.000, test loss 1.047, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 88, train loss 0.029, train accuracy 1.000, val loss 0.028, val accuracy 1.000, test loss 1.049, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Epoch 89, train loss 0.027, train accuracy 1.000, val loss 0.027, val accuracy 1.000, test loss 1.051, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Epoch 90, train loss 0.026, train accuracy 1.000, val loss 0.026, val accuracy 1.000, test loss 1.045, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 91, train loss 0.025, train accuracy 1.000, val loss 0.025, val accuracy 1.000, test loss 1.055, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 92, train loss 0.024, train accuracy 1.000, val loss 0.024, val accuracy 1.000, test loss 1.068, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 93, train loss 0.023, train accuracy 1.000, val loss 0.023, val accuracy 1.000, test loss 1.046, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Epoch 94, train loss 0.023, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 1.057, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 95, train loss 0.022, train accuracy 1.000, val loss 0.021, val accuracy 1.000, test loss 1.057, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 96, train loss 0.021, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 1.048, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Epoch 97, train loss 0.020, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 1.059, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 98, train loss 0.019, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 1.066, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 99, train loss 0.019, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 1.049, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 100, train loss 0.018, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 1.072, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 101, train loss 0.017, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 1.058, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 102, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 1.071, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 103, train loss 0.016, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 1.063, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Epoch 104, train loss 0.015, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 1.080, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Epoch 105, train loss 0.015, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 1.063, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 1.084, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Epoch 107, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 1.074, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 108, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 1.087, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 109, train loss 0.013, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.081, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 110, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.102, test accuracy 0.345\n",
            "Saving overall best train val model\n",
            "Epoch 111, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.082, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Epoch 112, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.113, test accuracy 0.349\n",
            "Saving overall best train val model\n",
            "Epoch 113, train loss 0.011, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.096, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 114, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.116, test accuracy 0.349\n",
            "Saving overall best train val model\n",
            "Epoch 115, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.104, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 116, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.119, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 117, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.096, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 118, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.122, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 119, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.116, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 120, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.120, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 121, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.115, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 122, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.127, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 123, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.118, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.136, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 125, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.133, test accuracy 0.374\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 126, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.139, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 127, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.136, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 128, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.143, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Epoch 129, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.138, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 130, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.145, test accuracy 0.382\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.144, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 132, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.141, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 133, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.141, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 134, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.144, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.139, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.147, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.141, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.150, test accuracy 0.382\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.145, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.152, test accuracy 0.382\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.149, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.156, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.154, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.160, test accuracy 0.382\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.161, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Epoch 146, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.168, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 147, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.176, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.154, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 149, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 1.174, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 5769\n",
            "9327\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.195, train accuracy 0.222, val loss 1.175, val accuracy 0.305, test loss 1.374, test accuracy 0.111\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.161, train accuracy 0.363, val loss 1.143, val accuracy 0.400, test loss 1.356, test accuracy 0.149\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 2, train loss 1.129, train accuracy 0.462, val loss 1.111, val accuracy 0.511, test loss 1.339, test accuracy 0.177\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.096, train accuracy 0.563, val loss 1.075, val accuracy 0.612, test loss 1.324, test accuracy 0.208\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.056, train accuracy 0.665, val loss 1.031, val accuracy 0.686, test loss 1.308, test accuracy 0.223\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 5, train loss 1.012, train accuracy 0.751, val loss 0.987, val accuracy 0.794, test loss 1.292, test accuracy 0.235\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.969, train accuracy 0.815, val loss 0.945, val accuracy 0.877, test loss 1.277, test accuracy 0.248\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 7, train loss 0.927, train accuracy 0.892, val loss 0.904, val accuracy 0.920, test loss 1.261, test accuracy 0.263\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 8, train loss 0.887, train accuracy 0.929, val loss 0.864, val accuracy 0.945, test loss 1.245, test accuracy 0.271\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.848, train accuracy 0.942, val loss 0.826, val accuracy 0.951, test loss 1.230, test accuracy 0.290\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.811, train accuracy 0.951, val loss 0.789, val accuracy 0.957, test loss 1.218, test accuracy 0.277\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 11, train loss 0.774, train accuracy 0.954, val loss 0.753, val accuracy 0.960, test loss 1.207, test accuracy 0.267\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 12, train loss 0.739, train accuracy 0.954, val loss 0.718, val accuracy 0.960, test loss 1.197, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Epoch 13, train loss 0.704, train accuracy 0.957, val loss 0.684, val accuracy 0.960, test loss 1.189, test accuracy 0.261\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 14, train loss 0.671, train accuracy 0.960, val loss 0.652, val accuracy 0.966, test loss 1.182, test accuracy 0.258\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 15, train loss 0.640, train accuracy 0.966, val loss 0.622, val accuracy 0.966, test loss 1.176, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 16, train loss 0.610, train accuracy 0.966, val loss 0.592, val accuracy 0.966, test loss 1.171, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.581, train accuracy 0.966, val loss 0.564, val accuracy 0.969, test loss 1.167, test accuracy 0.261\n",
            "Saving overall best train val model\n",
            "Epoch 18, train loss 0.553, train accuracy 0.966, val loss 0.536, val accuracy 0.969, test loss 1.163, test accuracy 0.256\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.526, train accuracy 0.969, val loss 0.511, val accuracy 0.975, test loss 1.159, test accuracy 0.252\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 20, train loss 0.501, train accuracy 0.969, val loss 0.487, val accuracy 0.975, test loss 1.154, test accuracy 0.254\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 21, train loss 0.478, train accuracy 0.969, val loss 0.464, val accuracy 0.975, test loss 1.149, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 22, train loss 0.456, train accuracy 0.975, val loss 0.443, val accuracy 0.975, test loss 1.144, test accuracy 0.261\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 23, train loss 0.435, train accuracy 0.975, val loss 0.423, val accuracy 0.975, test loss 1.139, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 24, train loss 0.416, train accuracy 0.975, val loss 0.403, val accuracy 0.978, test loss 1.135, test accuracy 0.275\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 25, train loss 0.397, train accuracy 0.975, val loss 0.385, val accuracy 0.978, test loss 1.132, test accuracy 0.277\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 26, train loss 0.379, train accuracy 0.975, val loss 0.367, val accuracy 0.978, test loss 1.128, test accuracy 0.277\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 27, train loss 0.362, train accuracy 0.975, val loss 0.351, val accuracy 0.985, test loss 1.124, test accuracy 0.271\n",
            "Saving overall best train val model\n",
            "Epoch 28, train loss 0.346, train accuracy 0.982, val loss 0.335, val accuracy 0.982, test loss 1.120, test accuracy 0.273\n",
            "Epoch 29, train loss 0.331, train accuracy 0.982, val loss 0.321, val accuracy 0.982, test loss 1.116, test accuracy 0.286\n",
            "Epoch 30, train loss 0.316, train accuracy 0.982, val loss 0.307, val accuracy 0.982, test loss 1.113, test accuracy 0.282\n",
            "Epoch 31, train loss 0.302, train accuracy 0.978, val loss 0.293, val accuracy 0.978, test loss 1.109, test accuracy 0.290\n",
            "Epoch 32, train loss 0.289, train accuracy 0.978, val loss 0.280, val accuracy 0.982, test loss 1.104, test accuracy 0.296\n",
            "Epoch 33, train loss 0.277, train accuracy 0.985, val loss 0.267, val accuracy 0.982, test loss 1.102, test accuracy 0.298\n",
            "Epoch 34, train loss 0.264, train accuracy 0.985, val loss 0.256, val accuracy 0.985, test loss 1.099, test accuracy 0.302\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 35, train loss 0.253, train accuracy 0.985, val loss 0.245, val accuracy 0.985, test loss 1.097, test accuracy 0.313\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 36, train loss 0.242, train accuracy 0.982, val loss 0.235, val accuracy 0.985, test loss 1.095, test accuracy 0.315\n",
            "Epoch 37, train loss 0.232, train accuracy 0.982, val loss 0.225, val accuracy 0.985, test loss 1.093, test accuracy 0.319\n",
            "Epoch 38, train loss 0.222, train accuracy 0.982, val loss 0.215, val accuracy 0.988, test loss 1.091, test accuracy 0.321\n",
            "Epoch 39, train loss 0.213, train accuracy 0.985, val loss 0.206, val accuracy 0.988, test loss 1.088, test accuracy 0.317\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 40, train loss 0.203, train accuracy 0.988, val loss 0.197, val accuracy 0.988, test loss 1.085, test accuracy 0.319\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 41, train loss 0.195, train accuracy 0.988, val loss 0.188, val accuracy 0.988, test loss 1.081, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 42, train loss 0.186, train accuracy 0.988, val loss 0.180, val accuracy 0.991, test loss 1.078, test accuracy 0.332\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 43, train loss 0.179, train accuracy 0.991, val loss 0.173, val accuracy 0.991, test loss 1.075, test accuracy 0.334\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 44, train loss 0.171, train accuracy 0.994, val loss 0.166, val accuracy 0.994, test loss 1.073, test accuracy 0.342\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 45, train loss 0.164, train accuracy 0.994, val loss 0.159, val accuracy 0.994, test loss 1.071, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 46, train loss 0.157, train accuracy 0.994, val loss 0.153, val accuracy 0.994, test loss 1.068, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 47, train loss 0.151, train accuracy 0.994, val loss 0.147, val accuracy 0.994, test loss 1.067, test accuracy 0.349\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 48, train loss 0.145, train accuracy 0.994, val loss 0.141, val accuracy 0.994, test loss 1.065, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Epoch 49, train loss 0.139, train accuracy 0.994, val loss 0.135, val accuracy 0.994, test loss 1.063, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 50, train loss 0.134, train accuracy 0.994, val loss 0.129, val accuracy 0.994, test loss 1.061, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 51, train loss 0.128, train accuracy 0.994, val loss 0.124, val accuracy 0.994, test loss 1.058, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 52, train loss 0.123, train accuracy 0.994, val loss 0.119, val accuracy 0.994, test loss 1.055, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 53, train loss 0.118, train accuracy 0.994, val loss 0.115, val accuracy 0.994, test loss 1.050, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 54, train loss 0.113, train accuracy 0.994, val loss 0.110, val accuracy 0.994, test loss 1.053, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 55, train loss 0.109, train accuracy 0.994, val loss 0.106, val accuracy 0.994, test loss 1.054, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 56, train loss 0.105, train accuracy 0.994, val loss 0.102, val accuracy 0.994, test loss 1.051, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 57, train loss 0.101, train accuracy 0.994, val loss 0.097, val accuracy 0.994, test loss 1.053, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Epoch 58, train loss 0.097, train accuracy 0.994, val loss 0.093, val accuracy 0.994, test loss 1.052, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Epoch 59, train loss 0.094, train accuracy 0.994, val loss 0.090, val accuracy 0.994, test loss 1.053, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 60, train loss 0.089, train accuracy 0.994, val loss 0.086, val accuracy 0.994, test loss 1.051, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 61, train loss 0.086, train accuracy 0.994, val loss 0.083, val accuracy 0.997, test loss 1.052, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 62, train loss 0.082, train accuracy 0.997, val loss 0.080, val accuracy 0.997, test loss 1.052, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 63, train loss 0.079, train accuracy 0.997, val loss 0.077, val accuracy 0.997, test loss 1.053, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 64, train loss 0.076, train accuracy 0.997, val loss 0.073, val accuracy 0.997, test loss 1.053, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 65, train loss 0.073, train accuracy 0.997, val loss 0.070, val accuracy 0.997, test loss 1.053, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 66, train loss 0.070, train accuracy 0.997, val loss 0.068, val accuracy 0.997, test loss 1.054, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 67, train loss 0.067, train accuracy 0.997, val loss 0.065, val accuracy 0.997, test loss 1.054, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 68, train loss 0.064, train accuracy 0.997, val loss 0.062, val accuracy 0.997, test loss 1.055, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 69, train loss 0.062, train accuracy 0.997, val loss 0.060, val accuracy 0.997, test loss 1.054, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 70, train loss 0.059, train accuracy 0.997, val loss 0.057, val accuracy 0.997, test loss 1.055, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 71, train loss 0.057, train accuracy 0.997, val loss 0.055, val accuracy 0.997, test loss 1.054, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 72, train loss 0.054, train accuracy 0.997, val loss 0.052, val accuracy 0.997, test loss 1.054, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 73, train loss 0.052, train accuracy 0.997, val loss 0.050, val accuracy 0.997, test loss 1.053, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 74, train loss 0.050, train accuracy 0.997, val loss 0.048, val accuracy 0.997, test loss 1.052, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 75, train loss 0.048, train accuracy 0.997, val loss 0.046, val accuracy 0.997, test loss 1.052, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 76, train loss 0.046, train accuracy 0.997, val loss 0.044, val accuracy 0.997, test loss 1.051, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 77, train loss 0.044, train accuracy 0.997, val loss 0.042, val accuracy 0.997, test loss 1.050, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 78, train loss 0.042, train accuracy 0.997, val loss 0.041, val accuracy 0.997, test loss 1.048, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 79, train loss 0.040, train accuracy 0.997, val loss 0.039, val accuracy 0.997, test loss 1.048, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 80, train loss 0.039, train accuracy 0.997, val loss 0.037, val accuracy 0.997, test loss 1.047, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 81, train loss 0.037, train accuracy 0.997, val loss 0.036, val accuracy 0.997, test loss 1.047, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Epoch 82, train loss 0.035, train accuracy 0.997, val loss 0.034, val accuracy 0.997, test loss 1.047, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Epoch 83, train loss 0.034, train accuracy 0.997, val loss 0.033, val accuracy 0.997, test loss 1.048, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.033, train accuracy 0.997, val loss 0.032, val accuracy 0.997, test loss 1.048, test accuracy 0.357\n",
            "Saving overall best train val model\n",
            "Epoch 85, train loss 0.031, train accuracy 0.997, val loss 0.030, val accuracy 0.997, test loss 1.049, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 86, train loss 0.030, train accuracy 0.997, val loss 0.029, val accuracy 1.000, test loss 1.050, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 87, train loss 0.029, train accuracy 1.000, val loss 0.028, val accuracy 1.000, test loss 1.052, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 88, train loss 0.028, train accuracy 1.000, val loss 0.027, val accuracy 1.000, test loss 1.053, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 89, train loss 0.027, train accuracy 1.000, val loss 0.026, val accuracy 1.000, test loss 1.056, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 90, train loss 0.025, train accuracy 1.000, val loss 0.025, val accuracy 1.000, test loss 1.058, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 91, train loss 0.024, train accuracy 1.000, val loss 0.024, val accuracy 1.000, test loss 1.061, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 92, train loss 0.023, train accuracy 1.000, val loss 0.023, val accuracy 1.000, test loss 1.060, test accuracy 0.366\n",
            "Saving overall best train val model\n",
            "Epoch 93, train loss 0.022, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 1.064, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Epoch 94, train loss 0.022, train accuracy 1.000, val loss 0.021, val accuracy 1.000, test loss 1.065, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 95, train loss 0.021, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 1.067, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 96, train loss 0.020, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 1.068, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 97, train loss 0.019, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 1.071, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 98, train loss 0.018, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 1.070, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 99, train loss 0.018, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 1.075, test accuracy 0.374\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 100, train loss 0.017, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 1.074, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Epoch 101, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 1.078, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Epoch 102, train loss 0.016, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 1.078, test accuracy 0.378\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 103, train loss 0.015, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 1.081, test accuracy 0.376\n",
            "Saving overall best train val model\n",
            "Epoch 104, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 1.082, test accuracy 0.382\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 105, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 1.087, test accuracy 0.374\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 1.084, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 107, train loss 0.013, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.084, test accuracy 0.382\n",
            "Saving overall best train val model\n",
            "Epoch 108, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 1.084, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 109, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.086, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 110, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 1.086, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 111, train loss 0.011, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.089, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 112, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.090, test accuracy 0.395\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 113, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 1.092, test accuracy 0.397\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 114, train loss 0.010, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.094, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Epoch 115, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.096, test accuracy 0.391\n",
            "Saving overall best train val model\n",
            "Epoch 116, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 1.097, test accuracy 0.395\n",
            "Saving overall best train val model\n",
            "Epoch 117, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.102, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Epoch 118, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.101, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Epoch 119, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 1.106, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 120, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.108, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Epoch 121, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.110, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Epoch 122, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.114, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Epoch 123, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 1.115, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.120, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Epoch 125, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.119, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 126, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.123, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Epoch 127, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 1.125, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Epoch 128, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.131, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Epoch 129, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.135, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Epoch 130, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.144, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.150, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Epoch 132, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 1.159, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Epoch 133, train loss 0.005, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.163, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.167, test accuracy 0.391\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.169, test accuracy 0.391\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.174, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.178, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.183, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 1.193, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.004, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.198, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.204, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.212, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.218, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.224, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.231, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Epoch 146, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.238, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Epoch 147, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.242, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 1.250, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Epoch 149, train loss 0.003, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 1.258, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 9327\n",
            "7867\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.169, train accuracy 0.212, val loss 1.146, val accuracy 0.298, test loss 1.344, test accuracy 0.084\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.129, train accuracy 0.388, val loss 1.107, val accuracy 0.440, test loss 1.338, test accuracy 0.097\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 2, train loss 1.088, train accuracy 0.535, val loss 1.065, val accuracy 0.603, test loss 1.330, test accuracy 0.097\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.040, train accuracy 0.683, val loss 1.006, val accuracy 0.748, test loss 1.324, test accuracy 0.090\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 4, train loss 0.985, train accuracy 0.791, val loss 0.959, val accuracy 0.837, test loss 1.321, test accuracy 0.101\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 5, train loss 0.939, train accuracy 0.871, val loss 0.914, val accuracy 0.898, test loss 1.314, test accuracy 0.095\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 6, train loss 0.894, train accuracy 0.920, val loss 0.869, val accuracy 0.935, test loss 1.306, test accuracy 0.101\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 7, train loss 0.850, train accuracy 0.929, val loss 0.825, val accuracy 0.942, test loss 1.296, test accuracy 0.115\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 8, train loss 0.807, train accuracy 0.951, val loss 0.783, val accuracy 0.954, test loss 1.285, test accuracy 0.139\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.765, train accuracy 0.957, val loss 0.742, val accuracy 0.960, test loss 1.274, test accuracy 0.155\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.726, train accuracy 0.957, val loss 0.704, val accuracy 0.966, test loss 1.259, test accuracy 0.189\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 11, train loss 0.689, train accuracy 0.960, val loss 0.669, val accuracy 0.966, test loss 1.240, test accuracy 0.221\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 12, train loss 0.656, train accuracy 0.966, val loss 0.637, val accuracy 0.969, test loss 1.221, test accuracy 0.240\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 13, train loss 0.625, train accuracy 0.966, val loss 0.608, val accuracy 0.975, test loss 1.203, test accuracy 0.265\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 14, train loss 0.597, train accuracy 0.966, val loss 0.581, val accuracy 0.972, test loss 1.187, test accuracy 0.282\n",
            "Epoch 15, train loss 0.571, train accuracy 0.969, val loss 0.556, val accuracy 0.972, test loss 1.170, test accuracy 0.288\n",
            "Epoch 16, train loss 0.547, train accuracy 0.969, val loss 0.532, val accuracy 0.975, test loss 1.150, test accuracy 0.305\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.523, train accuracy 0.969, val loss 0.509, val accuracy 0.978, test loss 1.132, test accuracy 0.311\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 18, train loss 0.501, train accuracy 0.972, val loss 0.487, val accuracy 0.978, test loss 1.115, test accuracy 0.324\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 19, train loss 0.480, train accuracy 0.975, val loss 0.467, val accuracy 0.978, test loss 1.100, test accuracy 0.332\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 20, train loss 0.459, train accuracy 0.975, val loss 0.447, val accuracy 0.975, test loss 1.085, test accuracy 0.338\n",
            "Epoch 21, train loss 0.440, train accuracy 0.975, val loss 0.429, val accuracy 0.978, test loss 1.071, test accuracy 0.345\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 22, train loss 0.422, train accuracy 0.978, val loss 0.411, val accuracy 0.978, test loss 1.059, test accuracy 0.345\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 23, train loss 0.404, train accuracy 0.978, val loss 0.394, val accuracy 0.985, test loss 1.049, test accuracy 0.347\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 24, train loss 0.388, train accuracy 0.982, val loss 0.378, val accuracy 0.985, test loss 1.039, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 25, train loss 0.372, train accuracy 0.982, val loss 0.363, val accuracy 0.985, test loss 1.031, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 26, train loss 0.358, train accuracy 0.985, val loss 0.349, val accuracy 0.988, test loss 1.023, test accuracy 0.359\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 27, train loss 0.344, train accuracy 0.985, val loss 0.336, val accuracy 0.988, test loss 1.015, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 28, train loss 0.331, train accuracy 0.988, val loss 0.323, val accuracy 0.991, test loss 1.007, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 29, train loss 0.319, train accuracy 0.988, val loss 0.312, val accuracy 0.991, test loss 1.000, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 30, train loss 0.307, train accuracy 0.988, val loss 0.300, val accuracy 0.991, test loss 0.994, test accuracy 0.376\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 31, train loss 0.296, train accuracy 0.988, val loss 0.289, val accuracy 0.991, test loss 0.988, test accuracy 0.382\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 32, train loss 0.285, train accuracy 0.988, val loss 0.278, val accuracy 0.991, test loss 0.982, test accuracy 0.382\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 33, train loss 0.275, train accuracy 0.988, val loss 0.268, val accuracy 0.991, test loss 0.976, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 34, train loss 0.264, train accuracy 0.991, val loss 0.258, val accuracy 0.991, test loss 0.970, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 35, train loss 0.255, train accuracy 0.991, val loss 0.248, val accuracy 0.991, test loss 0.964, test accuracy 0.397\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 36, train loss 0.245, train accuracy 0.991, val loss 0.239, val accuracy 0.991, test loss 0.958, test accuracy 0.397\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 37, train loss 0.236, train accuracy 0.991, val loss 0.230, val accuracy 0.994, test loss 0.955, test accuracy 0.410\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 38, train loss 0.227, train accuracy 0.994, val loss 0.221, val accuracy 0.994, test loss 0.950, test accuracy 0.414\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 39, train loss 0.218, train accuracy 0.994, val loss 0.213, val accuracy 0.994, test loss 0.943, test accuracy 0.422\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 40, train loss 0.210, train accuracy 0.994, val loss 0.205, val accuracy 0.994, test loss 0.938, test accuracy 0.427\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 41, train loss 0.202, train accuracy 0.994, val loss 0.197, val accuracy 0.997, test loss 0.933, test accuracy 0.433\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 42, train loss 0.194, train accuracy 0.997, val loss 0.189, val accuracy 0.997, test loss 0.928, test accuracy 0.429\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 43, train loss 0.187, train accuracy 0.997, val loss 0.182, val accuracy 0.997, test loss 0.923, test accuracy 0.431\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 44, train loss 0.180, train accuracy 0.997, val loss 0.175, val accuracy 0.997, test loss 0.917, test accuracy 0.431\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 45, train loss 0.173, train accuracy 0.997, val loss 0.168, val accuracy 0.997, test loss 0.912, test accuracy 0.433\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 46, train loss 0.166, train accuracy 0.997, val loss 0.162, val accuracy 0.997, test loss 0.908, test accuracy 0.443\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 47, train loss 0.159, train accuracy 0.997, val loss 0.156, val accuracy 0.997, test loss 0.904, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Epoch 48, train loss 0.153, train accuracy 0.997, val loss 0.149, val accuracy 0.997, test loss 0.901, test accuracy 0.445\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 49, train loss 0.147, train accuracy 0.997, val loss 0.144, val accuracy 0.997, test loss 0.899, test accuracy 0.447\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 50, train loss 0.141, train accuracy 0.997, val loss 0.138, val accuracy 0.997, test loss 0.898, test accuracy 0.448\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 51, train loss 0.136, train accuracy 0.997, val loss 0.132, val accuracy 0.997, test loss 0.893, test accuracy 0.447\n",
            "Saving overall best train val model\n",
            "Epoch 52, train loss 0.130, train accuracy 0.997, val loss 0.127, val accuracy 0.997, test loss 0.892, test accuracy 0.448\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 53, train loss 0.125, train accuracy 0.997, val loss 0.122, val accuracy 0.997, test loss 0.893, test accuracy 0.447\n",
            "Saving overall best train val model\n",
            "Epoch 54, train loss 0.120, train accuracy 0.997, val loss 0.117, val accuracy 0.997, test loss 0.891, test accuracy 0.447\n",
            "Saving overall best train val model\n",
            "Epoch 55, train loss 0.115, train accuracy 0.997, val loss 0.112, val accuracy 0.997, test loss 0.887, test accuracy 0.452\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 56, train loss 0.110, train accuracy 0.997, val loss 0.108, val accuracy 0.997, test loss 0.886, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 57, train loss 0.106, train accuracy 0.997, val loss 0.104, val accuracy 0.997, test loss 0.887, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 58, train loss 0.102, train accuracy 0.997, val loss 0.100, val accuracy 0.997, test loss 0.887, test accuracy 0.452\n",
            "Saving overall best train val model\n",
            "Epoch 59, train loss 0.098, train accuracy 0.997, val loss 0.095, val accuracy 0.997, test loss 0.881, test accuracy 0.452\n",
            "Saving overall best train val model\n",
            "Epoch 60, train loss 0.094, train accuracy 0.997, val loss 0.091, val accuracy 0.997, test loss 0.878, test accuracy 0.450\n",
            "Saving overall best train val model\n",
            "Epoch 61, train loss 0.090, train accuracy 0.997, val loss 0.088, val accuracy 0.997, test loss 0.881, test accuracy 0.458\n",
            "Saving overall best train val model\n",
            "Epoch 62, train loss 0.086, train accuracy 0.997, val loss 0.084, val accuracy 0.997, test loss 0.879, test accuracy 0.460\n",
            "Saving overall best train val model\n",
            "Epoch 63, train loss 0.083, train accuracy 0.997, val loss 0.081, val accuracy 0.997, test loss 0.879, test accuracy 0.456\n",
            "Saving overall best train val model\n",
            "Epoch 64, train loss 0.079, train accuracy 0.997, val loss 0.077, val accuracy 0.997, test loss 0.873, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 65, train loss 0.076, train accuracy 0.997, val loss 0.074, val accuracy 0.997, test loss 0.872, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 66, train loss 0.073, train accuracy 0.997, val loss 0.072, val accuracy 0.997, test loss 0.868, test accuracy 0.462\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 67, train loss 0.070, train accuracy 0.997, val loss 0.069, val accuracy 0.997, test loss 0.866, test accuracy 0.464\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 68, train loss 0.067, train accuracy 0.997, val loss 0.066, val accuracy 0.997, test loss 0.865, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 69, train loss 0.065, train accuracy 0.997, val loss 0.063, val accuracy 0.997, test loss 0.862, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 70, train loss 0.062, train accuracy 0.997, val loss 0.061, val accuracy 1.000, test loss 0.859, test accuracy 0.485\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 71, train loss 0.060, train accuracy 0.997, val loss 0.059, val accuracy 1.000, test loss 0.857, test accuracy 0.487\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 72, train loss 0.057, train accuracy 0.997, val loss 0.056, val accuracy 1.000, test loss 0.854, test accuracy 0.489\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 73, train loss 0.055, train accuracy 1.000, val loss 0.054, val accuracy 1.000, test loss 0.852, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 74, train loss 0.053, train accuracy 1.000, val loss 0.051, val accuracy 1.000, test loss 0.851, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Epoch 75, train loss 0.051, train accuracy 1.000, val loss 0.049, val accuracy 1.000, test loss 0.849, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Epoch 76, train loss 0.049, train accuracy 1.000, val loss 0.048, val accuracy 1.000, test loss 0.846, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 77, train loss 0.047, train accuracy 1.000, val loss 0.046, val accuracy 1.000, test loss 0.842, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Epoch 78, train loss 0.045, train accuracy 1.000, val loss 0.044, val accuracy 1.000, test loss 0.840, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Epoch 79, train loss 0.044, train accuracy 1.000, val loss 0.042, val accuracy 1.000, test loss 0.840, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Epoch 80, train loss 0.042, train accuracy 1.000, val loss 0.040, val accuracy 1.000, test loss 0.838, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 81, train loss 0.040, train accuracy 1.000, val loss 0.039, val accuracy 1.000, test loss 0.836, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 82, train loss 0.039, train accuracy 1.000, val loss 0.037, val accuracy 1.000, test loss 0.834, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 83, train loss 0.037, train accuracy 1.000, val loss 0.036, val accuracy 1.000, test loss 0.832, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.036, train accuracy 1.000, val loss 0.035, val accuracy 1.000, test loss 0.828, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Epoch 85, train loss 0.034, train accuracy 1.000, val loss 0.033, val accuracy 1.000, test loss 0.832, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 86, train loss 0.033, train accuracy 1.000, val loss 0.032, val accuracy 1.000, test loss 0.827, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Epoch 87, train loss 0.032, train accuracy 1.000, val loss 0.031, val accuracy 1.000, test loss 0.828, test accuracy 0.490\n",
            "Saving overall best train val model\n",
            "Epoch 88, train loss 0.030, train accuracy 1.000, val loss 0.030, val accuracy 1.000, test loss 0.828, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 89, train loss 0.029, train accuracy 1.000, val loss 0.028, val accuracy 1.000, test loss 0.828, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 90, train loss 0.028, train accuracy 1.000, val loss 0.027, val accuracy 1.000, test loss 0.828, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 91, train loss 0.027, train accuracy 1.000, val loss 0.026, val accuracy 1.000, test loss 0.829, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 92, train loss 0.026, train accuracy 1.000, val loss 0.025, val accuracy 1.000, test loss 0.830, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Epoch 93, train loss 0.025, train accuracy 1.000, val loss 0.024, val accuracy 1.000, test loss 0.833, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Epoch 94, train loss 0.024, train accuracy 1.000, val loss 0.023, val accuracy 1.000, test loss 0.832, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Epoch 95, train loss 0.023, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 0.829, test accuracy 0.506\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 96, train loss 0.022, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 0.833, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Epoch 97, train loss 0.021, train accuracy 1.000, val loss 0.021, val accuracy 1.000, test loss 0.823, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 98, train loss 0.021, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 0.813, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Epoch 99, train loss 0.020, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 0.810, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 100, train loss 0.019, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 0.807, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 101, train loss 0.018, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 0.809, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 102, train loss 0.018, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 0.810, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 103, train loss 0.017, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 0.812, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 104, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 0.812, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 105, train loss 0.016, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 0.818, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.015, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 0.815, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 107, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 0.819, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 108, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.816, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 109, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.826, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Epoch 110, train loss 0.013, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.816, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 111, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.805, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Epoch 112, train loss 0.013, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.814, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 113, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.803, test accuracy 0.517\n",
            "Saving overall best train val model\n",
            "Epoch 114, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.802, test accuracy 0.519\n",
            "Saving overall best train val model\n",
            "Epoch 115, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.802, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 116, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.802, test accuracy 0.525\n",
            "Saving overall best train val model\n",
            "Epoch 117, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.802, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 118, train loss 0.010, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.806, test accuracy 0.525\n",
            "Saving overall best train val model\n",
            "Epoch 119, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.803, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 120, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.801, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 121, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.818, test accuracy 0.523\n",
            "Saving overall best train val model\n",
            "Epoch 122, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.826, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 123, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.807, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.807, test accuracy 0.532\n",
            "Saving overall best train val model\n",
            "Epoch 125, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.809, test accuracy 0.536\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 126, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.810, test accuracy 0.536\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 127, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.812, test accuracy 0.532\n",
            "Saving overall best train val model\n",
            "Epoch 128, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.815, test accuracy 0.532\n",
            "Saving overall best train val model\n",
            "Epoch 129, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.814, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 130, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.814, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.825, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Epoch 132, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.830, test accuracy 0.532\n",
            "Saving overall best train val model\n",
            "Epoch 133, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.824, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.822, test accuracy 0.532\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.824, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.824, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.825, test accuracy 0.534\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.005, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.826, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.824, test accuracy 0.531\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.011, train accuracy 0.997, val loss 0.008, val accuracy 1.000, test loss 0.806, test accuracy 0.515\n",
            "Epoch 141, train loss 0.007, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.844, test accuracy 0.525\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.005, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.843, test accuracy 0.521\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.843, test accuracy 0.525\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.840, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.836, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Epoch 146, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.833, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Epoch 147, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.831, test accuracy 0.529\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.829, test accuracy 0.527\n",
            "Saving overall best train val model\n",
            "Epoch 149, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.827, test accuracy 0.532\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 7867\n",
            "4469\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.181, train accuracy 0.172, val loss 1.159, val accuracy 0.295, test loss 1.300, test accuracy 0.208\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.143, train accuracy 0.363, val loss 1.123, val accuracy 0.492, test loss 1.292, test accuracy 0.218\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 2, train loss 1.108, train accuracy 0.566, val loss 1.088, val accuracy 0.609, test loss 1.284, test accuracy 0.240\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.070, train accuracy 0.631, val loss 1.048, val accuracy 0.640, test loss 1.272, test accuracy 0.267\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.028, train accuracy 0.671, val loss 1.003, val accuracy 0.698, test loss 1.260, test accuracy 0.292\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 5, train loss 0.982, train accuracy 0.742, val loss 0.955, val accuracy 0.778, test loss 1.246, test accuracy 0.328\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.934, train accuracy 0.806, val loss 0.906, val accuracy 0.843, test loss 1.232, test accuracy 0.345\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 7, train loss 0.887, train accuracy 0.837, val loss 0.861, val accuracy 0.865, test loss 1.217, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 8, train loss 0.843, train accuracy 0.883, val loss 0.819, val accuracy 0.895, test loss 1.202, test accuracy 0.410\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.802, train accuracy 0.917, val loss 0.779, val accuracy 0.911, test loss 1.190, test accuracy 0.424\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.762, train accuracy 0.920, val loss 0.741, val accuracy 0.926, test loss 1.178, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 11, train loss 0.726, train accuracy 0.926, val loss 0.706, val accuracy 0.938, test loss 1.165, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 12, train loss 0.692, train accuracy 0.945, val loss 0.674, val accuracy 0.945, test loss 1.151, test accuracy 0.416\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 13, train loss 0.661, train accuracy 0.951, val loss 0.644, val accuracy 0.951, test loss 1.138, test accuracy 0.424\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 14, train loss 0.633, train accuracy 0.957, val loss 0.617, val accuracy 0.957, test loss 1.127, test accuracy 0.426\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 15, train loss 0.607, train accuracy 0.957, val loss 0.592, val accuracy 0.957, test loss 1.118, test accuracy 0.424\n",
            "Saving overall best train val model\n",
            "Epoch 16, train loss 0.583, train accuracy 0.960, val loss 0.569, val accuracy 0.957, test loss 1.110, test accuracy 0.426\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.560, train accuracy 0.960, val loss 0.546, val accuracy 0.960, test loss 1.103, test accuracy 0.435\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 18, train loss 0.538, train accuracy 0.960, val loss 0.525, val accuracy 0.963, test loss 1.095, test accuracy 0.429\n",
            "Saving overall best train val model\n",
            "Epoch 19, train loss 0.517, train accuracy 0.963, val loss 0.504, val accuracy 0.963, test loss 1.087, test accuracy 0.426\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 20, train loss 0.497, train accuracy 0.966, val loss 0.484, val accuracy 0.963, test loss 1.080, test accuracy 0.422\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 21, train loss 0.477, train accuracy 0.966, val loss 0.465, val accuracy 0.966, test loss 1.074, test accuracy 0.414\n",
            "Saving overall best train val model\n",
            "Epoch 22, train loss 0.458, train accuracy 0.969, val loss 0.446, val accuracy 0.972, test loss 1.071, test accuracy 0.401\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 23, train loss 0.440, train accuracy 0.969, val loss 0.428, val accuracy 0.972, test loss 1.062, test accuracy 0.401\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 24, train loss 0.422, train accuracy 0.972, val loss 0.411, val accuracy 0.972, test loss 1.056, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 25, train loss 0.406, train accuracy 0.972, val loss 0.394, val accuracy 0.975, test loss 1.050, test accuracy 0.380\n",
            "Saving overall best train val model\n",
            "Epoch 26, train loss 0.390, train accuracy 0.978, val loss 0.379, val accuracy 0.975, test loss 1.044, test accuracy 0.385\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 27, train loss 0.375, train accuracy 0.978, val loss 0.364, val accuracy 0.975, test loss 1.038, test accuracy 0.382\n",
            "Saving overall best train val model\n",
            "Epoch 28, train loss 0.360, train accuracy 0.978, val loss 0.350, val accuracy 0.978, test loss 1.032, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 29, train loss 0.346, train accuracy 0.978, val loss 0.337, val accuracy 0.978, test loss 1.027, test accuracy 0.384\n",
            "Saving overall best train val model\n",
            "Epoch 30, train loss 0.333, train accuracy 0.978, val loss 0.324, val accuracy 0.978, test loss 1.022, test accuracy 0.395\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 31, train loss 0.321, train accuracy 0.978, val loss 0.312, val accuracy 0.978, test loss 1.017, test accuracy 0.399\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 32, train loss 0.308, train accuracy 0.978, val loss 0.300, val accuracy 0.978, test loss 1.012, test accuracy 0.393\n",
            "Saving overall best train val model\n",
            "Epoch 33, train loss 0.297, train accuracy 0.978, val loss 0.288, val accuracy 0.978, test loss 1.000, test accuracy 0.395\n",
            "Saving overall best train val model\n",
            "Epoch 34, train loss 0.285, train accuracy 0.978, val loss 0.277, val accuracy 0.978, test loss 0.996, test accuracy 0.391\n",
            "Saving overall best train val model\n",
            "Epoch 35, train loss 0.274, train accuracy 0.978, val loss 0.267, val accuracy 0.978, test loss 0.984, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Epoch 36, train loss 0.264, train accuracy 0.982, val loss 0.257, val accuracy 0.978, test loss 0.981, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 37, train loss 0.254, train accuracy 0.982, val loss 0.247, val accuracy 0.982, test loss 0.973, test accuracy 0.397\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 38, train loss 0.244, train accuracy 0.982, val loss 0.238, val accuracy 0.985, test loss 0.968, test accuracy 0.403\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 39, train loss 0.235, train accuracy 0.985, val loss 0.228, val accuracy 0.985, test loss 0.965, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 40, train loss 0.226, train accuracy 0.985, val loss 0.220, val accuracy 0.985, test loss 0.962, test accuracy 0.422\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 41, train loss 0.217, train accuracy 0.985, val loss 0.211, val accuracy 0.985, test loss 0.958, test accuracy 0.420\n",
            "Saving overall best train val model\n",
            "Epoch 42, train loss 0.209, train accuracy 0.985, val loss 0.203, val accuracy 0.988, test loss 0.955, test accuracy 0.418\n",
            "Saving overall best train val model\n",
            "Epoch 43, train loss 0.201, train accuracy 0.985, val loss 0.195, val accuracy 0.988, test loss 0.950, test accuracy 0.418\n",
            "Saving overall best train val model\n",
            "Epoch 44, train loss 0.193, train accuracy 0.985, val loss 0.187, val accuracy 0.988, test loss 0.946, test accuracy 0.426\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 45, train loss 0.185, train accuracy 0.988, val loss 0.180, val accuracy 0.988, test loss 0.942, test accuracy 0.426\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 46, train loss 0.178, train accuracy 0.988, val loss 0.173, val accuracy 0.988, test loss 0.939, test accuracy 0.422\n",
            "Saving overall best train val model\n",
            "Epoch 47, train loss 0.171, train accuracy 0.988, val loss 0.166, val accuracy 0.988, test loss 0.936, test accuracy 0.418\n",
            "Saving overall best train val model\n",
            "Epoch 48, train loss 0.165, train accuracy 0.988, val loss 0.160, val accuracy 0.988, test loss 0.933, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Epoch 49, train loss 0.158, train accuracy 0.988, val loss 0.153, val accuracy 0.988, test loss 0.930, test accuracy 0.406\n",
            "Saving overall best train val model\n",
            "Epoch 50, train loss 0.152, train accuracy 0.988, val loss 0.147, val accuracy 0.988, test loss 0.927, test accuracy 0.408\n",
            "Saving overall best train val model\n",
            "Epoch 51, train loss 0.146, train accuracy 0.991, val loss 0.142, val accuracy 0.991, test loss 0.924, test accuracy 0.410\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 52, train loss 0.140, train accuracy 0.991, val loss 0.136, val accuracy 0.991, test loss 0.922, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 53, train loss 0.135, train accuracy 0.991, val loss 0.131, val accuracy 0.994, test loss 0.918, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 54, train loss 0.129, train accuracy 0.994, val loss 0.125, val accuracy 0.994, test loss 0.914, test accuracy 0.408\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 55, train loss 0.124, train accuracy 0.994, val loss 0.120, val accuracy 0.994, test loss 0.908, test accuracy 0.408\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 56, train loss 0.119, train accuracy 0.994, val loss 0.115, val accuracy 0.994, test loss 0.910, test accuracy 0.408\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 57, train loss 0.114, train accuracy 0.994, val loss 0.110, val accuracy 0.994, test loss 0.910, test accuracy 0.408\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 58, train loss 0.109, train accuracy 0.994, val loss 0.106, val accuracy 0.997, test loss 0.909, test accuracy 0.403\n",
            "Saving overall best train val model\n",
            "Epoch 59, train loss 0.105, train accuracy 0.994, val loss 0.101, val accuracy 0.997, test loss 0.909, test accuracy 0.405\n",
            "Saving overall best train val model\n",
            "Epoch 60, train loss 0.101, train accuracy 0.994, val loss 0.097, val accuracy 0.997, test loss 0.908, test accuracy 0.403\n",
            "Saving overall best train val model\n",
            "Epoch 61, train loss 0.097, train accuracy 0.997, val loss 0.093, val accuracy 0.997, test loss 0.907, test accuracy 0.397\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 62, train loss 0.093, train accuracy 0.997, val loss 0.090, val accuracy 0.997, test loss 0.905, test accuracy 0.399\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 63, train loss 0.089, train accuracy 0.997, val loss 0.086, val accuracy 0.997, test loss 0.902, test accuracy 0.397\n",
            "Saving overall best train val model\n",
            "Epoch 64, train loss 0.086, train accuracy 0.997, val loss 0.083, val accuracy 0.997, test loss 0.899, test accuracy 0.399\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 65, train loss 0.082, train accuracy 0.997, val loss 0.079, val accuracy 0.997, test loss 0.896, test accuracy 0.399\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 66, train loss 0.079, train accuracy 0.997, val loss 0.076, val accuracy 0.997, test loss 0.893, test accuracy 0.401\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 67, train loss 0.076, train accuracy 0.997, val loss 0.073, val accuracy 0.997, test loss 0.890, test accuracy 0.403\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 68, train loss 0.073, train accuracy 0.997, val loss 0.070, val accuracy 1.000, test loss 0.888, test accuracy 0.403\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 69, train loss 0.070, train accuracy 0.997, val loss 0.068, val accuracy 1.000, test loss 0.886, test accuracy 0.405\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 70, train loss 0.067, train accuracy 1.000, val loss 0.065, val accuracy 1.000, test loss 0.884, test accuracy 0.405\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 71, train loss 0.065, train accuracy 1.000, val loss 0.062, val accuracy 1.000, test loss 0.883, test accuracy 0.408\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 72, train loss 0.062, train accuracy 1.000, val loss 0.060, val accuracy 1.000, test loss 0.882, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 73, train loss 0.060, train accuracy 1.000, val loss 0.058, val accuracy 1.000, test loss 0.881, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 74, train loss 0.057, train accuracy 1.000, val loss 0.055, val accuracy 1.000, test loss 0.881, test accuracy 0.414\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 75, train loss 0.055, train accuracy 1.000, val loss 0.053, val accuracy 1.000, test loss 0.880, test accuracy 0.418\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 76, train loss 0.053, train accuracy 1.000, val loss 0.051, val accuracy 1.000, test loss 0.878, test accuracy 0.418\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 77, train loss 0.051, train accuracy 1.000, val loss 0.049, val accuracy 1.000, test loss 0.878, test accuracy 0.420\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 78, train loss 0.049, train accuracy 1.000, val loss 0.047, val accuracy 1.000, test loss 0.878, test accuracy 0.422\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 79, train loss 0.047, train accuracy 1.000, val loss 0.045, val accuracy 1.000, test loss 0.881, test accuracy 0.418\n",
            "Saving overall best train val model\n",
            "Epoch 80, train loss 0.045, train accuracy 1.000, val loss 0.043, val accuracy 1.000, test loss 0.884, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Epoch 81, train loss 0.043, train accuracy 1.000, val loss 0.042, val accuracy 1.000, test loss 0.884, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Epoch 82, train loss 0.042, train accuracy 1.000, val loss 0.040, val accuracy 1.000, test loss 0.886, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Epoch 83, train loss 0.040, train accuracy 1.000, val loss 0.039, val accuracy 1.000, test loss 0.884, test accuracy 0.416\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.039, train accuracy 1.000, val loss 0.038, val accuracy 1.000, test loss 0.938, test accuracy 0.399\n",
            "Saving overall best train val model\n",
            "Epoch 85, train loss 0.037, train accuracy 1.000, val loss 0.035, val accuracy 1.000, test loss 0.887, test accuracy 0.429\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 86, train loss 0.035, train accuracy 1.000, val loss 0.034, val accuracy 1.000, test loss 0.885, test accuracy 0.429\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 87, train loss 0.034, train accuracy 1.000, val loss 0.033, val accuracy 1.000, test loss 0.884, test accuracy 0.431\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 88, train loss 0.032, train accuracy 1.000, val loss 0.031, val accuracy 1.000, test loss 0.883, test accuracy 0.429\n",
            "Saving overall best train val model\n",
            "Epoch 89, train loss 0.031, train accuracy 1.000, val loss 0.030, val accuracy 1.000, test loss 0.881, test accuracy 0.435\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 90, train loss 0.030, train accuracy 1.000, val loss 0.029, val accuracy 1.000, test loss 0.878, test accuracy 0.435\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 91, train loss 0.029, train accuracy 1.000, val loss 0.028, val accuracy 1.000, test loss 0.877, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 92, train loss 0.028, train accuracy 1.000, val loss 0.027, val accuracy 1.000, test loss 0.877, test accuracy 0.437\n",
            "Saving overall best train val model\n",
            "Epoch 93, train loss 0.026, train accuracy 1.000, val loss 0.026, val accuracy 1.000, test loss 0.878, test accuracy 0.439\n",
            "Saving overall best train val model\n",
            "Epoch 94, train loss 0.025, train accuracy 1.000, val loss 0.025, val accuracy 1.000, test loss 0.883, test accuracy 0.435\n",
            "Saving overall best train val model\n",
            "Epoch 95, train loss 0.024, train accuracy 1.000, val loss 0.024, val accuracy 1.000, test loss 0.871, test accuracy 0.447\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 96, train loss 0.023, train accuracy 1.000, val loss 0.023, val accuracy 1.000, test loss 0.871, test accuracy 0.439\n",
            "Saving overall best train val model\n",
            "Epoch 97, train loss 0.023, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 0.865, test accuracy 0.443\n",
            "Saving overall best train val model\n",
            "Epoch 98, train loss 0.022, train accuracy 1.000, val loss 0.021, val accuracy 1.000, test loss 0.862, test accuracy 0.448\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 99, train loss 0.021, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 0.859, test accuracy 0.458\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 100, train loss 0.020, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 0.856, test accuracy 0.458\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 101, train loss 0.019, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 0.853, test accuracy 0.458\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 102, train loss 0.018, train accuracy 1.000, val loss 0.018, val accuracy 1.000, test loss 0.851, test accuracy 0.456\n",
            "Saving overall best train val model\n",
            "Epoch 103, train loss 0.018, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 0.851, test accuracy 0.456\n",
            "Saving overall best train val model\n",
            "Epoch 104, train loss 0.017, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 0.849, test accuracy 0.456\n",
            "Saving overall best train val model\n",
            "Epoch 105, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 0.846, test accuracy 0.458\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 106, train loss 0.016, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 0.844, test accuracy 0.460\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 107, train loss 0.015, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 0.840, test accuracy 0.464\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 108, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 0.839, test accuracy 0.464\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 109, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.839, test accuracy 0.469\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 110, train loss 0.013, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.841, test accuracy 0.471\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 111, train loss 0.013, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.843, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 112, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.842, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 113, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.842, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 114, train loss 0.012, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.857, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Epoch 115, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.844, test accuracy 0.479\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 116, train loss 0.011, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.847, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Epoch 117, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.841, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Epoch 118, train loss 0.010, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.840, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Epoch 119, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.838, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Epoch 120, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.840, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Epoch 121, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.838, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Epoch 122, train loss 0.009, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.859, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 123, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.851, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 124, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.834, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Epoch 125, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.845, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Epoch 126, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.846, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 127, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.847, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 128, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.847, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 129, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.849, test accuracy 0.479\n",
            "Saving overall best train val model\n",
            "Epoch 130, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.850, test accuracy 0.479\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.851, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 132, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.862, test accuracy 0.485\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 133, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.844, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.855, test accuracy 0.483\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.889, test accuracy 0.489\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 136, train loss 0.008, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.901, test accuracy 0.489\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 137, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.866, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 138, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.859, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.853, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.856, test accuracy 0.490\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.854, test accuracy 0.487\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.850, test accuracy 0.489\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.844, test accuracy 0.485\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.838, test accuracy 0.489\n",
            "Saving overall best train val model\n",
            "Epoch 145, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.834, test accuracy 0.489\n",
            "Saving overall best train val model\n",
            "Epoch 146, train loss 0.004, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.833, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 147, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.831, test accuracy 0.490\n",
            "Saving overall best train val model\n",
            "Epoch 148, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.838, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 149, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.845, test accuracy 0.487\n",
            "Saving overall best train val model\n",
            "Saving PupilID Nest for seq 4469\n",
            "4928\n",
            "LSTM_fixed_len(\n",
            "  (lstm): LSTM(1024, 64, batch_first=True)\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Scrambling test sequence\n",
            "Epoch 0, train loss 1.189, train accuracy 0.095, val loss 1.166, val accuracy 0.145, test loss 1.306, test accuracy 0.101\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 1, train loss 1.143, train accuracy 0.209, val loss 1.118, val accuracy 0.274, test loss 1.300, test accuracy 0.099\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 2, train loss 1.101, train accuracy 0.394, val loss 1.080, val accuracy 0.517, test loss 1.294, test accuracy 0.137\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 3, train loss 1.064, train accuracy 0.631, val loss 1.043, val accuracy 0.702, test loss 1.286, test accuracy 0.166\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 4, train loss 1.026, train accuracy 0.763, val loss 1.004, val accuracy 0.822, test loss 1.277, test accuracy 0.191\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 5, train loss 0.984, train accuracy 0.862, val loss 0.957, val accuracy 0.883, test loss 1.263, test accuracy 0.218\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 6, train loss 0.935, train accuracy 0.914, val loss 0.906, val accuracy 0.920, test loss 1.247, test accuracy 0.223\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 7, train loss 0.884, train accuracy 0.938, val loss 0.856, val accuracy 0.932, test loss 1.234, test accuracy 0.221\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 8, train loss 0.835, train accuracy 0.948, val loss 0.808, val accuracy 0.945, test loss 1.221, test accuracy 0.237\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 9, train loss 0.787, train accuracy 0.957, val loss 0.761, val accuracy 0.960, test loss 1.207, test accuracy 0.260\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 10, train loss 0.741, train accuracy 0.963, val loss 0.716, val accuracy 0.960, test loss 1.194, test accuracy 0.269\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 11, train loss 0.699, train accuracy 0.966, val loss 0.675, val accuracy 0.963, test loss 1.180, test accuracy 0.294\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 12, train loss 0.659, train accuracy 0.966, val loss 0.636, val accuracy 0.966, test loss 1.164, test accuracy 0.307\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 13, train loss 0.621, train accuracy 0.969, val loss 0.601, val accuracy 0.966, test loss 1.150, test accuracy 0.309\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 14, train loss 0.587, train accuracy 0.972, val loss 0.568, val accuracy 0.972, test loss 1.134, test accuracy 0.344\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 15, train loss 0.556, train accuracy 0.972, val loss 0.539, val accuracy 0.975, test loss 1.117, test accuracy 0.351\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 16, train loss 0.527, train accuracy 0.972, val loss 0.511, val accuracy 0.975, test loss 1.107, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 17, train loss 0.500, train accuracy 0.978, val loss 0.485, val accuracy 0.978, test loss 1.098, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 18, train loss 0.475, train accuracy 0.978, val loss 0.461, val accuracy 0.978, test loss 1.091, test accuracy 0.378\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 19, train loss 0.452, train accuracy 0.978, val loss 0.438, val accuracy 0.978, test loss 1.084, test accuracy 0.378\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 20, train loss 0.430, train accuracy 0.978, val loss 0.418, val accuracy 0.978, test loss 1.077, test accuracy 0.374\n",
            "Saving overall best train val model\n",
            "Epoch 21, train loss 0.410, train accuracy 0.978, val loss 0.398, val accuracy 0.982, test loss 1.074, test accuracy 0.355\n",
            "Saving overall best train val model\n",
            "Epoch 22, train loss 0.391, train accuracy 0.982, val loss 0.380, val accuracy 0.982, test loss 1.066, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 23, train loss 0.373, train accuracy 0.982, val loss 0.363, val accuracy 0.988, test loss 1.062, test accuracy 0.353\n",
            "Saving overall best train val model\n",
            "Epoch 24, train loss 0.357, train accuracy 0.982, val loss 0.346, val accuracy 0.985, test loss 1.054, test accuracy 0.361\n",
            "Epoch 25, train loss 0.340, train accuracy 0.985, val loss 0.329, val accuracy 0.988, test loss 1.048, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 26, train loss 0.324, train accuracy 0.988, val loss 0.314, val accuracy 0.988, test loss 1.041, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 27, train loss 0.309, train accuracy 0.988, val loss 0.299, val accuracy 0.991, test loss 1.037, test accuracy 0.361\n",
            "Saving overall best train val model\n",
            "Epoch 28, train loss 0.294, train accuracy 0.988, val loss 0.284, val accuracy 0.991, test loss 1.030, test accuracy 0.368\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 29, train loss 0.280, train accuracy 0.991, val loss 0.271, val accuracy 0.991, test loss 1.029, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Replacing overall best test model\n",
            "Epoch 30, train loss 0.267, train accuracy 0.991, val loss 0.258, val accuracy 0.994, test loss 1.022, test accuracy 0.363\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 31, train loss 0.254, train accuracy 0.994, val loss 0.246, val accuracy 0.994, test loss 1.017, test accuracy 0.370\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 32, train loss 0.243, train accuracy 0.994, val loss 0.235, val accuracy 0.994, test loss 1.015, test accuracy 0.365\n",
            "Saving overall best train val model\n",
            "Epoch 33, train loss 0.232, train accuracy 0.994, val loss 0.224, val accuracy 0.994, test loss 1.010, test accuracy 0.380\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 34, train loss 0.221, train accuracy 0.994, val loss 0.215, val accuracy 0.994, test loss 1.007, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Epoch 35, train loss 0.212, train accuracy 0.994, val loss 0.205, val accuracy 0.994, test loss 0.996, test accuracy 0.389\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 36, train loss 0.202, train accuracy 0.994, val loss 0.197, val accuracy 0.994, test loss 1.000, test accuracy 0.372\n",
            "Saving overall best train val model\n",
            "Epoch 37, train loss 0.194, train accuracy 0.994, val loss 0.188, val accuracy 0.994, test loss 0.983, test accuracy 0.405\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 38, train loss 0.185, train accuracy 0.994, val loss 0.180, val accuracy 0.994, test loss 0.989, test accuracy 0.387\n",
            "Saving overall best train val model\n",
            "Epoch 39, train loss 0.178, train accuracy 0.994, val loss 0.172, val accuracy 0.994, test loss 0.976, test accuracy 0.412\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 40, train loss 0.170, train accuracy 0.994, val loss 0.165, val accuracy 0.994, test loss 0.982, test accuracy 0.399\n",
            "Saving overall best train val model\n",
            "Epoch 41, train loss 0.163, train accuracy 0.994, val loss 0.158, val accuracy 0.994, test loss 0.969, test accuracy 0.416\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 42, train loss 0.156, train accuracy 0.994, val loss 0.152, val accuracy 0.994, test loss 0.976, test accuracy 0.399\n",
            "Saving overall best train val model\n",
            "Epoch 43, train loss 0.149, train accuracy 0.994, val loss 0.145, val accuracy 0.994, test loss 0.965, test accuracy 0.422\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 44, train loss 0.143, train accuracy 0.994, val loss 0.139, val accuracy 0.994, test loss 0.969, test accuracy 0.405\n",
            "Saving overall best train val model\n",
            "Epoch 45, train loss 0.136, train accuracy 0.994, val loss 0.132, val accuracy 0.994, test loss 0.964, test accuracy 0.418\n",
            "Saving overall best train val model\n",
            "Epoch 46, train loss 0.131, train accuracy 0.994, val loss 0.127, val accuracy 0.994, test loss 0.959, test accuracy 0.418\n",
            "Saving overall best train val model\n",
            "Epoch 47, train loss 0.125, train accuracy 0.994, val loss 0.121, val accuracy 0.994, test loss 0.962, test accuracy 0.414\n",
            "Saving overall best train val model\n",
            "Epoch 48, train loss 0.120, train accuracy 0.994, val loss 0.116, val accuracy 0.994, test loss 0.959, test accuracy 0.416\n",
            "Saving overall best train val model\n",
            "Epoch 49, train loss 0.114, train accuracy 0.994, val loss 0.111, val accuracy 0.994, test loss 0.954, test accuracy 0.422\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 50, train loss 0.110, train accuracy 0.994, val loss 0.106, val accuracy 0.994, test loss 0.949, test accuracy 0.429\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 51, train loss 0.105, train accuracy 0.994, val loss 0.101, val accuracy 0.994, test loss 0.946, test accuracy 0.431\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 52, train loss 0.100, train accuracy 0.994, val loss 0.097, val accuracy 0.994, test loss 0.941, test accuracy 0.431\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 53, train loss 0.096, train accuracy 0.994, val loss 0.093, val accuracy 0.997, test loss 0.939, test accuracy 0.433\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 54, train loss 0.092, train accuracy 0.994, val loss 0.089, val accuracy 0.997, test loss 0.935, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 55, train loss 0.088, train accuracy 0.997, val loss 0.085, val accuracy 0.997, test loss 0.934, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 56, train loss 0.084, train accuracy 0.997, val loss 0.081, val accuracy 0.997, test loss 0.932, test accuracy 0.445\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 57, train loss 0.080, train accuracy 0.997, val loss 0.078, val accuracy 0.997, test loss 0.931, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Epoch 58, train loss 0.077, train accuracy 0.997, val loss 0.074, val accuracy 0.997, test loss 0.927, test accuracy 0.445\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 59, train loss 0.074, train accuracy 0.997, val loss 0.071, val accuracy 0.997, test loss 0.925, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Epoch 60, train loss 0.071, train accuracy 0.997, val loss 0.068, val accuracy 0.997, test loss 0.923, test accuracy 0.441\n",
            "Saving overall best train val model\n",
            "Epoch 61, train loss 0.067, train accuracy 1.000, val loss 0.065, val accuracy 0.997, test loss 0.922, test accuracy 0.445\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 62, train loss 0.065, train accuracy 1.000, val loss 0.063, val accuracy 0.997, test loss 0.921, test accuracy 0.445\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 63, train loss 0.062, train accuracy 1.000, val loss 0.060, val accuracy 0.997, test loss 0.919, test accuracy 0.448\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 64, train loss 0.060, train accuracy 1.000, val loss 0.057, val accuracy 1.000, test loss 0.916, test accuracy 0.456\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 65, train loss 0.057, train accuracy 1.000, val loss 0.055, val accuracy 1.000, test loss 0.915, test accuracy 0.460\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 66, train loss 0.054, train accuracy 1.000, val loss 0.052, val accuracy 1.000, test loss 0.910, test accuracy 0.468\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 67, train loss 0.052, train accuracy 1.000, val loss 0.050, val accuracy 1.000, test loss 0.906, test accuracy 0.471\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 68, train loss 0.050, train accuracy 1.000, val loss 0.048, val accuracy 1.000, test loss 0.904, test accuracy 0.473\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 69, train loss 0.048, train accuracy 1.000, val loss 0.046, val accuracy 1.000, test loss 0.902, test accuracy 0.471\n",
            "Saving overall best train val model\n",
            "Epoch 70, train loss 0.046, train accuracy 1.000, val loss 0.044, val accuracy 1.000, test loss 0.902, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 71, train loss 0.044, train accuracy 1.000, val loss 0.042, val accuracy 1.000, test loss 0.892, test accuracy 0.471\n",
            "Saving overall best train val model\n",
            "Epoch 72, train loss 0.042, train accuracy 1.000, val loss 0.041, val accuracy 1.000, test loss 0.898, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 73, train loss 0.040, train accuracy 1.000, val loss 0.039, val accuracy 1.000, test loss 0.893, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 74, train loss 0.038, train accuracy 1.000, val loss 0.037, val accuracy 1.000, test loss 0.895, test accuracy 0.475\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 75, train loss 0.037, train accuracy 1.000, val loss 0.036, val accuracy 1.000, test loss 0.893, test accuracy 0.479\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 76, train loss 0.035, train accuracy 1.000, val loss 0.034, val accuracy 1.000, test loss 0.891, test accuracy 0.479\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 77, train loss 0.034, train accuracy 1.000, val loss 0.033, val accuracy 1.000, test loss 0.891, test accuracy 0.473\n",
            "Saving overall best train val model\n",
            "Epoch 78, train loss 0.032, train accuracy 1.000, val loss 0.031, val accuracy 1.000, test loss 0.891, test accuracy 0.473\n",
            "Saving overall best train val model\n",
            "Epoch 79, train loss 0.031, train accuracy 1.000, val loss 0.030, val accuracy 1.000, test loss 0.895, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 80, train loss 0.030, train accuracy 1.000, val loss 0.029, val accuracy 1.000, test loss 0.895, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 81, train loss 0.028, train accuracy 1.000, val loss 0.027, val accuracy 1.000, test loss 0.893, test accuracy 0.485\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 82, train loss 0.027, train accuracy 1.000, val loss 0.026, val accuracy 1.000, test loss 0.893, test accuracy 0.489\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 83, train loss 0.026, train accuracy 1.000, val loss 0.025, val accuracy 1.000, test loss 0.892, test accuracy 0.485\n",
            "Saving overall best train val model\n",
            "Epoch 84, train loss 0.025, train accuracy 1.000, val loss 0.024, val accuracy 1.000, test loss 0.894, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 85, train loss 0.024, train accuracy 1.000, val loss 0.023, val accuracy 1.000, test loss 0.892, test accuracy 0.487\n",
            "Saving overall best train val model\n",
            "Epoch 86, train loss 0.023, train accuracy 1.000, val loss 0.022, val accuracy 1.000, test loss 0.894, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 87, train loss 0.022, train accuracy 1.000, val loss 0.021, val accuracy 1.000, test loss 0.888, test accuracy 0.485\n",
            "Saving overall best train val model\n",
            "Epoch 88, train loss 0.021, train accuracy 1.000, val loss 0.020, val accuracy 1.000, test loss 0.891, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 89, train loss 0.020, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 0.889, test accuracy 0.490\n",
            "Saving overall best train val model\n",
            "Epoch 90, train loss 0.019, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 0.891, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 91, train loss 0.019, train accuracy 1.000, val loss 0.019, val accuracy 1.000, test loss 0.903, test accuracy 0.452\n",
            "Saving overall best train val model\n",
            "Epoch 92, train loss 0.019, train accuracy 1.000, val loss 0.017, val accuracy 1.000, test loss 0.896, test accuracy 0.487\n",
            "Saving overall best train val model\n",
            "Epoch 93, train loss 0.017, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 0.883, test accuracy 0.490\n",
            "Saving overall best train val model\n",
            "Epoch 94, train loss 0.016, train accuracy 1.000, val loss 0.016, val accuracy 1.000, test loss 0.888, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 95, train loss 0.016, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 0.889, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 96, train loss 0.015, train accuracy 1.000, val loss 0.015, val accuracy 1.000, test loss 0.890, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 97, train loss 0.015, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 0.890, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 98, train loss 0.014, train accuracy 1.000, val loss 0.014, val accuracy 1.000, test loss 0.892, test accuracy 0.489\n",
            "Saving overall best train val model\n",
            "Epoch 99, train loss 0.014, train accuracy 1.000, val loss 0.013, val accuracy 1.000, test loss 0.893, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 100, train loss 0.013, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.895, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 101, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.896, test accuracy 0.490\n",
            "Saving overall best train val model\n",
            "Epoch 102, train loss 0.012, train accuracy 1.000, val loss 0.012, val accuracy 1.000, test loss 0.897, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 103, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.896, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 104, train loss 0.011, train accuracy 1.000, val loss 0.011, val accuracy 1.000, test loss 0.896, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 105, train loss 0.011, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.895, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Epoch 106, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.899, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Epoch 107, train loss 0.010, train accuracy 1.000, val loss 0.010, val accuracy 1.000, test loss 0.902, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Epoch 108, train loss 0.010, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.894, test accuracy 0.485\n",
            "Saving overall best train val model\n",
            "Epoch 109, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.888, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Epoch 110, train loss 0.009, train accuracy 1.000, val loss 0.009, val accuracy 1.000, test loss 0.898, test accuracy 0.464\n",
            "Saving overall best train val model\n",
            "Epoch 111, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.882, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 112, train loss 0.008, train accuracy 1.000, val loss 0.008, val accuracy 1.000, test loss 0.886, test accuracy 0.489\n",
            "Saving overall best train val model\n",
            "Epoch 113, train loss 0.008, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.890, test accuracy 0.492\n",
            "Saving overall best train val model\n",
            "Epoch 114, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.892, test accuracy 0.490\n",
            "Saving overall best train val model\n",
            "Epoch 115, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.893, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Epoch 116, train loss 0.007, train accuracy 1.000, val loss 0.007, val accuracy 1.000, test loss 0.896, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 117, train loss 0.007, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.894, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 118, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.893, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 119, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.890, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 120, train loss 0.006, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.889, test accuracy 0.494\n",
            "Saving overall best train val model\n",
            "Epoch 121, train loss 0.006, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.890, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 122, train loss 0.005, train accuracy 1.000, val loss 0.006, val accuracy 1.000, test loss 0.908, test accuracy 0.477\n",
            "Saving overall best train val model\n",
            "Epoch 123, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.887, test accuracy 0.481\n",
            "Saving overall best train val model\n",
            "Epoch 124, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.886, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 125, train loss 0.005, train accuracy 1.000, val loss 0.005, val accuracy 1.000, test loss 0.889, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 126, train loss 0.005, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.891, test accuracy 0.506\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 127, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.893, test accuracy 0.506\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 128, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.896, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Epoch 129, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.899, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Epoch 130, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.903, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Epoch 131, train loss 0.004, train accuracy 1.000, val loss 0.004, val accuracy 1.000, test loss 0.907, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Epoch 132, train loss 0.004, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.911, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Epoch 133, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.916, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Epoch 134, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.921, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Epoch 135, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.924, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 136, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.927, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Epoch 137, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.931, test accuracy 0.496\n",
            "Saving overall best train val model\n",
            "Epoch 138, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.933, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 139, train loss 0.003, train accuracy 1.000, val loss 0.003, val accuracy 1.000, test loss 0.935, test accuracy 0.502\n",
            "Saving overall best train val model\n",
            "Epoch 140, train loss 0.003, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.937, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 141, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.937, test accuracy 0.500\n",
            "Saving overall best train val model\n",
            "Epoch 142, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.940, test accuracy 0.498\n",
            "Saving overall best train val model\n",
            "Epoch 143, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.939, test accuracy 0.504\n",
            "Saving overall best train val model\n",
            "Epoch 144, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.944, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 145, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.941, test accuracy 0.508\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 146, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.943, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 147, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.942, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 148, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.943, test accuracy 0.510\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Epoch 149, train loss 0.002, train accuracy 1.000, val loss 0.002, val accuracy 1.000, test loss 0.943, test accuracy 0.513\n",
            "Saving overall best train val model\n",
            "Saving overall best test model\n",
            "Saving PupilID Nest for seq 4928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "riqqCGh727MP",
        "outputId": "085cb2d2-5cce-4329-8db7-4e03d498849b"
      },
      "source": [
        "df_loss_accuracy_crossval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Loss</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Val Loss</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Test Loss</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.002029</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001981</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.746616</td>\n",
              "      <td>0.54389316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003702</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.003634</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.951716</td>\n",
              "      <td>0.47519085</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Train Loss Train Accuracy  Val Loss Val Accuracy  Test Loss Test Accuracy\n",
              "0    0.002029            1.0  0.001981          1.0   0.746616    0.54389316\n",
              "1    0.003702            1.0  0.003634          1.0   0.951716    0.47519085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "yQEmbf0F3Of-",
        "outputId": "4678f18f-d6e8-4095-b90c-b9201eb6b2d4"
      },
      "source": [
        "overall_df_loss_accuracy_crossval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Test Accuracy Equal Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5515267</td>\n",
              "      <td>0.435471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.48282441</td>\n",
              "      <td>0.410030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Train Accuracy Val Accuracy Test Accuracy  Test Accuracy Equal Weight\n",
              "0            1.0          1.0     0.5515267                    0.435471\n",
              "1            1.0          1.0    0.48282441                    0.410030"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfY4V9qAWRyA"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "V8qE19zs3RTn",
        "outputId": "bb1ff365-3f03-47a6-a488-7833296e8af3"
      },
      "source": [
        "plt.plot(Total_valid_loss[0])\n",
        "plt.plot(Total_test_loss[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0d92480d90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZD2sW2HmJ-e"
      },
      "source": [
        "from os import walk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaZPFefimJcV"
      },
      "source": [
        "search_path = '/content/gdrive/My Drive/ZFDataset/SavedModels/Final Architecture/LSTM/Unidirectional'\n",
        "_, _, filenames = next(walk(search_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKXEdNEGmGY4",
        "outputId": "ae71032a-8218-4ae4-f8fd-bf3ff7d3bd79"
      },
      "source": [
        "Accuracy_Table = pd.DataFrame(columns=['Train Accuracy', 'Val Accuracy', 'Test Accuracy'])\n",
        "\n",
        "for file in filenames:\n",
        "  if 'Accuracy_Table_Test' in file:\n",
        "    print(file)\n",
        "    Acc_data = pd.read_csv(search_path+file, index_col=False)\n",
        "    Acc_data = Acc_data.drop(columns=['Unnamed: 0'])\n",
        "    Accuracy_Table = Accuracy_Table.append(pd.Series(Acc_data.mean(axis=0).values, index=Accuracy_Table.columns.values), ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy_Table_Test_Random_3859.csv\n",
            "Accuracy_Table_Test_Random_7857.csv\n",
            "Accuracy_Table_Test_Random_7980.csv\n",
            "Accuracy_Table_Test_Random_2999.csv\n",
            "Accuracy_Table_Test_Random_3324.csv\n",
            "Accuracy_Table_Test_Random_1778.csv\n",
            "Accuracy_Table_Test_Random_329.csv\n",
            "Accuracy_Table_Test_Random_5689.csv\n",
            "Accuracy_Table_Test_Random_2746.csv\n",
            "Accuracy_Table_Test_Random_8964.csv\n",
            "Accuracy_Table_Test_Random_70.csv\n",
            "Accuracy_Table_Test_Random_4786.csv\n",
            "Accuracy_Table_Test_Random_2816.csv\n",
            "Accuracy_Table_Test_Random_2405.csv\n",
            "Accuracy_Table_Test_Random_2681.csv\n",
            "Accuracy_Table_Test_Random_5769.csv\n",
            "Accuracy_Table_Test_Random_9327.csv\n",
            "Accuracy_Table_Test_Random_7867.csv\n",
            "Accuracy_Table_Test_Random_4469.csv\n",
            "Accuracy_Table_Test_Random_4928.csv\n",
            "Accuracy_Table_Test_Random_5730.csv\n",
            "Accuracy_Table_Test_Random_858.csv\n",
            "Accuracy_Table_Test_Random_6775.csv\n",
            "Accuracy_Table_Test_Random_5487.csv\n",
            "Accuracy_Table_Test_Random_1464.csv\n",
            "Accuracy_Table_Test_Random_7365.csv\n",
            "Accuracy_Table_Test_Random_4313.csv\n",
            "Accuracy_Table_Test_Random_9324.csv\n",
            "Accuracy_Table_Test_Random_8958.csv\n",
            "Accuracy_Table_Test_Random_7663.csv\n",
            "Accuracy_Table_Test_Random_5362.csv\n",
            "Accuracy_Table_Test_Random_299.csv\n",
            "Accuracy_Table_Test_Random_4931.csv\n",
            "Accuracy_Table_Test_Random_4906.csv\n",
            "Accuracy_Table_Test_Random_5007.csv\n",
            "Accuracy_Table_Test_Random_5848.csv\n",
            "Accuracy_Table_Test_Random_7172.csv\n",
            "Accuracy_Table_Test_Random_6862.csv\n",
            "Accuracy_Table_Test_Random_3981.csv\n",
            "Accuracy_Table_Test_Random_8262.csv\n",
            "Accuracy_Table_Test_Random_5441.csv\n",
            "Accuracy_Table_Test_Random_4702.csv\n",
            "Accuracy_Table_Test_Random_4177.csv\n",
            "Accuracy_Table_Test_Random_2611.csv\n",
            "Accuracy_Table_Test_Random_6342.csv\n",
            "Accuracy_Table_Test_Random_9402.csv\n",
            "Accuracy_Table_Test_Random_5609.csv\n",
            "Accuracy_Table_Test_Random_3590.csv\n",
            "Accuracy_Table_Test_Random_5397.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R95N_yHpUbC"
      },
      "source": [
        "Accuracy_Table = pd.read_csv('/content/gdrive/My Drive/ZFDataset/SavedModels/Final Architecture/LSTM/Unidirectional/Accuracy_Table_Test_Random_5397.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKUVC0styc3J",
        "outputId": "0428d030-0556-405f-b03f-e9072dce2b09"
      },
      "source": [
        "Accuracy_Table.std(axis=0).values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00021483, 0.00049243, 0.00398278])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vU_2aOgHtx_"
      },
      "source": [
        "def train_model(model, kf, class_weights, epochs=10, lr=0.001):\n",
        "  parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "  optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "  for i in range(epochs):\n",
        "    model.train()\n",
        "    sum_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total = 0\n",
        "    sum_val_loss = 0.0\n",
        "    sum_val_acc = 0.0\n",
        "    sum_val_rmse = 0.0\n",
        "    for _fold, (train_index, val_index) in enumerate(kf.split(range(len(X_train)))):\n",
        "      X_train_subset = []; y_train_subset = [];\n",
        "      X_val_subset = []; y_val_subset = [];\n",
        "      for indx in train_index:\n",
        "        X_train_subset.append(X_train[indx])\n",
        "        y_train_subset.append(y_train[indx])\n",
        "      train_ds = ReviewsDataset(X_train_subset, y_train_subset)\n",
        "      for indx in val_index:\n",
        "        X_val_subset.append(X_train[indx])\n",
        "        y_val_subset.append(y_train[indx])\n",
        "      valid_ds = ReviewsDataset(X_val_subset, y_val_subset)\n",
        "      for x, y, l in train_ds:\n",
        "          x = x.float()\n",
        "          x.resize_((1,x.shape[0],x.shape[1]))\n",
        "          indv_class_weight = class_weights[y]\n",
        "          y = torch.tensor(y).long().resize_((1))\n",
        "          # y_pred = model(x, l)\n",
        "          y_pred = model(x)\n",
        "          optimizer.zero_grad()\n",
        "          loss = F.cross_entropy(y_pred, y)*indv_class_weight\n",
        "          # print(loss, indv_class_weight, loss*indv_class_weight)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          sum_loss += loss.item()*y.shape[0]\n",
        "          total += y.shape[0]\n",
        "          pred_train = torch.max(y_pred, 1)[1]\n",
        "          correct_train += (pred_train == y).float().sum()\n",
        "      val_loss, val_acc, val_rmse = validation_metrics(model, valid_ds, class_weights)\n",
        "      sum_val_loss += val_loss\n",
        "      sum_val_acc += val_acc\n",
        "      sum_val_rmse += val_rmse\n",
        "    # if i % 5 == 0:\n",
        "      # print(i)\n",
        "    print(\"Epoch %d, train loss %.3f, train accuracy %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (i, sum_loss/((_fold+1)*total), correct_train/total, sum_val_loss/(_fold+1), sum_val_acc/(_fold+1), val_rmse/(_fold+1)))\n",
        "  return (sum_loss/((_fold+1)*total)), (correct_train/total), (sum_val_loss/(_fold+1)), (sum_val_acc/(_fold+1))\n",
        "\n",
        "def validation_metrics (model, valid_dl, class_weights):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    sum_rmse = 0.0\n",
        "    for x, y, l in valid_dl:\n",
        "        x = x.float()\n",
        "        x.resize_((1,x.shape[0],x.shape[1]))\n",
        "        indv_class_weight = class_weights[y]\n",
        "        y = torch.tensor(y).long().resize_((1))\n",
        "        # y_hat = model(x, l)\n",
        "        y_hat = model(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        pred = torch.max(y_hat, 1)[1]\n",
        "        # print(y, pred)\n",
        "        correct += (pred == y).float().sum()\n",
        "        total += y.shape[0]\n",
        "        sum_loss += loss.item()*indv_class_weight*y.shape[0]\n",
        "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
        "    return sum_loss/total, correct/total, sum_rmse/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jrDVoqL-Fy0v",
        "outputId": "2c05ef3d-b91b-40b6-f6d5-5df0682b2a15"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/ZFDataset'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMQETLJPFvl4"
      },
      "source": [
        "model = torch.load('/content/gdrive/My Drive/ZFDataset/SavedModels/LSTM_Fold0_10_05_2021_19_07')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkYza0xHF-T8",
        "outputId": "03e0007c-ef1e-4830-c396-709657a413f5"
      },
      "source": [
        "for x, y, l in train_ds:\n",
        "  x = x.float()\n",
        "  x.resize_((1,x.shape[0],x.shape[1]))\n",
        "  indv_class_weight = class_weights[y]\n",
        "  y = torch.tensor(y).long().resize_((1))\n",
        "  # y_pred = model(x, l)\n",
        "  y_pred = model(x)\n",
        "  pred_train = torch.max(y_pred, 1)[1]\n",
        "  # print(y_pred)\n",
        "  print(y, pred_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0]) tensor([0])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([0]) tensor([0])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([0]) tensor([0])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([0]) tensor([0])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([0]) tensor([0])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([0]) tensor([0])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([1]) tensor([1])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([3]) tensor([3])\n",
            "tensor([4]) tensor([4])\n",
            "tensor([2]) tensor([2])\n",
            "tensor([3]) tensor([3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQDhZcaYH5xB"
      },
      "source": [
        "# batch_size = 50\n",
        "# train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "# val_dl = DataLoader(valid_ds, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saFdD0PyIVM5"
      },
      "source": [
        "model_fixed =  LSTM_fixed_len(1024, 10, 4)\n",
        "# model_fixed =  LSTM_fixed_len(100, 50, 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbdGBS2txEDR",
        "outputId": "c2dcd339-a566-4d4c-d3b7-a85f0480a3ea"
      },
      "source": [
        "model_fixed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM_fixed_len(\n",
              "  (lstm): LSTM(1024, 10, batch_first=True)\n",
              "  (linear): Linear(in_features=10, out_features=4, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdP3KX-Czg0q"
      },
      "source": [
        "# loss = nn.CrossEntropyLoss()\n",
        "# input = torch.randn(3, 5, requires_grad=True)\n",
        "# target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "# output = loss(input, target)\n",
        "# output.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b37gQyoYxzKN",
        "outputId": "48f38f8a-54d2-40d2-f0a6-c31d5084dcb5"
      },
      "source": [
        "train_loss, train_accuracy, val_loss, val_accuracy =  train_model(model_fixed, kf, class_weights, epochs=2, lr=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, train loss 0.001, train accuracy 0.997, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 1, train loss 0.001, train accuracy 0.997, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xS8Ux_ezc0a"
      },
      "source": [
        "test_ds = ReviewsDataset(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2nnQnIihrvz",
        "outputId": "c29992c6-0cb9-4730-86b2-75054ca76d4d"
      },
      "source": [
        "test_loss, test_correct, test_rmse = validation_metrics(model_fixed, test_ds)\n",
        "print(\"Test loss %.3f, Test Accuracy %.3f, Test RMSE %.3f\" %(test_loss, test_correct, test_rmse))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss 0.083, Test Accuracy 0.986, Test RMSE 0.014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZWU1lDyL9Ww",
        "outputId": "203c51fb-ee78-4b3b-9f2f-559adfed94b4"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[array([3.6964213e-04, 6.1388216e-03, 2.3623325e-03, ..., 5.9952104e-01,\n",
              "          4.7096276e-01, 6.7699389e-03], dtype=float32),\n",
              "   array([3.9546576e-04, 4.2689457e-03, 2.1646945e-03, ..., 1.0832235e+00,\n",
              "          5.0408190e-01, 8.0454396e-04], dtype=float32),\n",
              "   array([4.3923515e-04, 3.5873966e-03, 2.3025582e-03, ..., 4.5419684e-01,\n",
              "          9.9826270e-01, 5.8748936e-03], dtype=float32),\n",
              "   array([4.8858119e-04, 5.5127405e-03, 1.7675881e-03, ..., 2.6316303e-01,\n",
              "          6.5507305e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.0706727e-04, 4.3425970e-03, 1.8088806e-03, ..., 6.8255633e-02,\n",
              "          9.7876644e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6909830e-04, 7.3469197e-03, 2.3746886e-03, ..., 5.4688144e-01,\n",
              "          7.2352040e-01, 7.7279314e-02], dtype=float32),\n",
              "   array([4.8456003e-04, 3.6201791e-03, 2.1676929e-03, ..., 1.2960277e-01,\n",
              "          9.3385494e-01, 4.3036998e-03], dtype=float32),\n",
              "   array([0.00049007, 0.00513859, 0.00200676, ..., 0.47218606, 0.48447147,\n",
              "          0.        ], dtype=float32)],\n",
              "  8],\n",
              " [[array([3.3343013e-04, 6.0727731e-03, 2.3538477e-03, ..., 5.1893741e-01,\n",
              "          2.1159425e-01, 3.3753265e-03], dtype=float32),\n",
              "   array([5.1808293e-04, 5.3428398e-03, 2.2728948e-03, ..., 8.0331224e-01,\n",
              "          7.5812089e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6572561e-04, 3.1144130e-03, 2.4413806e-03, ..., 1.9249216e-01,\n",
              "          1.2541571e+00, 7.3547177e-03], dtype=float32),\n",
              "   array([4.8490436e-04, 5.1388498e-03, 1.8292585e-03, ..., 4.9388003e-01,\n",
              "          5.3523397e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5211861e-04, 5.0795851e-03, 1.8752126e-03, ..., 6.7967519e-02,\n",
              "          8.7708783e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6842734e-04, 6.2198802e-03, 2.5721183e-03, ..., 6.4622051e-01,\n",
              "          5.3599328e-01, 3.9356515e-02], dtype=float32),\n",
              "   array([4.7126075e-04, 3.6206034e-03, 2.2844584e-03, ..., 1.4479123e-01,\n",
              "          9.7128630e-01, 2.0742773e-03], dtype=float32),\n",
              "   array([5.0556491e-04, 4.5178705e-03, 2.0985904e-03, ..., 4.2757761e-01,\n",
              "          6.0354805e-01, 2.7559123e-03], dtype=float32)],\n",
              "  8],\n",
              " [[array([0.00033848, 0.00581859, 0.00233486, ..., 0.22096883, 0.2944104 ,\n",
              "          0.00573625], dtype=float32),\n",
              "   array([3.6357981e-04, 4.8770574e-03, 2.7243770e-03, ..., 1.3876805e+00,\n",
              "          6.9226855e-01, 4.0089716e-03], dtype=float32),\n",
              "   array([3.9900595e-04, 3.6901478e-03, 2.0134230e-03, ..., 1.8706410e-01,\n",
              "          8.2404679e-01, 8.1162173e-03], dtype=float32),\n",
              "   array([4.5991194e-04, 4.9659158e-03, 1.9709272e-03, ..., 2.3487601e-01,\n",
              "          6.4088446e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6184062e-04, 4.7522290e-03, 1.8739689e-03, ..., 2.4027671e-01,\n",
              "          7.0646763e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6998381e-04, 6.1706686e-03, 2.4681326e-03, ..., 4.9608344e-01,\n",
              "          4.3885997e-01, 5.7359684e-02], dtype=float32),\n",
              "   array([4.8585594e-04, 3.9023978e-03, 2.2892442e-03, ..., 1.3047023e-01,\n",
              "          1.4043065e+00, 6.8731173e-03], dtype=float32),\n",
              "   array([0.00051074, 0.0050065 , 0.00243465, ..., 0.4517301 , 0.50782377,\n",
              "          0.        ], dtype=float32)],\n",
              "  8],\n",
              " [[array([0.00033956, 0.00605118, 0.00227   , ..., 0.33730376, 0.2618032 ,\n",
              "          0.00411889], dtype=float32),\n",
              "   array([3.9856730e-04, 5.8386577e-03, 2.6507573e-03, ..., 1.7427983e+00,\n",
              "          8.5507059e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5612967e-04, 3.4172139e-03, 1.9381942e-03, ..., 2.3234996e-01,\n",
              "          5.6782633e-01, 3.3923425e-02], dtype=float32),\n",
              "   array([5.0693058e-04, 5.1467400e-03, 2.1013371e-03, ..., 3.0107984e-01,\n",
              "          1.0295651e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.3523792e-04, 4.8407051e-03, 1.8531701e-03, ..., 3.8859993e-01,\n",
              "          4.7791439e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8623673e-04, 7.1567819e-03, 2.5046729e-03, ..., 6.6654253e-01,\n",
              "          5.9102559e-01, 8.7015718e-02], dtype=float32),\n",
              "   array([4.3917709e-04, 3.5028113e-03, 1.8880118e-03, ..., 3.4438506e-01,\n",
              "          1.0768266e+00, 1.0062008e-02], dtype=float32),\n",
              "   array([5.2486442e-04, 4.8180232e-03, 2.4009682e-03, ..., 3.3931881e-01,\n",
              "          5.2715027e-01, 0.0000000e+00], dtype=float32)],\n",
              "  8],\n",
              " [[array([0.00034383, 0.00547278, 0.00233241, ..., 0.20057595, 0.20457415,\n",
              "          0.00280864], dtype=float32),\n",
              "   array([4.2936098e-04, 4.8302733e-03, 2.1614048e-03, ..., 8.7030154e-01,\n",
              "          6.7121065e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.90799546e-04, 3.55236954e-03, 2.44885311e-03, ...,\n",
              "          1.00180805e-01, 2.01962519e+00, 1.79783292e-02], dtype=float32),\n",
              "   array([4.6167933e-04, 4.3485705e-03, 1.7308397e-03, ..., 1.4717962e-01,\n",
              "          5.2642727e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.0442686e-04, 5.4020458e-03, 1.9347738e-03, ..., 5.2488837e-02,\n",
              "          5.7613266e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8254741e-04, 6.5051042e-03, 2.3432963e-03, ..., 4.5813552e-01,\n",
              "          4.7022590e-01, 8.8128656e-02], dtype=float32),\n",
              "   array([4.7612251e-04, 3.5939158e-03, 2.2581033e-03, ..., 7.5540163e-02,\n",
              "          1.0264896e+00, 4.9749054e-03], dtype=float32),\n",
              "   array([4.8337504e-04, 4.7475793e-03, 1.9076722e-03, ..., 3.7412092e-01,\n",
              "          6.5436780e-01, 0.0000000e+00], dtype=float32)],\n",
              "  8],\n",
              " [[array([3.3687119e-04, 5.3576306e-03, 2.3151576e-03, ..., 4.0874407e-01,\n",
              "          1.2906361e-01, 7.1172067e-04], dtype=float32),\n",
              "   array([3.4257647e-04, 5.5429307e-03, 2.3115210e-03, ..., 5.1131666e-01,\n",
              "          2.4723828e-01, 2.7553437e-04], dtype=float32),\n",
              "   array([5.1985821e-04, 4.7719921e-03, 2.5191035e-03, ..., 1.0082757e+00,\n",
              "          1.1112157e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([5.1509816e-04, 3.7813233e-03, 2.3137773e-03, ..., 1.8694431e-01,\n",
              "          9.3447638e-01, 9.8116668e-03], dtype=float32),\n",
              "   array([5.1317667e-04, 4.5158169e-03, 2.2110024e-03, ..., 1.6270953e-01,\n",
              "          6.2156469e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6624086e-04, 4.8361504e-03, 1.9257437e-03, ..., 1.2051160e-01,\n",
              "          6.2956953e-01, 0.0000000e+00], dtype=float32)],\n",
              "  6],\n",
              " [[array([3.5717461e-04, 5.8917995e-03, 2.3104507e-03, ..., 6.1707711e-01,\n",
              "          3.6289155e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.3875389e-04, 5.2485904e-03, 2.1675352e-03, ..., 1.7431715e-01,\n",
              "          6.5483636e-01, 2.7334899e-02], dtype=float32),\n",
              "   array([4.6838351e-04, 3.0252198e-03, 1.9697910e-03, ..., 2.3865171e-01,\n",
              "          1.1758147e+00, 9.4658826e-03], dtype=float32),\n",
              "   array([4.9082027e-04, 5.2662538e-03, 2.2494944e-03, ..., 9.2592061e-01,\n",
              "          6.0136396e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4764488e-04, 4.4275178e-03, 1.8694045e-03, ..., 2.5918314e-01,\n",
              "          1.0612046e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5744644e-04, 6.6071902e-03, 2.4405641e-03, ..., 3.5214260e-01,\n",
              "          5.4738182e-01, 2.7782820e-02], dtype=float32),\n",
              "   array([4.2403344e-04, 4.1197035e-03, 1.9409180e-03, ..., 6.8329521e-02,\n",
              "          1.7443528e+00, 2.4654272e-03], dtype=float32)],\n",
              "  7],\n",
              " [[array([3.3879047e-04, 5.8956365e-03, 2.2894454e-03, ..., 5.1116294e-01,\n",
              "          3.8174468e-01, 1.3467368e-02], dtype=float32),\n",
              "   array([4.1869076e-04, 6.0086516e-03, 2.6426176e-03, ..., 1.3237580e+00,\n",
              "          5.9347683e-01, 1.2494739e-04], dtype=float32),\n",
              "   array([4.9425842e-04, 3.2171381e-03, 2.1994128e-03, ..., 3.0877519e-01,\n",
              "          1.1699560e+00, 2.6218013e-03], dtype=float32),\n",
              "   array([4.4410411e-04, 4.6863044e-03, 1.8245452e-03, ..., 5.0364256e-01,\n",
              "          4.9232301e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([0.0004517 , 0.00519962, 0.00181232, ..., 0.13256425, 0.37773573,\n",
              "          0.        ], dtype=float32),\n",
              "   array([3.4619684e-04, 7.1843015e-03, 2.3476423e-03, ..., 4.5380870e-01,\n",
              "          5.6313223e-01, 6.0560539e-02], dtype=float32),\n",
              "   array([4.6870747e-04, 3.6512096e-03, 2.0788554e-03, ..., 9.6916780e-02,\n",
              "          1.0684489e+00, 4.0216427e-03], dtype=float32),\n",
              "   array([4.8915658e-04, 4.8501547e-03, 2.0204561e-03, ..., 1.2567054e-01,\n",
              "          8.1273848e-01, 0.0000000e+00], dtype=float32)],\n",
              "  8],\n",
              " [[array([3.3668996e-04, 6.1256015e-03, 2.3521024e-03, ..., 4.7107485e-01,\n",
              "          3.1806669e-01, 1.7820221e-03], dtype=float32),\n",
              "   array([4.1833473e-04, 4.9293600e-03, 2.4573400e-03, ..., 8.0033696e-01,\n",
              "          8.9775628e-01, 1.2693161e-04], dtype=float32),\n",
              "   array([4.2710156e-04, 3.2184322e-03, 2.1593033e-03, ..., 7.5507693e-02,\n",
              "          1.6101217e+00, 8.6897900e-03], dtype=float32),\n",
              "   array([4.7850073e-04, 5.1298472e-03, 2.0488859e-03, ..., 6.0163045e-01,\n",
              "          6.8255562e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([5.0788373e-04, 4.5457277e-03, 1.8282761e-03, ..., 1.1094266e-02,\n",
              "          9.1495252e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6337657e-04, 7.5274413e-03, 2.3692849e-03, ..., 3.6119792e-01,\n",
              "          5.3218198e-01, 2.1841373e-01], dtype=float32),\n",
              "   array([4.3891568e-04, 4.0529054e-03, 1.7798081e-03, ..., 3.8391843e-02,\n",
              "          1.5408015e+00, 6.2911729e-03], dtype=float32),\n",
              "   array([4.5050567e-04, 4.5545958e-03, 1.9341925e-03, ..., 3.6683244e-01,\n",
              "          6.3654017e-01, 3.6499834e-05], dtype=float32)],\n",
              "  8],\n",
              " [[array([0.00034139, 0.0064418 , 0.00225155, ..., 0.13104713, 0.32336733,\n",
              "          0.00288885], dtype=float32),\n",
              "   array([4.2305671e-04, 5.1006223e-03, 1.9741107e-03, ..., 1.1088823e+00,\n",
              "          8.2028884e-01, 1.1556495e-02], dtype=float32),\n",
              "   array([5.0622725e-04, 3.3616922e-03, 2.3666192e-03, ..., 1.2267703e-01,\n",
              "          1.1230495e+00, 3.0774511e-03], dtype=float32),\n",
              "   array([5.3454348e-04, 4.8936433e-03, 2.0154340e-03, ..., 1.9868289e-01,\n",
              "          6.2828559e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.9681117e-04, 4.6334490e-03, 1.8878063e-03, ..., 1.1944145e-01,\n",
              "          8.2609308e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4232601e-04, 7.1077249e-03, 2.2924759e-03, ..., 4.9516600e-01,\n",
              "          5.3653574e-01, 1.3352953e-01], dtype=float32),\n",
              "   array([4.6272139e-04, 3.4463932e-03, 2.1868858e-03, ..., 1.8032183e-01,\n",
              "          1.1317656e+00, 8.9280996e-03], dtype=float32),\n",
              "   array([4.9692573e-04, 4.9694795e-03, 1.9741678e-03, ..., 1.8560837e-01,\n",
              "          5.2063006e-01, 0.0000000e+00], dtype=float32)],\n",
              "  8],\n",
              " [[array([3.5172034e-04, 6.2281969e-03, 2.3420074e-03, ..., 3.7885880e-01,\n",
              "          2.2785580e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4413607e-04, 5.1289531e-03, 2.3532584e-03, ..., 9.0216845e-01,\n",
              "          8.7197721e-01, 1.3430008e-02], dtype=float32),\n",
              "   array([4.3326203e-04, 3.4829995e-03, 2.2375046e-03, ..., 1.2034016e-01,\n",
              "          1.7525165e+00, 1.8940594e-02], dtype=float32),\n",
              "   array([5.1054946e-04, 4.7210515e-03, 1.7295744e-03, ..., 1.8055546e-01,\n",
              "          7.4168772e-01, 3.4751724e-03], dtype=float32),\n",
              "   array([4.0695973e-04, 5.4661375e-03, 1.9356762e-03, ..., 1.0450286e-03,\n",
              "          6.3310224e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7079785e-04, 7.5308681e-03, 2.3592394e-03, ..., 4.4873026e-01,\n",
              "          7.2706145e-01, 1.4104183e-01], dtype=float32),\n",
              "   array([4.7565514e-04, 3.5054248e-03, 2.0385107e-03, ..., 8.8533185e-02,\n",
              "          1.3340887e+00, 1.0576640e-04], dtype=float32),\n",
              "   array([4.7015760e-04, 4.4204667e-03, 1.8753548e-03, ..., 6.8826061e-01,\n",
              "          4.8818389e-01, 0.0000000e+00], dtype=float32)],\n",
              "  8],\n",
              " [[array([3.4314883e-04, 6.5967841e-03, 2.3283968e-03, ..., 2.5099948e-01,\n",
              "          3.5258356e-01, 3.3668827e-03], dtype=float32),\n",
              "   array([4.0933306e-04, 5.4697320e-03, 2.3219306e-03, ..., 1.4363636e+00,\n",
              "          8.2380235e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([5.1797507e-04, 3.4605316e-03, 2.0962127e-03, ..., 1.7514357e-01,\n",
              "          1.4306126e+00, 2.6460879e-03], dtype=float32),\n",
              "   array([4.4929140e-04, 4.8123435e-03, 1.9103130e-03, ..., 2.9101446e-01,\n",
              "          5.5414891e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6149481e-04, 4.4873906e-03, 2.0124323e-03, ..., 4.8979175e-01,\n",
              "          4.8789987e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6542575e-04, 6.9553694e-03, 2.4076500e-03, ..., 3.8880810e-01,\n",
              "          4.8773617e-01, 1.3793454e-01], dtype=float32),\n",
              "   array([4.2654437e-04, 3.6598283e-03, 2.5499526e-03, ..., 2.6790336e-02,\n",
              "          1.6280990e+00, 1.7134626e-03], dtype=float32),\n",
              "   array([5.0793384e-04, 5.2843690e-03, 1.9917632e-03, ..., 2.3538907e-01,\n",
              "          5.5473590e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9073924e-04, 4.7958279e-03, 1.9287997e-03, ..., 2.0706865e-01,\n",
              "          8.1017148e-01, 0.0000000e+00], dtype=float32)],\n",
              "  9],\n",
              " [[array([3.5752368e-04, 5.6137787e-03, 2.3225229e-03, ..., 4.0711433e-01,\n",
              "          2.5124010e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.2438451e-04, 6.3675344e-03, 2.1499032e-03, ..., 2.3326823e-01,\n",
              "          3.9794189e-01, 1.8368667e-02], dtype=float32),\n",
              "   array([4.0660624e-04, 5.4841824e-03, 2.2773175e-03, ..., 8.5138243e-01,\n",
              "          7.4064898e-01, 2.1823156e-03], dtype=float32),\n",
              "   array([5.0301745e-04, 4.0104869e-03, 2.4533509e-03, ..., 1.9485787e-01,\n",
              "          1.1662085e+00, 5.2295630e-03], dtype=float32),\n",
              "   array([4.6711563e-04, 5.1041786e-03, 2.0124661e-03, ..., 5.7135665e-01,\n",
              "          6.4563990e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5392851e-04, 4.9561271e-03, 1.7977902e-03, ..., 1.8448330e-02,\n",
              "          9.1873324e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5887325e-04, 6.8279351e-03, 2.4478999e-03, ..., 5.2903867e-01,\n",
              "          6.3865680e-01, 6.9951550e-03], dtype=float32),\n",
              "   array([5.0090894e-04, 3.5525193e-03, 1.9924231e-03, ..., 8.3474725e-02,\n",
              "          1.0649027e+00, 5.2001304e-03], dtype=float32),\n",
              "   array([5.0875888e-04, 5.5079274e-03, 2.4132356e-03, ..., 3.9633489e-01,\n",
              "          6.9397759e-01, 0.0000000e+00], dtype=float32)],\n",
              "  9],\n",
              " [[array([0.00033341, 0.00633931, 0.00236416, ..., 0.18358372, 0.2776209 ,\n",
              "          0.00375144], dtype=float32),\n",
              "   array([0.00035555, 0.00578232, 0.0022809 , ..., 0.31994376, 0.27777103,\n",
              "          0.00248235], dtype=float32),\n",
              "   array([5.0708035e-04, 5.2279169e-03, 2.2001378e-03, ..., 2.9676655e-01,\n",
              "          5.4878819e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5725401e-04, 3.5831390e-03, 2.1973187e-03, ..., 2.4612886e-01,\n",
              "          1.1447901e+00, 2.9554768e-03], dtype=float32),\n",
              "   array([5.2976998e-04, 4.5290585e-03, 2.2335160e-03, ..., 3.1413579e-01,\n",
              "          6.4194971e-01, 5.0086365e-04], dtype=float32),\n",
              "   array([4.7137888e-04, 4.9809520e-03, 1.8194063e-03, ..., 3.8169261e-02,\n",
              "          7.6785809e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7142899e-04, 7.2539155e-03, 2.5116263e-03, ..., 5.0941664e-01,\n",
              "          6.5556282e-01, 7.1510866e-02], dtype=float32),\n",
              "   array([4.3561554e-04, 3.1228105e-03, 2.3421436e-03, ..., 2.1295664e-01,\n",
              "          8.2893753e-01, 5.1459670e-03], dtype=float32),\n",
              "   array([5.1278871e-04, 5.0342577e-03, 1.9060981e-03, ..., 2.1783353e-01,\n",
              "          6.3187504e-01, 0.0000000e+00], dtype=float32)],\n",
              "  9],\n",
              " [[array([3.5215222e-04, 5.7575600e-03, 2.4308481e-03, ..., 4.5505041e-01,\n",
              "          1.5973754e-01, 1.5617033e-03], dtype=float32),\n",
              "   array([4.4727189e-04, 6.0886419e-03, 2.1190220e-03, ..., 6.2764078e-01,\n",
              "          7.3141104e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.3336858e-04, 4.1339030e-03, 2.2063290e-03, ..., 2.7530912e-01,\n",
              "          1.2682507e+00, 3.5530545e-03], dtype=float32),\n",
              "   array([4.9326924e-04, 4.8129861e-03, 1.8990304e-03, ..., 8.6835855e-01,\n",
              "          3.0537394e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.1639322e-04, 4.7464566e-03, 2.0730468e-03, ..., 1.9110830e-01,\n",
              "          6.2375873e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4431057e-04, 6.4214137e-03, 2.3226428e-03, ..., 6.9641697e-01,\n",
              "          4.9632126e-01, 1.7844805e-01], dtype=float32),\n",
              "   array([4.9338175e-04, 3.8885323e-03, 2.4096386e-03, ..., 1.4970180e-01,\n",
              "          9.0183580e-01, 1.5891204e-02], dtype=float32),\n",
              "   array([4.7000137e-04, 5.2365344e-03, 1.8981955e-03, ..., 7.2648652e-02,\n",
              "          8.5196108e-01, 4.3531932e-04], dtype=float32)],\n",
              "  8],\n",
              " [[array([3.71297851e-04, 6.17470220e-03, 2.40939925e-03, ...,\n",
              "          6.88623846e-01, 1.15366645e-01, 0.00000000e+00], dtype=float32),\n",
              "   array([3.6231230e-04, 6.0183830e-03, 2.2895096e-03, ..., 6.0725844e-01,\n",
              "          2.1641833e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.8769350e-04, 5.2495599e-03, 2.0979322e-03, ..., 8.4289992e-01,\n",
              "          7.8899187e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6526294e-04, 3.4466269e-03, 1.9314575e-03, ..., 5.4698594e-02,\n",
              "          1.0097841e+00, 3.9322930e-03], dtype=float32),\n",
              "   array([4.5851679e-04, 4.7391774e-03, 1.8524281e-03, ..., 2.6297683e-01,\n",
              "          4.8850033e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.2877026e-04, 4.3191044e-03, 1.9057679e-03, ..., 6.5534502e-02,\n",
              "          1.1371022e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6086715e-04, 7.0075723e-03, 2.3193131e-03, ..., 6.0380262e-01,\n",
              "          4.7773108e-01, 1.7618783e-02], dtype=float32),\n",
              "   array([4.6216237e-04, 3.6295902e-03, 2.1701809e-03, ..., 2.2434470e-01,\n",
              "          8.9932626e-01, 6.5067606e-03], dtype=float32),\n",
              "   array([0.0004967 , 0.00458701, 0.00237949, ..., 0.29883707, 0.42751986,\n",
              "          0.        ], dtype=float32),\n",
              "   array([4.4895930e-04, 5.1107784e-03, 1.7033245e-03, ..., 2.9248191e-02,\n",
              "          8.5454816e-01, 0.0000000e+00], dtype=float32)],\n",
              "  10],\n",
              " [[array([3.5705743e-04, 6.2373923e-03, 2.3197315e-03, ..., 5.9311831e-01,\n",
              "          1.6294526e-01, 1.4279225e-03], dtype=float32),\n",
              "   array([4.1831072e-04, 6.1147287e-03, 2.3392760e-03, ..., 4.9822846e-01,\n",
              "          7.9551256e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([5.0043868e-04, 3.7833480e-03, 2.2981442e-03, ..., 1.5284483e-01,\n",
              "          6.9836789e-01, 2.1722008e-02], dtype=float32),\n",
              "   array([4.5855527e-04, 4.6662311e-03, 2.2434797e-03, ..., 1.8656423e-02,\n",
              "          6.5936756e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.7544090e-04, 5.1842080e-03, 1.8898241e-03, ..., 2.4178891e-01,\n",
              "          5.2025712e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5731535e-04, 6.6141286e-03, 2.3256070e-03, ..., 5.6209087e-01,\n",
              "          7.0877171e-01, 1.7011367e-01], dtype=float32),\n",
              "   array([4.62796161e-04, 3.48524866e-03, 2.40567164e-03, ...,\n",
              "          1.10673055e-01, 9.35650349e-01, 1.49572641e-02], dtype=float32),\n",
              "   array([4.7358856e-04, 5.2008703e-03, 1.9241264e-03, ..., 2.7949750e-01,\n",
              "          6.8286353e-01, 0.0000000e+00], dtype=float32)],\n",
              "  8],\n",
              " [[array([3.4588290e-04, 6.8607726e-03, 2.1326633e-03, ..., 3.8435417e-01,\n",
              "          2.7157119e-01, 3.4782847e-03], dtype=float32),\n",
              "   array([3.4660177e-04, 6.2150103e-03, 2.2342692e-03, ..., 4.5682222e-01,\n",
              "          1.3064852e-01, 3.3926291e-03], dtype=float32),\n",
              "   array([4.1726005e-04, 4.8811473e-03, 2.1742606e-03, ..., 6.8984181e-01,\n",
              "          8.6104357e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.1677195e-04, 3.7723172e-03, 2.1518755e-03, ..., 7.2259210e-02,\n",
              "          1.4066545e+00, 4.6325359e-03], dtype=float32),\n",
              "   array([0.00046717, 0.00460243, 0.00179679, ..., 0.36078072, 0.43569484,\n",
              "          0.        ], dtype=float32),\n",
              "   array([4.5009033e-04, 4.5739859e-03, 2.0366269e-03, ..., 5.7918787e-01,\n",
              "          5.8473492e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6756086e-04, 7.0987954e-03, 2.3910415e-03, ..., 3.5514846e-01,\n",
              "          7.1682137e-01, 2.3438652e-01], dtype=float32),\n",
              "   array([4.6590960e-04, 3.3221361e-03, 2.1188466e-03, ..., 2.0443822e-01,\n",
              "          1.5120932e+00, 4.1464912e-03], dtype=float32),\n",
              "   array([4.5452651e-04, 4.8224316e-03, 1.8944616e-03, ..., 4.7124469e-01,\n",
              "          5.4766196e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6118643e-04, 5.1791565e-03, 1.9657139e-03, ..., 9.1358081e-02,\n",
              "          8.5837471e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6123075e-04, 7.1058241e-03, 2.3971715e-03, ..., 3.5501650e-01,\n",
              "          6.8738496e-01, 2.7200112e-01], dtype=float32),\n",
              "   array([4.4289653e-04, 3.6620805e-03, 2.3240505e-03, ..., 6.6364311e-02,\n",
              "          1.3707550e+00, 4.2640199e-03], dtype=float32),\n",
              "   array([4.5672161e-04, 4.3465081e-03, 2.0605826e-03, ..., 2.8055975e-01,\n",
              "          6.1110711e-01, 0.0000000e+00], dtype=float32)],\n",
              "  13],\n",
              " [[array([3.3292806e-04, 6.0313605e-03, 2.3342238e-03, ..., 3.6304435e-01,\n",
              "          5.0500828e-01, 3.7322935e-02], dtype=float32),\n",
              "   array([4.6103972e-04, 6.0409545e-03, 2.0899160e-03, ..., 1.5098394e+00,\n",
              "          8.0526805e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([5.2425952e-04, 3.9058460e-03, 2.3864114e-03, ..., 2.2899817e-01,\n",
              "          1.0994178e+00, 1.3980459e-02], dtype=float32),\n",
              "   array([4.5947777e-04, 4.6279333e-03, 1.8397688e-03, ..., 4.3043518e-01,\n",
              "          4.2577714e-01, 3.9770908e-05], dtype=float32),\n",
              "   array([4.434237e-04, 5.120112e-03, 1.736009e-03, ..., 7.846528e-02,\n",
              "          8.430878e-01, 0.000000e+00], dtype=float32),\n",
              "   array([3.5596424e-04, 6.8837875e-03, 2.3765785e-03, ..., 5.2279168e-01,\n",
              "          7.1642506e-01, 8.0763109e-02], dtype=float32),\n",
              "   array([4.8651884e-04, 3.8724013e-03, 2.3170004e-03, ..., 2.2246894e-01,\n",
              "          1.0902811e+00, 4.0968796e-03], dtype=float32),\n",
              "   array([5.2583090e-04, 4.5493511e-03, 2.0212065e-03, ..., 1.8437511e-01,\n",
              "          6.0846436e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5086298e-04, 5.0606541e-03, 1.9910932e-03, ..., 4.8335370e-01,\n",
              "          8.7168932e-01, 0.0000000e+00], dtype=float32)],\n",
              "  9],\n",
              " [[array([0.00034568, 0.00591708, 0.00229158, ..., 0.33152634, 0.22297236,\n",
              "          0.05512186], dtype=float32),\n",
              "   array([3.5146068e-04, 6.0827937e-03, 2.2614019e-03, ..., 4.0365908e-01,\n",
              "          2.7592641e-01, 3.0298100e-03], dtype=float32),\n",
              "   array([4.4649967e-04, 5.0035794e-03, 2.2131668e-03, ..., 2.6333112e-01,\n",
              "          7.0229781e-01, 7.9608355e-03], dtype=float32),\n",
              "   array([4.4279132e-04, 3.2352614e-03, 2.2883082e-03, ..., 8.0865622e-02,\n",
              "          1.3364472e+00, 6.1804885e-03], dtype=float32),\n",
              "   array([4.7730855e-04, 4.7189537e-03, 2.1354381e-03, ..., 4.6790251e-01,\n",
              "          6.9005913e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.7597956e-04, 4.6469672e-03, 1.8190250e-03, ..., 1.3862242e-01,\n",
              "          6.1026686e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3345859e-04, 7.3901713e-03, 2.2776339e-03, ..., 4.0725547e-01,\n",
              "          5.8965719e-01, 1.7433095e-01], dtype=float32),\n",
              "   array([4.5634474e-04, 3.6078794e-03, 2.3633935e-03, ..., 1.8121280e-01,\n",
              "          9.9817073e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9482350e-04, 5.1047062e-03, 1.9870955e-03, ..., 1.3808547e-01,\n",
              "          8.6190897e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.26367915e-04, 5.18863136e-03, 2.04553641e-03, ...,\n",
              "          1.17852844e-01, 7.98809826e-01, 0.00000000e+00], dtype=float32)],\n",
              "  10],\n",
              " [[array([3.6805568e-04, 6.4774221e-03, 2.1148094e-03, ..., 2.5190446e-01,\n",
              "          7.0431668e-01, 2.7666658e-02], dtype=float32),\n",
              "   array([3.7666524e-04, 5.5723884e-03, 2.2946906e-03, ..., 2.3630601e-01,\n",
              "          4.9230504e-01, 1.3220313e-02], dtype=float32),\n",
              "   array([3.4651381e-04, 6.2673721e-03, 2.3995563e-03, ..., 6.0920888e-01,\n",
              "          7.1988356e-01, 5.0624274e-02], dtype=float32),\n",
              "   array([3.8817676e-04, 5.4191304e-03, 2.7692122e-03, ..., 2.4449712e-01,\n",
              "          8.8550550e-01, 2.5156862e-03], dtype=float32),\n",
              "   array([3.9003661e-04, 5.9207068e-03, 2.4565698e-03, ..., 9.9565782e-02,\n",
              "          8.2049531e-01, 1.3719170e-01], dtype=float32),\n",
              "   array([4.4771150e-04, 4.1313148e-03, 2.2978396e-03, ..., 4.9661520e-01,\n",
              "          9.1696310e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6234863e-04, 4.9474314e-03, 1.9155622e-03, ..., 2.0995587e-02,\n",
              "          1.0664905e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4389057e-04, 6.4341524e-03, 2.4732687e-03, ..., 3.6870241e-01,\n",
              "          3.9220950e-01, 1.0982872e-01], dtype=float32),\n",
              "   array([3.7689356e-04, 5.6029079e-03, 2.5623457e-03, ..., 2.7767286e-01,\n",
              "          5.5398428e-01, 4.3692801e-02], dtype=float32),\n",
              "   array([3.7579413e-04, 5.2251620e-03, 2.6452534e-03, ..., 2.4467045e-02,\n",
              "          1.0037889e+00, 8.0301784e-02], dtype=float32),\n",
              "   array([4.4273905e-04, 4.5485804e-03, 2.2146238e-03, ..., 4.2739230e-01,\n",
              "          7.7702540e-01, 2.3142018e-03], dtype=float32),\n",
              "   array([4.9371802e-04, 5.8339275e-03, 2.0815392e-03, ..., 1.0698297e-01,\n",
              "          9.8344862e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5078463e-04, 6.3069239e-03, 2.4453269e-03, ..., 3.1687894e-01,\n",
              "          3.8912746e-01, 5.3260639e-02], dtype=float32),\n",
              "   array([3.8077545e-04, 6.4630145e-03, 2.6323241e-03, ..., 2.3336716e-01,\n",
              "          6.7856401e-01, 2.0113327e-03], dtype=float32),\n",
              "   array([3.5632323e-04, 5.7436801e-03, 2.3416700e-03, ..., 2.2290764e-02,\n",
              "          5.7784039e-01, 2.5842434e-02], dtype=float32),\n",
              "   array([4.8256738e-04, 5.0542266e-03, 1.9481608e-03, ..., 2.4902579e-01,\n",
              "          1.1593153e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9071334e-04, 4.8563741e-03, 1.8213044e-03, ..., 7.5061738e-02,\n",
              "          1.1689411e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4983017e-04, 4.1114995e-03, 2.6028561e-03, ..., 7.9616964e-02,\n",
              "          1.2161034e+00, 1.2459665e-02], dtype=float32),\n",
              "   array([3.4625019e-04, 6.1253570e-03, 2.6922955e-03, ..., 3.7889847e-01,\n",
              "          3.9866856e-01, 1.0741890e-02], dtype=float32),\n",
              "   array([3.8031276e-04, 5.8818082e-03, 2.4633540e-03, ..., 6.9394973e-03,\n",
              "          6.8348306e-01, 4.2411599e-02], dtype=float32),\n",
              "   array([4.8426588e-04, 4.4384813e-03, 2.2363595e-03, ..., 1.5668435e-01,\n",
              "          1.2300854e+00, 0.0000000e+00], dtype=float32)],\n",
              "  21],\n",
              " [[array([3.4843697e-04, 5.5650966e-03, 2.4578439e-03, ..., 1.3466460e+00,\n",
              "          3.9990950e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7078315e-04, 6.5660886e-03, 2.2065544e-03, ..., 3.8093749e-01,\n",
              "          7.6203412e-01, 3.0944064e-01], dtype=float32),\n",
              "   array([3.6236882e-04, 6.0340986e-03, 2.5621189e-03, ..., 4.0811247e-01,\n",
              "          5.7082754e-01, 5.0052788e-02], dtype=float32),\n",
              "   array([4.1545220e-04, 7.2281221e-03, 3.0563108e-03, ..., 3.4795746e-01,\n",
              "          1.3601644e+00, 4.6835560e-03], dtype=float32),\n",
              "   array([3.8233635e-04, 5.2405917e-03, 2.4427783e-03, ..., 1.2793025e-01,\n",
              "          6.3112289e-01, 6.3660763e-02], dtype=float32),\n",
              "   array([4.8916251e-04, 5.6280154e-03, 2.3008718e-03, ..., 1.9365698e-01,\n",
              "          9.7267526e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9276231e-04, 5.4849559e-03, 1.8950199e-03, ..., 1.8980116e-01,\n",
              "          8.0950487e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5642617e-04, 6.0157971e-03, 2.5366254e-03, ..., 5.8424294e-01,\n",
              "          4.6444732e-01, 5.9152313e-02], dtype=float32),\n",
              "   array([3.9376906e-04, 6.8143271e-03, 2.8640884e-03, ..., 1.9376832e-01,\n",
              "          9.4757718e-01, 1.8201493e-02], dtype=float32),\n",
              "   array([3.6259787e-04, 5.6629824e-03, 2.3136786e-03, ..., 4.5465443e-02,\n",
              "          6.9802177e-01, 7.8807054e-03], dtype=float32),\n",
              "   array([4.5680121e-04, 4.1405610e-03, 2.6415337e-03, ..., 2.3356636e-01,\n",
              "          1.0078887e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4923637e-04, 5.0736633e-03, 1.6815221e-03, ..., 2.2061652e-01,\n",
              "          1.0960406e+00, 6.7994660e-03], dtype=float32)],\n",
              "  12],\n",
              " [[array([3.3247215e-04, 6.5205512e-03, 2.3095128e-03, ..., 5.1813161e-01,\n",
              "          3.2194987e-01, 6.1772082e-02], dtype=float32),\n",
              "   array([3.4636457e-04, 5.4698414e-03, 2.1242457e-03, ..., 4.9337797e-02,\n",
              "          4.5896342e-01, 1.1050420e-02], dtype=float32),\n",
              "   array([3.6716674e-04, 6.0995417e-03, 2.7918462e-03, ..., 1.3793597e-01,\n",
              "          7.0635039e-01, 1.5964331e-02], dtype=float32),\n",
              "   array([3.77153949e-04, 6.02885522e-03, 2.93621351e-03, ...,\n",
              "          1.07384816e-01, 1.03223681e+00, 7.31738238e-03], dtype=float32),\n",
              "   array([3.7190935e-04, 5.7790293e-03, 2.5199528e-03, ..., 0.0000000e+00,\n",
              "          7.2078121e-01, 3.4275871e-02], dtype=float32),\n",
              "   array([4.7015931e-04, 4.7823018e-03, 2.1688314e-03, ..., 3.1977591e-01,\n",
              "          1.0305212e+00, 4.8282626e-03], dtype=float32),\n",
              "   array([5.0176639e-04, 4.9190195e-03, 2.2645763e-03, ..., 2.4180576e-01,\n",
              "          1.1896000e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5689116e-04, 5.4337145e-03, 2.5246139e-03, ..., 2.8557169e-01,\n",
              "          4.1967380e-01, 1.2483008e-02], dtype=float32),\n",
              "   array([3.6588334e-04, 6.5556206e-03, 2.6176297e-03, ..., 3.0639687e-01,\n",
              "          5.7121503e-01, 3.8094550e-02], dtype=float32),\n",
              "   array([3.6761674e-04, 6.0541444e-03, 2.3160670e-03, ..., 4.2904769e-03,\n",
              "          6.8592864e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.7060262e-04, 4.1135289e-03, 2.0507858e-03, ..., 1.2918046e-01,\n",
              "          7.1897244e-01, 4.0698783e-03], dtype=float32),\n",
              "   array([5.1893783e-04, 5.3175315e-03, 2.0343252e-03, ..., 5.4887205e-02,\n",
              "          1.1294398e+00, 0.0000000e+00], dtype=float32)],\n",
              "  12],\n",
              " [[array([3.6615017e-04, 5.9838966e-03, 2.1700743e-03, ..., 1.9043344e-01,\n",
              "          4.9489173e-01, 2.2470665e-01], dtype=float32),\n",
              "   array([3.5584933e-04, 6.3929544e-03, 2.2360799e-03, ..., 8.3768867e-02,\n",
              "          4.6056807e-01, 2.4568634e-03], dtype=float32),\n",
              "   array([3.3986568e-04, 6.5849740e-03, 2.5952647e-03, ..., 3.9894113e-01,\n",
              "          7.6665109e-01, 4.7095843e-02], dtype=float32),\n",
              "   array([3.7804956e-04, 6.4220615e-03, 2.5194092e-03, ..., 3.7481713e-01,\n",
              "          7.7681613e-01, 4.9811997e-02], dtype=float32),\n",
              "   array([3.7888647e-04, 5.7416903e-03, 2.6140418e-03, ..., 3.9895657e-02,\n",
              "          6.9737989e-01, 5.0291844e-02], dtype=float32),\n",
              "   array([4.9895275e-04, 5.1709712e-03, 2.7387938e-03, ..., 1.8810102e-01,\n",
              "          8.7344140e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.7021045e-04, 4.9578086e-03, 2.0517351e-03, ..., 2.0082408e-04,\n",
              "          1.0466958e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4791254e-04, 5.5966121e-03, 2.4832904e-03, ..., 4.5112944e-01,\n",
              "          3.2075131e-01, 4.2846490e-02], dtype=float32),\n",
              "   array([3.9723632e-04, 5.8831330e-03, 2.9094717e-03, ..., 6.3025579e-02,\n",
              "          9.7243601e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([0.00033712, 0.00605964, 0.00255022, ..., 0.2990231 , 0.31873184,\n",
              "          0.1058322 ], dtype=float32),\n",
              "   array([4.4539091e-04, 4.8762448e-03, 2.5063434e-03, ..., 7.5856400e-01,\n",
              "          7.4304146e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([5.2340113e-04, 5.3116446e-03, 2.0925032e-03, ..., 1.6060573e-01,\n",
              "          8.7985110e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4657851e-04, 5.9475577e-03, 2.5603594e-03, ..., 3.1469887e-01,\n",
              "          5.6525272e-01, 1.2790354e-01], dtype=float32),\n",
              "   array([3.9111762e-04, 5.2645840e-03, 2.4298211e-03, ..., 3.7799075e-01,\n",
              "          4.6497589e-01, 2.5023049e-02], dtype=float32),\n",
              "   array([3.7014886e-04, 5.9730746e-03, 2.2499398e-03, ..., 7.8775413e-02,\n",
              "          6.1235476e-01, 3.1030513e-02], dtype=float32),\n",
              "   array([4.6471169e-04, 4.8531061e-03, 2.2681446e-03, ..., 6.4477587e-01,\n",
              "          9.6185142e-01, 2.6560997e-04], dtype=float32)],\n",
              "  16],\n",
              " [[array([3.6488884e-04, 6.4784214e-03, 2.2638938e-03, ..., 3.5834721e-01,\n",
              "          6.4128244e-01, 1.1005109e-01], dtype=float32),\n",
              "   array([3.6665300e-04, 5.7243453e-03, 2.1765612e-03, ..., 4.9448666e-01,\n",
              "          6.7944479e-01, 4.6814922e-02], dtype=float32),\n",
              "   array([3.4453126e-04, 5.7875938e-03, 2.5370028e-03, ..., 1.2102597e+00,\n",
              "          2.7461767e-01, 3.5586592e-02], dtype=float32),\n",
              "   array([3.6651082e-04, 5.7885484e-03, 2.5464883e-03, ..., 3.6993015e-01,\n",
              "          4.0190887e-01, 2.7463550e-02], dtype=float32),\n",
              "   array([3.6408912e-04, 5.7936078e-03, 2.4996279e-03, ..., 2.7529013e-01,\n",
              "          8.7882411e-01, 1.0021242e-01], dtype=float32),\n",
              "   array([4.6696034e-04, 4.6837055e-03, 1.8637001e-03, ..., 3.8258123e-01,\n",
              "          7.6801169e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.8538958e-04, 4.5479788e-03, 2.3473206e-03, ..., 1.4106844e-01,\n",
              "          1.0142249e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4891989e-04, 5.7419352e-03, 2.4698589e-03, ..., 4.1340011e-01,\n",
              "          4.8380408e-01, 3.4698091e-02], dtype=float32),\n",
              "   array([3.9668960e-04, 5.4644286e-03, 2.4776456e-03, ..., 4.0759053e-02,\n",
              "          7.5758183e-01, 2.0431401e-03], dtype=float32),\n",
              "   array([3.6983503e-04, 5.9863264e-03, 2.4304006e-03, ..., 0.0000000e+00,\n",
              "          6.6051912e-01, 5.8778087e-03], dtype=float32),\n",
              "   array([4.2924035e-04, 4.0289555e-03, 2.4619892e-03, ..., 4.6914390e-01,\n",
              "          8.5629612e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6465138e-04, 5.2343444e-03, 2.1404184e-03, ..., 8.0932118e-02,\n",
              "          9.3221891e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6149198e-04, 5.1868912e-03, 2.5890607e-03, ..., 5.8556193e-01,\n",
              "          4.5572931e-01, 3.8181946e-02], dtype=float32),\n",
              "   array([3.9542458e-04, 5.6732679e-03, 2.7617710e-03, ..., 1.4673562e-01,\n",
              "          9.0412575e-01, 1.3637322e-04], dtype=float32),\n",
              "   array([3.7784121e-04, 5.5799843e-03, 2.3873148e-03, ..., 1.3728821e-02,\n",
              "          9.1826826e-01, 1.5753120e-02], dtype=float32),\n",
              "   array([4.8350709e-04, 5.0442927e-03, 2.0875297e-03, ..., 2.8983036e-01,\n",
              "          8.4746051e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6900884e-04, 5.0354376e-03, 1.9925477e-03, ..., 1.4888412e-01,\n",
              "          1.0314847e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.49079812e-04, 5.97992120e-03, 2.41190428e-03, ...,\n",
              "          1.69379041e-01, 5.17326951e-01, 1.07250586e-01], dtype=float32),\n",
              "   array([3.8315690e-04, 6.0534324e-03, 2.5006626e-03, ..., 3.2069185e-01,\n",
              "          5.4249525e-01, 2.7386252e-02], dtype=float32),\n",
              "   array([3.7974404e-04, 6.1680032e-03, 2.2359239e-03, ..., 2.5695926e-02,\n",
              "          7.1719253e-01, 9.9468321e-02], dtype=float32),\n",
              "   array([4.6122295e-04, 4.5882203e-03, 2.1282542e-03, ..., 2.1219093e-01,\n",
              "          9.4827366e-01, 0.0000000e+00], dtype=float32)],\n",
              "  21],\n",
              " [[array([3.6072888e-04, 6.4932131e-03, 2.0152470e-03, ..., 3.0527610e-01,\n",
              "          7.1479267e-01, 1.3465448e-01], dtype=float32),\n",
              "   array([3.56592878e-04, 6.16828725e-03, 2.15038215e-03, ...,\n",
              "          1.22047305e-01, 6.42331123e-01, 6.77887350e-02], dtype=float32),\n",
              "   array([3.6452155e-04, 5.8551249e-03, 2.5405758e-03, ..., 3.3130771e-01,\n",
              "          4.5245588e-01, 8.5558191e-02], dtype=float32),\n",
              "   array([3.7281404e-04, 6.8430821e-03, 2.6071877e-03, ..., 1.9344990e-01,\n",
              "          6.8731099e-01, 2.0804468e-03], dtype=float32),\n",
              "   array([3.5577777e-04, 5.7857675e-03, 2.4279638e-03, ..., 1.5494754e-03,\n",
              "          9.6398669e-01, 3.6252305e-02], dtype=float32),\n",
              "   array([5.1354105e-04, 4.7509670e-03, 2.4531728e-03, ..., 2.0369475e-01,\n",
              "          7.8206664e-01, 1.5602322e-04], dtype=float32),\n",
              "   array([4.5148990e-04, 4.7989758e-03, 1.9774665e-03, ..., 3.2245713e-01,\n",
              "          7.6320881e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.69456568e-04, 5.75785292e-03, 2.56730244e-03, ...,\n",
              "          5.83948076e-01, 4.90096331e-01, 1.03770554e-01], dtype=float32),\n",
              "   array([4.1727439e-04, 5.5777808e-03, 2.8950314e-03, ..., 3.9637920e-01,\n",
              "          6.3019133e-01, 2.7049643e-03], dtype=float32),\n",
              "   array([3.6668259e-04, 5.2407337e-03, 2.6251415e-03, ..., 5.7229758e-03,\n",
              "          5.6713408e-01, 1.6975651e-02], dtype=float32),\n",
              "   array([5.4343819e-04, 5.7008667e-03, 2.5582688e-03, ..., 2.1751228e-01,\n",
              "          9.0854460e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.3999305e-04, 4.8453202e-03, 2.1178527e-03, ..., 1.5860407e-01,\n",
              "          7.7156812e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4027189e-04, 5.6265062e-03, 2.4753846e-03, ..., 6.8002647e-01,\n",
              "          3.6101663e-01, 6.2836342e-02], dtype=float32),\n",
              "   array([3.9502850e-04, 6.2489086e-03, 2.9376966e-03, ..., 5.0691258e-02,\n",
              "          1.4130538e+00, 1.3766062e-02], dtype=float32),\n",
              "   array([3.5738773e-04, 5.5490253e-03, 2.7904899e-03, ..., 7.4373530e-03,\n",
              "          9.7464085e-01, 1.4512522e-02], dtype=float32),\n",
              "   array([4.5612978e-04, 4.6609319e-03, 2.3231008e-03, ..., 2.6264656e-01,\n",
              "          9.0375978e-01, 2.1890763e-03], dtype=float32)],\n",
              "  16],\n",
              " [[array([3.7364877e-04, 6.2823375e-03, 2.0761045e-03, ..., 1.5562157e-02,\n",
              "          5.3708428e-01, 1.5251118e-01], dtype=float32),\n",
              "   array([3.6604900e-04, 6.2857880e-03, 2.2445123e-03, ..., 3.1157032e-01,\n",
              "          6.0084832e-01, 1.6977468e-01], dtype=float32),\n",
              "   array([3.7018524e-04, 5.8840248e-03, 2.1198872e-03, ..., 3.8606274e-01,\n",
              "          5.8312106e-01, 1.6955705e-01], dtype=float32),\n",
              "   array([3.5183656e-04, 6.3159270e-03, 2.4106158e-03, ..., 8.4912956e-01,\n",
              "          5.0489491e-01, 5.6480329e-02], dtype=float32),\n",
              "   array([3.8807376e-04, 5.7714875e-03, 2.6969013e-03, ..., 1.4786960e-01,\n",
              "          5.8655554e-01, 3.1124777e-03], dtype=float32),\n",
              "   array([3.83610546e-04, 5.48416609e-03, 2.89715454e-03, ...,\n",
              "          1.17049664e-01, 9.38412964e-01, 5.63675305e-03], dtype=float32),\n",
              "   array([4.7079855e-04, 5.2142199e-03, 2.1142834e-03, ..., 4.7881365e-01,\n",
              "          8.7809980e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.7541331e-04, 5.2985316e-03, 1.9776034e-03, ..., 5.3605914e-01,\n",
              "          9.2822081e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5599657e-04, 5.8720871e-03, 2.5693746e-03, ..., 5.0561583e-01,\n",
              "          6.6271549e-01, 8.5080452e-03], dtype=float32),\n",
              "   array([3.8745996e-04, 5.9109642e-03, 2.4815889e-03, ..., 5.2019811e-01,\n",
              "          5.3042179e-01, 2.0701176e-02], dtype=float32),\n",
              "   array([3.5987599e-04, 5.8553801e-03, 2.1687960e-03, ..., 1.6687728e-02,\n",
              "          5.7420778e-01, 1.6224572e-02], dtype=float32),\n",
              "   array([4.8140422e-04, 4.1855392e-03, 2.0967089e-03, ..., 1.5690620e-01,\n",
              "          1.0145285e+00, 5.5971309e-03], dtype=float32),\n",
              "   array([4.6390534e-04, 4.8006512e-03, 1.9759522e-03, ..., 1.2288934e-01,\n",
              "          1.1451894e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.50312364e-04, 4.66737803e-03, 2.04954389e-03, ...,\n",
              "          1.10516526e-01, 7.89230287e-01, 2.28627361e-02], dtype=float32),\n",
              "   array([3.6107079e-04, 6.3953446e-03, 2.6891318e-03, ..., 2.6056668e-01,\n",
              "          6.5467876e-01, 3.9719179e-02], dtype=float32),\n",
              "   array([3.3428322e-04, 5.6532756e-03, 2.2892824e-03, ..., 3.1770450e-01,\n",
              "          6.2114114e-01, 1.3861345e-01], dtype=float32),\n",
              "   array([4.7125659e-04, 5.0534643e-03, 1.9553928e-03, ..., 2.7487543e-01,\n",
              "          9.6165931e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.3846370e-04, 4.8435312e-03, 1.9741494e-03, ..., 6.4970404e-02,\n",
              "          6.1820281e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6340202e-04, 5.3072288e-03, 1.9818745e-03, ..., 9.5250234e-02,\n",
              "          1.2328346e+00, 1.2211144e-02], dtype=float32),\n",
              "   array([3.7658671e-04, 6.2520020e-03, 2.6808106e-03, ..., 7.4572667e-02,\n",
              "          8.1675720e-01, 5.8730163e-02], dtype=float32),\n",
              "   array([3.7068748e-04, 5.9196609e-03, 2.5644212e-03, ..., 1.9277643e-02,\n",
              "          5.9716874e-01, 8.9894623e-02], dtype=float32),\n",
              "   array([4.9025944e-04, 4.2170500e-03, 2.3130178e-03, ..., 2.2220168e-01,\n",
              "          1.0042039e+00, 4.5780879e-03], dtype=float32),\n",
              "   array([4.7467847e-04, 5.9080003e-03, 1.7304301e-03, ..., 2.4058318e-01,\n",
              "          1.0179096e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5211418e-04, 6.1953464e-03, 2.5315629e-03, ..., 4.1336516e-01,\n",
              "          4.8111370e-01, 1.1512074e-01], dtype=float32),\n",
              "   array([3.9302546e-04, 6.0469117e-03, 2.7705841e-03, ..., 8.1984907e-01,\n",
              "          9.6291661e-01, 2.4058342e-03], dtype=float32),\n",
              "   array([3.6051369e-04, 5.3769504e-03, 2.5846350e-03, ..., 1.0736942e-01,\n",
              "          6.4786243e-01, 6.9174089e-02], dtype=float32),\n",
              "   array([4.5459144e-04, 5.0181681e-03, 2.0875679e-03, ..., 5.4311961e-01,\n",
              "          9.9966192e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.8107220e-04, 5.7943841e-03, 1.7301647e-03, ..., 9.4779976e-02,\n",
              "          1.0634929e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6158427e-04, 5.3879186e-03, 2.5316039e-03, ..., 6.3580865e-01,\n",
              "          5.9872913e-01, 6.1144572e-02], dtype=float32),\n",
              "   array([3.5696040e-04, 5.8885608e-03, 2.7818936e-03, ..., 1.9623610e-01,\n",
              "          7.7895564e-01, 1.1239700e-02], dtype=float32),\n",
              "   array([3.57062003e-04, 5.91363059e-03, 2.29174481e-03, ...,\n",
              "          1.07360417e-02, 7.53197134e-01, 1.02595255e-01], dtype=float32),\n",
              "   array([4.7108383e-04, 4.8426134e-03, 2.1306735e-03, ..., 6.7040235e-01,\n",
              "          9.0401119e-01, 3.1470037e-03], dtype=float32)],\n",
              "  32],\n",
              " [[array([4.0989707e-04, 4.8274384e-03, 2.2818279e-03, ..., 7.7317548e-01,\n",
              "          7.0529628e-01, 5.0161801e-02], dtype=float32),\n",
              "   array([3.7690077e-04, 5.9788730e-03, 2.3242419e-03, ..., 1.2783922e-01,\n",
              "          5.1342678e-01, 4.7157317e-02], dtype=float32),\n",
              "   array([3.8608362e-04, 6.1566280e-03, 2.1311296e-03, ..., 3.5831645e-01,\n",
              "          5.7815188e-01, 1.6481201e-01], dtype=float32),\n",
              "   array([3.7669489e-04, 5.8330810e-03, 2.4805332e-03, ..., 3.9747438e-01,\n",
              "          6.0061866e-01, 4.3931533e-02], dtype=float32),\n",
              "   array([3.5644573e-04, 6.2376936e-03, 2.4654563e-03, ..., 5.4289293e-01,\n",
              "          6.5081447e-01, 1.2862154e-02], dtype=float32),\n",
              "   array([3.4415215e-04, 5.7921107e-03, 2.2817419e-03, ..., 1.3970137e-02,\n",
              "          6.5988213e-01, 7.3118664e-02], dtype=float32),\n",
              "   array([4.8974453e-04, 4.5915362e-03, 2.2088431e-03, ..., 4.2801118e-01,\n",
              "          9.1520101e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.1468715e-04, 4.9967058e-03, 2.1699660e-03, ..., 3.4467183e-02,\n",
              "          7.1476603e-01, 2.3981940e-03], dtype=float32),\n",
              "   array([3.4788396e-04, 6.2520420e-03, 2.3350888e-03, ..., 2.5945267e-01,\n",
              "          4.4000027e-01, 2.4016665e-02], dtype=float32),\n",
              "   array([3.9291082e-04, 5.4874634e-03, 2.2778162e-03, ..., 4.6878549e-01,\n",
              "          4.1685203e-01, 5.9961076e-03], dtype=float32),\n",
              "   array([3.52208706e-04, 6.20017899e-03, 2.38578091e-03, ...,\n",
              "          8.59244764e-02, 7.46841133e-01, 1.22179035e-02], dtype=float32),\n",
              "   array([4.8156391e-04, 4.7912509e-03, 2.4063410e-03, ..., 2.3318899e-01,\n",
              "          8.7595415e-01, 2.4461583e-03], dtype=float32),\n",
              "   array([4.3822514e-04, 5.4994025e-03, 1.7244122e-03, ..., 2.8874008e-02,\n",
              "          8.5081863e-01, 8.0203913e-02], dtype=float32),\n",
              "   array([3.2617364e-04, 6.1863619e-03, 2.3568603e-03, ..., 7.3455662e-01,\n",
              "          2.7115977e-01, 4.0499020e-02], dtype=float32),\n",
              "   array([3.5504956e-04, 6.3496185e-03, 2.6718588e-03, ..., 8.7080860e-01,\n",
              "          5.6192887e-01, 7.2095538e-03], dtype=float32),\n",
              "   array([3.5210323e-04, 5.6452667e-03, 2.5186015e-03, ..., 2.6119152e-01,\n",
              "          5.7576799e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4790230e-04, 4.8073446e-03, 2.3445592e-03, ..., 3.5460040e-01,\n",
              "          9.0620804e-01, 0.0000000e+00], dtype=float32)],\n",
              "  17],\n",
              " [[array([3.5355639e-04, 6.1340407e-03, 2.2233592e-03, ..., 4.6506289e-01,\n",
              "          9.3129241e-01, 5.8851555e-02], dtype=float32),\n",
              "   array([3.7986602e-04, 5.9547536e-03, 2.3533732e-03, ..., 4.7058091e-01,\n",
              "          6.1152798e-01, 1.8362030e-01], dtype=float32),\n",
              "   array([3.9418030e-04, 5.5745840e-03, 2.4408686e-03, ..., 1.4603743e-01,\n",
              "          4.4172996e-01, 1.4839501e-02], dtype=float32),\n",
              "   array([3.5674375e-04, 5.6006615e-03, 2.5453931e-03, ..., 2.0523350e-01,\n",
              "          6.5342277e-01, 8.6614065e-02], dtype=float32),\n",
              "   array([3.4659836e-04, 6.0419319e-03, 2.6424564e-03, ..., 7.1285409e-01,\n",
              "          4.2035323e-01, 7.6428214e-03], dtype=float32),\n",
              "   array([3.7654216e-04, 5.4672942e-03, 2.6417733e-03, ..., 7.9028703e-02,\n",
              "          9.5388800e-01, 4.0343110e-02], dtype=float32),\n",
              "   array([4.6887132e-04, 5.2712969e-03, 2.2095111e-03, ..., 3.9949089e-01,\n",
              "          8.2330143e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.3232669e-04, 4.9621523e-03, 1.9914282e-03, ..., 2.9344014e-03,\n",
              "          8.8321579e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5697766e-04, 6.2565114e-03, 2.4758480e-03, ..., 2.2152318e-01,\n",
              "          4.1057196e-01, 4.1823398e-02], dtype=float32),\n",
              "   array([3.8256816e-04, 5.4958798e-03, 2.6678462e-03, ..., 1.2190050e-01,\n",
              "          8.4758335e-01, 1.9994825e-02], dtype=float32),\n",
              "   array([3.6847161e-04, 4.7198264e-03, 2.5361197e-03, ..., 7.0186071e-02,\n",
              "          7.2951514e-01, 1.6467046e-02], dtype=float32),\n",
              "   array([5.0938845e-04, 5.0184843e-03, 2.5001648e-03, ..., 1.0538766e+00,\n",
              "          7.1216363e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.63531440e-04, 5.25385514e-03, 2.11028242e-03, ...,\n",
              "          1.11295074e-01, 9.91180241e-01, 0.00000000e+00], dtype=float32),\n",
              "   array([3.5593208e-04, 5.9484364e-03, 2.5619029e-03, ..., 3.1293693e-01,\n",
              "          4.5221582e-01, 2.4278656e-02], dtype=float32),\n",
              "   array([3.7080079e-04, 5.0576651e-03, 2.6451191e-03, ..., 3.4367588e-01,\n",
              "          5.3275466e-01, 5.9480350e-03], dtype=float32),\n",
              "   array([3.5510203e-04, 5.0183334e-03, 2.3868477e-03, ..., 9.8489681e-03,\n",
              "          3.8742286e-01, 5.9803859e-03], dtype=float32),\n",
              "   array([4.7177414e-04, 4.5615025e-03, 2.3478325e-03, ..., 7.1073425e-01,\n",
              "          6.0679317e-01, 0.0000000e+00], dtype=float32)],\n",
              "  17],\n",
              " [[array([3.5219139e-04, 4.7632568e-03, 2.0447236e-03, ..., 5.0264168e-01,\n",
              "          9.0526497e-01, 2.2421140e-02], dtype=float32),\n",
              "   array([3.5530428e-04, 5.6066043e-03, 2.1781828e-03, ..., 2.6949042e-01,\n",
              "          5.2139646e-01, 1.2331016e-01], dtype=float32),\n",
              "   array([3.74515512e-04, 5.23536792e-03, 2.37543951e-03, ...,\n",
              "          2.67088860e-01, 7.87413836e-01, 1.11558214e-01], dtype=float32),\n",
              "   array([3.3941917e-04, 5.5507300e-03, 2.3850866e-03, ..., 6.3531828e-01,\n",
              "          1.5314908e-01, 1.6574655e-02], dtype=float32),\n",
              "   array([3.63274186e-04, 5.85337309e-03, 2.31971405e-03, ...,\n",
              "          1.45733245e-02, 6.40731871e-01, 9.91719496e-03], dtype=float32),\n",
              "   array([3.5491632e-04, 5.0932881e-03, 2.4425539e-03, ..., 8.0311656e-01,\n",
              "          2.7038863e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8962226e-04, 6.0007339e-03, 2.8726966e-03, ..., 2.9206356e-01,\n",
              "          8.9141905e-01, 1.4643931e-02], dtype=float32),\n",
              "   array([3.4820553e-04, 5.2538915e-03, 2.4570071e-03, ..., 3.0456463e-01,\n",
              "          5.5661362e-01, 4.7539070e-02], dtype=float32),\n",
              "   array([5.0283957e-04, 4.9386974e-03, 2.3484607e-03, ..., 2.3878606e-01,\n",
              "          9.6267271e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.49808809e-04, 4.71766619e-03, 2.37821206e-03, ...,\n",
              "          1.13567054e-01, 6.76190734e-01, 0.00000000e+00], dtype=float32),\n",
              "   array([3.7784738e-04, 6.5353671e-03, 2.3737894e-03, ..., 2.7844825e-01,\n",
              "          7.1772027e-01, 1.6460362e-01], dtype=float32),\n",
              "   array([3.6597322e-04, 6.0480479e-03, 2.5691013e-03, ..., 1.6738133e-01,\n",
              "          5.8738369e-01, 4.4736974e-02], dtype=float32),\n",
              "   array([3.6771718e-04, 4.8762206e-03, 2.5303967e-03, ..., 4.9742207e-01,\n",
              "          5.8286655e-01, 1.2919737e-02], dtype=float32),\n",
              "   array([5.1606284e-04, 5.2060904e-03, 2.2873699e-03, ..., 2.2902335e-01,\n",
              "          8.8240427e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5412479e-04, 4.9034245e-03, 1.9278016e-03, ..., 1.7041233e-01,\n",
              "          9.8337173e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6074361e-04, 4.9975719e-03, 1.8829178e-03, ..., 1.1636990e-01,\n",
              "          8.8582146e-01, 2.5813759e-03], dtype=float32),\n",
              "   array([3.6044422e-04, 5.8123325e-03, 2.5984438e-03, ..., 1.1239882e-01,\n",
              "          7.5774843e-01, 1.6743945e-02], dtype=float32),\n",
              "   array([3.6710128e-04, 5.9138560e-03, 2.3517185e-03, ..., 1.2250532e-01,\n",
              "          5.9021235e-01, 8.2570173e-02], dtype=float32),\n",
              "   array([4.4969234e-04, 4.7391490e-03, 1.9949572e-03, ..., 7.5476028e-02,\n",
              "          9.4292223e-01, 5.4055597e-03], dtype=float32),\n",
              "   array([4.7119972e-04, 5.1382557e-03, 1.9040332e-03, ..., 1.9325942e-02,\n",
              "          1.1255608e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5344821e-04, 5.5142348e-03, 2.4002206e-03, ..., 2.7837962e-01,\n",
              "          4.5303267e-01, 3.3223331e-02], dtype=float32),\n",
              "   array([3.9141733e-04, 5.5142683e-03, 2.4963908e-03, ..., 6.4006515e-02,\n",
              "          6.9591069e-01, 1.6122919e-02], dtype=float32),\n",
              "   array([3.7301096e-04, 5.3815162e-03, 2.4766482e-03, ..., 3.9534446e-02,\n",
              "          6.0752141e-01, 2.9215569e-02], dtype=float32),\n",
              "   array([5.3234684e-04, 4.4705099e-03, 2.4445879e-03, ..., 2.6995575e-01,\n",
              "          7.2354209e-01, 3.9421408e-03], dtype=float32),\n",
              "   array([5.1480526e-04, 4.8437901e-03, 2.0598869e-03, ..., 2.4372068e-01,\n",
              "          8.8188177e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4626253e-04, 5.6138393e-03, 2.4742575e-03, ..., 1.0096744e+00,\n",
              "          3.0701327e-01, 1.5338961e-02], dtype=float32),\n",
              "   array([3.9661018e-04, 6.4170342e-03, 2.5241186e-03, ..., 4.5662349e-01,\n",
              "          4.9035978e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4681222e-04, 5.9287762e-03, 2.4751562e-03, ..., 0.0000000e+00,\n",
              "          8.6105567e-01, 5.0157327e-02], dtype=float32)],\n",
              "  28],\n",
              " [[array([3.22338048e-04, 5.91025408e-03, 2.28330120e-03, ...,\n",
              "          5.16992450e-01, 3.48340720e-01, 1.23787755e-02], dtype=float32),\n",
              "   array([0.00034668, 0.00628235, 0.00232173, ..., 0.03992718, 0.32691586,\n",
              "          0.01702571], dtype=float32),\n",
              "   array([3.6058936e-04, 6.1086789e-03, 2.3584135e-03, ..., 1.5376018e-01,\n",
              "          4.5884320e-01, 7.2425455e-02], dtype=float32),\n",
              "   array([3.4109675e-04, 5.3265118e-03, 2.5964626e-03, ..., 6.8300229e-01,\n",
              "          6.1287773e-01, 3.2096818e-02], dtype=float32),\n",
              "   array([3.7282589e-04, 6.3253585e-03, 2.4674207e-03, ..., 1.9812374e-01,\n",
              "          5.2292156e-01, 3.3225857e-03], dtype=float32),\n",
              "   array([3.5174808e-04, 6.0636858e-03, 2.5617103e-03, ..., 2.0967771e-01,\n",
              "          7.0376647e-01, 2.2744521e-02], dtype=float32),\n",
              "   array([4.5994346e-04, 4.7282535e-03, 2.3678064e-03, ..., 7.5288370e-02,\n",
              "          1.1146905e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.8987853e-04, 5.4314635e-03, 2.0263237e-03, ..., 1.7019508e-02,\n",
              "          8.5220712e-01, 1.0356954e-02], dtype=float32),\n",
              "   array([3.4045835e-04, 5.8790608e-03, 2.4653764e-03, ..., 1.1653305e+00,\n",
              "          2.9707766e-01, 7.5494120e-04], dtype=float32),\n",
              "   array([3.3982145e-04, 6.6929264e-03, 2.3894624e-03, ..., 7.9851192e-01,\n",
              "          5.5998099e-01, 2.6055247e-02], dtype=float32),\n",
              "   array([3.6241973e-04, 5.9578395e-03, 2.2947700e-03, ..., 3.2010987e-01,\n",
              "          8.4266287e-01, 5.2286789e-02], dtype=float32),\n",
              "   array([4.3809679e-04, 4.8682028e-03, 2.0932914e-03, ..., 2.2176667e-01,\n",
              "          9.4439620e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.0383250e-04, 4.9824063e-03, 2.0825434e-03, ..., 1.7026477e-02,\n",
              "          7.4399829e-01, 2.1904020e-03], dtype=float32),\n",
              "   array([3.9908753e-04, 6.1655785e-03, 2.7274955e-03, ..., 7.6138288e-01,\n",
              "          5.5642974e-01, 4.6013487e-03], dtype=float32),\n",
              "   array([0.00038961, 0.00455011, 0.00256636, ..., 0.26152065, 0.34920162,\n",
              "          0.01071769], dtype=float32),\n",
              "   array([3.6235838e-04, 5.6978352e-03, 2.1073031e-03, ..., 1.8680003e-02,\n",
              "          6.9816530e-01, 1.4282175e-02], dtype=float32),\n",
              "   array([4.4965211e-04, 4.3189791e-03, 2.2987691e-03, ..., 3.1956860e-01,\n",
              "          7.7534282e-01, 2.3487212e-02], dtype=float32),\n",
              "   array([3.5334440e-04, 6.6042459e-03, 2.4019461e-03, ..., 3.1085449e-01,\n",
              "          5.0242823e-01, 2.6145777e-02], dtype=float32),\n",
              "   array([3.6155205e-04, 5.9382897e-03, 1.9861620e-03, ..., 1.5595415e-01,\n",
              "          6.0540342e-01, 5.4370865e-02], dtype=float32),\n",
              "   array([3.6390495e-04, 6.4740777e-03, 2.5187072e-03, ..., 2.0513560e-01,\n",
              "          9.8452270e-01, 7.8950832e-03], dtype=float32),\n",
              "   array([3.5204538e-04, 5.8217244e-03, 2.5773731e-03, ..., 7.1377611e-01,\n",
              "          6.6838777e-01, 3.4380215e-03], dtype=float32),\n",
              "   array([3.6922851e-04, 6.3013709e-03, 2.3279849e-03, ..., 1.1328050e-01,\n",
              "          1.0516659e+00, 3.8157459e-02], dtype=float32),\n",
              "   array([4.8626342e-04, 4.9810605e-03, 2.2414289e-03, ..., 2.3701085e-01,\n",
              "          9.9935853e-01, 1.6512701e-02], dtype=float32)],\n",
              "  23],\n",
              " [[array([3.8293810e-04, 6.1443094e-03, 2.1266735e-03, ..., 2.1029480e-01,\n",
              "          8.0562508e-01, 5.9212051e-02], dtype=float32),\n",
              "   array([3.5270813e-04, 5.5975998e-03, 2.1951569e-03, ..., 2.1664083e-01,\n",
              "          4.8016891e-01, 1.0606906e-01], dtype=float32),\n",
              "   array([3.4628162e-04, 6.5901135e-03, 2.5612086e-03, ..., 4.2005694e-01,\n",
              "          6.2538296e-01, 2.8974015e-02], dtype=float32),\n",
              "   array([3.4820006e-04, 6.2842844e-03, 2.5103111e-03, ..., 6.4920682e-01,\n",
              "          4.4857493e-01, 6.6169380e-04], dtype=float32),\n",
              "   array([3.5521458e-04, 6.3598123e-03, 2.1887615e-03, ..., 2.1168096e-02,\n",
              "          8.6026222e-01, 4.8885483e-02], dtype=float32),\n",
              "   array([4.9269234e-04, 5.1431321e-03, 2.2573860e-03, ..., 2.7715105e-01,\n",
              "          8.3967632e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.69996245e-04, 5.05842129e-03, 2.17465474e-03, ...,\n",
              "          1.21609986e-01, 7.10440159e-01, 0.00000000e+00], dtype=float32),\n",
              "   array([3.3888195e-04, 5.8487579e-03, 2.7105440e-03, ..., 9.7992682e-01,\n",
              "          4.9259025e-01, 1.9517111e-02], dtype=float32),\n",
              "   array([3.6998271e-04, 5.3787394e-03, 2.3844491e-03, ..., 9.8504376e-01,\n",
              "          4.6836549e-01, 1.6719268e-03], dtype=float32),\n",
              "   array([3.7044671e-04, 5.8012092e-03, 2.3410465e-03, ..., 4.4461619e-02,\n",
              "          5.5113262e-01, 6.5488915e-04], dtype=float32),\n",
              "   array([5.1700632e-04, 4.9713952e-03, 2.8233479e-03, ..., 6.7097194e-02,\n",
              "          1.0553420e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.8695650e-04, 5.4741139e-03, 2.0155725e-03, ..., 2.8586904e-02,\n",
              "          8.2099098e-01, 1.7406830e-03], dtype=float32),\n",
              "   array([4.3077895e-04, 4.0047532e-03, 2.4122063e-03, ..., 1.0029780e-01,\n",
              "          7.9985869e-01, 9.0110023e-04], dtype=float32),\n",
              "   array([3.5300257e-04, 6.0823467e-03, 2.5858253e-03, ..., 4.0140519e-01,\n",
              "          6.1445653e-01, 2.7003391e-02], dtype=float32),\n",
              "   array([3.7519730e-04, 6.0776784e-03, 2.1863333e-03, ..., 1.6501695e-02,\n",
              "          6.2696666e-01, 9.9330686e-02], dtype=float32),\n",
              "   array([4.6098777e-04, 5.1382128e-03, 2.4169346e-03, ..., 2.8339988e-01,\n",
              "          9.7103506e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9384899e-04, 5.4130191e-03, 2.2007038e-03, ..., 4.2928419e-01,\n",
              "          8.4427840e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4526287e-04, 5.7350574e-03, 2.4381208e-03, ..., 9.6064448e-01,\n",
              "          3.2282764e-01, 5.2159014e-03], dtype=float32),\n",
              "   array([3.8159540e-04, 6.8939850e-03, 2.7321256e-03, ..., 2.7955753e-01,\n",
              "          7.8000081e-01, 8.0031408e-03], dtype=float32),\n",
              "   array([3.6423616e-04, 6.2416778e-03, 2.0749890e-03, ..., 1.1234918e-01,\n",
              "          8.0684972e-01, 1.2035585e-01], dtype=float32),\n",
              "   array([4.5612195e-04, 5.1807398e-03, 2.3000124e-03, ..., 5.6971288e-01,\n",
              "          1.1708955e+00, 3.1180123e-03], dtype=float32),\n",
              "   array([4.9362547e-04, 5.8790627e-03, 2.0785469e-03, ..., 1.2663837e-02,\n",
              "          6.9552583e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8179473e-04, 5.3277002e-03, 2.1615562e-03, ..., 5.8547467e-01,\n",
              "          9.1017789e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([6.1470264e-04, 4.0202681e-03, 2.1951706e-03, ..., 2.7586758e-01,\n",
              "          1.2899487e+00, 1.3048848e-02], dtype=float32),\n",
              "   array([3.4368000e-04, 5.6718746e-03, 2.5468948e-03, ..., 4.6863917e-01,\n",
              "          3.5373354e-01, 4.0185526e-02], dtype=float32),\n",
              "   array([3.6340323e-04, 5.1686703e-03, 2.5298502e-03, ..., 7.2665411e-01,\n",
              "          6.8441975e-01, 1.6333936e-02], dtype=float32),\n",
              "   array([3.4532420e-04, 6.0403738e-03, 2.2369621e-03, ..., 1.1601564e-02,\n",
              "          5.2043152e-01, 4.7555096e-02], dtype=float32),\n",
              "   array([5.6749117e-04, 4.7935173e-03, 2.2044154e-03, ..., 1.4151965e-01,\n",
              "          6.7448825e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9884722e-04, 5.7712793e-03, 1.8672355e-03, ..., 1.9227207e-01,\n",
              "          7.3256218e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3417999e-04, 6.5816981e-03, 2.3664024e-03, ..., 1.4372855e-01,\n",
              "          3.5994595e-01, 2.1966927e-02], dtype=float32)],\n",
              "  30],\n",
              " [[array([3.5074042e-04, 4.8137056e-03, 2.2136099e-03, ..., 6.8126607e-01,\n",
              "          1.2165176e+00, 1.7657613e-02], dtype=float32),\n",
              "   array([3.8196705e-04, 5.5035073e-03, 2.1929012e-03, ..., 6.6823438e-02,\n",
              "          5.5314445e-01, 3.7534337e-02], dtype=float32),\n",
              "   array([3.7421923e-04, 5.2126385e-03, 2.0986954e-03, ..., 2.1263177e-02,\n",
              "          7.2042692e-01, 2.4608554e-01], dtype=float32),\n",
              "   array([3.6707666e-04, 6.9820029e-03, 2.4428191e-03, ..., 3.7014869e-01,\n",
              "          6.7187190e-01, 1.0148019e-01], dtype=float32),\n",
              "   array([3.5697571e-04, 7.0173466e-03, 2.6705402e-03, ..., 1.3508639e-01,\n",
              "          9.7582293e-01, 1.5574007e-02], dtype=float32),\n",
              "   array([3.7565097e-04, 5.9735780e-03, 2.5563531e-03, ..., 4.6060089e-02,\n",
              "          8.4590292e-01, 5.0044425e-02], dtype=float32),\n",
              "   array([5.2424066e-04, 5.5494723e-03, 2.5729078e-03, ..., 5.4566222e-01,\n",
              "          8.2095486e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.8488172e-04, 4.7543882e-03, 2.0793350e-03, ..., 2.0897996e-01,\n",
              "          1.0775361e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5366032e-04, 5.6526321e-03, 2.4877002e-03, ..., 3.0065969e-01,\n",
              "          3.8271868e-01, 1.3957440e-02], dtype=float32),\n",
              "   array([3.6980203e-04, 5.8157686e-03, 2.5547843e-03, ..., 6.2681282e-01,\n",
              "          5.7743955e-01, 1.3205279e-03], dtype=float32),\n",
              "   array([3.6726566e-04, 5.1887590e-03, 2.3213148e-03, ..., 2.1081951e-01,\n",
              "          8.7034124e-01, 5.0571233e-02], dtype=float32),\n",
              "   array([4.7291280e-04, 4.8493771e-03, 2.0517656e-03, ..., 6.5472645e-01,\n",
              "          9.4492358e-01, 1.1523623e-03], dtype=float32),\n",
              "   array([5.3758675e-04, 5.6636217e-03, 1.9702115e-03, ..., 1.5402104e-01,\n",
              "          8.1447542e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6096710e-04, 5.5670142e-03, 2.6948291e-03, ..., 7.7174860e-01,\n",
              "          4.9468637e-01, 2.8838875e-02], dtype=float32),\n",
              "   array([3.7652525e-04, 6.4560394e-03, 2.4914623e-03, ..., 3.4334067e-01,\n",
              "          5.5214977e-01, 5.3987238e-03], dtype=float32),\n",
              "   array([3.5380296e-04, 5.7407357e-03, 2.2428171e-03, ..., 5.5059105e-01,\n",
              "          4.7845367e-01, 4.3685019e-02], dtype=float32),\n",
              "   array([4.886209e-04, 4.964433e-03, 2.649082e-03, ..., 3.624112e-01,\n",
              "          9.971365e-01, 3.357429e-02], dtype=float32),\n",
              "   array([4.7794767e-04, 5.1235105e-03, 2.3380688e-03, ..., 1.2352778e-02,\n",
              "          9.7796786e-01, 6.4677424e-03], dtype=float32),\n",
              "   array([5.1257835e-04, 5.2420264e-03, 2.3781070e-03, ..., 2.1416509e-01,\n",
              "          6.1942261e-01, 1.2101907e-02], dtype=float32),\n",
              "   array([3.7138621e-04, 6.1992928e-03, 2.5873301e-03, ..., 1.0744847e-01,\n",
              "          4.2937243e-01, 5.9866495e-03], dtype=float32),\n",
              "   array([3.7481225e-04, 6.0631274e-03, 2.5713586e-03, ..., 2.1939347e-03,\n",
              "          9.6475315e-01, 2.4740409e-02], dtype=float32),\n",
              "   array([4.7935697e-04, 4.9862657e-03, 2.3749692e-03, ..., 9.3415838e-01,\n",
              "          8.4138179e-01, 0.0000000e+00], dtype=float32)],\n",
              "  22],\n",
              " [[array([3.5872051e-04, 6.2842402e-03, 1.9339101e-03, ..., 2.5720832e-01,\n",
              "          5.2558893e-01, 2.2231846e-01], dtype=float32),\n",
              "   array([3.6843622e-04, 6.2788669e-03, 2.2633849e-03, ..., 3.8092755e-02,\n",
              "          6.4838254e-01, 1.9142000e-01], dtype=float32),\n",
              "   array([3.6518273e-04, 5.9795561e-03, 2.5656563e-03, ..., 5.2770174e-01,\n",
              "          3.6229798e-01, 1.1230799e-02], dtype=float32),\n",
              "   array([3.4650462e-04, 6.7593274e-03, 2.4553146e-03, ..., 3.9262310e-01,\n",
              "          6.4938986e-01, 2.4782965e-02], dtype=float32),\n",
              "   array([3.6855094e-04, 5.4758568e-03, 2.3264629e-03, ..., 8.7178219e-03,\n",
              "          7.4423110e-01, 5.5120550e-02], dtype=float32),\n",
              "   array([4.2554422e-04, 4.8214784e-03, 2.3675985e-03, ..., 2.7311358e-01,\n",
              "          7.5721884e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.1860607e-04, 4.8954315e-03, 1.9840221e-03, ..., 7.3731750e-02,\n",
              "          1.0601790e+00, 4.7557089e-03], dtype=float32),\n",
              "   array([0.00033005, 0.00546881, 0.00249366, ..., 0.3106316 , 0.30546957,\n",
              "          0.01082522], dtype=float32),\n",
              "   array([3.9753655e-04, 5.6137322e-03, 2.8358090e-03, ..., 1.7015341e-01,\n",
              "          7.3050368e-01, 3.0505955e-03], dtype=float32),\n",
              "   array([3.81343765e-04, 5.79906255e-03, 2.45613791e-03, ...,\n",
              "          1.27885975e-02, 9.56386805e-01, 5.49389161e-02], dtype=float32),\n",
              "   array([4.8865011e-04, 4.7081714e-03, 2.5612058e-03, ..., 2.2939935e-01,\n",
              "          1.0439876e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9959699e-04, 5.1211151e-03, 2.1345161e-03, ..., 7.1544774e-02,\n",
              "          8.9474165e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6827766e-04, 4.8090066e-03, 1.9164955e-03, ..., 3.8474506e-01,\n",
              "          5.4669684e-01, 1.9171936e-03], dtype=float32),\n",
              "   array([3.7438364e-04, 6.7167063e-03, 2.6911797e-03, ..., 3.0630478e-01,\n",
              "          6.5073037e-01, 1.1480711e-02], dtype=float32),\n",
              "   array([3.7606742e-04, 5.8063678e-03, 2.5687704e-03, ..., 2.3052143e-02,\n",
              "          8.9318776e-01, 2.0904824e-02], dtype=float32),\n",
              "   array([4.8180384e-04, 4.6540932e-03, 2.1629520e-03, ..., 6.7845476e-01,\n",
              "          6.6003692e-01, 6.4667580e-03], dtype=float32),\n",
              "   array([4.9390458e-04, 5.0636665e-03, 2.1443625e-03, ..., 2.7343148e-01,\n",
              "          1.0289967e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3405187e-04, 6.6912910e-03, 2.2640612e-03, ..., 6.3374501e-01,\n",
              "          5.3397644e-01, 5.7872545e-02], dtype=float32)],\n",
              "  18],\n",
              " [[array([5.0739769e-04, 4.6718302e-03, 2.2374142e-03, ..., 4.8382151e-01,\n",
              "          1.6657249e+00, 3.7887755e-03], dtype=float32),\n",
              "   array([3.4860120e-04, 5.5659460e-03, 2.5651364e-03, ..., 1.2366197e+00,\n",
              "          4.2410040e-01, 2.8315967e-02], dtype=float32),\n",
              "   array([3.5752545e-04, 5.8905720e-03, 2.7811250e-03, ..., 5.1507473e-01,\n",
              "          1.0895588e+00, 1.6254893e-02], dtype=float32),\n",
              "   array([3.6601300e-04, 6.0751573e-03, 2.3880156e-03, ..., 6.0111742e-02,\n",
              "          7.9558134e-01, 5.0697692e-02], dtype=float32),\n",
              "   array([4.7858479e-04, 4.8170728e-03, 2.5739614e-03, ..., 6.6467333e-01,\n",
              "          6.8360525e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5266590e-04, 6.3571925e-03, 2.1302765e-03, ..., 3.0011165e-01,\n",
              "          8.4925812e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3651694e-04, 6.0576419e-03, 2.6299707e-03, ..., 8.4750867e-01,\n",
              "          6.1631858e-01, 9.1165714e-03], dtype=float32),\n",
              "   array([3.6786674e-04, 5.4960311e-03, 2.5038577e-03, ..., 2.1349977e-01,\n",
              "          4.1665590e-01, 1.7456794e-02], dtype=float32),\n",
              "   array([3.3667090e-04, 6.4488072e-03, 2.3789722e-03, ..., 1.2579482e-02,\n",
              "          5.7393783e-01, 9.8853745e-02], dtype=float32),\n",
              "   array([4.4541448e-04, 4.5051142e-03, 2.0959177e-03, ..., 6.1445653e-01,\n",
              "          8.2294947e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9816724e-04, 5.2338182e-03, 1.9583169e-03, ..., 7.8015807e-03,\n",
              "          7.5349736e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.2905623e-04, 5.9917173e-03, 2.4497753e-03, ..., 9.0501094e-01,\n",
              "          2.7315283e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5125090e-04, 6.0272897e-03, 2.5287066e-03, ..., 3.4724590e-01,\n",
              "          5.7254672e-01, 1.7251253e-02], dtype=float32),\n",
              "   array([3.9734980e-04, 6.2763793e-03, 2.7784766e-03, ..., 2.2275212e-01,\n",
              "          7.9565990e-01, 5.7460447e-03], dtype=float32),\n",
              "   array([3.6091107e-04, 5.9763794e-03, 2.2606917e-03, ..., 2.5667755e-02,\n",
              "          5.7792258e-01, 2.6613342e-02], dtype=float32),\n",
              "   array([4.28701111e-04, 4.86765010e-03, 2.32844334e-03, ...,\n",
              "          1.01962656e-01, 1.08119464e+00, 1.38945834e-04], dtype=float32)],\n",
              "  16],\n",
              " [[array([3.5445092e-04, 6.1480575e-03, 2.1907417e-03, ..., 1.9164371e-01,\n",
              "          6.0980904e-01, 8.8177487e-02], dtype=float32),\n",
              "   array([3.6671120e-04, 5.6647039e-03, 2.1155912e-03, ..., 2.7300933e-01,\n",
              "          5.8881128e-01, 2.7020580e-01], dtype=float32),\n",
              "   array([3.3377658e-04, 6.2684114e-03, 2.4001084e-03, ..., 3.3594382e-01,\n",
              "          3.6615282e-01, 7.0865624e-02], dtype=float32),\n",
              "   array([3.8740810e-04, 5.8127441e-03, 2.6749698e-03, ..., 1.9666581e-01,\n",
              "          6.6978675e-01, 1.1339545e-02], dtype=float32),\n",
              "   array([3.5818148e-04, 6.0405773e-03, 2.7127785e-03, ..., 5.4806739e-02,\n",
              "          6.8528843e-01, 2.6096990e-02], dtype=float32),\n",
              "   array([5.0193944e-04, 4.8155920e-03, 2.5052289e-03, ..., 4.3370706e-01,\n",
              "          9.4937128e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4810589e-04, 5.5677136e-03, 1.9101367e-03, ..., 1.2751646e-01,\n",
              "          9.6600515e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3383793e-04, 5.7575260e-03, 2.5758501e-03, ..., 4.1385490e-01,\n",
              "          4.2416227e-01, 3.4010582e-02], dtype=float32),\n",
              "   array([3.8643682e-04, 5.6144185e-03, 2.8855433e-03, ..., 1.4296371e-01,\n",
              "          9.9321365e-01, 2.8972416e-03], dtype=float32),\n",
              "   array([3.6747553e-04, 4.8114886e-03, 2.6088126e-03, ..., 3.7437066e-01,\n",
              "          7.5864047e-01, 5.0362792e-02], dtype=float32),\n",
              "   array([5.0198444e-04, 4.7914353e-03, 2.2602326e-03, ..., 5.1592320e-01,\n",
              "          9.6577787e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.8131493e-04, 4.8404103e-03, 1.9513750e-03, ..., 4.7856742e-01,\n",
              "          8.7139261e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.9417454e-04, 5.9934654e-03, 2.6430252e-03, ..., 4.8397991e-01,\n",
              "          4.7116449e-01, 1.7032038e-02], dtype=float32),\n",
              "   array([3.91136244e-04, 6.06494583e-03, 2.53090612e-03, ...,\n",
              "          1.07716754e-01, 8.73587787e-01, 5.89996316e-02], dtype=float32),\n",
              "   array([3.8266298e-04, 5.9974249e-03, 2.4951075e-03, ..., 5.7011261e-03,\n",
              "          8.3368558e-01, 1.1398197e-02], dtype=float32),\n",
              "   array([4.6338033e-04, 4.3859477e-03, 2.1487402e-03, ..., 2.9226038e-01,\n",
              "          8.6309582e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6090016e-04, 5.8328388e-03, 1.8797283e-03, ..., 1.0675900e-01,\n",
              "          8.1996822e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6931696e-04, 5.0158524e-03, 1.9780775e-03, ..., 2.3672526e-01,\n",
              "          7.1293116e-01, 1.1383781e-02], dtype=float32),\n",
              "   array([3.5321192e-04, 4.8051877e-03, 2.6685882e-03, ..., 4.9037489e-01,\n",
              "          4.6802652e-01, 4.9271146e-03], dtype=float32),\n",
              "   array([3.3369899e-04, 5.3567225e-03, 2.4794359e-03, ..., 3.6514025e-02,\n",
              "          4.6411449e-01, 3.3467058e-02], dtype=float32),\n",
              "   array([4.8277713e-04, 5.0981315e-03, 2.5523922e-03, ..., 8.8397637e-02,\n",
              "          1.0158926e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([5.2550208e-04, 5.4935580e-03, 2.1690282e-03, ..., 2.2839287e-01,\n",
              "          9.3747437e-01, 0.0000000e+00], dtype=float32)],\n",
              "  22],\n",
              " [[array([3.7019796e-04, 6.4469315e-03, 2.1997709e-03, ..., 3.6713165e-01,\n",
              "          4.9454129e-01, 8.0352224e-02], dtype=float32),\n",
              "   array([3.6620477e-04, 6.2159006e-03, 2.0912285e-03, ..., 1.6499875e-01,\n",
              "          5.2106249e-01, 1.9105192e-01], dtype=float32),\n",
              "   array([3.5040156e-04, 5.7144389e-03, 2.1958712e-03, ..., 4.3604532e-01,\n",
              "          4.5853740e-01, 1.3759144e-01], dtype=float32),\n",
              "   array([3.6357279e-04, 6.1659240e-03, 2.3139634e-03, ..., 8.8162112e-01,\n",
              "          2.8370962e-01, 1.1916702e-02], dtype=float32),\n",
              "   array([3.7463207e-04, 5.3953691e-03, 2.6528679e-03, ..., 2.0691355e-01,\n",
              "          4.4166163e-01, 2.4495982e-02], dtype=float32),\n",
              "   array([3.7130935e-04, 5.2447664e-03, 2.5554872e-03, ..., 6.1404128e-02,\n",
              "          5.7284409e-01, 2.0903779e-02], dtype=float32),\n",
              "   array([4.9077399e-04, 4.3023345e-03, 2.1028777e-03, ..., 1.6580205e-01,\n",
              "          7.0253366e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5498111e-04, 4.8904493e-03, 1.8630695e-03, ..., 1.8318992e-03,\n",
              "          8.5637283e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3693554e-04, 7.1792109e-03, 2.3359465e-03, ..., 8.9421892e-01,\n",
              "          5.9311467e-01, 7.3339874e-03], dtype=float32),\n",
              "   array([3.7685386e-04, 5.6912815e-03, 2.4579230e-03, ..., 2.3008747e-01,\n",
              "          4.7391659e-01, 1.9453952e-02], dtype=float32),\n",
              "   array([3.8119918e-04, 5.6910273e-03, 2.7245602e-03, ..., 4.6672802e-02,\n",
              "          8.5809934e-01, 2.3628818e-02], dtype=float32),\n",
              "   array([4.9671187e-04, 4.7398987e-03, 1.7477432e-03, ..., 3.4813690e-01,\n",
              "          5.9131199e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.2766359e-04, 5.2018226e-03, 1.6258439e-03, ..., 1.3154870e-01,\n",
              "          8.4350616e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4395317e-04, 7.3642847e-03, 2.3227613e-03, ..., 7.6824319e-01,\n",
              "          4.0395090e-01, 2.4526343e-02], dtype=float32),\n",
              "   array([3.6055740e-04, 5.2756732e-03, 2.3216766e-03, ..., 2.7734983e-01,\n",
              "          5.0315708e-01, 3.7387732e-02], dtype=float32),\n",
              "   array([3.9621469e-04, 5.8281608e-03, 2.2883066e-03, ..., 1.3217495e-01,\n",
              "          7.7691555e-01, 5.7040997e-02], dtype=float32),\n",
              "   array([4.7587731e-04, 5.0044470e-03, 1.7954101e-03, ..., 1.3524091e-01,\n",
              "          7.1421134e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9519842e-04, 5.1921043e-03, 1.9415608e-03, ..., 9.0908907e-02,\n",
              "          9.7095048e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3895799e-04, 6.4503173e-03, 2.2914622e-03, ..., 7.4445266e-01,\n",
              "          3.8579011e-01, 4.7411644e-03], dtype=float32),\n",
              "   array([3.8418660e-04, 5.6927409e-03, 2.7376236e-03, ..., 7.3170774e-03,\n",
              "          6.9727427e-01, 1.1494090e-03], dtype=float32),\n",
              "   array([3.7887527e-04, 5.2296324e-03, 2.4414482e-03, ..., 4.1232429e-02,\n",
              "          9.6030205e-01, 5.2205600e-02], dtype=float32),\n",
              "   array([4.5224102e-04, 4.4844304e-03, 1.5772895e-03, ..., 7.2019160e-02,\n",
              "          1.1551248e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.34528687e-04, 5.36297308e-03, 1.84912840e-03, ...,\n",
              "          1.03477105e-01, 6.28295839e-01, 0.00000000e+00], dtype=float32),\n",
              "   array([4.0149159e-04, 5.4434435e-03, 2.5387271e-03, ..., 1.0538756e+00,\n",
              "          4.5838547e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.2403119e-04, 6.2046824e-03, 2.2686415e-03, ..., 3.5351896e-01,\n",
              "          4.6232283e-01, 3.0293888e-03], dtype=float32)],\n",
              "  25],\n",
              " [[array([3.6138561e-04, 5.7015540e-03, 2.1336053e-03, ..., 1.2887810e-01,\n",
              "          4.5145378e-01, 1.4517468e-01], dtype=float32),\n",
              "   array([3.6607223e-04, 6.1906213e-03, 2.1680500e-03, ..., 5.1962292e-01,\n",
              "          5.4434162e-01, 5.0793730e-02], dtype=float32),\n",
              "   array([3.6476413e-04, 5.9160469e-03, 2.4401757e-03, ..., 1.1465101e+00,\n",
              "          3.3774135e-01, 1.0690104e-02], dtype=float32),\n",
              "   array([3.61515617e-04, 5.79779316e-03, 2.56436877e-03, ...,\n",
              "          1.05501875e-01, 4.88431543e-01, 3.91542651e-02], dtype=float32),\n",
              "   array([3.7742915e-04, 5.7979976e-03, 2.3640236e-03, ..., 2.7933748e-02,\n",
              "          7.7149653e-01, 2.5629912e-02], dtype=float32),\n",
              "   array([4.8622245e-04, 4.4700573e-03, 1.9770993e-03, ..., 3.2666692e-01,\n",
              "          8.3194113e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9086951e-04, 5.0494764e-03, 2.3269418e-03, ..., 7.6515019e-02,\n",
              "          1.0561957e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5030133e-04, 6.3210209e-03, 2.4832636e-03, ..., 5.7292640e-01,\n",
              "          2.8476155e-01, 2.3622036e-02], dtype=float32),\n",
              "   array([3.6774151e-04, 5.0426535e-03, 2.5783423e-03, ..., 7.7055299e-01,\n",
              "          3.5037321e-01, 1.5278021e-03], dtype=float32),\n",
              "   array([3.9300209e-04, 5.7576280e-03, 2.4280904e-03, ..., 1.1152214e-01,\n",
              "          1.0639844e+00, 6.4224616e-02], dtype=float32),\n",
              "   array([4.7633375e-04, 5.1779505e-03, 1.9197249e-03, ..., 1.8990731e-01,\n",
              "          7.8401154e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6943524e-04, 5.1727220e-03, 2.1073890e-03, ..., 4.3607015e-02,\n",
              "          9.7232968e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8263868e-04, 6.2465691e-03, 2.4373024e-03, ..., 4.9919558e-01,\n",
              "          4.2026350e-01, 9.3001379e-03], dtype=float32),\n",
              "   array([3.7839651e-04, 5.2684499e-03, 2.5326957e-03, ..., 2.7028835e-01,\n",
              "          6.9112265e-01, 2.2295896e-02], dtype=float32),\n",
              "   array([3.8884097e-04, 6.0114623e-03, 2.7243395e-03, ..., 1.7935841e-01,\n",
              "          9.2503881e-01, 4.9980313e-02], dtype=float32),\n",
              "   array([4.6426180e-04, 4.2728302e-03, 1.7065242e-03, ..., 5.0040615e-01,\n",
              "          1.0757091e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([5.0729065e-04, 5.1531633e-03, 2.0377347e-03, ..., 1.3415997e-01,\n",
              "          9.5630044e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6429725e-04, 4.6035466e-03, 2.0908860e-03, ..., 2.8233755e-01,\n",
              "          6.0056329e-01, 5.5617592e-03], dtype=float32),\n",
              "   array([3.5378267e-04, 6.0130064e-03, 2.4425227e-03, ..., 4.8981586e-01,\n",
              "          5.1326030e-01, 1.6558671e-02], dtype=float32),\n",
              "   array([3.7485501e-04, 5.9454245e-03, 2.3741138e-03, ..., 2.6494337e-02,\n",
              "          6.7857158e-01, 4.2655304e-02], dtype=float32),\n",
              "   array([5.1714131e-04, 5.0918451e-03, 1.8201864e-03, ..., 2.2384852e-01,\n",
              "          7.6956409e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.8411707e-04, 5.6254561e-03, 1.8513342e-03, ..., 1.0900602e-01,\n",
              "          9.5213437e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5078224e-04, 6.6149458e-03, 2.3834063e-03, ..., 6.2851346e-01,\n",
              "          2.6164374e-01, 3.3451539e-02], dtype=float32),\n",
              "   array([3.6161058e-04, 5.3607221e-03, 2.5947732e-03, ..., 3.9236549e-01,\n",
              "          3.8385102e-01, 2.6232963e-02], dtype=float32),\n",
              "   array([3.8611289e-04, 6.1797621e-03, 2.3348285e-03, ..., 2.0044447e-01,\n",
              "          6.5399992e-01, 7.3550597e-02], dtype=float32),\n",
              "   array([4.3773933e-04, 4.4289194e-03, 1.8452909e-03, ..., 3.3464110e-01,\n",
              "          9.7094673e-01, 1.1823119e-02], dtype=float32)],\n",
              "  26],\n",
              " [[array([5.9471535e-04, 4.0907110e-03, 2.0739667e-03, ..., 2.9874933e-01,\n",
              "          7.7833462e-01, 3.2401078e-03], dtype=float32),\n",
              "   array([4.9111067e-04, 4.4469964e-03, 2.3435464e-03, ..., 1.4710335e-01,\n",
              "          1.5974463e+00, 1.2873307e-02], dtype=float32),\n",
              "   array([3.5575073e-04, 5.7009594e-03, 2.0803409e-03, ..., 7.0975438e-02,\n",
              "          5.7838690e-01, 7.1116537e-02], dtype=float32),\n",
              "   array([3.3987459e-04, 6.0867402e-03, 2.4067017e-03, ..., 4.8990527e-01,\n",
              "          3.9943278e-01, 9.6983016e-03], dtype=float32),\n",
              "   array([3.4094395e-04, 5.2565522e-03, 2.4167767e-03, ..., 3.5368839e-01,\n",
              "          3.7941971e-01, 1.1644118e-02], dtype=float32),\n",
              "   array([3.6971844e-04, 5.2973316e-03, 2.4209432e-03, ..., 3.5405937e-01,\n",
              "          5.2404600e-01, 1.1321355e-02], dtype=float32),\n",
              "   array([4.3782219e-04, 4.3450259e-03, 1.9751685e-03, ..., 3.6202493e-01,\n",
              "          8.0305147e-01, 1.7065564e-03], dtype=float32),\n",
              "   array([4.3376625e-04, 4.9671186e-03, 1.9774723e-03, ..., 6.1107043e-02,\n",
              "          7.4278027e-01, 1.9842001e-02], dtype=float32),\n",
              "   array([3.5124941e-04, 6.7058066e-03, 2.5170622e-03, ..., 3.4026632e-01,\n",
              "          5.1327318e-01, 1.9392315e-02], dtype=float32),\n",
              "   array([3.4846427e-04, 5.3173783e-03, 2.5107774e-03, ..., 8.3057785e-01,\n",
              "          2.3464195e-01, 1.9368858e-03], dtype=float32),\n",
              "   array([3.9509969e-04, 5.4802359e-03, 2.2329008e-03, ..., 6.8529584e-02,\n",
              "          9.4499791e-01, 8.0708183e-02], dtype=float32),\n",
              "   array([4.4234892e-04, 4.3151067e-03, 1.6738490e-03, ..., 2.1645083e-01,\n",
              "          7.9661107e-01, 9.7359298e-03], dtype=float32),\n",
              "   array([4.5621372e-04, 5.2330871e-03, 1.9444603e-03, ..., 1.2110221e-01,\n",
              "          8.8347173e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6012015e-04, 4.9626534e-03, 1.8143903e-03, ..., 1.4443946e-01,\n",
              "          6.9816941e-01, 1.1626383e-02], dtype=float32),\n",
              "   array([3.6784704e-04, 5.2472944e-03, 2.5242867e-03, ..., 6.6125363e-01,\n",
              "          5.6894314e-01, 1.6811080e-02], dtype=float32),\n",
              "   array([3.7246506e-04, 6.0600778e-03, 2.4115760e-03, ..., 6.5774530e-02,\n",
              "          4.8562378e-01, 4.1462090e-03], dtype=float32),\n",
              "   array([4.5411228e-04, 5.0201463e-03, 1.8655910e-03, ..., 1.6353558e-01,\n",
              "          6.3983858e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4237470e-04, 4.6237702e-03, 1.9405324e-03, ..., 2.0987187e-01,\n",
              "          1.0592815e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7400785e-04, 5.9552575e-03, 2.3832340e-03, ..., 9.3945265e-01,\n",
              "          1.0621240e+00, 5.6842162e-04], dtype=float32),\n",
              "   array([3.5438489e-04, 6.7781345e-03, 2.3693689e-03, ..., 2.0246021e-01,\n",
              "          4.4716406e-01, 5.6733042e-02], dtype=float32),\n",
              "   array([3.6733199e-04, 5.4439697e-03, 2.4801649e-03, ..., 1.1581333e+00,\n",
              "          3.0230090e-01, 2.0453465e-04], dtype=float32),\n",
              "   array([3.7443737e-04, 5.9540495e-03, 2.5635681e-03, ..., 5.6116438e-01,\n",
              "          4.7655043e-01, 1.8123434e-03], dtype=float32),\n",
              "   array([3.7396920e-04, 5.5535915e-03, 2.3248668e-03, ..., 3.9996478e-01,\n",
              "          5.8434236e-01, 4.7155764e-02], dtype=float32),\n",
              "   array([4.4416334e-04, 4.6230112e-03, 1.7809242e-03, ..., 3.1176791e-01,\n",
              "          7.2956443e-01, 0.0000000e+00], dtype=float32)],\n",
              "  24],\n",
              " [[array([6.0320698e-04, 3.4899085e-03, 2.7386891e-03, ..., 4.9075190e-02,\n",
              "          1.5107706e+00, 1.4551599e-02], dtype=float32),\n",
              "   array([3.6631193e-04, 6.4066565e-03, 2.0994616e-03, ..., 4.8369769e-02,\n",
              "          5.0254267e-01, 9.8293111e-02], dtype=float32),\n",
              "   array([3.7728847e-04, 6.0682613e-03, 2.4869998e-03, ..., 3.8439980e-01,\n",
              "          6.0551012e-01, 7.1271442e-02], dtype=float32),\n",
              "   array([3.6839920e-04, 5.5180048e-03, 2.6156839e-03, ..., 4.6442491e-01,\n",
              "          3.7644827e-01, 1.1822239e-02], dtype=float32),\n",
              "   array([3.8086771e-04, 5.5694613e-03, 2.4947564e-03, ..., 4.5922232e-01,\n",
              "          6.6868865e-01, 2.4393303e-02], dtype=float32),\n",
              "   array([4.7695939e-04, 5.1783146e-03, 2.1392598e-03, ..., 7.7340908e-02,\n",
              "          6.8165249e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5123647e-04, 4.5895595e-03, 1.9449724e-03, ..., 4.6204124e-03,\n",
              "          8.3515900e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4567140e-04, 6.4158062e-03, 2.4514012e-03, ..., 8.8654041e-01,\n",
              "          2.7258605e-01, 5.0519682e-03], dtype=float32),\n",
              "   array([3.7110780e-04, 5.8271028e-03, 2.6199154e-03, ..., 4.8056552e-01,\n",
              "          6.0100293e-01, 1.0179946e-02], dtype=float32),\n",
              "   array([3.6664403e-04, 6.0816980e-03, 2.2673267e-03, ..., 1.8437378e-01,\n",
              "          6.2528867e-01, 4.0348407e-02], dtype=float32),\n",
              "   array([4.4107859e-04, 4.8641637e-03, 1.8322638e-03, ..., 3.6012408e-01,\n",
              "          7.5184679e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9655279e-04, 4.7517833e-03, 2.3200272e-03, ..., 1.4891639e-01,\n",
              "          1.0552884e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5906758e-04, 6.3367249e-03, 2.3854396e-03, ..., 5.6733185e-01,\n",
              "          2.0172614e-01, 1.1794059e-02], dtype=float32),\n",
              "   array([3.6498974e-04, 5.3808196e-03, 2.5838432e-03, ..., 7.6874942e-01,\n",
              "          3.4119213e-01, 1.4776804e-02], dtype=float32),\n",
              "   array([3.8898626e-04, 4.8194909e-03, 2.3065899e-03, ..., 2.5764719e-02,\n",
              "          6.7632550e-01, 1.8616738e-02], dtype=float32),\n",
              "   array([4.4283978e-04, 4.6486920e-03, 1.7058685e-03, ..., 3.3849156e-01,\n",
              "          6.8966955e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.9025496e-04, 5.3819255e-03, 2.2673756e-03, ..., 1.5942332e-01,\n",
              "          7.5318241e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4001432e-04, 6.5344870e-03, 2.3157047e-03, ..., 5.1752645e-01,\n",
              "          4.9303031e-01, 1.3282886e-02], dtype=float32),\n",
              "   array([3.4286961e-04, 5.8163577e-03, 2.4033219e-03, ..., 7.3230439e-01,\n",
              "          4.1050732e-01, 3.1473298e-04], dtype=float32),\n",
              "   array([3.3609907e-04, 6.6435654e-03, 2.3572745e-03, ..., 3.0734864e-01,\n",
              "          5.4942214e-01, 1.1786411e-03], dtype=float32),\n",
              "   array([0.00035734, 0.00663884, 0.00212578, ..., 0.35056737, 0.23633677,\n",
              "          0.0097657 ], dtype=float32),\n",
              "   array([4.4222898e-04, 4.5559830e-03, 1.7458212e-03, ..., 3.8243383e-01,\n",
              "          6.7085826e-01, 0.0000000e+00], dtype=float32)],\n",
              "  22],\n",
              " [[array([3.7573834e-04, 6.6860178e-03, 2.0214168e-03, ..., 3.4972739e-01,\n",
              "          6.9320583e-01, 2.4193057e-01], dtype=float32),\n",
              "   array([3.3855956e-04, 6.5926844e-03, 1.8612068e-03, ..., 1.3577747e-01,\n",
              "          4.9459431e-01, 7.3219948e-02], dtype=float32),\n",
              "   array([3.4674045e-04, 6.2591904e-03, 2.4739760e-03, ..., 7.7408344e-01,\n",
              "          4.1749573e-01, 1.2204801e-02], dtype=float32),\n",
              "   array([3.8050528e-04, 5.5944319e-03, 2.5461316e-03, ..., 7.8670043e-01,\n",
              "          5.6300968e-01, 2.0228015e-02], dtype=float32),\n",
              "   array([3.8718421e-04, 6.5009310e-03, 2.3524219e-03, ..., 4.0401253e-01,\n",
              "          6.8624377e-01, 8.6950459e-02], dtype=float32),\n",
              "   array([4.5375820e-04, 4.7729192e-03, 1.8786838e-03, ..., 1.0582832e-01,\n",
              "          4.9392360e-01, 3.9622602e-03], dtype=float32),\n",
              "   array([4.5704900e-04, 4.7449912e-03, 2.0199157e-03, ..., 7.9522669e-02,\n",
              "          8.2425773e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3929580e-04, 6.0661747e-03, 2.4660903e-03, ..., 5.5364227e-01,\n",
              "          5.0306809e-01, 8.2402462e-03], dtype=float32),\n",
              "   array([3.7367741e-04, 5.5023078e-03, 2.5638323e-03, ..., 4.8682675e-01,\n",
              "          5.4310185e-01, 9.2502600e-03], dtype=float32),\n",
              "   array([4.0745881e-04, 5.6682769e-03, 2.3188980e-03, ..., 1.2389575e-02,\n",
              "          7.8844047e-01, 1.7263021e-02], dtype=float32),\n",
              "   array([4.8633886e-04, 4.7230539e-03, 1.9893879e-03, ..., 2.7374700e-01,\n",
              "          7.2670192e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.7606134e-04, 5.3800568e-03, 2.0686802e-03, ..., 2.7726048e-01,\n",
              "          8.1414115e-01, 1.1451863e-02], dtype=float32),\n",
              "   array([0.00033872, 0.0059983 , 0.00226954, ..., 0.27384278, 0.27543336,\n",
              "          0.01329182], dtype=float32),\n",
              "   array([3.7015718e-04, 6.0950737e-03, 2.3884859e-03, ..., 1.2723441e+00,\n",
              "          2.5350249e-01, 5.1148646e-03], dtype=float32),\n",
              "   array([3.4064069e-04, 5.1444061e-03, 2.5551571e-03, ..., 1.2473322e+00,\n",
              "          4.4934845e-01, 3.2563377e-03], dtype=float32),\n",
              "   array([4.0196674e-04, 5.7995892e-03, 2.4923848e-03, ..., 2.2274619e-01,\n",
              "          9.1672701e-01, 1.0171174e-03], dtype=float32),\n",
              "   array([4.0880233e-04, 4.8279441e-03, 2.0522373e-03, ..., 3.2896483e-01,\n",
              "          8.5661882e-01, 4.9919263e-03], dtype=float32),\n",
              "   array([4.6544126e-04, 5.2864966e-03, 2.1744289e-03, ..., 4.7122985e-02,\n",
              "          9.9491960e-01, 0.0000000e+00], dtype=float32)],\n",
              "  18],\n",
              " [[array([3.5677676e-04, 5.9325132e-03, 2.0498792e-03, ..., 1.5865538e-01,\n",
              "          4.0671256e-01, 1.6713031e-02], dtype=float32),\n",
              "   array([3.7614588e-04, 6.1646760e-03, 2.1160527e-03, ..., 8.5358366e-02,\n",
              "          6.7373115e-01, 1.4416905e-01], dtype=float32),\n",
              "   array([3.5446370e-04, 5.8303257e-03, 2.3052148e-03, ..., 1.0366884e+00,\n",
              "          1.2000984e-01, 3.6720694e-03], dtype=float32),\n",
              "   array([3.6580017e-04, 6.0288887e-03, 2.4833479e-03, ..., 8.3862430e-01,\n",
              "          4.3449754e-01, 7.2862529e-03], dtype=float32),\n",
              "   array([3.6650736e-04, 5.8847093e-03, 2.4390388e-03, ..., 4.4379696e-01,\n",
              "          7.8140843e-01, 8.5052609e-02], dtype=float32),\n",
              "   array([5.4258970e-04, 5.3703752e-03, 2.1861750e-03, ..., 5.8178997e-01,\n",
              "          6.3943374e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5325910e-04, 5.3433641e-03, 1.8830688e-03, ..., 1.6824236e-02,\n",
              "          7.5168025e-01, 3.8805085e-03], dtype=float32),\n",
              "   array([3.6804093e-04, 6.3044010e-03, 2.4524564e-03, ..., 7.5482959e-01,\n",
              "          3.9156008e-01, 8.7956227e-03], dtype=float32),\n",
              "   array([3.5554930e-04, 5.4289224e-03, 2.5638093e-03, ..., 3.0090022e-01,\n",
              "          4.3983915e-01, 4.0450267e-02], dtype=float32),\n",
              "   array([3.7499928e-04, 5.7892739e-03, 2.1909461e-03, ..., 3.7259772e-01,\n",
              "          8.2164156e-01, 6.5604992e-02], dtype=float32),\n",
              "   array([4.8908184e-04, 4.8784171e-03, 1.7610705e-03, ..., 2.0965953e-01,\n",
              "          1.0932840e+00, 9.3828384e-03], dtype=float32),\n",
              "   array([4.3715874e-04, 4.6531772e-03, 1.7684852e-03, ..., 9.8284088e-02,\n",
              "          7.0184088e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4040437e-04, 6.5007098e-03, 2.3970297e-03, ..., 3.7166727e-01,\n",
              "          2.7604520e-01, 3.0939924e-02], dtype=float32),\n",
              "   array([3.7825364e-04, 6.1288364e-03, 2.5601564e-03, ..., 4.8154044e-01,\n",
              "          7.3065078e-01, 1.2618378e-02], dtype=float32),\n",
              "   array([3.9285608e-04, 5.5835531e-03, 2.1714312e-03, ..., 1.6869523e-02,\n",
              "          7.0703226e-01, 4.8943412e-02], dtype=float32),\n",
              "   array([4.2893118e-04, 4.6257926e-03, 1.9559672e-03, ..., 1.2103370e+00,\n",
              "          6.5393674e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5143650e-04, 5.0121630e-03, 1.7005684e-03, ..., 3.6347353e-01,\n",
              "          8.3055401e-01, 6.3688075e-03], dtype=float32),\n",
              "   array([3.6889466e-04, 5.4958281e-03, 2.2314340e-03, ..., 6.1554819e-01,\n",
              "          6.0697323e-01, 3.4437399e-02], dtype=float32)],\n",
              "  18],\n",
              " [[array([0.00035794, 0.00475054, 0.00230765, ..., 0.1711512 , 0.30704898,\n",
              "          0.        ], dtype=float32),\n",
              "   array([3.8901978e-04, 5.2541676e-03, 2.5712163e-03, ..., 5.1368392e-01,\n",
              "          3.8881719e-01, 5.6830551e-03], dtype=float32),\n",
              "   array([4.7303987e-04, 5.1430282e-03, 2.5010300e-03, ..., 4.1764981e-01,\n",
              "          6.8346232e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4978916e-04, 5.3057736e-03, 1.8633723e-03, ..., 2.0143189e-02,\n",
              "          6.6755199e-01, 2.6386849e-06], dtype=float32),\n",
              "   array([3.3058788e-04, 6.1712121e-03, 2.3237697e-03, ..., 6.1369205e-01,\n",
              "          2.2776368e-01, 1.0709071e-03], dtype=float32),\n",
              "   array([4.0363963e-04, 4.4637080e-03, 2.0423888e-03, ..., 1.8793908e-01,\n",
              "          6.1388445e-01, 2.2838861e-02], dtype=float32),\n",
              "   array([3.9475271e-04, 5.6624375e-03, 2.6379433e-03, ..., 5.8160138e-01,\n",
              "          6.0090685e-01, 2.9117823e-02], dtype=float32),\n",
              "   array([4.85066907e-04, 4.68035508e-03, 2.45694211e-03, ...,\n",
              "          1.16441034e-01, 8.30109656e-01, 0.00000000e+00], dtype=float32),\n",
              "   array([4.4533936e-04, 5.4075196e-03, 1.8169943e-03, ..., 3.4018438e-03,\n",
              "          6.4393270e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5355933e-04, 5.7983794e-03, 2.4018465e-03, ..., 5.1452279e-01,\n",
              "          3.4319231e-01, 7.1603688e-04], dtype=float32),\n",
              "   array([3.9476083e-04, 3.9120042e-03, 2.0952227e-03, ..., 1.2786764e-01,\n",
              "          5.2237612e-01, 1.6303200e-02], dtype=float32),\n",
              "   array([3.7076249e-04, 5.2074254e-03, 2.5713108e-03, ..., 1.7206743e-01,\n",
              "          5.0903362e-01, 1.0479891e-02], dtype=float32),\n",
              "   array([4.49479354e-04, 4.78614355e-03, 2.32825754e-03, ...,\n",
              "          1.02787495e-01, 5.71895540e-01, 0.00000000e+00], dtype=float32)],\n",
              "  13],\n",
              " [[array([3.9404156e-04, 5.6605423e-03, 2.3524961e-03, ..., 4.7168466e-01,\n",
              "          6.0491049e-01, 2.4893381e-02], dtype=float32),\n",
              "   array([3.8406884e-04, 5.5779759e-03, 2.4361513e-03, ..., 6.8386719e-02,\n",
              "          5.3729445e-01, 1.1470303e-02], dtype=float32),\n",
              "   array([4.6917886e-04, 4.6020434e-03, 2.3842361e-03, ..., 1.7283377e-01,\n",
              "          7.6149267e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7654064e-04, 5.9617423e-03, 1.9147517e-03, ..., 1.1151890e-01,\n",
              "          4.8726583e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7459307e-04, 6.0613849e-03, 2.4872092e-03, ..., 9.0158892e-01,\n",
              "          2.4884479e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.2125699e-04, 4.5301071e-03, 2.2823585e-03, ..., 1.7517239e-02,\n",
              "          5.9035838e-01, 3.4602021e-04], dtype=float32),\n",
              "   array([3.6528084e-04, 5.8163740e-03, 2.5946726e-03, ..., 7.1835536e-01,\n",
              "          5.3255135e-01, 3.9387077e-02], dtype=float32),\n",
              "   array([4.7701836e-04, 5.1138122e-03, 2.2196483e-03, ..., 9.9368185e-02,\n",
              "          8.3989412e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.2836805e-04, 4.8710429e-03, 1.8453297e-03, ..., 2.2768231e-01,\n",
              "          7.1046174e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4226960e-04, 6.1351424e-03, 2.3076765e-03, ..., 4.2624381e-01,\n",
              "          3.7160546e-01, 1.0434277e-03], dtype=float32),\n",
              "   array([4.1567822e-04, 4.0083746e-03, 2.1137469e-03, ..., 3.7289125e-01,\n",
              "          4.8700061e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7672656e-04, 5.6385044e-03, 2.6226651e-03, ..., 9.3906029e-04,\n",
              "          6.4830101e-01, 2.1397462e-02], dtype=float32),\n",
              "   array([4.8420220e-04, 4.9794181e-03, 2.1423714e-03, ..., 5.9736066e-02,\n",
              "          9.4513226e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.3301369e-04, 5.3087194e-03, 1.7376861e-03, ..., 4.1875789e-01,\n",
              "          8.2231933e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4807448e-04, 5.9945984e-03, 2.3756737e-03, ..., 3.6468828e-01,\n",
              "          3.9434728e-01, 1.9046903e-03], dtype=float32),\n",
              "   array([4.1234991e-04, 4.2204307e-03, 2.2258910e-03, ..., 1.2172473e-01,\n",
              "          6.0815907e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7296288e-04, 5.6409640e-03, 2.6771976e-03, ..., 2.2706589e-01,\n",
              "          5.6654465e-01, 4.1007977e-02], dtype=float32),\n",
              "   array([4.8351937e-04, 4.8698569e-03, 2.2413745e-03, ..., 1.7875889e-01,\n",
              "          1.1372908e+00, 0.0000000e+00], dtype=float32)],\n",
              "  18],\n",
              " [[array([0.00036721, 0.00441314, 0.00213858, ..., 0.08018043, 0.3189041 ,\n",
              "          0.00446095], dtype=float32),\n",
              "   array([3.7269469e-04, 6.1210990e-03, 2.5959087e-03, ..., 4.1774258e-01,\n",
              "          5.4311019e-01, 1.1676837e-02], dtype=float32),\n",
              "   array([4.3245481e-04, 4.3887766e-03, 2.0576997e-03, ..., 2.1718661e-01,\n",
              "          7.6027459e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.9780847e-04, 5.3953920e-03, 1.7099679e-03, ..., 4.1640490e-02,\n",
              "          1.0137043e+00, 2.3772616e-03], dtype=float32),\n",
              "   array([3.4459101e-04, 6.0307267e-03, 2.4397490e-03, ..., 8.0397236e-01,\n",
              "          4.3485937e-01, 5.7511372e-03], dtype=float32),\n",
              "   array([3.8732152e-04, 4.3449812e-03, 1.9984660e-03, ..., 3.5111032e-02,\n",
              "          7.2174728e-01, 3.5877228e-02], dtype=float32),\n",
              "   array([3.7434621e-04, 6.7243790e-03, 2.5535244e-03, ..., 4.0565774e-01,\n",
              "          6.3150686e-01, 1.0477806e-02], dtype=float32),\n",
              "   array([4.5264637e-04, 4.4520060e-03, 2.3354024e-03, ..., 4.7834921e-01,\n",
              "          1.0430719e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5036364e-04, 5.4960232e-03, 1.7557007e-03, ..., 1.8724155e-01,\n",
              "          9.8477346e-01, 2.2773698e-03], dtype=float32)],\n",
              "  9],\n",
              " [[array([3.5313080e-04, 5.8704815e-03, 2.3082304e-03, ..., 9.9779534e-01,\n",
              "          2.8319997e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([0.000381  , 0.00448241, 0.00191947, ..., 0.35103008, 0.3082271 ,\n",
              "          0.01529185], dtype=float32),\n",
              "   array([3.6867239e-04, 5.9478125e-03, 2.5252751e-03, ..., 5.2263099e-01,\n",
              "          6.6960114e-01, 4.0815398e-02], dtype=float32),\n",
              "   array([4.6694797e-04, 4.8252163e-03, 2.1278008e-03, ..., 4.6368551e-01,\n",
              "          8.4809411e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.9896506e-04, 5.0000283e-03, 1.9917171e-03, ..., 1.8260155e-02,\n",
              "          6.3322800e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5757574e-04, 6.5282350e-03, 2.3288392e-03, ..., 4.3172649e-01,\n",
              "          3.0096972e-01, 8.2376236e-03], dtype=float32),\n",
              "   array([3.9247036e-04, 4.2138910e-03, 2.0840403e-03, ..., 5.9341196e-02,\n",
              "          4.8353845e-01, 5.4432984e-02], dtype=float32),\n",
              "   array([3.6863299e-04, 6.7544891e-03, 2.6069721e-03, ..., 3.7190422e-01,\n",
              "          6.5307724e-01, 6.2269829e-02], dtype=float32),\n",
              "   array([4.6947424e-04, 4.3583149e-03, 2.1565405e-03, ..., 2.1046554e-01,\n",
              "          7.6287812e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5143714e-04, 5.2192211e-03, 2.0473066e-03, ..., 6.2315747e-02,\n",
              "          6.1376393e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6879478e-04, 6.2071588e-03, 2.3338527e-03, ..., 4.2162389e-01,\n",
              "          4.4267657e-01, 7.4419999e-03], dtype=float32),\n",
              "   array([4.2455594e-04, 4.7667609e-03, 2.0388830e-03, ..., 7.2290748e-02,\n",
              "          4.6879598e-01, 1.3755762e-03], dtype=float32),\n",
              "   array([3.8002286e-04, 5.4421462e-03, 2.6096459e-03, ..., 3.0234638e-01,\n",
              "          5.4827327e-01, 1.9959658e-02], dtype=float32),\n",
              "   array([5.1335385e-04, 5.0092214e-03, 2.3820736e-03, ..., 2.4264181e-01,\n",
              "          8.5991931e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4633983e-04, 6.6600638e-03, 1.7114533e-03, ..., 3.1880713e-01,\n",
              "          8.5455227e-01, 3.9397961e-01], dtype=float32)],\n",
              "  15],\n",
              " [[array([3.4348282e-04, 5.7554264e-03, 2.0833123e-03, ..., 3.7187961e-01,\n",
              "          3.9325595e-01, 8.3037674e-05], dtype=float32),\n",
              "   array([3.5153836e-04, 5.9871455e-03, 2.4217875e-03, ..., 4.1296753e-01,\n",
              "          2.5652424e-01, 1.1892025e-03], dtype=float32),\n",
              "   array([3.4654033e-04, 6.1899042e-03, 2.5324635e-03, ..., 1.1154710e+00,\n",
              "          7.2270048e-01, 1.0838509e-02], dtype=float32),\n",
              "   array([3.6020810e-04, 5.3095184e-03, 2.4610483e-03, ..., 3.7180811e-01,\n",
              "          5.2723575e-01, 7.9613198e-03], dtype=float32),\n",
              "   array([4.2121351e-04, 4.8917090e-03, 2.2855652e-03, ..., 1.4667551e-02,\n",
              "          7.0800495e-01, 2.0903731e-02], dtype=float32),\n",
              "   array([3.4879736e-04, 6.0165264e-03, 2.4959741e-03, ..., 2.4564610e-01,\n",
              "          5.7534748e-01, 1.8482417e-02], dtype=float32),\n",
              "   array([4.4307631e-04, 4.2707049e-03, 2.0557526e-03, ..., 1.6175300e-01,\n",
              "          6.9913936e-01, 4.0881845e-04], dtype=float32)],\n",
              "  7],\n",
              " [[array([3.4922358e-04, 5.7910271e-03, 2.2718101e-03, ..., 4.9347779e-01,\n",
              "          2.8811231e-01, 2.5104969e-03], dtype=float32),\n",
              "   array([0.00034863, 0.00479196, 0.00243974, ..., 0.21503308, 0.32621667,\n",
              "          0.08379641], dtype=float32),\n",
              "   array([3.4678812e-04, 5.4508452e-03, 2.3938576e-03, ..., 5.5500585e-01,\n",
              "          4.5086151e-01, 2.6417159e-02], dtype=float32),\n",
              "   array([4.4285442e-04, 4.0635508e-03, 2.6002573e-03, ..., 2.6347279e-03,\n",
              "          5.8685374e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6421849e-04, 5.5246726e-03, 2.5606148e-03, ..., 5.2561283e-01,\n",
              "          7.2218877e-01, 4.7799330e-03], dtype=float32),\n",
              "   array([4.6356255e-04, 4.1897940e-03, 2.2532209e-03, ..., 1.6723166e-01,\n",
              "          8.5858577e-01, 4.9931323e-04], dtype=float32),\n",
              "   array([4.5971858e-04, 4.5507997e-03, 2.5205479e-03, ..., 1.6841643e-01,\n",
              "          8.2901824e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5313613e-04, 5.3940481e-03, 2.4155010e-03, ..., 3.5539868e-01,\n",
              "          4.4131899e-01, 2.2839477e-02], dtype=float32),\n",
              "   array([4.3389367e-04, 4.3525849e-03, 2.4389969e-03, ..., 1.5511677e-01,\n",
              "          5.8159310e-01, 2.6741365e-03], dtype=float32),\n",
              "   array([3.5861135e-04, 6.2582656e-03, 2.5147947e-03, ..., 5.7711673e-01,\n",
              "          4.8913738e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5370741e-04, 4.7980780e-03, 1.9605514e-03, ..., 4.7684801e-01,\n",
              "          6.9158763e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.2300788e-04, 5.3686681e-03, 2.6491485e-03, ..., 1.9073987e-03,\n",
              "          8.3469218e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5963632e-04, 5.7851956e-03, 2.5517344e-03, ..., 5.1112825e-01,\n",
              "          3.7794143e-01, 8.8403039e-02], dtype=float32),\n",
              "   array([4.5697388e-04, 4.6218778e-03, 2.1473246e-03, ..., 3.0067533e-03,\n",
              "          6.6568530e-01, 7.9874508e-03], dtype=float32),\n",
              "   array([3.7147841e-04, 5.1032482e-03, 2.5222944e-03, ..., 7.4821955e-01,\n",
              "          3.4832710e-01, 7.9373189e-04], dtype=float32)],\n",
              "  15],\n",
              " [[array([3.4159946e-04, 5.8352030e-03, 2.3956336e-03, ..., 4.6311724e-01,\n",
              "          5.0186080e-01, 3.1687485e-03], dtype=float32),\n",
              "   array([0.00035807, 0.00540468, 0.00244413, ..., 0.35340047, 0.24781436,\n",
              "          0.02075655], dtype=float32),\n",
              "   array([3.4627842e-04, 5.0527724e-03, 2.3872969e-03, ..., 1.0474424e-01,\n",
              "          3.5812095e-01, 2.2854974e-02], dtype=float32),\n",
              "   array([3.4212184e-04, 5.9389239e-03, 2.5816830e-03, ..., 5.0867343e-01,\n",
              "          6.0792607e-01, 2.6319429e-02], dtype=float32),\n",
              "   array([4.4866302e-04, 4.4070072e-03, 1.9841113e-03, ..., 5.2246237e-03,\n",
              "          6.3860011e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6500974e-04, 6.0428623e-03, 2.6361041e-03, ..., 5.7472360e-01,\n",
              "          6.2273157e-01, 8.9135498e-04], dtype=float32),\n",
              "   array([5.4062920e-04, 5.0366553e-03, 2.3637686e-03, ..., 5.9292430e-01,\n",
              "          5.3282905e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.2547355e-04, 5.4326183e-03, 1.9405807e-03, ..., 3.4201879e-03,\n",
              "          1.0129248e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8005481e-04, 5.3856010e-03, 2.4885316e-03, ..., 1.3430344e+00,\n",
              "          2.6906565e-01, 3.7587245e-03], dtype=float32),\n",
              "   array([4.3843267e-04, 4.5821294e-03, 2.2009942e-03, ..., 2.0117098e-02,\n",
              "          6.6977930e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8146129e-04, 4.9588215e-03, 2.5892644e-03, ..., 8.0258077e-01,\n",
              "          3.4408790e-01, 1.3786176e-02], dtype=float32),\n",
              "   array([4.3931787e-04, 4.7260649e-03, 2.1185842e-03, ..., 4.5098376e-01,\n",
              "          9.3833828e-01, 0.0000000e+00], dtype=float32)],\n",
              "  12],\n",
              " [[array([0.00034027, 0.00616725, 0.00235397, ..., 0.0835413 , 0.3070553 ,\n",
              "          0.02434096], dtype=float32),\n",
              "   array([3.7183877e-04, 5.6160893e-03, 2.4411629e-03, ..., 4.3972179e-01,\n",
              "          2.7593055e-01, 2.9534094e-02], dtype=float32),\n",
              "   array([3.5530183e-04, 5.6785443e-03, 2.4173397e-03, ..., 4.4838959e-01,\n",
              "          4.7766510e-01, 1.3749797e-02], dtype=float32),\n",
              "   array([3.4591914e-04, 5.8733127e-03, 2.3777110e-03, ..., 3.4908971e-01,\n",
              "          5.2955526e-01, 2.2160690e-02], dtype=float32),\n",
              "   array([4.4381627e-04, 3.6583035e-03, 2.3684604e-03, ..., 9.0400435e-02,\n",
              "          5.2142096e-01, 1.8124267e-03], dtype=float32),\n",
              "   array([3.6571320e-04, 6.5087038e-03, 2.6408366e-03, ..., 6.2734455e-01,\n",
              "          5.2637291e-01, 1.7107949e-02], dtype=float32),\n",
              "   array([4.2010177e-04, 4.6032695e-03, 1.9816142e-03, ..., 4.1490266e-01,\n",
              "          6.9393134e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4774826e-04, 4.7852071e-03, 1.9803597e-03, ..., 5.0940760e-03,\n",
              "          9.3543172e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5344830e-04, 5.3449706e-03, 2.4403674e-03, ..., 3.3582684e-01,\n",
              "          5.6671327e-01, 5.5248749e-02], dtype=float32),\n",
              "   array([4.1153608e-04, 4.4968603e-03, 2.1239498e-03, ..., 1.6313663e-02,\n",
              "          6.9066000e-01, 2.4143364e-02], dtype=float32),\n",
              "   array([3.7667283e-04, 5.9157982e-03, 2.5594728e-03, ..., 7.8931612e-01,\n",
              "          4.8005545e-01, 1.9173751e-02], dtype=float32),\n",
              "   array([4.9994380e-04, 5.3483187e-03, 2.1958270e-03, ..., 6.8210942e-01,\n",
              "          8.1133252e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.7087946e-04, 4.9402411e-03, 2.0860203e-03, ..., 1.0429759e-02,\n",
              "          1.2114313e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6770196e-04, 5.3936644e-03, 2.4930923e-03, ..., 4.0864021e-01,\n",
              "          4.8712423e-01, 5.2627388e-02], dtype=float32),\n",
              "   array([4.2412270e-04, 4.2964523e-03, 2.0087464e-03, ..., 1.2862767e-02,\n",
              "          8.3864242e-01, 3.1276293e-02], dtype=float32),\n",
              "   array([3.5727580e-04, 5.0858427e-03, 2.5152096e-03, ..., 7.6731873e-01,\n",
              "          3.2385054e-01, 8.3620716e-03], dtype=float32),\n",
              "   array([4.4530464e-04, 4.8700836e-03, 1.7745743e-03, ..., 4.0759623e-01,\n",
              "          9.8916048e-01, 0.0000000e+00], dtype=float32)],\n",
              "  17],\n",
              " [[array([3.5651191e-04, 6.7240898e-03, 2.3212500e-03, ..., 1.9339606e-01,\n",
              "          8.9448291e-01, 5.9815766e-03], dtype=float32),\n",
              "   array([3.4979320e-04, 5.8423029e-03, 2.5513193e-03, ..., 3.3258486e-01,\n",
              "          5.2949303e-01, 5.8707073e-02], dtype=float32),\n",
              "   array([3.5755697e-04, 6.9624004e-03, 2.7027400e-03, ..., 4.9109533e-02,\n",
              "          8.7216246e-01, 2.7029572e-02], dtype=float32),\n",
              "   array([4.3996217e-04, 4.9720933e-03, 1.9629945e-03, ..., 2.3782630e-02,\n",
              "          4.8161891e-01, 2.8131880e-02], dtype=float32),\n",
              "   array([3.7484174e-04, 6.1266408e-03, 2.5630086e-03, ..., 6.7435944e-01,\n",
              "          4.8364484e-01, 5.1162709e-02], dtype=float32),\n",
              "   array([5.4794271e-04, 5.2501224e-03, 2.1966586e-03, ..., 3.0601639e-01,\n",
              "          8.6878312e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.96090327e-04, 4.50540241e-03, 2.10911431e-03, ...,\n",
              "          2.14881487e-02, 8.45314741e-01, 1.20040905e-02], dtype=float32),\n",
              "   array([3.6029727e-04, 6.0084504e-03, 2.5223393e-03, ..., 9.0105340e-02,\n",
              "          4.1645536e-01, 3.7203938e-02], dtype=float32),\n",
              "   array([4.7616826e-04, 4.2662667e-03, 2.4653014e-03, ..., 2.1176555e-03,\n",
              "          8.6235636e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7021039e-04, 5.6572240e-03, 2.5297545e-03, ..., 9.8035657e-01,\n",
              "          4.7804505e-01, 1.7588739e-03], dtype=float32),\n",
              "   array([4.6137735e-04, 4.0712482e-03, 2.3084683e-03, ..., 1.0463734e-01,\n",
              "          6.7695880e-01, 3.3293460e-03], dtype=float32),\n",
              "   array([3.3703534e-04, 6.4476165e-03, 2.5425809e-03, ..., 8.1877179e-02,\n",
              "          4.1535223e-01, 4.1331105e-02], dtype=float32),\n",
              "   array([3.8708487e-04, 5.5938377e-03, 2.4911987e-03, ..., 5.6450689e-01,\n",
              "          3.5302693e-01, 7.1429014e-03], dtype=float32),\n",
              "   array([4.1347826e-04, 4.5568803e-03, 2.2152178e-03, ..., 1.0427840e-02,\n",
              "          6.1086261e-01, 4.2696524e-02], dtype=float32),\n",
              "   array([3.6649097e-04, 7.1138940e-03, 2.4125080e-03, ..., 1.5919109e-01,\n",
              "          7.6952004e-01, 1.1334662e-02], dtype=float32),\n",
              "   array([4.5583604e-04, 4.0063462e-03, 2.2406979e-03, ..., 2.9676938e-01,\n",
              "          6.6768998e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5238098e-04, 4.7692899e-03, 2.1613978e-03, ..., 1.4016509e-02,\n",
              "          8.8793534e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5933839e-04, 5.7011209e-03, 2.4198834e-03, ..., 1.8234468e-01,\n",
              "          3.8605094e-01, 4.8152436e-02], dtype=float32),\n",
              "   array([4.0841504e-04, 4.1655195e-03, 2.1961855e-03, ..., 6.0546234e-02,\n",
              "          7.2504342e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7244870e-04, 5.7104011e-03, 2.6191662e-03, ..., 6.5274268e-01,\n",
              "          5.3830761e-01, 1.5831700e-02], dtype=float32)],\n",
              "  20],\n",
              " [[array([3.5327187e-04, 6.9084810e-03, 2.3348462e-03, ..., 1.8699989e-01,\n",
              "          6.3471067e-01, 3.1534612e-02], dtype=float32),\n",
              "   array([3.4675957e-04, 6.4585609e-03, 2.2170623e-03, ..., 1.8651035e-01,\n",
              "          5.0253528e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6341487e-04, 5.4986393e-03, 2.4065452e-03, ..., 7.2493595e-01,\n",
              "          2.8819326e-01, 1.1742186e-02], dtype=float32),\n",
              "   array([3.6431279e-04, 5.4676710e-03, 2.4191281e-03, ..., 2.1643102e-01,\n",
              "          4.4194382e-01, 6.1141297e-02], dtype=float32),\n",
              "   array([4.1743292e-04, 4.6450379e-03, 2.1731267e-03, ..., 2.5854522e-01,\n",
              "          6.0704046e-01, 1.8711027e-02], dtype=float32),\n",
              "   array([3.66622844e-04, 5.79532236e-03, 2.57630320e-03, ...,\n",
              "          2.95958668e-01, 4.15092468e-01, 1.55668575e-02], dtype=float32),\n",
              "   array([4.8654154e-04, 4.6131397e-03, 2.2162218e-03, ..., 3.9263952e-01,\n",
              "          7.8841090e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.0316838e-04, 4.9909959e-03, 1.9802961e-03, ..., 4.0540166e-02,\n",
              "          9.9527866e-01, 1.0874040e-03], dtype=float32),\n",
              "   array([3.4997263e-04, 5.1185912e-03, 2.5028912e-03, ..., 3.5570264e-01,\n",
              "          3.6730427e-01, 3.0073721e-02], dtype=float32),\n",
              "   array([4.1392574e-04, 4.1978643e-03, 1.9374769e-03, ..., 3.1590950e-02,\n",
              "          6.7794800e-01, 2.6978336e-02], dtype=float32),\n",
              "   array([3.6757553e-04, 6.0119177e-03, 2.5429686e-03, ..., 1.6534920e-01,\n",
              "          5.9848970e-01, 2.9793462e-02], dtype=float32),\n",
              "   array([4.5620700e-04, 4.6988511e-03, 2.2510788e-03, ..., 4.7263148e-01,\n",
              "          6.7931259e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.3841702e-04, 4.7102268e-03, 2.2806560e-03, ..., 2.0817852e-01,\n",
              "          9.2691326e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5962265e-04, 5.3974050e-03, 2.5127688e-03, ..., 2.8046662e-01,\n",
              "          4.4833934e-01, 3.0901536e-02], dtype=float32),\n",
              "   array([4.2449162e-04, 4.5462502e-03, 2.0567356e-03, ..., 1.5547120e-02,\n",
              "          5.9137708e-01, 1.3773177e-05], dtype=float32),\n",
              "   array([3.5522229e-04, 5.9057958e-03, 2.5366149e-03, ..., 3.9637575e-01,\n",
              "          4.7461581e-01, 5.3021144e-02], dtype=float32),\n",
              "   array([4.8073949e-04, 4.6324497e-03, 2.3432435e-03, ..., 7.9796559e-01,\n",
              "          4.8670658e-01, 1.1719415e-03], dtype=float32),\n",
              "   array([4.4353816e-04, 4.8825173e-03, 2.1155905e-03, ..., 1.5869670e-01,\n",
              "          8.2939559e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4942778e-04, 5.7062590e-03, 2.4971280e-03, ..., 1.5371297e-01,\n",
              "          4.4659606e-01, 4.7856055e-02], dtype=float32),\n",
              "   array([4.2397404e-04, 4.1981712e-03, 2.1574039e-03, ..., 9.2351157e-03,\n",
              "          6.6330320e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5616272e-04, 6.5550483e-03, 2.5537368e-03, ..., 3.1292614e-01,\n",
              "          4.8091823e-01, 4.5470465e-02], dtype=float32)],\n",
              "  21],\n",
              " [[array([3.5773491e-04, 6.5648947e-03, 2.1849549e-03, ..., 4.6036059e-01,\n",
              "          7.8425795e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([0.00034472, 0.00614346, 0.00236726, ..., 0.28415096, 0.24543153,\n",
              "          0.01291097], dtype=float32),\n",
              "   array([0.00035376, 0.0055864 , 0.00256075, ..., 0.24586949, 0.26100403,\n",
              "          0.09021463], dtype=float32),\n",
              "   array([3.6205500e-04, 5.3658658e-03, 2.4677832e-03, ..., 2.7682376e-01,\n",
              "          3.7734449e-01, 2.1537831e-02], dtype=float32),\n",
              "   array([4.21719160e-04, 4.40138485e-03, 2.20283028e-03, ...,\n",
              "          1.01409934e-01, 5.40865362e-01, 6.88977400e-03], dtype=float32),\n",
              "   array([3.5361337e-04, 5.8581056e-03, 2.5922146e-03, ..., 7.8367281e-01,\n",
              "          6.6157991e-01, 4.9192673e-03], dtype=float32),\n",
              "   array([4.6016756e-04, 4.2353375e-03, 2.1144920e-03, ..., 2.5423190e-01,\n",
              "          8.1608838e-01, 3.5153504e-02], dtype=float32),\n",
              "   array([4.4401709e-04, 5.2490854e-03, 2.0762940e-03, ..., 3.5602119e-02,\n",
              "          8.7372541e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5839254e-04, 5.4473178e-03, 2.5219000e-03, ..., 2.2631587e-01,\n",
              "          4.1113514e-01, 3.2605235e-02], dtype=float32),\n",
              "   array([4.3998696e-04, 4.9672741e-03, 2.0579465e-03, ..., 1.6728299e-02,\n",
              "          6.2757897e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6880534e-04, 5.0289300e-03, 2.6149163e-03, ..., 7.1764684e-01,\n",
              "          5.8051622e-01, 2.2014944e-02], dtype=float32),\n",
              "   array([4.9343053e-04, 3.8623901e-03, 2.4015340e-03, ..., 3.3994791e-01,\n",
              "          1.1625140e+00, 2.8828809e-03], dtype=float32),\n",
              "   array([4.5850623e-04, 5.4041669e-03, 1.8831455e-03, ..., 8.7456547e-02,\n",
              "          7.8097314e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7317426e-04, 5.9128688e-03, 2.4746568e-03, ..., 5.5895209e-01,\n",
              "          5.9225202e-01, 6.3158996e-02], dtype=float32),\n",
              "   array([4.2411996e-04, 4.6558520e-03, 2.1704214e-03, ..., 1.7587494e-02,\n",
              "          6.9144726e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6998442e-04, 5.1374892e-03, 2.5548539e-03, ..., 4.3560117e-01,\n",
              "          6.3620037e-01, 3.2307666e-02], dtype=float32),\n",
              "   array([4.9035478e-04, 4.4581275e-03, 2.3343288e-03, ..., 2.7705935e-01,\n",
              "          8.9347309e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5253348e-04, 5.3975922e-03, 2.2522723e-03, ..., 3.3637225e-03,\n",
              "          6.5305269e-01, 0.0000000e+00], dtype=float32)],\n",
              "  18],\n",
              " [[array([3.5114496e-04, 6.8211751e-03, 2.0089641e-03, ..., 2.2891834e-01,\n",
              "          6.4514351e-01, 3.4290578e-04], dtype=float32),\n",
              "   array([3.5781824e-04, 5.6943097e-03, 2.4346476e-03, ..., 4.8176318e-01,\n",
              "          4.6210852e-01, 3.1640202e-02], dtype=float32),\n",
              "   array([3.7655921e-04, 5.4692705e-03, 2.5149779e-03, ..., 7.6890814e-01,\n",
              "          4.4918188e-01, 1.4757398e-02], dtype=float32),\n",
              "   array([4.1257474e-04, 4.7027147e-03, 2.1646884e-03, ..., 9.0202987e-03,\n",
              "          1.1860120e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6277209e-04, 5.4972391e-03, 2.5657464e-03, ..., 2.4002680e-01,\n",
              "          4.0783194e-01, 7.1973763e-03], dtype=float32),\n",
              "   array([5.4142944e-04, 4.7994689e-03, 2.0473639e-03, ..., 2.8893331e-01,\n",
              "          9.3615854e-01, 3.8677605e-05], dtype=float32),\n",
              "   array([4.4644263e-04, 5.4765046e-03, 2.0245451e-03, ..., 1.4071310e-01,\n",
              "          9.7758508e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4494785e-04, 5.6649731e-03, 2.4704016e-03, ..., 6.2375975e-01,\n",
              "          4.6207491e-01, 1.1140378e-01], dtype=float32),\n",
              "   array([4.4274045e-04, 4.6336167e-03, 2.2563757e-03, ..., 1.1781046e-02,\n",
              "          7.0719397e-01, 1.6993636e-02], dtype=float32),\n",
              "   array([3.7008338e-04, 5.7371440e-03, 2.5900165e-03, ..., 4.1404951e-01,\n",
              "          5.0652027e-01, 3.0023701e-02], dtype=float32),\n",
              "   array([4.8897672e-04, 4.9647745e-03, 2.2108930e-03, ..., 1.2970608e-01,\n",
              "          8.0735558e-01, 1.1177997e-03], dtype=float32),\n",
              "   array([4.3369381e-04, 4.8816293e-03, 1.9871639e-03, ..., 7.5125650e-02,\n",
              "          8.3603215e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6506334e-04, 5.6976303e-03, 2.4430268e-03, ..., 1.3087240e-01,\n",
              "          4.4769073e-01, 5.9883799e-02], dtype=float32),\n",
              "   array([4.6161696e-04, 4.0115351e-03, 2.1698342e-03, ..., 3.0699076e-02,\n",
              "          7.0603889e-01, 1.8041542e-02], dtype=float32),\n",
              "   array([3.5763608e-04, 5.6800758e-03, 2.5569655e-03, ..., 5.3778893e-01,\n",
              "          6.2056631e-01, 7.9049142e-03], dtype=float32),\n",
              "   array([4.9098779e-04, 4.6265847e-03, 2.3095342e-03, ..., 3.4106848e-01,\n",
              "          8.8841367e-01, 0.0000000e+00], dtype=float32)],\n",
              "  16],\n",
              " [[array([3.3619799e-04, 5.3463513e-03, 2.4969305e-03, ..., 3.6103964e-01,\n",
              "          2.4741343e-01, 8.9999726e-03], dtype=float32),\n",
              "   array([3.3067612e-04, 5.5253580e-03, 2.4592215e-03, ..., 4.2892262e-01,\n",
              "          3.2311019e-01, 3.8631935e-02], dtype=float32),\n",
              "   array([3.5701843e-04, 5.4857675e-03, 2.5048647e-03, ..., 1.1059260e+00,\n",
              "          5.9173626e-01, 1.9097449e-02], dtype=float32),\n",
              "   array([4.3268182e-04, 4.2214319e-03, 2.1833281e-03, ..., 3.5457712e-01,\n",
              "          6.0598075e-01, 1.3735763e-02], dtype=float32),\n",
              "   array([3.5579709e-04, 5.9076292e-03, 2.5063427e-03, ..., 6.5562963e-01,\n",
              "          5.8101064e-01, 3.4485071e-03], dtype=float32),\n",
              "   array([4.7283727e-04, 4.8047756e-03, 2.2139847e-03, ..., 2.6710781e-01,\n",
              "          8.3649850e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.3658001e-04, 4.9493751e-03, 2.5095453e-03, ..., 1.5390024e-03,\n",
              "          1.0076036e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7612955e-04, 6.3481526e-03, 2.6822605e-03, ..., 7.0093587e-02,\n",
              "          8.0906916e-01, 2.3716878e-02], dtype=float32),\n",
              "   array([4.3662323e-04, 4.1508880e-03, 2.1713115e-03, ..., 3.3940502e-02,\n",
              "          6.2275690e-01, 4.3515670e-03], dtype=float32),\n",
              "   array([3.6977031e-04, 5.9735137e-03, 2.5891908e-03, ..., 1.1938132e+00,\n",
              "          6.2612695e-01, 2.6215594e-03], dtype=float32),\n",
              "   array([4.7475682e-04, 4.2243642e-03, 1.9296240e-03, ..., 3.4971046e-01,\n",
              "          7.8807938e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5024464e-04, 5.3051645e-03, 2.0081298e-03, ..., 1.3977767e-02,\n",
              "          7.9208368e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6135362e-04, 5.5176597e-03, 2.4178217e-03, ..., 1.0639930e+00,\n",
              "          4.2602021e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.0116397e-04, 4.6685208e-03, 2.2796374e-03, ..., 8.7111723e-03,\n",
              "          6.6156924e-01, 7.6575041e-02], dtype=float32),\n",
              "   array([3.5976403e-04, 5.6506931e-03, 2.5904188e-03, ..., 6.3607025e-01,\n",
              "          5.4001927e-01, 3.6400329e-02], dtype=float32),\n",
              "   array([5.0142861e-04, 4.3795984e-03, 1.9431949e-03, ..., 6.0657954e-01,\n",
              "          8.5871029e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4765052e-04, 5.6296531e-03, 2.3434765e-03, ..., 6.1647445e-01,\n",
              "          3.0713817e-01, 3.8717352e-02], dtype=float32),\n",
              "   array([3.6473328e-04, 5.1517887e-03, 2.5854327e-03, ..., 8.0494767e-01,\n",
              "          4.4481885e-01, 4.6235930e-02], dtype=float32),\n",
              "   array([4.2304522e-04, 4.3051932e-03, 1.9436767e-03, ..., 4.2773385e-02,\n",
              "          7.5786215e-01, 1.1819243e-01], dtype=float32),\n",
              "   array([3.7440122e-04, 5.7604890e-03, 2.5411781e-03, ..., 3.9222345e-01,\n",
              "          6.9186634e-01, 2.6427260e-02], dtype=float32),\n",
              "   array([4.7033129e-04, 4.2203334e-03, 2.4632157e-03, ..., 3.4249470e-01,\n",
              "          6.7458385e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([5.2593031e-04, 4.5443526e-03, 2.3185133e-03, ..., 1.1295643e-01,\n",
              "          7.0682931e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4704580e-04, 5.5406815e-03, 2.4687499e-03, ..., 3.5597035e-01,\n",
              "          5.0014019e-01, 3.5442553e-02], dtype=float32),\n",
              "   array([4.3756299e-04, 4.6720160e-03, 2.0710118e-03, ..., 2.5074540e-02,\n",
              "          6.8277621e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6366901e-04, 6.1170775e-03, 2.5081378e-03, ..., 2.7754042e-01,\n",
              "          4.6997887e-01, 2.9438483e-02], dtype=float32),\n",
              "   array([5.1485549e-04, 4.6540522e-03, 1.8815234e-03, ..., 2.6461554e-01,\n",
              "          8.5908401e-01, 5.2372634e-04], dtype=float32),\n",
              "   array([4.1558099e-04, 4.6084560e-03, 1.8643455e-03, ..., 5.2927937e-03,\n",
              "          8.3340305e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5469641e-04, 6.5858648e-03, 2.6325623e-03, ..., 3.2182831e-01,\n",
              "          9.3123174e-01, 3.5141401e-02], dtype=float32),\n",
              "   array([4.3147284e-04, 4.3830695e-03, 2.0161083e-03, ..., 7.9521267e-03,\n",
              "          7.1775007e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8135651e-04, 5.0778813e-03, 2.5716666e-03, ..., 5.6803644e-01,\n",
              "          4.8066202e-01, 8.9242775e-03], dtype=float32),\n",
              "   array([4.5802907e-04, 4.2006369e-03, 2.4789323e-03, ..., 9.0082392e-02,\n",
              "          7.6094109e-01, 0.0000000e+00], dtype=float32)],\n",
              "  31],\n",
              " [[array([3.4328044e-04, 6.5951184e-03, 2.2887809e-03, ..., 2.3113096e-01,\n",
              "          4.3195453e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4767156e-04, 5.7705417e-03, 2.3359666e-03, ..., 5.4701483e-01,\n",
              "          3.5029370e-01, 2.2959622e-02], dtype=float32),\n",
              "   array([3.4675151e-04, 6.0957079e-03, 2.5705406e-03, ..., 8.1910241e-01,\n",
              "          5.5969793e-01, 5.0977193e-02], dtype=float32),\n",
              "   array([3.8389352e-04, 4.8452620e-03, 2.5090845e-03, ..., 3.8351858e-01,\n",
              "          6.6656595e-01, 1.2695345e-01], dtype=float32),\n",
              "   array([4.3505765e-04, 4.4922675e-03, 1.9591048e-03, ..., 4.0360391e-02,\n",
              "          7.4292368e-01, 6.7103235e-04], dtype=float32),\n",
              "   array([3.5199514e-04, 6.0516554e-03, 2.5053737e-03, ..., 9.1403556e-01,\n",
              "          5.7049304e-01, 7.4492451e-03], dtype=float32),\n",
              "   array([4.9457571e-04, 4.5416183e-03, 1.7800648e-03, ..., 2.2147942e-01,\n",
              "          9.6933794e-01, 2.0572288e-02], dtype=float32),\n",
              "   array([4.2334883e-04, 4.6009757e-03, 2.2311339e-03, ..., 1.2715945e-01,\n",
              "          7.1232706e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4583631e-04, 5.6756809e-03, 2.4683138e-03, ..., 5.4647976e-01,\n",
              "          3.8629302e-01, 2.7365763e-02], dtype=float32),\n",
              "   array([0.00043534, 0.00419241, 0.00207833, ..., 0.05049049, 0.42235246,\n",
              "          0.        ], dtype=float32),\n",
              "   array([3.5637402e-04, 6.8886657e-03, 2.3980844e-03, ..., 3.1101337e-01,\n",
              "          7.0984900e-01, 3.6090214e-02], dtype=float32),\n",
              "   array([4.8306861e-04, 4.7745481e-03, 2.0866110e-03, ..., 9.6169122e-02,\n",
              "          9.2564446e-01, 7.2903316e-03], dtype=float32),\n",
              "   array([4.4321408e-04, 4.6686167e-03, 2.1785093e-03, ..., 7.5843535e-02,\n",
              "          6.9451863e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3633635e-04, 5.5522118e-03, 2.4468962e-03, ..., 7.3269242e-01,\n",
              "          4.4844556e-01, 2.2253571e-02], dtype=float32),\n",
              "   array([4.4434992e-04, 4.3744282e-03, 1.9644492e-03, ..., 2.7231788e-02,\n",
              "          7.5885642e-01, 3.6656391e-02], dtype=float32),\n",
              "   array([3.5445779e-04, 5.5788700e-03, 2.5659383e-03, ..., 1.0609657e+00,\n",
              "          4.6899888e-01, 2.9413253e-02], dtype=float32),\n",
              "   array([4.3583260e-04, 4.5600515e-03, 1.9511253e-03, ..., 5.0810236e-01,\n",
              "          1.0682775e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.8333558e-04, 5.3802170e-03, 2.3494936e-03, ..., 1.0853194e-02,\n",
              "          9.1634160e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5274785e-04, 5.5737295e-03, 2.6161619e-03, ..., 4.7489458e-01,\n",
              "          7.7295780e-01, 2.8642684e-02], dtype=float32),\n",
              "   array([4.3012956e-04, 4.2940862e-03, 2.3242529e-03, ..., 1.2953657e-01,\n",
              "          5.7054389e-01, 5.3357859e-03], dtype=float32),\n",
              "   array([3.5023445e-04, 6.5370374e-03, 2.4777984e-03, ..., 5.4968786e-01,\n",
              "          6.5921128e-01, 4.2640485e-02], dtype=float32),\n",
              "   array([4.9185299e-04, 4.2184736e-03, 2.2149701e-03, ..., 2.7133729e-02,\n",
              "          6.5896577e-01, 1.0924817e-02], dtype=float32),\n",
              "   array([4.2701577e-04, 5.0662640e-03, 2.3424167e-03, ..., 2.4995227e-01,\n",
              "          7.5693113e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3807469e-04, 5.9130932e-03, 2.4852674e-03, ..., 6.6848230e-01,\n",
              "          4.9077344e-01, 3.1196073e-02], dtype=float32),\n",
              "   array([4.3274250e-04, 4.1205767e-03, 1.9607686e-03, ..., 6.8488777e-02,\n",
              "          8.5787231e-01, 2.5855673e-02], dtype=float32),\n",
              "   array([3.5835110e-04, 6.1646942e-03, 2.4389639e-03, ..., 9.3576056e-01,\n",
              "          5.5146194e-01, 8.5089915e-03], dtype=float32),\n",
              "   array([4.4121104e-04, 4.5800474e-03, 2.0295633e-03, ..., 3.7301385e-01,\n",
              "          8.6939400e-01, 3.7968695e-02], dtype=float32),\n",
              "   array([3.5587908e-04, 5.5615697e-03, 2.5558146e-03, ..., 6.6265875e-01,\n",
              "          4.8141351e-01, 6.9925440e-03], dtype=float32),\n",
              "   array([3.4049287e-04, 5.8142887e-03, 2.4887361e-03, ..., 8.3720738e-01,\n",
              "          5.5661780e-01, 2.9338464e-02], dtype=float32),\n",
              "   array([4.3098183e-04, 4.1451831e-03, 2.0682898e-03, ..., 1.8910225e-02,\n",
              "          4.6645537e-01, 2.8631520e-02], dtype=float32),\n",
              "   array([3.6807309e-04, 6.5863514e-03, 2.5147966e-03, ..., 4.8812234e-01,\n",
              "          7.2771537e-01, 8.0350051e-03], dtype=float32),\n",
              "   array([4.6357815e-04, 4.6603382e-03, 2.5502804e-03, ..., 1.8563965e-02,\n",
              "          7.2966921e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6181309e-04, 5.1625175e-03, 2.2707414e-03, ..., 8.8814251e-02,\n",
              "          7.4605894e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5797665e-04, 6.1258958e-03, 2.5006982e-03, ..., 7.4986166e-01,\n",
              "          6.5273988e-01, 4.2260315e-02], dtype=float32),\n",
              "   array([4.2976136e-04, 4.6857931e-03, 1.9896128e-03, ..., 3.4673050e-02,\n",
              "          7.5867605e-01, 9.4873831e-05], dtype=float32),\n",
              "   array([3.7795183e-04, 6.1689797e-03, 2.5292935e-03, ..., 2.7340010e-01,\n",
              "          6.3525122e-01, 4.4682436e-03], dtype=float32),\n",
              "   array([0.00054732, 0.00501967, 0.00209956, ..., 0.3269939 , 0.49833283,\n",
              "          0.        ], dtype=float32),\n",
              "   array([3.6232857e-04, 5.6922152e-03, 2.6106548e-03, ..., 6.8520147e-01,\n",
              "          6.1990708e-01, 2.9193426e-02], dtype=float32),\n",
              "   array([0.00033851, 0.00551923, 0.00234677, ..., 0.30875796, 0.24377999,\n",
              "          0.00872937], dtype=float32),\n",
              "   array([3.7083030e-04, 5.4286956e-03, 2.5225540e-03, ..., 6.2733680e-01,\n",
              "          3.9257264e-01, 5.6684323e-02], dtype=float32),\n",
              "   array([3.5397810e-04, 5.9676827e-03, 2.3782044e-03, ..., 5.6150788e-01,\n",
              "          6.1051005e-01, 8.2865454e-02], dtype=float32),\n",
              "   array([4.4931783e-04, 4.5056506e-03, 2.0930578e-03, ..., 2.3539305e-02,\n",
              "          7.4910414e-01, 3.1885453e-02], dtype=float32),\n",
              "   array([3.6288498e-04, 5.9458870e-03, 2.4734135e-03, ..., 4.4948918e-01,\n",
              "          5.6887966e-01, 2.2148197e-03], dtype=float32),\n",
              "   array([5.1688089e-04, 4.2738137e-03, 2.3329342e-03, ..., 1.9009614e-01,\n",
              "          5.7995230e-01, 1.7288266e-02], dtype=float32),\n",
              "   array([4.7141497e-04, 5.0640269e-03, 2.1797635e-03, ..., 9.4041787e-02,\n",
              "          6.9006145e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4439770e-04, 6.6788383e-03, 2.5678873e-03, ..., 4.3705058e-01,\n",
              "          7.4335259e-01, 9.7190410e-02], dtype=float32),\n",
              "   array([4.3459525e-04, 4.5473990e-03, 2.3704602e-03, ..., 1.7835024e-01,\n",
              "          6.1013430e-01, 1.3257739e-02], dtype=float32),\n",
              "   array([3.5144790e-04, 6.5553407e-03, 2.5443246e-03, ..., 5.7815295e-01,\n",
              "          4.4543993e-01, 2.2063702e-02], dtype=float32),\n",
              "   array([4.8158676e-04, 4.0361290e-03, 2.0646504e-03, ..., 2.3660977e-01,\n",
              "          6.5839034e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4090446e-04, 5.1572355e-03, 2.0608495e-03, ..., 6.6363327e-02,\n",
              "          7.4293280e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5050191e-04, 5.9693460e-03, 2.5223084e-03, ..., 6.2753856e-01,\n",
              "          6.6870266e-01, 6.4170949e-02], dtype=float32),\n",
              "   array([4.20396042e-04, 4.51667840e-03, 2.17434391e-03, ...,\n",
              "          1.09113395e-01, 7.48476446e-01, 9.84204188e-02], dtype=float32),\n",
              "   array([3.6124140e-04, 6.6454676e-03, 2.5188271e-03, ..., 3.9330181e-01,\n",
              "          8.5644770e-01, 2.5496628e-02], dtype=float32),\n",
              "   array([3.5100180e-04, 6.5421117e-03, 2.5635569e-03, ..., 7.2026396e-01,\n",
              "          6.8330687e-01, 2.3407470e-03], dtype=float32),\n",
              "   array([3.5167707e-04, 6.1888755e-03, 2.3001493e-03, ..., 8.7594026e-01,\n",
              "          3.0100286e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.2950560e-04, 4.2053126e-03, 2.2107274e-03, ..., 7.6192915e-02,\n",
              "          7.4110889e-01, 4.5034993e-02], dtype=float32),\n",
              "   array([3.6406878e-04, 5.5691726e-03, 2.5401574e-03, ..., 1.1057018e+00,\n",
              "          5.0805342e-01, 2.7634918e-03], dtype=float32),\n",
              "   array([4.6371194e-04, 4.7929590e-03, 2.1179735e-03, ..., 5.7740543e-02,\n",
              "          9.6066719e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4655005e-04, 4.9826396e-03, 2.1597960e-03, ..., 6.4892299e-02,\n",
              "          7.7274042e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6132667e-04, 5.2516917e-03, 2.6250575e-03, ..., 1.0314025e+00,\n",
              "          3.2702807e-01, 2.0039041e-02], dtype=float32),\n",
              "   array([4.6517610e-04, 3.9491081e-03, 2.1786047e-03, ..., 7.2288781e-02,\n",
              "          7.0575106e-01, 9.0555605e-03], dtype=float32),\n",
              "   array([3.7720514e-04, 6.3462914e-03, 2.5854704e-03, ..., 5.4162681e-01,\n",
              "          5.6010902e-01, 1.5967323e-02], dtype=float32),\n",
              "   array([4.5582501e-04, 4.3361150e-03, 2.3939621e-03, ..., 6.4987481e-02,\n",
              "          5.4414755e-01, 1.7140171e-02], dtype=float32),\n",
              "   array([4.8060779e-04, 5.3199390e-03, 2.2749009e-03, ..., 1.0202876e-02,\n",
              "          6.8192923e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6949702e-04, 5.8192159e-03, 2.5192793e-03, ..., 5.6405157e-01,\n",
              "          4.4131619e-01, 1.7615448e-03], dtype=float32),\n",
              "   array([4.4000021e-04, 4.3213582e-03, 2.1752950e-03, ..., 7.3083758e-02,\n",
              "          5.7331109e-01, 1.8266343e-02], dtype=float32),\n",
              "   array([3.7163138e-04, 5.4863337e-03, 2.5583412e-03, ..., 5.8993268e-01,\n",
              "          6.1291361e-01, 2.3973610e-02], dtype=float32),\n",
              "   array([3.4058228e-04, 5.5649495e-03, 2.5113286e-03, ..., 3.4164813e-01,\n",
              "          3.9053851e-01, 1.7451257e-02], dtype=float32),\n",
              "   array([3.4422814e-04, 5.6979437e-03, 2.4253847e-03, ..., 9.4604850e-01,\n",
              "          2.2442873e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6011334e-04, 5.2076643e-03, 2.5067844e-03, ..., 6.4309406e-01,\n",
              "          5.2059966e-01, 6.3472182e-02], dtype=float32),\n",
              "   array([3.7476869e-04, 7.0782588e-03, 2.7014245e-03, ..., 3.5544646e-01,\n",
              "          7.3267668e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.1970203e-04, 4.5716283e-03, 2.3841956e-03, ..., 2.3866359e-02,\n",
              "          7.0661068e-01, 1.9560212e-02], dtype=float32),\n",
              "   array([3.6598477e-04, 6.1805751e-03, 2.5234304e-03, ..., 2.0157160e-01,\n",
              "          5.5733979e-01, 2.3836074e-02], dtype=float32),\n",
              "   array([4.5433402e-04, 5.0817225e-03, 1.9861273e-03, ..., 2.2303541e-01,\n",
              "          9.8788953e-01, 2.4131186e-02], dtype=float32)],\n",
              "  74],\n",
              " [[array([3.5287341e-04, 5.9752259e-03, 2.5245240e-03, ..., 8.2884657e-01,\n",
              "          3.3280733e-01, 1.8584099e-02], dtype=float32),\n",
              "   array([3.4221550e-04, 5.7877097e-03, 2.3551388e-03, ..., 5.3347039e-01,\n",
              "          3.5190853e-01, 1.7982302e-03], dtype=float32),\n",
              "   array([3.4269853e-04, 5.4526799e-03, 2.5083842e-03, ..., 5.8981657e-01,\n",
              "          4.6073049e-01, 6.5195106e-02], dtype=float32),\n",
              "   array([3.6425213e-04, 5.4805260e-03, 2.4270953e-03, ..., 5.4228771e-01,\n",
              "          5.9940636e-01, 5.1117104e-02], dtype=float32),\n",
              "   array([4.4935578e-04, 4.5373328e-03, 2.1453393e-03, ..., 2.0548655e-02,\n",
              "          6.3064253e-01, 1.7660847e-02], dtype=float32),\n",
              "   array([3.5307632e-04, 6.8358020e-03, 2.3950518e-03, ..., 3.8841271e-01,\n",
              "          5.6600589e-01, 5.2188560e-03], dtype=float32),\n",
              "   array([4.5377726e-04, 4.7167218e-03, 2.1055397e-03, ..., 9.2178129e-02,\n",
              "          7.9274958e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6054288e-04, 5.0795651e-03, 2.1804755e-03, ..., 5.4888250e-03,\n",
              "          9.8808360e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8788951e-04, 4.9220468e-03, 2.5491726e-03, ..., 8.3094537e-01,\n",
              "          3.5074499e-01, 9.3448414e-03], dtype=float32),\n",
              "   array([4.5130530e-04, 4.3787677e-03, 2.0800065e-03, ..., 1.4104900e-02,\n",
              "          7.3751098e-01, 1.5214157e-02], dtype=float32),\n",
              "   array([3.6905194e-04, 6.0323118e-03, 2.5416343e-03, ..., 7.4529421e-01,\n",
              "          5.7352459e-01, 7.2951494e-03], dtype=float32),\n",
              "   array([4.6241895e-04, 4.8192106e-03, 1.8378552e-03, ..., 3.0838022e-01,\n",
              "          9.0565747e-01, 1.3888061e-01], dtype=float32)],\n",
              "  12],\n",
              " [[array([0.00035039, 0.00474769, 0.00227791, ..., 0.2630456 , 0.15566917,\n",
              "          0.00761889], dtype=float32),\n",
              "   array([3.5614186e-04, 4.5889411e-03, 2.5562991e-03, ..., 1.0322692e+00,\n",
              "          3.9734775e-01, 7.5406335e-02], dtype=float32),\n",
              "   array([3.8361101e-04, 6.3429954e-03, 2.8465597e-03, ..., 4.0615883e-01,\n",
              "          9.8831600e-01, 2.4611475e-02], dtype=float32),\n",
              "   array([4.3221592e-04, 3.8918692e-03, 2.0927347e-03, ..., 1.4055975e-01,\n",
              "          4.5759839e-01, 2.2664191e-03], dtype=float32),\n",
              "   array([3.6428554e-04, 5.5955793e-03, 2.5536981e-03, ..., 8.7680537e-01,\n",
              "          4.7292215e-01, 1.0225367e-02], dtype=float32),\n",
              "   array([4.5793407e-04, 4.3741292e-03, 2.2951926e-03, ..., 3.3307025e-01,\n",
              "          9.8068094e-01, 4.9212467e-02], dtype=float32),\n",
              "   array([4.7388976e-04, 4.9488298e-03, 1.9974168e-03, ..., 1.6756624e-01,\n",
              "          9.9970609e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5685231e-04, 5.7900175e-03, 2.5011778e-03, ..., 4.8671749e-01,\n",
              "          5.7540911e-01, 4.7862218e-03], dtype=float32),\n",
              "   array([4.6422903e-04, 3.9881989e-03, 1.9443380e-03, ..., 5.9069440e-02,\n",
              "          7.5235540e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5235667e-04, 5.8303662e-03, 2.4420710e-03, ..., 2.8736630e-01,\n",
              "          7.9793572e-01, 2.6138470e-02], dtype=float32),\n",
              "   array([4.9173937e-04, 4.8313993e-03, 2.1355560e-03, ..., 8.6546876e-02,\n",
              "          8.1303477e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.8491979e-04, 4.9523539e-03, 2.1654717e-03, ..., 3.2108437e-02,\n",
              "          7.0194572e-01, 2.6084494e-03], dtype=float32),\n",
              "   array([3.5166292e-04, 5.0085033e-03, 2.6218973e-03, ..., 9.9327421e-01,\n",
              "          4.1807806e-01, 9.3342951e-03], dtype=float32),\n",
              "   array([4.2280153e-04, 4.3879109e-03, 2.1833503e-03, ..., 2.3154428e-02,\n",
              "          7.3946553e-01, 6.1542697e-02], dtype=float32),\n",
              "   array([3.5728948e-04, 6.4950683e-03, 2.5803379e-03, ..., 7.6927906e-01,\n",
              "          7.9777932e-01, 1.7734567e-02], dtype=float32),\n",
              "   array([4.9667963e-04, 4.6305419e-03, 2.2481156e-03, ..., 3.5688594e-02,\n",
              "          9.3057960e-01, 2.6554975e-04], dtype=float32),\n",
              "   array([4.4777099e-04, 5.1637227e-03, 1.8959669e-03, ..., 7.2750703e-02,\n",
              "          7.0699978e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4487940e-04, 6.0046837e-03, 2.3710863e-03, ..., 7.0531011e-01,\n",
              "          5.5870837e-01, 1.1866169e-02], dtype=float32),\n",
              "   array([3.4942114e-04, 5.3786770e-03, 2.5779186e-03, ..., 1.0221885e+00,\n",
              "          5.2950740e-01, 9.3068890e-02], dtype=float32),\n",
              "   array([4.2587062e-04, 4.6622031e-03, 2.1740424e-03, ..., 4.6995699e-02,\n",
              "          5.7544255e-01, 7.8083336e-02], dtype=float32),\n",
              "   array([3.7400983e-04, 5.6733149e-03, 2.6058049e-03, ..., 4.6596402e-01,\n",
              "          5.2271712e-01, 2.0271722e-02], dtype=float32),\n",
              "   array([4.5101380e-04, 4.6936269e-03, 2.3235411e-03, ..., 1.1248814e-01,\n",
              "          5.4463756e-01, 1.6221001e-04], dtype=float32)],\n",
              "  22],\n",
              " [[array([3.2962547e-04, 5.3322120e-03, 2.3816777e-03, ..., 6.0208201e-01,\n",
              "          3.1938532e-01, 2.9943157e-02], dtype=float32),\n",
              "   array([3.4135010e-04, 6.4720931e-03, 2.1387117e-03, ..., 5.6371140e-01,\n",
              "          2.6965284e-01, 3.0891481e-03], dtype=float32),\n",
              "   array([3.3007946e-04, 5.3401547e-03, 2.6155771e-03, ..., 5.9463727e-01,\n",
              "          3.8134083e-01, 6.0347512e-02], dtype=float32),\n",
              "   array([3.6801226e-04, 6.5411441e-03, 2.5943497e-03, ..., 5.5049229e-01,\n",
              "          6.6337895e-01, 5.3765024e-03], dtype=float32),\n",
              "   array([4.7378565e-04, 4.5396192e-03, 2.5738787e-03, ..., 2.7751956e-02,\n",
              "          5.7516092e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5143271e-04, 6.5002521e-03, 2.5234888e-03, ..., 7.2412717e-01,\n",
              "          7.6942652e-01, 1.0296040e-02], dtype=float32),\n",
              "   array([5.1039527e-04, 4.4742171e-03, 2.2183419e-03, ..., 1.4803569e-01,\n",
              "          6.8725467e-01, 1.8687093e-03], dtype=float32),\n",
              "   array([4.3907549e-04, 4.3122247e-03, 2.0677398e-03, ..., 1.7464174e-01,\n",
              "          6.0929167e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4823327e-04, 6.0148286e-03, 2.5525305e-03, ..., 1.4657582e+00,\n",
              "          4.3567088e-01, 4.6646702e-03], dtype=float32),\n",
              "   array([4.3138614e-04, 3.9704330e-03, 2.2284631e-03, ..., 1.1406121e-01,\n",
              "          6.4486110e-01, 1.0670455e-03], dtype=float32),\n",
              "   array([3.6153200e-04, 6.3101682e-03, 2.5031327e-03, ..., 6.3902867e-01,\n",
              "          5.9795678e-01, 3.7283299e-04], dtype=float32),\n",
              "   array([3.7263753e-04, 6.0871840e-03, 2.3755096e-03, ..., 5.3115237e-01,\n",
              "          6.8507314e-01, 3.2324332e-03], dtype=float32),\n",
              "   array([3.6221559e-04, 4.0708827e-03, 2.6232915e-03, ..., 1.3097996e+00,\n",
              "          1.8077531e-01, 3.2331564e-02], dtype=float32),\n",
              "   array([4.1084870e-04, 3.8585016e-03, 2.3495827e-03, ..., 6.4658769e-04,\n",
              "          5.6982952e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5477470e-04, 6.2617189e-03, 2.5115849e-03, ..., 3.2886252e-01,\n",
              "          4.6197101e-01, 1.6870322e-02], dtype=float32),\n",
              "   array([4.8497767e-04, 4.3575857e-03, 1.9953989e-03, ..., 1.6694853e-01,\n",
              "          6.6912305e-01, 5.3485301e-03], dtype=float32),\n",
              "   array([4.4671743e-04, 4.9600126e-03, 2.3004450e-03, ..., 4.5296538e-01,\n",
              "          7.4843806e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4583049e-04, 5.9361281e-03, 2.5320575e-03, ..., 4.9940348e-01,\n",
              "          5.7122427e-01, 2.1948272e-02], dtype=float32),\n",
              "   array([4.2703908e-04, 3.9146938e-03, 2.2256684e-03, ..., 3.3584449e-02,\n",
              "          6.3791293e-01, 3.1634320e-02], dtype=float32),\n",
              "   array([3.5676226e-04, 5.6797285e-03, 2.5286069e-03, ..., 5.7661980e-01,\n",
              "          5.2582902e-01, 1.1055779e-02], dtype=float32),\n",
              "   array([3.3746072e-04, 6.7071840e-03, 2.2746359e-03, ..., 5.9926265e-01,\n",
              "          4.6842742e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.2964113e-04, 6.2705656e-03, 2.3755287e-03, ..., 6.9261009e-01,\n",
              "          6.5297908e-01, 5.6871671e-02], dtype=float32),\n",
              "   array([3.5280685e-04, 5.5779042e-03, 2.5254320e-03, ..., 4.7667658e-01,\n",
              "          4.4359642e-01, 3.8533756e-03], dtype=float32),\n",
              "   array([3.5040674e-04, 5.4120496e-03, 2.5614235e-03, ..., 1.0770530e+00,\n",
              "          3.8392973e-01, 7.0758006e-03], dtype=float32),\n",
              "   array([4.5510373e-04, 3.5907060e-03, 2.5084852e-03, ..., 1.0990736e-02,\n",
              "          5.7051247e-01, 3.1073069e-02], dtype=float32),\n",
              "   array([3.6194114e-04, 6.2538045e-03, 2.4530648e-03, ..., 1.0146483e+00,\n",
              "          5.4723972e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.8595355e-04, 4.6241260e-03, 2.0375017e-03, ..., 1.8523656e-01,\n",
              "          7.6581293e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.7860167e-04, 5.2381777e-03, 2.3572750e-03, ..., 1.8212426e-03,\n",
              "          7.6176584e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6329354e-04, 4.9785683e-03, 2.5702100e-03, ..., 3.5778365e-01,\n",
              "          5.6758952e-01, 2.1804284e-02], dtype=float32),\n",
              "   array([4.1974115e-04, 4.4090515e-03, 2.3792614e-03, ..., 6.2651612e-02,\n",
              "          4.9912542e-01, 6.7782179e-02], dtype=float32),\n",
              "   array([3.57710669e-04, 6.01093611e-03, 2.55470257e-03, ...,\n",
              "          6.50740087e-01, 6.69291735e-01, 1.52044175e-02], dtype=float32),\n",
              "   array([4.4808880e-04, 4.7930032e-03, 1.9872559e-03, ..., 4.0621987e-01,\n",
              "          6.6934311e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6207415e-04, 5.6479778e-03, 2.4541167e-03, ..., 1.0059521e+00,\n",
              "          2.0675506e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4693701e-04, 4.9754321e-03, 2.5478862e-03, ..., 1.3992599e+00,\n",
              "          3.5806832e-01, 5.4052453e-02], dtype=float32),\n",
              "   array([4.7130321e-04, 4.3583424e-03, 2.3441778e-03, ..., 7.4934714e-02,\n",
              "          7.1473956e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5916554e-04, 6.2053539e-03, 2.5618095e-03, ..., 8.1480551e-01,\n",
              "          6.0464662e-01, 3.1909975e-03], dtype=float32),\n",
              "   array([4.4245008e-04, 4.6775602e-03, 1.8565427e-03, ..., 2.5358611e-01,\n",
              "          9.2834455e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5728983e-04, 5.2638552e-03, 2.5966621e-03, ..., 9.0142325e-02,\n",
              "          5.4188007e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7390803e-04, 5.6456649e-03, 2.5453838e-03, ..., 3.8616329e-01,\n",
              "          6.6620821e-01, 1.0616636e-02], dtype=float32),\n",
              "   array([4.1710681e-04, 3.9923927e-03, 2.1349939e-03, ..., 2.9712915e-01,\n",
              "          7.7436727e-01, 5.4455690e-02], dtype=float32),\n",
              "   array([3.5304442e-04, 6.2396927e-03, 2.4386041e-03, ..., 5.9359086e-01,\n",
              "          3.7919605e-01, 7.2593801e-03], dtype=float32),\n",
              "   array([4.8143181e-04, 4.8677791e-03, 1.8837744e-03, ..., 3.0156597e-01,\n",
              "          8.5186869e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6424704e-04, 5.0020115e-03, 2.0820966e-03, ..., 1.4222062e-02,\n",
              "          7.9380316e-01, 1.2443826e-03], dtype=float32),\n",
              "   array([3.7050832e-04, 4.7595436e-03, 2.5357599e-03, ..., 1.0893625e+00,\n",
              "          2.8851661e-01, 3.9649969e-03], dtype=float32),\n",
              "   array([4.1611891e-04, 4.1339830e-03, 2.2837983e-03, ..., 1.6403663e-01,\n",
              "          4.7615391e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5445695e-04, 6.3446765e-03, 2.5275343e-03, ..., 7.6019949e-01,\n",
              "          6.8438524e-01, 7.8147801e-04], dtype=float32),\n",
              "   array([4.9614953e-04, 4.9892887e-03, 2.0924108e-03, ..., 3.2633162e-01,\n",
              "          9.5108640e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4610531e-04, 6.0213055e-03, 2.6051959e-03, ..., 5.0604498e-01,\n",
              "          2.7895612e-01, 1.1672011e-02], dtype=float32),\n",
              "   array([3.2965440e-04, 5.8411811e-03, 2.3373959e-03, ..., 4.9222204e-01,\n",
              "          2.9543579e-01, 3.7625772e-03], dtype=float32),\n",
              "   array([3.4938875e-04, 5.8393357e-03, 2.4855109e-03, ..., 5.8152103e-01,\n",
              "          5.5118454e-01, 3.8530838e-02], dtype=float32),\n",
              "   array([3.4206401e-04, 5.8689006e-03, 2.5166213e-03, ..., 1.0637027e+00,\n",
              "          5.3333795e-01, 2.8889433e-02], dtype=float32),\n",
              "   array([4.5585434e-04, 4.0609315e-03, 2.1334807e-03, ..., 3.4128528e-02,\n",
              "          5.7155043e-01, 1.4936848e-03], dtype=float32),\n",
              "   array([3.6316621e-04, 6.0230680e-03, 2.5004470e-03, ..., 2.0039037e-01,\n",
              "          3.6902723e-01, 3.6634047e-02], dtype=float32),\n",
              "   array([4.7257383e-04, 4.7912784e-03, 2.4313410e-03, ..., 7.4513615e-03,\n",
              "          7.0009792e-01, 1.6115151e-02], dtype=float32),\n",
              "   array([4.6494397e-04, 4.8380457e-03, 2.4486354e-03, ..., 1.4928928e-01,\n",
              "          6.2986797e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6747617e-04, 5.1192683e-03, 2.5543612e-03, ..., 3.2580179e-01,\n",
              "          5.3418779e-01, 6.7378275e-02], dtype=float32),\n",
              "   array([0.00046107, 0.00452907, 0.00254017, ..., 0.04516721, 0.39849815,\n",
              "          0.01362035], dtype=float32),\n",
              "   array([3.4363830e-04, 6.2842709e-03, 2.4387939e-03, ..., 7.6666266e-01,\n",
              "          5.6501412e-01, 3.2422098e-03], dtype=float32),\n",
              "   array([4.3748866e-04, 4.6249591e-03, 2.0940069e-03, ..., 1.8691623e-01,\n",
              "          6.7926848e-01, 1.8246894e-03], dtype=float32),\n",
              "   array([4.4359977e-04, 5.6285239e-03, 2.2603618e-03, ..., 4.2681103e-03,\n",
              "          5.7176346e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5444187e-04, 5.6178193e-03, 2.6350031e-03, ..., 6.3692343e-01,\n",
              "          4.7294608e-01, 1.6250629e-02], dtype=float32),\n",
              "   array([4.3663030e-04, 3.6051306e-03, 2.3220512e-03, ..., 1.4060795e-01,\n",
              "          6.4152378e-01, 4.9966699e-03], dtype=float32),\n",
              "   array([3.6150910e-04, 6.4771646e-03, 2.5328570e-03, ..., 6.7056733e-01,\n",
              "          7.2634405e-01, 7.9016313e-03], dtype=float32),\n",
              "   array([3.506950e-04, 5.317429e-03, 2.610929e-03, ..., 7.638685e-01,\n",
              "          3.230370e-01, 3.498739e-03], dtype=float32),\n",
              "   array([3.5327673e-04, 6.1935955e-03, 2.4902418e-03, ..., 1.0433943e+00,\n",
              "          4.7701007e-01, 2.4344387e-02], dtype=float32),\n",
              "   array([3.6329307e-04, 4.6858033e-03, 2.5615566e-03, ..., 1.1266465e+00,\n",
              "          3.4099296e-01, 2.1031896e-02], dtype=float32),\n",
              "   array([4.0840553e-04, 4.0433444e-03, 2.1191381e-03, ..., 4.0487863e-02,\n",
              "          6.8806732e-01, 1.0180947e-01], dtype=float32),\n",
              "   array([3.6040010e-04, 6.3921674e-03, 2.5401288e-03, ..., 2.7592254e-01,\n",
              "          5.3530115e-01, 3.3988718e-02], dtype=float32),\n",
              "   array([5.2323821e-04, 5.3481571e-03, 2.3222042e-03, ..., 3.0086231e-01,\n",
              "          6.1040568e-01, 5.1503208e-02], dtype=float32),\n",
              "   array([4.4804526e-04, 5.2226619e-03, 2.0282841e-03, ..., 1.9455096e-02,\n",
              "          8.3709943e-01, 2.4252788e-05], dtype=float32),\n",
              "   array([3.4166439e-04, 6.3786991e-03, 2.4974537e-03, ..., 4.5333090e-01,\n",
              "          4.2862159e-01, 1.9376455e-02], dtype=float32),\n",
              "   array([4.21988807e-04, 4.14675847e-03, 2.29073735e-03, ...,\n",
              "          6.21018279e-03, 8.36628675e-01, 1.09604765e-02], dtype=float32),\n",
              "   array([3.6279089e-04, 6.5949019e-03, 2.5412010e-03, ..., 9.1391397e-01,\n",
              "          6.1645085e-01, 5.8450298e-03], dtype=float32),\n",
              "   array([3.2820168e-04, 7.6496843e-03, 2.1602011e-03, ..., 8.9675325e-01,\n",
              "          4.1179174e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5499333e-04, 6.3317241e-03, 2.4523062e-03, ..., 5.0263882e-01,\n",
              "          4.9873531e-01, 5.3748819e-03], dtype=float32),\n",
              "   array([3.4811028e-04, 5.9982114e-03, 2.4414449e-03, ..., 1.0951656e+00,\n",
              "          1.4317797e-01, 2.2697661e-03], dtype=float32),\n",
              "   array([3.4618675e-04, 4.6797530e-03, 2.5411712e-03, ..., 6.5464330e-01,\n",
              "          4.3112069e-01, 6.7593187e-02], dtype=float32),\n",
              "   array([3.5436251e-04, 4.9931738e-03, 2.4820087e-03, ..., 7.6973867e-01,\n",
              "          4.3177912e-01, 1.6541004e-02], dtype=float32),\n",
              "   array([4.5399016e-04, 4.3606497e-03, 2.0428144e-03, ..., 9.6571505e-02,\n",
              "          5.8878833e-01, 4.5131728e-02], dtype=float32),\n",
              "   array([3.5435424e-04, 6.3151713e-03, 2.5134399e-03, ..., 8.4611672e-01,\n",
              "          4.4432756e-01, 6.4531504e-03], dtype=float32),\n",
              "   array([4.0577006e-04, 4.3946034e-03, 1.8766151e-03, ..., 8.8389553e-02,\n",
              "          8.3290070e-01, 3.0143219e-03], dtype=float32),\n",
              "   array([4.4503112e-04, 5.7109431e-03, 2.1420103e-03, ..., 3.5647683e-02,\n",
              "          7.8918135e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5341954e-04, 4.6330388e-03, 2.5049550e-03, ..., 7.6759869e-01,\n",
              "          6.1956042e-01, 8.0695990e-03], dtype=float32),\n",
              "   array([4.7542097e-04, 4.2001158e-03, 2.1692968e-03, ..., 6.8940409e-02,\n",
              "          5.4277897e-01, 7.0453696e-03], dtype=float32),\n",
              "   array([3.5971100e-04, 5.2954373e-03, 2.5251461e-03, ..., 1.0474874e+00,\n",
              "          5.3785872e-01, 7.6400215e-04], dtype=float32),\n",
              "   array([5.1224878e-04, 4.4974880e-03, 2.3251823e-03, ..., 1.2938522e-01,\n",
              "          5.5783534e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4195191e-04, 4.6588206e-03, 2.2315450e-03, ..., 1.8143178e-03,\n",
              "          9.1591865e-01, 1.0767492e-03], dtype=float32),\n",
              "   array([0.00034398, 0.00612449, 0.00258185, ..., 0.25821823, 0.32643008,\n",
              "          0.02817386], dtype=float32),\n",
              "   array([3.3749756e-04, 5.5929655e-03, 2.4390134e-03, ..., 6.5765452e-01,\n",
              "          2.3647702e-01, 8.6072898e-03], dtype=float32),\n",
              "   array([4.5911339e-04, 4.4449791e-03, 2.0273991e-03, ..., 2.0007339e-01,\n",
              "          7.1009618e-01, 1.3221568e-01], dtype=float32),\n",
              "   array([3.5448276e-04, 6.4222114e-03, 2.4827793e-03, ..., 4.6968076e-01,\n",
              "          8.1486994e-01, 1.5924081e-02], dtype=float32),\n",
              "   array([4.9269974e-04, 4.7704512e-03, 2.0874096e-03, ..., 4.4128594e-01,\n",
              "          7.2763956e-01, 1.4365821e-02], dtype=float32),\n",
              "   array([3.6286784e-04, 4.5029554e-03, 2.4839779e-03, ..., 6.7155939e-01,\n",
              "          5.8340043e-01, 9.1605810e-03], dtype=float32),\n",
              "   array([3.3666677e-04, 4.9956567e-03, 2.4259163e-03, ..., 9.2088860e-01,\n",
              "          1.6547891e-01, 2.7575077e-02], dtype=float32),\n",
              "   array([3.5560556e-04, 4.9410122e-03, 2.5172320e-03, ..., 2.7367648e-01,\n",
              "          3.7049970e-01, 6.6887692e-02], dtype=float32),\n",
              "   array([0.00043166, 0.00357114, 0.0022633 , ..., 0.03607147, 0.38664603,\n",
              "          0.046841  ], dtype=float32),\n",
              "   array([3.5452432e-04, 5.6179743e-03, 2.6165075e-03, ..., 6.0118580e-01,\n",
              "          3.8545027e-01, 1.9598724e-02], dtype=float32),\n",
              "   array([4.8476428e-04, 5.1342901e-03, 2.3396916e-03, ..., 8.6777270e-02,\n",
              "          8.2964224e-01, 2.9585040e-03], dtype=float32),\n",
              "   array([4.3653618e-04, 5.0434698e-03, 2.7105878e-03, ..., 4.1630152e-03,\n",
              "          4.7139856e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6399925e-04, 5.5605783e-03, 2.4898390e-03, ..., 1.0048513e+00,\n",
              "          4.1664886e-01, 2.1982512e-02], dtype=float32),\n",
              "   array([4.2935382e-04, 4.4133132e-03, 2.1981704e-03, ..., 8.0104262e-02,\n",
              "          5.5883068e-01, 3.1441901e-02], dtype=float32),\n",
              "   array([3.5850302e-04, 5.4261945e-03, 2.6367614e-03, ..., 9.0559596e-01,\n",
              "          6.7255050e-01, 2.1006051e-02], dtype=float32),\n",
              "   array([3.2262434e-04, 6.4761424e-03, 2.3150553e-03, ..., 6.8114424e-01,\n",
              "          5.2547425e-01, 1.1816850e-03], dtype=float32),\n",
              "   array([3.6054800e-04, 5.5019781e-03, 2.4148466e-03, ..., 2.1356049e-01,\n",
              "          6.4360768e-01, 1.5594700e-02], dtype=float32),\n",
              "   array([3.2965091e-04, 5.3273672e-03, 2.4789271e-03, ..., 7.3815107e-01,\n",
              "          1.7229702e-01, 3.1027626e-03], dtype=float32),\n",
              "   array([3.7414560e-04, 5.5022337e-03, 2.6991777e-03, ..., 8.8210136e-01,\n",
              "          2.8812984e-01, 2.9061839e-02], dtype=float32),\n",
              "   array([3.5866292e-04, 6.1469655e-03, 2.4763611e-03, ..., 7.5687563e-01,\n",
              "          4.2148998e-01, 7.2279431e-02], dtype=float32),\n",
              "   array([4.2731292e-04, 4.3432973e-03, 2.0746556e-03, ..., 3.2764472e-02,\n",
              "          5.0121093e-01, 1.2513061e-02], dtype=float32),\n",
              "   array([3.5133437e-04, 6.3854400e-03, 2.4698935e-03, ..., 2.8103280e-01,\n",
              "          5.9050298e-01, 1.0008285e-02], dtype=float32),\n",
              "   array([4.7570805e-04, 4.8796250e-03, 1.9478396e-03, ..., 7.1459293e-02,\n",
              "          6.4980388e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5192989e-04, 6.5180515e-03, 2.5197661e-03, ..., 3.6258617e-01,\n",
              "          5.8308077e-01, 1.4170488e-02], dtype=float32),\n",
              "   array([3.4754636e-04, 5.4054186e-03, 2.4271049e-03, ..., 9.9723798e-01,\n",
              "          3.8365653e-01, 5.1330649e-03], dtype=float32),\n",
              "   array([4.4217790e-04, 4.2260890e-03, 2.5362761e-03, ..., 3.4632686e-01,\n",
              "          5.9234816e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5940256e-04, 6.5270108e-03, 2.5169575e-03, ..., 5.6777221e-01,\n",
              "          5.1263064e-01, 2.7944945e-02], dtype=float32),\n",
              "   array([4.6236324e-04, 4.5417827e-03, 2.3084064e-03, ..., 2.6233722e-02,\n",
              "          7.8039557e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.7865239e-04, 4.8936107e-03, 2.2569532e-03, ..., 4.5528777e-02,\n",
              "          7.8766811e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3967430e-04, 6.3908561e-03, 2.4477162e-03, ..., 6.8290669e-01,\n",
              "          5.0926083e-01, 1.4897223e-02], dtype=float32),\n",
              "   array([4.3498815e-04, 4.6008104e-03, 2.2786518e-03, ..., 2.6232111e-01,\n",
              "          6.9136953e-01, 1.4022769e-03], dtype=float32),\n",
              "   array([3.6517679e-04, 6.1700083e-03, 2.4918751e-03, ..., 5.6180537e-01,\n",
              "          6.1043298e-01, 4.7156241e-02], dtype=float32),\n",
              "   array([3.4757360e-04, 5.7558827e-03, 2.5668056e-03, ..., 4.5859364e-01,\n",
              "          3.8126585e-01, 8.1362883e-03], dtype=float32),\n",
              "   array([3.4308276e-04, 6.0792388e-03, 2.3592839e-03, ..., 4.7874942e-01,\n",
              "          2.2339542e-01, 5.0218436e-03], dtype=float32),\n",
              "   array([4.5234631e-04, 4.4877348e-03, 1.8943569e-03, ..., 2.2375790e-02,\n",
              "          6.5252984e-01, 4.4069510e-02], dtype=float32),\n",
              "   array([3.5920436e-04, 6.5064882e-03, 2.5411008e-03, ..., 2.3992893e-01,\n",
              "          5.6643647e-01, 9.7558282e-02], dtype=float32),\n",
              "   array([4.7670482e-04, 4.6061142e-03, 2.0237814e-03, ..., 1.6889742e-01,\n",
              "          5.2093345e-01, 2.9911837e-03], dtype=float32),\n",
              "   array([4.4344139e-04, 5.0766133e-03, 2.2652941e-03, ..., 1.4879124e-01,\n",
              "          6.5638357e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3720749e-04, 5.2705007e-03, 2.4502012e-03, ..., 5.2539676e-01,\n",
              "          6.4829099e-01, 9.2514768e-02], dtype=float32),\n",
              "   array([0.00044378, 0.00391492, 0.00222702, ..., 0.02194973, 0.35839933,\n",
              "          0.        ], dtype=float32),\n",
              "   array([3.4987781e-04, 6.3755647e-03, 2.4282930e-03, ..., 3.8298094e-01,\n",
              "          4.5809895e-01, 3.8952436e-02], dtype=float32),\n",
              "   array([4.6405706e-04, 4.3600267e-03, 2.2165948e-03, ..., 6.3850097e-02,\n",
              "          9.1606438e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5535806e-04, 6.1589675e-03, 2.3745177e-03, ..., 1.1928060e-01,\n",
              "          4.7833502e-01, 1.3242013e-02], dtype=float32),\n",
              "   array([3.6926800e-04, 5.4755085e-03, 2.6511154e-03, ..., 1.3220330e+00,\n",
              "          4.5577019e-01, 1.4077080e-02], dtype=float32),\n",
              "   array([4.6303161e-04, 4.0899962e-03, 2.2533145e-03, ..., 2.3730558e-01,\n",
              "          5.9029520e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5199037e-04, 6.0581905e-03, 2.5420289e-03, ..., 6.2856668e-01,\n",
              "          3.4272113e-01, 1.2818388e-02], dtype=float32),\n",
              "   array([4.5025573e-04, 4.3572658e-03, 2.3850736e-03, ..., 2.0114334e-01,\n",
              "          7.3684967e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6372111e-04, 5.6825969e-03, 2.3631137e-03, ..., 8.8332601e-02,\n",
              "          7.1218294e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8068776e-04, 5.2338196e-03, 2.5346866e-03, ..., 5.2769250e-01,\n",
              "          4.9751303e-01, 1.3153438e-02], dtype=float32),\n",
              "   array([3.4898156e-04, 5.4939045e-03, 2.6269329e-03, ..., 8.8713127e-01,\n",
              "          2.0874289e-01, 3.2856651e-03], dtype=float32),\n",
              "   array([3.6292311e-04, 5.6956415e-03, 2.5306123e-03, ..., 1.1082000e+00,\n",
              "          3.1174061e-01, 7.0606116e-03], dtype=float32),\n",
              "   array([3.4320066e-04, 5.0768321e-03, 2.6714958e-03, ..., 6.8430680e-01,\n",
              "          4.7939196e-01, 3.1956486e-02], dtype=float32),\n",
              "   array([0.00047957, 0.004695  , 0.00235283, ..., 0.15939288, 0.41231233,\n",
              "          0.00785266], dtype=float32),\n",
              "   array([3.5392429e-04, 5.9367102e-03, 2.5420184e-03, ..., 7.0367908e-01,\n",
              "          5.1182538e-01, 1.7197309e-02], dtype=float32),\n",
              "   array([4.8824114e-04, 4.9919649e-03, 2.0844282e-03, ..., 3.2918215e-01,\n",
              "          5.3579611e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5292070e-04, 5.9219422e-03, 2.2915308e-03, ..., 4.2560834e-01,\n",
              "          2.5061968e-01, 4.3579973e-03], dtype=float32),\n",
              "   array([0.00035371, 0.00565146, 0.00239527, ..., 0.13062742, 0.2112852 ,\n",
              "          0.01431598], dtype=float32),\n",
              "   array([3.3364244e-04, 6.0446323e-03, 2.3776419e-03, ..., 6.1657619e-01,\n",
              "          1.9747256e-01, 4.4736532e-03], dtype=float32),\n",
              "   array([3.6205153e-04, 4.9846349e-03, 2.4206787e-03, ..., 3.7688041e-01,\n",
              "          1.2550060e-01, 1.0987138e-02], dtype=float32),\n",
              "   array([3.48231406e-04, 5.92251169e-03, 2.50810874e-03, ...,\n",
              "          2.53904194e-01, 4.92129654e-01, 1.08776465e-01], dtype=float32),\n",
              "   array([3.5101830e-04, 4.9559423e-03, 2.6154164e-03, ..., 1.4250432e+00,\n",
              "          4.3666685e-01, 2.6498609e-03], dtype=float32),\n",
              "   array([4.4176591e-04, 3.8193325e-03, 2.1553321e-03, ..., 1.4956476e-01,\n",
              "          5.4304510e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5985507e-04, 5.6148828e-03, 2.5406259e-03, ..., 4.0702540e-01,\n",
              "          4.4013447e-01, 4.2228322e-02], dtype=float32),\n",
              "   array([4.5685345e-04, 4.2829863e-03, 2.1201354e-03, ..., 2.2222392e-01,\n",
              "          7.7685767e-01, 1.9771582e-02], dtype=float32),\n",
              "   array([4.8501749e-04, 5.1107816e-03, 2.4292578e-03, ..., 1.8312789e-01,\n",
              "          5.2426058e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7576709e-04, 5.5589280e-03, 2.5875058e-03, ..., 9.3655825e-01,\n",
              "          4.4322595e-01, 7.8900628e-02], dtype=float32)],\n",
              "  153],\n",
              " [[array([0.00035394, 0.00612897, 0.00248243, ..., 0.33527058, 0.24946637,\n",
              "          0.00612455], dtype=float32),\n",
              "   array([3.5417947e-04, 5.1216823e-03, 2.3860049e-03, ..., 4.5522189e-01,\n",
              "          2.8263918e-01, 2.3105559e-03], dtype=float32),\n",
              "   array([3.6872839e-04, 5.1435377e-03, 2.5817342e-03, ..., 2.6950383e-01,\n",
              "          4.2016080e-01, 3.3033878e-02], dtype=float32),\n",
              "   array([3.5480439e-04, 5.5203047e-03, 2.7523253e-03, ..., 5.4405272e-01,\n",
              "          6.3912779e-01, 2.5280524e-02], dtype=float32),\n",
              "   array([4.6678816e-04, 4.3528490e-03, 2.4707299e-03, ..., 2.9538574e-02,\n",
              "          9.0156507e-01, 2.3697659e-02], dtype=float32),\n",
              "   array([3.6984510e-04, 6.6401721e-03, 2.6920857e-03, ..., 9.2091143e-01,\n",
              "          7.9784757e-01, 2.0486807e-02], dtype=float32),\n",
              "   array([4.9056811e-04, 4.4960086e-03, 2.4112030e-03, ..., 1.6435036e-01,\n",
              "          7.3652017e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.2315800e-04, 4.6490841e-03, 2.3332925e-03, ..., 4.5294333e-01,\n",
              "          8.3392483e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6565322e-04, 6.0199145e-03, 2.5558483e-03, ..., 1.0352614e+00,\n",
              "          5.1078945e-01, 5.8611389e-03], dtype=float32),\n",
              "   array([4.9288856e-04, 4.2809253e-03, 2.3017698e-03, ..., 1.8651941e-01,\n",
              "          7.2786605e-01, 6.7320839e-03], dtype=float32),\n",
              "   array([3.5921033e-04, 7.1858717e-03, 2.5190257e-03, ..., 7.8664458e-01,\n",
              "          7.5339299e-01, 1.6643217e-02], dtype=float32),\n",
              "   array([4.9272319e-04, 4.7023227e-03, 1.8247162e-03, ..., 1.9180667e-01,\n",
              "          9.1700315e-01, 0.0000000e+00], dtype=float32)],\n",
              "  12],\n",
              " [[array([3.3879129e-04, 6.0296766e-03, 2.3678383e-03, ..., 8.5258991e-01,\n",
              "          2.5512868e-01, 2.1489630e-03], dtype=float32),\n",
              "   array([3.8027170e-04, 5.5735135e-03, 2.5073455e-03, ..., 4.2947862e-01,\n",
              "          4.7094521e-01, 1.2617112e-02], dtype=float32),\n",
              "   array([3.5522596e-04, 5.6699263e-03, 2.4880064e-03, ..., 7.2812021e-01,\n",
              "          5.5790579e-01, 1.6424967e-02], dtype=float32),\n",
              "   array([3.5480870e-04, 5.8095395e-03, 2.4942451e-03, ..., 6.0890341e-01,\n",
              "          5.8428174e-01, 3.3975251e-02], dtype=float32),\n",
              "   array([4.7531415e-04, 4.7982251e-03, 2.1696475e-03, ..., 1.7798626e-01,\n",
              "          5.8303368e-01, 1.0258468e-02], dtype=float32),\n",
              "   array([3.4580546e-04, 6.1037601e-03, 2.5215792e-03, ..., 8.9819634e-01,\n",
              "          4.5354930e-01, 1.0811257e-03], dtype=float32),\n",
              "   array([4.8908358e-04, 5.6037027e-03, 2.0183371e-03, ..., 4.4469145e-01,\n",
              "          7.2367913e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([5.0177932e-04, 4.5829024e-03, 2.6919472e-03, ..., 7.2274983e-01,\n",
              "          7.1549255e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5084764e-04, 5.6780037e-03, 2.6554307e-03, ..., 1.0175742e+00,\n",
              "          4.5352325e-01, 2.5144411e-02], dtype=float32),\n",
              "   array([4.5328602e-04, 4.2920671e-03, 2.6513208e-03, ..., 1.3555475e-01,\n",
              "          4.7369000e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6753106e-04, 5.8269366e-03, 2.4408279e-03, ..., 3.6362916e-01,\n",
              "          4.2757273e-01, 3.0769493e-02], dtype=float32),\n",
              "   array([5.4347818e-04, 5.4386640e-03, 1.8701031e-03, ..., 8.6284745e-01,\n",
              "          5.7067382e-01, 7.3847797e-04], dtype=float32)],\n",
              "  12],\n",
              " [[array([3.2989532e-04, 6.5212469e-03, 2.3686232e-03, ..., 1.2654553e-01,\n",
              "          7.4129909e-01, 1.2959072e-03], dtype=float32),\n",
              "   array([3.4698623e-04, 5.7935514e-03, 2.5041553e-03, ..., 1.2424453e+00,\n",
              "          4.2537788e-01, 1.1180185e-02], dtype=float32),\n",
              "   array([3.6134856e-04, 6.2167770e-03, 3.1272429e-03, ..., 5.4547036e-01,\n",
              "          8.8424450e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5032677e-04, 3.9956071e-03, 2.3204891e-03, ..., 5.7908016e-01,\n",
              "          6.9086051e-01, 9.9125002e-03], dtype=float32),\n",
              "   array([3.7618383e-04, 5.5970950e-03, 2.6124816e-03, ..., 8.2942241e-01,\n",
              "          4.1086948e-01, 7.0011877e-03], dtype=float32),\n",
              "   array([4.9176050e-04, 4.8376257e-03, 2.1615135e-03, ..., 3.8267440e-01,\n",
              "          6.5841120e-01, 1.4988382e-02], dtype=float32),\n",
              "   array([4.7560944e-04, 5.0183348e-03, 2.2601162e-03, ..., 3.5270847e-02,\n",
              "          9.8254377e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4822265e-04, 6.2428969e-03, 2.6236139e-03, ..., 7.8794831e-01,\n",
              "          4.8036599e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6068078e-04, 4.5726695e-03, 1.9307211e-03, ..., 1.4400975e-01,\n",
              "          7.4006402e-01, 1.4155476e-03], dtype=float32),\n",
              "   array([3.5974715e-04, 6.3907881e-03, 2.5187253e-03, ..., 6.0621256e-01,\n",
              "          6.6577864e-01, 1.2139213e-02], dtype=float32),\n",
              "   array([5.2194326e-04, 5.1454525e-03, 2.4405639e-03, ..., 8.0317795e-01,\n",
              "          5.0549299e-01, 5.3597209e-03], dtype=float32)],\n",
              "  11],\n",
              " [[array([3.3676808e-04, 5.4406091e-03, 2.5312465e-03, ..., 5.8537298e-01,\n",
              "          2.6850468e-01, 1.9382148e-03], dtype=float32),\n",
              "   array([3.6230261e-04, 6.0578538e-03, 2.5301732e-03, ..., 6.1416000e-01,\n",
              "          7.4678445e-01, 8.4668182e-02], dtype=float32),\n",
              "   array([3.8105054e-04, 7.4067707e-03, 2.5464401e-03, ..., 1.5929911e-01,\n",
              "          8.7799996e-01, 1.3573068e-01], dtype=float32),\n",
              "   array([4.2637304e-04, 4.0579312e-03, 2.2087542e-03, ..., 0.0000000e+00,\n",
              "          7.7490658e-01, 5.8235507e-03], dtype=float32),\n",
              "   array([3.5643441e-04, 6.5455958e-03, 2.4414158e-03, ..., 1.6250621e-01,\n",
              "          6.2700629e-01, 1.5984060e-02], dtype=float32),\n",
              "   array([4.6292448e-04, 4.9255225e-03, 2.0867079e-03, ..., 1.6446841e-01,\n",
              "          6.3093561e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.6174170e-04, 5.2693412e-03, 3.0886214e-03, ..., 9.0345778e-03,\n",
              "          7.3148906e-01, 1.0688639e-03], dtype=float32),\n",
              "   array([3.7548356e-04, 6.0398178e-03, 2.4084467e-03, ..., 3.1156896e-02,\n",
              "          5.5262619e-01, 5.0931592e-02], dtype=float32),\n",
              "   array([4.4813281e-04, 4.5986278e-03, 2.0082174e-03, ..., 8.0795409e-03,\n",
              "          6.6977453e-01, 1.6613086e-03], dtype=float32),\n",
              "   array([3.8334183e-04, 5.1761707e-03, 2.6630529e-03, ..., 9.4738549e-01,\n",
              "          4.8507336e-01, 4.5889821e-03], dtype=float32)],\n",
              "  10],\n",
              " [[array([3.4176861e-04, 5.7464801e-03, 2.6195589e-03, ..., 8.5541689e-01,\n",
              "          5.0925225e-01, 6.3517215e-03], dtype=float32),\n",
              "   array([3.6668190e-04, 6.0115415e-03, 2.6909786e-03, ..., 6.0562956e-01,\n",
              "          8.0485183e-01, 2.7558938e-02], dtype=float32),\n",
              "   array([4.6818392e-04, 4.6218131e-03, 2.3922874e-03, ..., 6.7580283e-02,\n",
              "          6.7298466e-01, 7.4274674e-02], dtype=float32),\n",
              "   array([3.6505249e-04, 6.6412706e-03, 2.5182175e-03, ..., 2.7273041e-01,\n",
              "          6.0436970e-01, 8.8804429e-03], dtype=float32),\n",
              "   array([4.5773888e-04, 4.1197133e-03, 2.3883826e-03, ..., 1.1823372e-01,\n",
              "          7.3398864e-01, 1.0847324e-03], dtype=float32),\n",
              "   array([4.8367190e-04, 5.2750940e-03, 2.4796540e-03, ..., 1.3350177e-02,\n",
              "          8.5914427e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6005699e-04, 7.0374566e-03, 2.5110997e-03, ..., 4.1349664e-01,\n",
              "          8.4265476e-01, 2.5804061e-02], dtype=float32),\n",
              "   array([4.5404723e-04, 4.2033917e-03, 2.2785398e-03, ..., 1.3017657e-01,\n",
              "          7.0731562e-01, 6.7834191e-02], dtype=float32),\n",
              "   array([3.7338378e-04, 6.3042454e-03, 2.5070121e-03, ..., 5.7971632e-01,\n",
              "          2.8171200e-01, 3.6298923e-02], dtype=float32),\n",
              "   array([4.9378746e-04, 4.6090982e-03, 1.8014645e-03, ..., 1.7531556e-01,\n",
              "          8.6085540e-01, 3.7744915e-04], dtype=float32),\n",
              "   array([4.2378626e-04, 5.2199322e-03, 2.3880324e-03, ..., 1.2538782e-01,\n",
              "          8.4970504e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7363492e-04, 5.3191986e-03, 2.4856941e-03, ..., 3.4531543e-01,\n",
              "          4.5806086e-01, 4.2033419e-02], dtype=float32),\n",
              "   array([4.5031475e-04, 4.5141107e-03, 1.8666504e-03, ..., 1.6173208e-01,\n",
              "          7.6577121e-01, 1.9238453e-02], dtype=float32),\n",
              "   array([3.8024710e-04, 6.4976355e-03, 2.6583951e-03, ..., 5.2684367e-01,\n",
              "          6.5630341e-01, 1.9367760e-02], dtype=float32),\n",
              "   array([4.7905659e-04, 4.0452564e-03, 1.8716580e-03, ..., 2.8596005e-01,\n",
              "          8.5563791e-01, 2.7931347e-02], dtype=float32),\n",
              "   array([4.2288599e-04, 4.7213570e-03, 2.1036775e-03, ..., 5.7839107e-02,\n",
              "          9.1813016e-01, 3.9146305e-04], dtype=float32),\n",
              "   array([3.6317940e-04, 6.4911488e-03, 2.4278632e-03, ..., 2.0707406e-01,\n",
              "          5.5282038e-01, 6.5477438e-02], dtype=float32),\n",
              "   array([4.8528379e-04, 4.5767105e-03, 2.2891362e-03, ..., 3.3396643e-02,\n",
              "          6.0781407e-01, 1.1435524e-01], dtype=float32),\n",
              "   array([3.8269549e-04, 6.0514552e-03, 2.5573801e-03, ..., 4.3097723e-01,\n",
              "          4.7413838e-01, 5.3573191e-02], dtype=float32),\n",
              "   array([4.3883731e-04, 4.3655620e-03, 2.0821502e-03, ..., 8.8173285e-02,\n",
              "          8.3462226e-01, 4.4176180e-02], dtype=float32),\n",
              "   array([3.5520794e-04, 5.2054701e-03, 2.4238345e-03, ..., 4.3220320e-01,\n",
              "          4.1621563e-01, 6.8159372e-02], dtype=float32),\n",
              "   array([3.6816800e-04, 5.1451009e-03, 2.5007874e-03, ..., 4.2691666e-01,\n",
              "          4.1183972e-01, 1.8133285e-02], dtype=float32),\n",
              "   array([3.6995235e-04, 6.6382764e-03, 2.7134644e-03, ..., 2.9522407e-01,\n",
              "          1.1552545e+00, 4.4499084e-02], dtype=float32),\n",
              "   array([0.00049982, 0.00433681, 0.00258989, ..., 0.05906109, 0.44518292,\n",
              "          0.04186434], dtype=float32),\n",
              "   array([3.8272032e-04, 6.0447240e-03, 2.7544724e-03, ..., 5.1331598e-01,\n",
              "          4.9931929e-01, 2.2280946e-02], dtype=float32),\n",
              "   array([4.7341533e-04, 5.0015752e-03, 2.3133513e-03, ..., 1.9857326e-01,\n",
              "          8.5235292e-01, 2.4645212e-03], dtype=float32),\n",
              "   array([4.4734060e-04, 4.9325600e-03, 2.3458838e-03, ..., 1.7092209e-02,\n",
              "          8.2295871e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5917747e-04, 5.3458530e-03, 2.4552275e-03, ..., 4.9644446e-01,\n",
              "          6.3938427e-01, 1.0296484e-01], dtype=float32),\n",
              "   array([4.5544712e-04, 4.4603404e-03, 2.2958750e-03, ..., 2.8703751e-02,\n",
              "          6.3890791e-01, 4.4019014e-02], dtype=float32),\n",
              "   array([3.6872219e-04, 5.8671893e-03, 2.6256940e-03, ..., 5.9012544e-01,\n",
              "          5.8999991e-01, 2.3708750e-02], dtype=float32),\n",
              "   array([4.5643211e-04, 4.9956748e-03, 2.3236435e-03, ..., 3.4242782e-01,\n",
              "          8.1644779e-01, 0.0000000e+00], dtype=float32)],\n",
              "  31],\n",
              " [[array([3.4169923e-04, 6.5685553e-03, 2.2977474e-03, ..., 3.5149062e-01,\n",
              "          6.5197951e-01, 6.4271912e-03], dtype=float32),\n",
              "   array([0.00033971, 0.00568884, 0.00244009, ..., 0.30006698, 0.27650848,\n",
              "          0.00815634], dtype=float32),\n",
              "   array([3.4419150e-04, 5.4767733e-03, 2.6240917e-03, ..., 6.9935369e-01,\n",
              "          6.2768406e-01, 1.7720638e-02], dtype=float32),\n",
              "   array([3.5655437e-04, 5.4038269e-03, 2.6040697e-03, ..., 3.4087420e-01,\n",
              "          4.9999401e-01, 2.9368859e-02], dtype=float32),\n",
              "   array([4.5541627e-04, 4.6863565e-03, 2.1465605e-03, ..., 3.7630487e-02,\n",
              "          6.5660280e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4754912e-04, 6.6937604e-03, 2.5784445e-03, ..., 8.6156899e-01,\n",
              "          5.9483206e-01, 8.4133158e-03], dtype=float32),\n",
              "   array([4.6331881e-04, 4.7603445e-03, 1.9301797e-03, ..., 1.5017259e-01,\n",
              "          8.6757922e-01, 8.9527126e-03], dtype=float32)],\n",
              "  7],\n",
              " [[array([3.3261563e-04, 5.7546599e-03, 2.3753957e-03, ..., 5.1491630e-01,\n",
              "          2.2965014e-01, 5.4036123e-03], dtype=float32),\n",
              "   array([3.7255776e-04, 5.1909350e-03, 2.6635111e-03, ..., 1.1090125e+00,\n",
              "          5.8206111e-01, 2.6111219e-02], dtype=float32),\n",
              "   array([3.7951869e-04, 5.9591178e-03, 2.8004057e-03, ..., 4.6463192e-01,\n",
              "          1.1086620e+00, 1.3713504e-02], dtype=float32),\n",
              "   array([4.2677784e-04, 4.2724833e-03, 2.2323329e-03, ..., 2.3493836e-02,\n",
              "          4.7281480e-01, 3.0836773e-03], dtype=float32),\n",
              "   array([3.6309400e-04, 6.4551686e-03, 2.6304570e-03, ..., 2.4283479e-01,\n",
              "          4.7015595e-01, 2.7206037e-02], dtype=float32),\n",
              "   array([5.8805360e-04, 5.0973846e-03, 2.4750726e-03, ..., 8.0911410e-01,\n",
              "          3.0069286e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.57268296e-04, 4.80551599e-03, 2.65346793e-03, ...,\n",
              "          1.45452216e-01, 9.61122096e-01, 1.17248615e-04], dtype=float32)],\n",
              "  7],\n",
              " [[array([3.4982924e-04, 6.1240927e-03, 2.4121583e-03, ..., 3.0477789e-01,\n",
              "          5.0609404e-01, 4.8532579e-03], dtype=float32),\n",
              "   array([3.7284769e-04, 6.6675716e-03, 2.6095621e-03, ..., 4.2921317e-01,\n",
              "          6.3914007e-01, 1.1929985e-02], dtype=float32),\n",
              "   array([3.4210877e-04, 6.5919636e-03, 2.5552036e-03, ..., 4.6684676e-01,\n",
              "          6.0937965e-01, 7.0707664e-02], dtype=float32),\n",
              "   array([4.7487539e-04, 4.3568220e-03, 2.1969439e-03, ..., 8.8491514e-03,\n",
              "          7.1489745e-01, 6.3099167e-03], dtype=float32),\n",
              "   array([3.7029240e-04, 5.7472233e-03, 2.6365893e-03, ..., 6.3850814e-01,\n",
              "          6.1139458e-01, 2.2881288e-02], dtype=float32),\n",
              "   array([4.8308674e-04, 5.1264223e-03, 2.3117785e-03, ..., 5.9313238e-02,\n",
              "          8.3346862e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4578989e-04, 4.8577106e-03, 2.1938607e-03, ..., 1.8592602e-02,\n",
              "          1.0122753e+00, 7.8857917e-04], dtype=float32),\n",
              "   array([3.6636426e-04, 6.4364416e-03, 2.4026204e-03, ..., 3.1342369e-01,\n",
              "          6.6127896e-01, 4.3779373e-02], dtype=float32),\n",
              "   array([4.6135762e-04, 4.5993989e-03, 2.0625163e-03, ..., 6.5296769e-02,\n",
              "          8.6543679e-01, 2.1419358e-02], dtype=float32),\n",
              "   array([3.6472504e-04, 6.3203853e-03, 2.5163617e-03, ..., 6.2614620e-01,\n",
              "          6.2731326e-01, 9.5750280e-03], dtype=float32),\n",
              "   array([4.5649760e-04, 4.3017161e-03, 2.2853813e-03, ..., 1.6084518e-01,\n",
              "          8.2233167e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.2309362e-04, 5.0594192e-03, 2.3362504e-03, ..., 7.0470512e-02,\n",
              "          6.9383550e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5670085e-04, 5.8335681e-03, 2.5172578e-03, ..., 4.1354558e-01,\n",
              "          5.0537533e-01, 1.3282486e-02], dtype=float32),\n",
              "   array([4.7372023e-04, 4.4856044e-03, 2.1066116e-03, ..., 4.1664094e-02,\n",
              "          6.6506201e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6540625e-04, 6.4557455e-03, 2.5147314e-03, ..., 3.6324361e-01,\n",
              "          5.9085739e-01, 5.9702699e-03], dtype=float32),\n",
              "   array([4.6472275e-04, 4.2559840e-03, 2.3956837e-03, ..., 3.1510064e-01,\n",
              "          8.7179995e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3574688e-04, 6.2919650e-03, 2.3930599e-03, ..., 9.3520349e-01,\n",
              "          2.3923816e-01, 1.2149305e-02], dtype=float32),\n",
              "   array([3.5585099e-04, 5.7400619e-03, 2.5878337e-03, ..., 4.9711490e-01,\n",
              "          4.2474377e-01, 6.6546172e-02], dtype=float32),\n",
              "   array([3.7497378e-04, 6.5392717e-03, 2.8565628e-03, ..., 1.1881311e+00,\n",
              "          9.8551780e-01, 3.8559813e-02], dtype=float32),\n",
              "   array([4.9455342e-04, 4.4762813e-03, 2.2328810e-03, ..., 3.8025308e-02,\n",
              "          7.0625710e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6692579e-04, 6.4441799e-03, 2.5777679e-03, ..., 3.3071619e-01,\n",
              "          5.7031798e-01, 2.5464702e-02], dtype=float32),\n",
              "   array([5.2666460e-04, 4.2440291e-03, 2.4537048e-03, ..., 2.4057561e-01,\n",
              "          4.7169515e-01, 3.7931290e-04], dtype=float32),\n",
              "   array([4.6738671e-04, 5.0814566e-03, 2.5979914e-03, ..., 3.6497295e-01,\n",
              "          5.9670669e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4025460e-04, 5.7421401e-03, 2.8314434e-03, ..., 6.6071558e-01,\n",
              "          6.7939192e-01, 1.3483825e-02], dtype=float32),\n",
              "   array([4.3675525e-04, 4.3872013e-03, 2.3159727e-03, ..., 2.9908270e-02,\n",
              "          7.3509622e-01, 5.9374042e-02], dtype=float32),\n",
              "   array([3.7638721e-04, 6.8450351e-03, 2.3911502e-03, ..., 5.8604825e-01,\n",
              "          6.9237179e-01, 4.5319684e-03], dtype=float32)],\n",
              "  26],\n",
              " [[array([3.4840513e-04, 5.9762876e-03, 2.4747583e-03, ..., 5.8204341e-01,\n",
              "          3.6810604e-01, 6.1870256e-04], dtype=float32),\n",
              "   array([3.5063017e-04, 6.7520021e-03, 2.1894213e-03, ..., 1.3008046e-01,\n",
              "          4.9029842e-01, 3.0546584e-03], dtype=float32),\n",
              "   array([3.6492338e-04, 5.9547382e-03, 2.4905209e-03, ..., 1.3644652e+00,\n",
              "          2.9918596e-01, 1.3830458e-02], dtype=float32),\n",
              "   array([3.6113063e-04, 6.3518304e-03, 2.6093628e-03, ..., 1.1858444e+00,\n",
              "          5.6083006e-01, 6.1889486e-03], dtype=float32),\n",
              "   array([4.4334354e-04, 4.3412531e-03, 2.3930289e-03, ..., 7.0050985e-02,\n",
              "          4.5219913e-01, 2.0631982e-02], dtype=float32),\n",
              "   array([3.6027591e-04, 5.4643690e-03, 2.4434053e-03, ..., 1.4099607e+00,\n",
              "          3.9865726e-01, 5.7762973e-03], dtype=float32),\n",
              "   array([4.2129710e-04, 4.5137960e-03, 2.2748681e-03, ..., 2.6746494e-01,\n",
              "          8.6216581e-01, 1.8659789e-02], dtype=float32),\n",
              "   array([4.3081754e-04, 4.9116188e-03, 2.5352705e-03, ..., 5.7517448e-03,\n",
              "          7.3853701e-01, 9.9358021e-04], dtype=float32),\n",
              "   array([3.5936004e-04, 7.0659495e-03, 2.6630708e-03, ..., 5.7686388e-01,\n",
              "          7.0403349e-01, 1.7944714e-02], dtype=float32),\n",
              "   array([4.6804600e-04, 4.4821613e-03, 2.3523136e-03, ..., 6.1118475e-04,\n",
              "          8.0028999e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6008237e-04, 5.8601103e-03, 2.5317434e-03, ..., 3.0080754e-01,\n",
              "          4.1376516e-01, 2.2937289e-02], dtype=float32),\n",
              "   array([4.7885498e-04, 4.9436754e-03, 2.1865286e-03, ..., 2.1685933e-01,\n",
              "          6.7209721e-01, 2.1614201e-02], dtype=float32),\n",
              "   array([4.2764819e-04, 4.8523978e-03, 2.1896942e-03, ..., 7.0416187e-03,\n",
              "          9.1251594e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5400642e-04, 6.4771436e-03, 2.6543248e-03, ..., 6.0816503e-01,\n",
              "          7.3606002e-01, 1.8358745e-02], dtype=float32),\n",
              "   array([4.5022980e-04, 4.4190683e-03, 2.4943436e-03, ..., 2.0888861e-01,\n",
              "          5.1958030e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4997007e-04, 6.4393603e-03, 2.4438670e-03, ..., 6.7851162e-01,\n",
              "          4.1609076e-01, 5.5311140e-02], dtype=float32)],\n",
              "  16],\n",
              " [[array([3.5316509e-04, 5.2107135e-03, 2.5910544e-03, ..., 4.4833210e-01,\n",
              "          2.4898319e-01, 1.0921923e-02], dtype=float32),\n",
              "   array([3.4589329e-04, 5.3148950e-03, 2.5423700e-03, ..., 1.1103237e+00,\n",
              "          3.3791354e-01, 1.2941501e-03], dtype=float32),\n",
              "   array([3.7730596e-04, 6.1294152e-03, 2.6521939e-03, ..., 6.4051688e-01,\n",
              "          1.0035436e+00, 5.0850813e-03], dtype=float32),\n",
              "   array([4.3977893e-04, 4.1460753e-03, 2.4164063e-03, ..., 2.3040283e-01,\n",
              "          4.4960535e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8044975e-04, 6.0910797e-03, 2.5711043e-03, ..., 6.0476488e-01,\n",
              "          5.3392607e-01, 4.7390942e-02], dtype=float32),\n",
              "   array([5.2133633e-04, 5.0083743e-03, 2.0502131e-03, ..., 3.8927260e-01,\n",
              "          5.9029013e-01, 4.8597474e-03], dtype=float32),\n",
              "   array([4.3118023e-04, 4.9314247e-03, 2.0728435e-03, ..., 7.2825551e-03,\n",
              "          7.4158168e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5615618e-04, 5.0340975e-03, 2.6079514e-03, ..., 6.8316263e-01,\n",
              "          4.0644011e-01, 3.3052545e-03], dtype=float32),\n",
              "   array([4.6456116e-04, 4.4614868e-03, 2.2723956e-03, ..., 3.8557276e-02,\n",
              "          5.4088521e-01, 1.9764135e-02], dtype=float32),\n",
              "   array([3.7883857e-04, 5.9244819e-03, 2.5741744e-03, ..., 5.4342300e-01,\n",
              "          4.2871615e-01, 3.1224268e-02], dtype=float32),\n",
              "   array([5.3548696e-04, 4.6352702e-03, 2.2794220e-03, ..., 2.9945460e-01,\n",
              "          9.3497944e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.5161499e-04, 5.2366336e-03, 2.1512862e-03, ..., 1.0097371e-01,\n",
              "          8.2364452e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5383034e-04, 5.9841652e-03, 2.5075348e-03, ..., 5.8098787e-01,\n",
              "          4.8459715e-01, 3.5922103e-02], dtype=float32),\n",
              "   array([4.7832556e-04, 4.4212104e-03, 2.2875424e-03, ..., 4.2379954e-01,\n",
              "          6.0279483e-01, 1.2464277e-02], dtype=float32),\n",
              "   array([3.6233940e-04, 6.2127444e-03, 2.5611382e-03, ..., 4.0594029e-01,\n",
              "          4.9044317e-01, 6.2454179e-02], dtype=float32),\n",
              "   array([5.2235415e-04, 4.8686760e-03, 2.2202432e-03, ..., 3.6485738e-01,\n",
              "          7.0619231e-01, 3.0982651e-02], dtype=float32),\n",
              "   array([4.7696181e-04, 5.0036563e-03, 2.1657895e-03, ..., 5.7102536e-04,\n",
              "          1.1253120e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5061914e-04, 5.8222534e-03, 2.4015880e-03, ..., 7.4100310e-01,\n",
              "          5.5595571e-01, 1.3802645e-02], dtype=float32),\n",
              "   array([4.6242098e-04, 4.3117530e-03, 2.3941291e-03, ..., 1.5105928e-01,\n",
              "          5.9817070e-01, 1.9299438e-02], dtype=float32),\n",
              "   array([3.6496742e-04, 6.3140816e-03, 2.4662274e-03, ..., 3.9683020e-01,\n",
              "          5.0365597e-01, 3.2722477e-02], dtype=float32),\n",
              "   array([5.1470916e-04, 4.5793816e-03, 2.4354188e-03, ..., 2.1185578e-01,\n",
              "          6.4520234e-01, 2.9801400e-03], dtype=float32)],\n",
              "  21],\n",
              " [[array([3.2632277e-04, 5.2991151e-03, 2.4378363e-03, ..., 4.7582248e-01,\n",
              "          2.3671964e-01, 1.3288300e-03], dtype=float32),\n",
              "   array([3.6628044e-04, 5.4003503e-03, 2.5685558e-03, ..., 5.1222390e-01,\n",
              "          6.0869229e-01, 1.6324077e-02], dtype=float32),\n",
              "   array([3.5726742e-04, 6.4166426e-03, 2.6916417e-03, ..., 6.1755311e-01,\n",
              "          8.1192279e-01, 4.4297997e-02], dtype=float32),\n",
              "   array([5.0527632e-04, 4.0738066e-03, 2.5252048e-03, ..., 1.8564069e-01,\n",
              "          9.0739346e-01, 8.1003057e-03], dtype=float32),\n",
              "   array([4.9748202e-04, 4.0738122e-03, 2.4485197e-03, ..., 9.3778324e-01,\n",
              "          3.9637059e-01, 5.3314880e-02], dtype=float32),\n",
              "   array([4.4503043e-04, 4.6812911e-03, 1.8808227e-03, ..., 7.4476455e-03,\n",
              "          1.1313350e+00, 3.2778664e-03], dtype=float32),\n",
              "   array([3.5627090e-04, 7.0146169e-03, 2.8178878e-03, ..., 5.9245741e-01,\n",
              "          9.6631271e-01, 2.1202220e-03], dtype=float32),\n",
              "   array([4.2536148e-04, 4.3540257e-03, 2.3855958e-03, ..., 1.0751170e-01,\n",
              "          6.0219669e-01, 1.4202147e-02], dtype=float32),\n",
              "   array([3.6264272e-04, 6.1147637e-03, 2.5856427e-03, ..., 4.7973236e-01,\n",
              "          5.1549292e-01, 5.1584002e-02], dtype=float32),\n",
              "   array([4.84583055e-04, 4.70610242e-03, 2.27967813e-03, ...,\n",
              "          5.88273048e-01, 4.64990079e-01, 1.00304425e-01], dtype=float32),\n",
              "   array([4.6550491e-04, 4.8512272e-03, 2.2817804e-03, ..., 9.2976943e-02,\n",
              "          9.5610768e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7181261e-04, 6.7216046e-03, 2.5337287e-03, ..., 3.8066873e-01,\n",
              "          6.0100996e-01, 5.0193012e-02], dtype=float32),\n",
              "   array([4.2094354e-04, 4.6061571e-03, 1.9836060e-03, ..., 5.6754854e-02,\n",
              "          5.2064341e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6372701e-04, 5.7166177e-03, 2.5503801e-03, ..., 5.1097393e-01,\n",
              "          5.7635289e-01, 5.9794381e-02], dtype=float32),\n",
              "   array([3.8088599e-04, 5.5869855e-03, 2.5222781e-03, ..., 6.4008152e-01,\n",
              "          3.1361645e-01, 3.1818558e-02], dtype=float32),\n",
              "   array([3.3113483e-04, 5.5865827e-03, 2.4285521e-03, ..., 9.7295761e-01,\n",
              "          3.8696864e-01, 8.1016995e-02], dtype=float32),\n",
              "   array([3.4708786e-04, 5.0639384e-03, 2.4197237e-03, ..., 6.5976459e-01,\n",
              "          4.1348800e-01, 5.2603971e-02], dtype=float32),\n",
              "   array([4.2459043e-04, 4.7980123e-03, 2.5798010e-03, ..., 2.9046792e-01,\n",
              "          4.3734702e-01, 2.2263460e-04], dtype=float32),\n",
              "   array([3.6459506e-04, 5.8093085e-03, 2.6137677e-03, ..., 1.2187084e+00,\n",
              "          5.2372336e-01, 1.0615683e-03], dtype=float32),\n",
              "   array([5.1008444e-04, 4.9819993e-03, 2.1768254e-03, ..., 5.7650971e-01,\n",
              "          4.1487795e-01, 7.2989345e-04], dtype=float32),\n",
              "   array([4.4028211e-04, 4.2433538e-03, 2.0261409e-03, ..., 4.4565707e-02,\n",
              "          1.2105516e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.8195032e-04, 5.3612865e-03, 2.6044620e-03, ..., 8.3796972e-01,\n",
              "          5.5040032e-01, 7.0224721e-03], dtype=float32),\n",
              "   array([0.00045703, 0.00446292, 0.00259017, ..., 0.19493192, 0.4022189 ,\n",
              "          0.        ], dtype=float32),\n",
              "   array([3.5554901e-04, 5.8043892e-03, 2.5064852e-03, ..., 8.4231526e-01,\n",
              "          4.7779861e-01, 3.1842289e-03], dtype=float32),\n",
              "   array([4.7177155e-04, 4.4789203e-03, 2.0149541e-03, ..., 4.6159539e-01,\n",
              "          6.4761162e-01, 2.6160939e-02], dtype=float32),\n",
              "   array([4.65920981e-04, 4.95259138e-03, 2.61076307e-03, ...,\n",
              "          1.05636664e-01, 6.70698822e-01, 0.00000000e+00], dtype=float32),\n",
              "   array([3.2942483e-04, 6.6953753e-03, 2.7626781e-03, ..., 7.7505028e-01,\n",
              "          8.7981397e-01, 1.4729839e-02], dtype=float32),\n",
              "   array([4.5208170e-04, 4.8539499e-03, 2.2017471e-03, ..., 1.6059361e-01,\n",
              "          6.4328992e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7307793e-04, 6.0008741e-03, 2.3640296e-03, ..., 1.1195940e-01,\n",
              "          5.4399925e-01, 4.1226815e-02], dtype=float32),\n",
              "   array([0.00046951, 0.00461087, 0.00221863, ..., 0.40102962, 0.46226773,\n",
              "          0.04538945], dtype=float32)],\n",
              "  30],\n",
              " [[array([3.2535833e-04, 5.8474587e-03, 2.3806414e-03, ..., 5.3683084e-01,\n",
              "          3.7438974e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4438013e-04, 5.5441856e-03, 2.4508208e-03, ..., 4.2205516e-01,\n",
              "          2.4328506e-01, 1.2010910e-02], dtype=float32),\n",
              "   array([3.6196545e-04, 5.3803800e-03, 2.6199629e-03, ..., 8.9258569e-01,\n",
              "          3.4668994e-01, 7.6352549e-04], dtype=float32),\n",
              "   array([3.4497876e-04, 6.0514505e-03, 2.3719566e-03, ..., 8.1050366e-01,\n",
              "          5.9103334e-01, 5.7011187e-02], dtype=float32),\n",
              "   array([4.3594860e-04, 4.2017642e-03, 2.4591200e-03, ..., 3.9072317e-01,\n",
              "          5.4122931e-01, 1.0226505e-02], dtype=float32),\n",
              "   array([3.5516097e-04, 5.8067818e-03, 2.5673353e-03, ..., 8.1174207e-01,\n",
              "          6.0191035e-01, 3.9659999e-02], dtype=float32),\n",
              "   array([4.5848888e-04, 4.0085828e-03, 2.1695655e-03, ..., 4.2988053e-01,\n",
              "          5.4938334e-01, 3.2920614e-02], dtype=float32),\n",
              "   array([4.0944043e-04, 4.9701021e-03, 2.4919878e-03, ..., 2.2772357e-01,\n",
              "          4.7615573e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3849059e-04, 5.6924350e-03, 2.6022098e-03, ..., 4.6309434e-02,\n",
              "          9.5963103e-01, 7.1912348e-02], dtype=float32),\n",
              "   array([4.5737677e-04, 4.2943074e-03, 2.3638699e-03, ..., 1.2379944e-01,\n",
              "          4.7196066e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5908681e-04, 5.6540454e-03, 2.7071913e-03, ..., 1.1026113e+00,\n",
              "          4.5743978e-01, 3.1099210e-02], dtype=float32),\n",
              "   array([4.6897991e-04, 4.7251764e-03, 2.4659995e-03, ..., 5.0034249e-01,\n",
              "          6.2664419e-01, 4.2595330e-04], dtype=float32),\n",
              "   array([4.20276454e-04, 4.69518639e-03, 2.07431545e-03, ...,\n",
              "          1.06567964e-01, 7.59020686e-01, 0.00000000e+00], dtype=float32),\n",
              "   array([3.4589230e-04, 6.3513042e-03, 2.5245256e-03, ..., 7.3452169e-01,\n",
              "          4.4826189e-01, 1.8166604e-02], dtype=float32),\n",
              "   array([4.3038442e-04, 4.6177343e-03, 2.2346361e-03, ..., 1.0142052e-01,\n",
              "          5.9469950e-01, 2.6713626e-03], dtype=float32),\n",
              "   array([3.6206667e-04, 6.0984516e-03, 2.5448275e-03, ..., 5.5381221e-01,\n",
              "          3.8037479e-01, 3.3175580e-02], dtype=float32),\n",
              "   array([3.3032245e-04, 5.8623455e-03, 2.3377466e-03, ..., 4.1893843e-01,\n",
              "          3.6005321e-01, 7.9151792e-03], dtype=float32),\n",
              "   array([5.2256911e-04, 4.7959732e-03, 2.2068683e-03, ..., 4.0951601e-01,\n",
              "          6.0836267e-01, 1.4469348e-01], dtype=float32),\n",
              "   array([4.1282666e-04, 5.1145833e-03, 2.1996072e-03, ..., 0.0000000e+00,\n",
              "          1.0168577e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5759844e-04, 6.3264780e-03, 2.4144002e-03, ..., 7.7924675e-01,\n",
              "          4.3356895e-01, 3.5847852e-03], dtype=float32),\n",
              "   array([4.3342376e-04, 4.3855617e-03, 2.0970267e-03, ..., 1.2243175e-02,\n",
              "          6.4677638e-01, 2.6621167e-02], dtype=float32),\n",
              "   array([3.6311656e-04, 6.4032790e-03, 2.6025309e-03, ..., 6.9060218e-01,\n",
              "          4.0538585e-01, 7.3843896e-02], dtype=float32),\n",
              "   array([0.00054524, 0.00489785, 0.0023658 , ..., 0.13460726, 0.542359  ,\n",
              "          0.00507904], dtype=float32),\n",
              "   array([4.4242214e-04, 4.7244229e-03, 2.2064717e-03, ..., 3.6478404e-02,\n",
              "          8.2964128e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4737343e-04, 5.4389313e-03, 2.5269068e-03, ..., 4.9333012e-01,\n",
              "          3.5095546e-01, 6.9279987e-03], dtype=float32),\n",
              "   array([3.3546425e-04, 6.4613237e-03, 2.5259762e-03, ..., 6.0147280e-01,\n",
              "          4.7985664e-01, 1.9052047e-02], dtype=float32),\n",
              "   array([0.00045057, 0.00430894, 0.00230022, ..., 0.27164102, 0.3447848 ,\n",
              "          0.        ], dtype=float32),\n",
              "   array([3.6395228e-04, 6.2598037e-03, 2.5487277e-03, ..., 2.7013662e-01,\n",
              "          6.0675704e-01, 3.2224752e-02], dtype=float32),\n",
              "   array([4.9408374e-04, 4.7271987e-03, 2.1868739e-03, ..., 2.5411326e-01,\n",
              "          7.1717530e-01, 1.7193316e-03], dtype=float32),\n",
              "   array([3.5664550e-04, 5.7171565e-03, 2.4264245e-03, ..., 7.8956598e-01,\n",
              "          4.5849150e-01, 2.7575498e-02], dtype=float32),\n",
              "   array([3.4059561e-04, 5.8560404e-03, 2.3727801e-03, ..., 1.1679577e+00,\n",
              "          2.8167704e-01, 5.7713375e-03], dtype=float32),\n",
              "   array([4.7459122e-04, 4.9361703e-03, 1.8958645e-03, ..., 5.5089258e-03,\n",
              "          6.8386340e-01, 7.5542722e-03], dtype=float32),\n",
              "   array([3.5676084e-04, 5.8248397e-03, 2.6925160e-03, ..., 7.7807975e-01,\n",
              "          4.5505056e-01, 3.1266876e-02], dtype=float32),\n",
              "   array([4.4052987e-04, 4.3734964e-03, 2.3403615e-03, ..., 2.7701572e-01,\n",
              "          5.3545767e-01, 3.3786349e-02], dtype=float32),\n",
              "   array([3.3684444e-04, 6.4664748e-03, 2.5641106e-03, ..., 7.0897520e-01,\n",
              "          4.5247877e-01, 2.9749645e-02], dtype=float32),\n",
              "   array([3.5749850e-04, 6.2720324e-03, 2.6259916e-03, ..., 7.8832470e-02,\n",
              "          6.3984334e-01, 1.0139125e-01], dtype=float32),\n",
              "   array([3.6601484e-04, 5.2143717e-03, 2.6018887e-03, ..., 6.1482060e-01,\n",
              "          5.4394799e-01, 1.0756513e-01], dtype=float32),\n",
              "   array([3.4169678e-04, 5.5307010e-03, 2.6223275e-03, ..., 4.4649908e-01,\n",
              "          6.4444095e-01, 1.5967002e-02], dtype=float32),\n",
              "   array([4.5396434e-04, 4.4927564e-03, 2.2774637e-03, ..., 3.4087700e-01,\n",
              "          5.1959282e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7107861e-04, 5.8777519e-03, 2.6041521e-03, ..., 5.7206005e-01,\n",
              "          5.2429307e-01, 5.1826347e-02], dtype=float32),\n",
              "   array([4.6122025e-04, 4.8172050e-03, 2.2166960e-03, ..., 2.5630730e-01,\n",
              "          5.5981725e-01, 5.7657767e-02], dtype=float32),\n",
              "   array([5.3667964e-04, 4.6144719e-03, 2.3750782e-03, ..., 4.4300094e-02,\n",
              "          8.0231911e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6422830e-04, 6.4033289e-03, 2.3814107e-03, ..., 1.1216532e+00,\n",
              "          5.8636248e-01, 1.8640207e-02], dtype=float32),\n",
              "   array([4.6026008e-04, 4.5240270e-03, 2.3609488e-03, ..., 5.9034306e-01,\n",
              "          5.1882333e-01, 1.5870204e-02], dtype=float32),\n",
              "   array([3.4288751e-04, 5.8612805e-03, 2.6184337e-03, ..., 6.3533181e-01,\n",
              "          3.2022727e-01, 3.6825988e-02], dtype=float32),\n",
              "   array([4.1448246e-04, 4.7365283e-03, 2.3375826e-03, ..., 1.8775181e+00,\n",
              "          5.2542919e-01, 1.1492289e-03], dtype=float32)],\n",
              "  46],\n",
              " [[array([3.5391757e-04, 5.5983332e-03, 2.4716440e-03, ..., 7.5430572e-01,\n",
              "          3.8035288e-01, 1.3081510e-02], dtype=float32),\n",
              "   array([3.36606929e-04, 6.32307539e-03, 2.45997636e-03, ...,\n",
              "          6.86950505e-01, 7.47432768e-01, 1.20987706e-01], dtype=float32),\n",
              "   array([3.6057358e-04, 5.9043840e-03, 2.6474597e-03, ..., 3.7910247e-01,\n",
              "          8.3221048e-01, 4.3325696e-02], dtype=float32),\n",
              "   array([4.4655887e-04, 4.7771647e-03, 2.2005378e-03, ..., 4.2433053e-02,\n",
              "          7.2397721e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6136195e-04, 6.3267592e-03, 2.5123032e-03, ..., 4.3918443e-01,\n",
              "          4.7228664e-01, 6.5084174e-03], dtype=float32),\n",
              "   array([5.1864929e-04, 4.8672776e-03, 1.9188623e-03, ..., 2.8875208e-01,\n",
              "          5.7217735e-01, 3.3885885e-03], dtype=float32),\n",
              "   array([4.4801284e-04, 4.8012240e-03, 2.0798238e-03, ..., 3.9707994e-04,\n",
              "          1.0683550e+00, 2.1190608e-04], dtype=float32),\n",
              "   array([3.7458775e-04, 6.4038271e-03, 2.3971589e-03, ..., 1.2735188e-01,\n",
              "          5.0954074e-01, 8.2698539e-02], dtype=float32),\n",
              "   array([4.3843489e-04, 4.4026310e-03, 1.9561800e-03, ..., 4.5208767e-02,\n",
              "          7.4913353e-01, 3.4944866e-02], dtype=float32),\n",
              "   array([3.7221934e-04, 6.1904234e-03, 2.5323441e-03, ..., 4.3686700e-01,\n",
              "          5.2683675e-01, 4.2605955e-02], dtype=float32),\n",
              "   array([4.68986982e-04, 5.04685706e-03, 2.26654345e-03, ...,\n",
              "          1.17725685e-01, 9.83021975e-01, 1.23088583e-02], dtype=float32),\n",
              "   array([3.4903266e-04, 5.2369535e-03, 2.4958898e-03, ..., 6.6120130e-01,\n",
              "          5.1888156e-01, 2.9526813e-02], dtype=float32),\n",
              "   array([3.6489873e-04, 6.1765723e-03, 2.5182858e-03, ..., 5.0821745e-01,\n",
              "          2.2720443e-01, 4.6079303e-03], dtype=float32),\n",
              "   array([4.3945684e-04, 4.6611154e-03, 1.9561821e-03, ..., 3.3289690e-02,\n",
              "          6.0163528e-01, 1.2104116e-02], dtype=float32),\n",
              "   array([3.5701168e-04, 6.0684062e-03, 2.5775391e-03, ..., 7.1656257e-01,\n",
              "          4.5717394e-01, 1.3346476e-03], dtype=float32),\n",
              "   array([5.0089078e-04, 4.8235590e-03, 2.2690303e-03, ..., 2.6941106e-01,\n",
              "          7.8921849e-01, 3.0055290e-02], dtype=float32),\n",
              "   array([4.7688221e-04, 4.8634661e-03, 2.0354344e-03, ..., 8.8819943e-02,\n",
              "          8.8677448e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.1233827e-04, 5.0288662e-03, 3.0496784e-03, ..., 4.2877011e-02,\n",
              "          9.4173664e-01, 2.3752958e-02], dtype=float32),\n",
              "   array([4.4817841e-04, 4.4109672e-03, 2.1058419e-03, ..., 4.0613431e-02,\n",
              "          6.1105484e-01, 9.5372878e-02], dtype=float32),\n",
              "   array([3.5936438e-04, 6.1640982e-03, 2.5905478e-03, ..., 5.1821131e-01,\n",
              "          5.5239391e-01, 2.5382852e-02], dtype=float32)],\n",
              "  20],\n",
              " [[array([3.4107588e-04, 5.7381447e-03, 2.4536971e-03, ..., 1.7585520e-01,\n",
              "          4.2897025e-01, 4.0737889e-03], dtype=float32),\n",
              "   array([3.4509393e-04, 6.4187129e-03, 2.4634702e-03, ..., 5.8835709e-01,\n",
              "          6.5458661e-01, 8.3280064e-02], dtype=float32),\n",
              "   array([3.4634094e-04, 6.6698538e-03, 2.4565763e-03, ..., 6.7416131e-01,\n",
              "          5.6093544e-01, 5.1118664e-02], dtype=float32),\n",
              "   array([4.4781817e-04, 4.3206792e-03, 2.0664406e-03, ..., 1.5242768e-02,\n",
              "          5.9028101e-01, 1.3969422e-03], dtype=float32),\n",
              "   array([3.7547559e-04, 6.3165003e-03, 2.5479007e-03, ..., 3.7164202e-01,\n",
              "          5.8985090e-01, 1.6587691e-02], dtype=float32),\n",
              "   array([4.8489487e-04, 4.1820719e-03, 2.0783425e-03, ..., 3.6991549e-01,\n",
              "          7.4354786e-01, 9.6712541e-03], dtype=float32),\n",
              "   array([4.45732614e-04, 4.95208148e-03, 2.38139718e-03, ...,\n",
              "          1.16266675e-01, 8.82277191e-01, 0.00000000e+00], dtype=float32),\n",
              "   array([3.3532950e-04, 6.2679900e-03, 2.5030174e-03, ..., 3.6379293e-01,\n",
              "          4.9792823e-01, 8.9671589e-02], dtype=float32),\n",
              "   array([4.5574471e-04, 4.2155664e-03, 2.0088428e-03, ..., 2.7411209e-02,\n",
              "          6.9029957e-01, 2.1320747e-02], dtype=float32),\n",
              "   array([3.5433882e-04, 6.6856327e-03, 2.4612036e-03, ..., 1.0089965e+00,\n",
              "          7.2230601e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6206210e-04, 5.5492446e-03, 2.1932535e-03, ..., 7.9037958e-01,\n",
              "          4.7002462e-01, 2.3859015e-02], dtype=float32),\n",
              "   array([3.2813067e-04, 7.4155387e-03, 2.5302800e-03, ..., 1.1758508e-01,\n",
              "          3.5120586e-01, 8.8307671e-02], dtype=float32),\n",
              "   array([4.0198278e-04, 6.5220660e-03, 2.5724832e-03, ..., 2.9665887e-01,\n",
              "          8.3923548e-01, 3.9574418e-02], dtype=float32),\n",
              "   array([4.3133047e-04, 3.9480841e-03, 2.2283792e-03, ..., 5.7356600e-02,\n",
              "          4.7936937e-01, 1.4527695e-02], dtype=float32),\n",
              "   array([3.5893195e-04, 6.2308940e-03, 2.5792271e-03, ..., 5.1666176e-01,\n",
              "          4.4392729e-01, 2.1293601e-02], dtype=float32),\n",
              "   array([4.6120569e-04, 4.0384107e-03, 2.4028937e-03, ..., 4.4233027e-01,\n",
              "          7.8324467e-01, 5.2892580e-03], dtype=float32),\n",
              "   array([4.3582430e-04, 4.7536506e-03, 2.3526065e-03, ..., 5.9287148e-03,\n",
              "          6.0591906e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5636153e-04, 5.9318431e-03, 2.5468213e-03, ..., 2.2195563e-01,\n",
              "          4.2688927e-01, 1.8410118e-02], dtype=float32),\n",
              "   array([4.3037086e-04, 4.2560212e-03, 2.2878333e-03, ..., 6.6406527e-03,\n",
              "          6.3550818e-01, 4.6955256e-04], dtype=float32),\n",
              "   array([3.5935314e-04, 5.9242207e-03, 2.6558440e-03, ..., 4.9302804e-01,\n",
              "          3.9458019e-01, 1.1535689e-02], dtype=float32),\n",
              "   array([4.0312635e-04, 4.4700904e-03, 1.9211401e-03, ..., 1.9479725e-01,\n",
              "          9.3918246e-01, 7.6323926e-02], dtype=float32)],\n",
              "  21],\n",
              " [[array([3.3576501e-04, 6.9620786e-03, 2.2799256e-03, ..., 2.0036915e-01,\n",
              "          5.7936114e-01, 2.9747270e-02], dtype=float32),\n",
              "   array([3.5779114e-04, 6.8693664e-03, 2.4381769e-03, ..., 3.9840364e-01,\n",
              "          4.4389650e-01, 7.2559086e-03], dtype=float32),\n",
              "   array([3.7110559e-04, 6.5587759e-03, 2.6494958e-03, ..., 8.2773793e-01,\n",
              "          6.9935882e-01, 4.5548428e-02], dtype=float32),\n",
              "   array([3.5923033e-04, 6.3744518e-03, 2.5565412e-03, ..., 2.3162296e-01,\n",
              "          5.5076569e-01, 7.7308908e-02], dtype=float32),\n",
              "   array([4.6777524e-04, 4.2014290e-03, 1.8657896e-03, ..., 1.7131248e-01,\n",
              "          1.1586559e+00, 2.6392397e-02], dtype=float32),\n",
              "   array([3.4848665e-04, 6.4909025e-03, 2.1534446e-03, ..., 2.7469486e-01,\n",
              "          4.0653652e-01, 4.7031054e-03], dtype=float32),\n",
              "   array([4.5515667e-04, 3.6688526e-03, 2.0815588e-03, ..., 1.3073105e-01,\n",
              "          7.0900226e-01, 5.1755006e-03], dtype=float32),\n",
              "   array([4.6373726e-04, 5.0107297e-03, 2.4702726e-03, ..., 9.6161269e-02,\n",
              "          8.3010769e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3567569e-04, 5.6732101e-03, 2.5928337e-03, ..., 4.3661997e-02,\n",
              "          6.1578894e-01, 6.3105546e-02], dtype=float32),\n",
              "   array([4.3762653e-04, 4.2807111e-03, 2.1590961e-03, ..., 8.0025293e-02,\n",
              "          6.5430164e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.75994918e-04, 5.77846030e-03, 2.57774326e-03, ...,\n",
              "          1.80392668e-01, 4.20169681e-01, 1.04116425e-02], dtype=float32),\n",
              "   array([4.7197563e-04, 4.1121305e-03, 2.1133544e-03, ..., 2.7767959e-01,\n",
              "          6.4161700e-01, 5.2694655e-03], dtype=float32),\n",
              "   array([3.6375955e-04, 6.5193647e-03, 2.7780258e-03, ..., 4.7538482e-02,\n",
              "          5.3269607e-01, 4.9936220e-02], dtype=float32),\n",
              "   array([3.5359187e-04, 6.2974691e-03, 2.4039678e-03, ..., 6.8473256e-01,\n",
              "          4.3169329e-01, 2.5611280e-02], dtype=float32),\n",
              "   array([4.3901271e-04, 4.2450242e-03, 2.0999734e-03, ..., 3.7209183e-02,\n",
              "          5.8030349e-01, 1.7684430e-01], dtype=float32),\n",
              "   array([3.6785693e-04, 5.5636545e-03, 2.6987165e-03, ..., 4.5005280e-01,\n",
              "          6.1046284e-01, 3.5401136e-02], dtype=float32),\n",
              "   array([4.0667877e-04, 4.0674331e-03, 2.4466745e-03, ..., 1.0854549e+00,\n",
              "          6.6667831e-01, 1.8357906e-01], dtype=float32),\n",
              "   array([4.7685765e-04, 4.9693370e-03, 2.1556858e-03, ..., 1.0535497e-01,\n",
              "          8.3960563e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4141418e-04, 5.7378425e-03, 2.3926815e-03, ..., 8.0952930e-01,\n",
              "          3.9193767e-01, 2.1054694e-02], dtype=float32),\n",
              "   array([4.7171922e-04, 4.2608790e-03, 2.4838615e-03, ..., 7.0010588e-02,\n",
              "          9.1923320e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5404897e-04, 6.3301260e-03, 2.6557622e-03, ..., 8.0300647e-01,\n",
              "          5.3535569e-01, 2.0333322e-02], dtype=float32),\n",
              "   array([4.2572196e-04, 4.5553590e-03, 2.0614541e-03, ..., 2.3626333e-01,\n",
              "          9.2400485e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.2726472e-04, 4.9141813e-03, 2.6405957e-03, ..., 5.8840577e-02,\n",
              "          9.6148252e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6239807e-04, 6.3091596e-03, 2.4737832e-03, ..., 2.6558697e-01,\n",
              "          4.7544900e-01, 6.6288143e-02], dtype=float32),\n",
              "   array([5.0571334e-04, 4.3957587e-03, 2.2962443e-03, ..., 5.7095367e-02,\n",
              "          6.4089453e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6512231e-04, 5.8173300e-03, 2.6089859e-03, ..., 5.8708251e-01,\n",
              "          6.3799316e-01, 5.6102440e-02], dtype=float32)],\n",
              "  26],\n",
              " [[array([3.5330723e-04, 6.3992897e-03, 2.3539243e-03, ..., 3.6619779e-01,\n",
              "          6.5373671e-01, 1.8650522e-02], dtype=float32),\n",
              "   array([3.3483186e-04, 6.0535651e-03, 2.4200161e-03, ..., 2.4091725e-01,\n",
              "          5.0111181e-01, 1.2288546e-03], dtype=float32),\n",
              "   array([3.4411385e-04, 5.6854947e-03, 2.5301366e-03, ..., 9.5294833e-01,\n",
              "          3.9346468e-01, 6.3991182e-02], dtype=float32),\n",
              "   array([3.6470455e-04, 5.5143610e-03, 2.8060039e-03, ..., 8.2714701e-01,\n",
              "          5.9498864e-01, 6.0051944e-02], dtype=float32),\n",
              "   array([4.4350012e-04, 4.2037945e-03, 2.1972000e-03, ..., 1.6025595e-01,\n",
              "          6.5495396e-01, 1.1338711e-02], dtype=float32),\n",
              "   array([3.6308056e-04, 6.2819119e-03, 2.5664805e-03, ..., 3.6319983e-01,\n",
              "          4.8065448e-01, 3.6945537e-02], dtype=float32),\n",
              "   array([4.7081444e-04, 5.2445326e-03, 2.4809765e-03, ..., 3.1899315e-01,\n",
              "          8.1985670e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([4.4123892e-04, 4.5277695e-03, 2.6047872e-03, ..., 3.7339953e-01,\n",
              "          7.7937675e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.3929572e-04, 6.5300916e-03, 2.5037008e-03, ..., 1.2398045e-01,\n",
              "          4.3423936e-01, 6.0547542e-02], dtype=float32),\n",
              "   array([4.8490180e-04, 4.6201828e-03, 2.4181951e-03, ..., 1.5150203e-01,\n",
              "          5.5571121e-01, 1.4627826e-02], dtype=float32),\n",
              "   array([3.6964173e-04, 6.0514822e-03, 2.3834163e-03, ..., 6.5177089e-01,\n",
              "          3.8362348e-01, 5.2716523e-02], dtype=float32),\n",
              "   array([4.4519355e-04, 4.5198048e-03, 1.9565858e-03, ..., 1.1185535e-01,\n",
              "          8.6035377e-01, 1.6894763e-02], dtype=float32),\n",
              "   array([4.0374530e-04, 4.9160500e-03, 2.0229181e-03, ..., 6.2650844e-02,\n",
              "          1.0892872e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.4606113e-04, 5.8737858e-03, 2.5000616e-03, ..., 9.8923993e-01,\n",
              "          6.2502366e-01, 7.1566157e-02], dtype=float32),\n",
              "   array([4.5347781e-04, 4.3479982e-03, 2.5195470e-03, ..., 3.9484343e-01,\n",
              "          6.1753064e-01, 7.8297615e-02], dtype=float32),\n",
              "   array([3.4380515e-04, 5.8801142e-03, 2.5028263e-03, ..., 3.7351269e-01,\n",
              "          4.0522814e-01, 2.8202711e-02], dtype=float32),\n",
              "   array([4.9984077e-04, 4.8262961e-03, 2.2029500e-03, ..., 2.2161838e-01,\n",
              "          7.5572503e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([0.00035019, 0.00605071, 0.00230599, ..., 0.32725173, 0.25545576,\n",
              "          0.00539153], dtype=float32),\n",
              "   array([4.3724279e-04, 4.5836344e-03, 2.3822854e-03, ..., 1.3519618e-02,\n",
              "          5.1404732e-01, 1.5394782e-03], dtype=float32),\n",
              "   array([3.4498409e-04, 6.1565163e-03, 2.5447272e-03, ..., 4.2878154e-01,\n",
              "          4.3249854e-01, 5.1133167e-02], dtype=float32)],\n",
              "  20],\n",
              " [[array([3.5217800e-04, 5.7428265e-03, 2.4795996e-03, ..., 4.0351996e-01,\n",
              "          3.5443270e-01, 3.3313507e-04], dtype=float32),\n",
              "   array([3.6667587e-04, 5.8544828e-03, 2.4257991e-03, ..., 8.8362932e-01,\n",
              "          2.4635532e-01, 9.9066144e-04], dtype=float32),\n",
              "   array([3.6490307e-04, 5.4417215e-03, 2.6466595e-03, ..., 5.8887655e-01,\n",
              "          7.4241483e-01, 1.8920429e-02], dtype=float32),\n",
              "   array([3.6559629e-04, 6.9714542e-03, 3.1420346e-03, ..., 1.7719585e-01,\n",
              "          1.2546208e+00, 6.7762621e-02], dtype=float32),\n",
              "   array([3.7492500e-04, 6.1170915e-03, 2.8107732e-03, ..., 2.6806906e-01,\n",
              "          9.7647780e-01, 2.2445029e-02], dtype=float32),\n",
              "   array([4.1385912e-04, 3.9621857e-03, 2.2929693e-03, ..., 4.8502337e-02,\n",
              "          4.2463273e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6539970e-04, 5.9650815e-03, 2.4876981e-03, ..., 5.8604479e-01,\n",
              "          4.4036308e-01, 1.3046840e-02], dtype=float32),\n",
              "   array([5.5031001e-04, 5.0088726e-03, 2.1211389e-03, ..., 2.9787084e-01,\n",
              "          1.0923090e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([4.1239444e-04, 4.9023395e-03, 2.1159099e-03, ..., 1.0810948e-01,\n",
              "          8.1952339e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.5447971e-04, 6.5823384e-03, 2.4217190e-03, ..., 4.6516103e-01,\n",
              "          4.4090465e-01, 9.8978532e-03], dtype=float32),\n",
              "   array([4.4202417e-04, 4.4639390e-03, 2.2136674e-03, ..., 1.9364931e-02,\n",
              "          7.1991855e-01, 3.3829875e-02], dtype=float32),\n",
              "   array([3.6783467e-04, 6.2375311e-03, 2.5399537e-03, ..., 2.7223030e-01,\n",
              "          6.3546467e-01, 2.0319827e-02], dtype=float32),\n",
              "   array([4.8206214e-04, 4.4231284e-03, 2.0228706e-03, ..., 2.5095385e-01,\n",
              "          6.2982410e-01, 6.0651437e-03], dtype=float32),\n",
              "   array([4.1814338e-04, 4.7504390e-03, 2.1973618e-03, ..., 6.7814216e-02,\n",
              "          9.3487680e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.7583438e-04, 5.9241201e-03, 2.5337511e-03, ..., 3.6541581e-01,\n",
              "          5.3013605e-01, 8.8059334e-03], dtype=float32),\n",
              "   array([4.3577564e-04, 4.4945148e-03, 2.3275223e-03, ..., 4.9541347e-02,\n",
              "          4.9812561e-01, 2.8169241e-03], dtype=float32),\n",
              "   array([3.7839857e-04, 6.3385069e-03, 2.4549149e-03, ..., 8.9827675e-01,\n",
              "          2.5310814e-01, 4.2976546e-03], dtype=float32),\n",
              "   array([4.7666667e-04, 4.5393612e-03, 2.2028177e-03, ..., 1.4723442e-01,\n",
              "          1.0872570e+00, 9.2528751e-03], dtype=float32)],\n",
              "  18],\n",
              " [[array([3.5354728e-04, 5.4618074e-03, 2.4618651e-03, ..., 9.6167934e-01,\n",
              "          9.1824912e-02, 2.0951957e-03], dtype=float32),\n",
              "   array([3.2890119e-04, 6.0112514e-03, 2.4539859e-03, ..., 2.1484584e-01,\n",
              "          4.5606029e-01, 2.3848177e-03], dtype=float32),\n",
              "   array([3.9601701e-04, 5.0927694e-03, 2.4994276e-03, ..., 2.5893426e-02,\n",
              "          4.4017553e-01, 3.9044663e-02], dtype=float32),\n",
              "   array([3.5481207e-04, 5.3543164e-03, 2.5391418e-03, ..., 9.4996423e-01,\n",
              "          4.8729324e-01, 9.0613286e-04], dtype=float32),\n",
              "   array([3.3391392e-04, 5.9988424e-03, 2.5258008e-03, ..., 7.8691053e-01,\n",
              "          8.4263456e-01, 9.3304329e-03], dtype=float32),\n",
              "   array([4.8382109e-04, 4.9237940e-03, 2.2340121e-03, ..., 1.7435359e-02,\n",
              "          1.0974160e+00, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6185814e-04, 6.4133997e-03, 2.6313432e-03, ..., 2.7023977e-01,\n",
              "          6.5664774e-01, 3.5821237e-02], dtype=float32),\n",
              "   array([4.8472115e-04, 3.9861090e-03, 2.0749648e-03, ..., 5.7620382e-01,\n",
              "          4.7284123e-01, 1.0441833e-02], dtype=float32),\n",
              "   array([4.6788930e-04, 5.1395162e-03, 2.0891984e-03, ..., 1.1285856e-02,\n",
              "          7.8907692e-01, 0.0000000e+00], dtype=float32),\n",
              "   array([3.6184920e-04, 6.2183640e-03, 2.3480779e-03, ..., 1.6478935e-01,\n",
              "          5.1528460e-01, 2.9990321e-02], dtype=float32),\n",
              "   array([4.3664803e-04, 4.2951778e-03, 2.0150128e-03, ..., 1.0081889e-01,\n",
              "          6.7206365e-01, 3.2448385e-02], dtype=float32),\n",
              "   array([3.9298658e-04, 6.2921559e-03, 2.5947806e-03, ..., 3.0516142e-01,\n",
              "          6.2853324e-01, 2.7410716e-02], dtype=float32),\n",
              "   array([4.3686613e-04, 4.6636621e-03, 1.9368220e-03, ..., 1.0382740e-01,\n",
              "          7.2589469e-01, 0.0000000e+00], dtype=float32)],\n",
              "  13]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ1CRwEBoP9Q",
        "outputId": "13a6a0f3-478d-46db-ee12-0f2995316850"
      },
      "source": [
        "num_experiment_repeat = 100\n",
        "num_epoch = 50\n",
        "kf = KFold(n_splits  = 5)\n",
        "\n",
        "df_loss_accuracy = pd.DataFrame(columns=['Train Loss', 'Train Accuracy', 'Val Loss', 'Val Accuracy', 'Test Loss', 'Test Accuracy'])\n",
        "for iter in range(num_experiment_repeat):\n",
        "  print('\\n Iteration number :', iter)\n",
        "  encoded_targets, train_keys, test_keys, le = data_splitting_based_on_sample_size(syllable_df_Nest_Total, train_test_split_ratio = 0.5)\n",
        "\n",
        "  num_occurences = encoded_targets.groupby('indvi').nunique()\n",
        "  class_weights = num_occurences['key'].min()/num_occurences['key'].values\n",
        "\n",
        "  X_train = []; X_test =[];\n",
        "  y_train = []; y_test =[];\n",
        "\n",
        "  for key in encoded_targets['key'].unique():# [:10]:\n",
        "      data, label = create_sequence_feature(syllable_df_Nest_Total, key, le)\n",
        "      if key in train_keys:\n",
        "        X_train.append(data)\n",
        "        y_train.append(label)\n",
        "      elif key in test_keys:\n",
        "        X_test.append(data)\n",
        "        y_test.append(label)\n",
        "      else:\n",
        "        print(key, \"Not Found\")\n",
        "\n",
        "  model_fixed =  LSTM_fixed_len(1024, 10, 4)\n",
        "\n",
        "  train_loss, train_accuracy, val_loss, val_accuracy =  train_model(model_fixed, kf, class_weights, epochs=num_epoch, lr=0.001)\n",
        "\n",
        "  test_ds = ReviewsDataset(X_test, y_test)\n",
        "\n",
        "  test_loss, test_accuracy, test_rmse = validation_metrics(model_fixed, test_ds, class_weights)\n",
        "\n",
        "  df_loss_accuracy = df_loss_accuracy.append({'Train Loss': train_loss , 'Train Accuracy': train_accuracy.numpy(),  'Val Loss':  val_loss, \n",
        "                                            'Val Accuracy': val_accuracy.numpy(),'Test Loss': test_loss, 'Test Accuracy': test_accuracy.numpy()} , ignore_index=True)\n",
        "  df_loss_accuracy.to_csv(base_path+'/Results/'+Nest_analysis+'_'+'Backup_if_terminate.csv')\n",
        "\n",
        "now = datetime.now() \n",
        "dt_string = now.strftime(\"%d_%m_%Y_%H_%M\")\n",
        "df_loss_accuracy.to_csv(base_path+'/Results/'+Nest_analysis+'_'+dt_string+'.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 42, train loss 0.002, train accuracy 0.984, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 0.984, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 0.997, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.997, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.984, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.997, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 4\n",
            "Epoch 0, train loss 0.053, train accuracy 0.218, val loss 0.277, val accuracy 0.243, and val rmse 0.333\n",
            "Epoch 1, train loss 0.052, train accuracy 0.321, val loss 0.268, val accuracy 0.213, and val rmse 0.347\n",
            "Epoch 2, train loss 0.050, train accuracy 0.344, val loss 0.257, val accuracy 0.280, and val rmse 0.147\n",
            "Epoch 3, train loss 0.048, train accuracy 0.279, val loss 0.257, val accuracy 0.053, and val rmse 0.213\n",
            "Epoch 4, train loss 0.045, train accuracy 0.373, val loss 0.234, val accuracy 0.260, and val rmse 0.347\n",
            "Epoch 5, train loss 0.042, train accuracy 0.516, val loss 0.211, val accuracy 0.438, and val rmse 0.347\n",
            "Epoch 6, train loss 0.039, train accuracy 0.692, val loss 0.201, val accuracy 0.756, and val rmse 0.053\n",
            "Epoch 7, train loss 0.036, train accuracy 0.727, val loss 0.184, val accuracy 0.756, and val rmse 0.053\n",
            "Epoch 8, train loss 0.034, train accuracy 0.750, val loss 0.172, val accuracy 0.756, and val rmse 0.053\n",
            "Epoch 9, train loss 0.031, train accuracy 0.789, val loss 0.153, val accuracy 0.806, and val rmse 0.053\n",
            "Epoch 10, train loss 0.028, train accuracy 0.818, val loss 0.142, val accuracy 0.859, and val rmse 0.027\n",
            "Epoch 11, train loss 0.027, train accuracy 0.818, val loss 0.135, val accuracy 0.847, and val rmse 0.027\n",
            "Epoch 12, train loss 0.024, train accuracy 0.844, val loss 0.120, val accuracy 0.846, and val rmse 0.000\n",
            "Epoch 13, train loss 0.024, train accuracy 0.776, val loss 0.125, val accuracy 0.833, and val rmse 0.000\n",
            "Epoch 14, train loss 0.022, train accuracy 0.828, val loss 0.108, val accuracy 0.846, and val rmse 0.000\n",
            "Epoch 15, train loss 0.019, train accuracy 0.860, val loss 0.098, val accuracy 0.846, and val rmse 0.000\n",
            "Epoch 16, train loss 0.019, train accuracy 0.873, val loss 0.085, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 17, train loss 0.018, train accuracy 0.864, val loss 0.083, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 18, train loss 0.016, train accuracy 0.886, val loss 0.080, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 19, train loss 0.015, train accuracy 0.903, val loss 0.073, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 20, train loss 0.014, train accuracy 0.893, val loss 0.067, val accuracy 0.898, and val rmse 0.000\n",
            "Epoch 21, train loss 0.011, train accuracy 0.925, val loss 0.058, val accuracy 0.898, and val rmse 0.027\n",
            "Epoch 22, train loss 0.010, train accuracy 0.971, val loss 0.051, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 23, train loss 0.010, train accuracy 0.964, val loss 0.046, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.010, train accuracy 0.951, val loss 0.043, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.009, train accuracy 0.971, val loss 0.037, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.008, train accuracy 0.977, val loss 0.037, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 27, train loss 0.008, train accuracy 0.990, val loss 0.032, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.007, train accuracy 0.987, val loss 0.030, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.007, train accuracy 0.987, val loss 0.048, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 30, train loss 0.005, train accuracy 0.987, val loss 0.027, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.005, train accuracy 0.987, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.006, train accuracy 0.984, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.997, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 0.994, val loss 0.028, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.994, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.987, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.990, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.997, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.997, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 1.000, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.997, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.997, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.004, train accuracy 0.971, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 5\n",
            "Epoch 0, train loss 0.050, train accuracy 0.552, val loss 0.282, val accuracy 0.063, and val rmse 0.400\n",
            "Epoch 1, train loss 0.045, train accuracy 0.581, val loss 0.228, val accuracy 0.562, and val rmse 0.387\n",
            "Epoch 2, train loss 0.042, train accuracy 0.578, val loss 0.212, val accuracy 0.582, and val rmse 0.160\n",
            "Epoch 3, train loss 0.038, train accuracy 0.666, val loss 0.206, val accuracy 0.463, and val rmse 0.200\n",
            "Epoch 4, train loss 0.035, train accuracy 0.594, val loss 0.185, val accuracy 0.549, and val rmse 0.253\n",
            "Epoch 5, train loss 0.032, train accuracy 0.646, val loss 0.166, val accuracy 0.502, and val rmse 0.253\n",
            "Epoch 6, train loss 0.028, train accuracy 0.659, val loss 0.141, val accuracy 0.617, and val rmse 0.253\n",
            "Epoch 7, train loss 0.026, train accuracy 0.682, val loss 0.128, val accuracy 0.669, and val rmse 0.200\n",
            "Epoch 8, train loss 0.025, train accuracy 0.711, val loss 0.126, val accuracy 0.561, and val rmse 0.307\n",
            "Epoch 9, train loss 0.025, train accuracy 0.640, val loss 0.122, val accuracy 0.565, and val rmse 0.240\n",
            "Epoch 10, train loss 0.023, train accuracy 0.695, val loss 0.115, val accuracy 0.565, and val rmse 0.213\n",
            "Epoch 11, train loss 0.020, train accuracy 0.756, val loss 0.101, val accuracy 0.673, and val rmse 0.213\n",
            "Epoch 12, train loss 0.019, train accuracy 0.815, val loss 0.094, val accuracy 0.795, and val rmse 0.040\n",
            "Epoch 13, train loss 0.015, train accuracy 0.903, val loss 0.076, val accuracy 0.934, and val rmse 0.040\n",
            "Epoch 14, train loss 0.013, train accuracy 0.938, val loss 0.065, val accuracy 0.947, and val rmse 0.067\n",
            "Epoch 15, train loss 0.012, train accuracy 0.935, val loss 0.060, val accuracy 0.947, and val rmse 0.067\n",
            "Epoch 16, train loss 0.012, train accuracy 0.925, val loss 0.120, val accuracy 0.797, and val rmse 0.067\n",
            "Epoch 17, train loss 0.010, train accuracy 0.948, val loss 0.044, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 18, train loss 0.009, train accuracy 0.971, val loss 0.038, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 19, train loss 0.008, train accuracy 0.964, val loss 0.034, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 20, train loss 0.007, train accuracy 0.968, val loss 0.030, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 21, train loss 0.006, train accuracy 0.990, val loss 0.027, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 22, train loss 0.006, train accuracy 0.971, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 23, train loss 0.006, train accuracy 0.981, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.004, train accuracy 0.987, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.006, train accuracy 0.994, val loss 0.030, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.005, train accuracy 0.984, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.005, train accuracy 0.981, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.005, train accuracy 0.990, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.004, train accuracy 0.981, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.004, train accuracy 0.981, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.004, train accuracy 0.948, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.004, train accuracy 0.974, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.003, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.003, train accuracy 1.000, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.002, train accuracy 0.997, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.002, train accuracy 0.987, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.990, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.994, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 6\n",
            "Epoch 0, train loss 0.054, train accuracy 0.172, val loss 0.278, val accuracy 0.272, and val rmse 0.400\n",
            "Epoch 1, train loss 0.054, train accuracy 0.315, val loss 0.293, val accuracy 0.213, and val rmse 0.480\n",
            "Epoch 2, train loss 0.052, train accuracy 0.247, val loss 0.272, val accuracy 0.173, and val rmse 0.307\n",
            "Epoch 3, train loss 0.051, train accuracy 0.299, val loss 0.272, val accuracy 0.147, and val rmse 0.387\n",
            "Epoch 4, train loss 0.050, train accuracy 0.279, val loss 0.256, val accuracy 0.199, and val rmse 0.387\n",
            "Epoch 5, train loss 0.049, train accuracy 0.367, val loss 0.266, val accuracy 0.198, and val rmse 0.387\n",
            "Epoch 6, train loss 0.047, train accuracy 0.380, val loss 0.257, val accuracy 0.105, and val rmse 0.387\n",
            "Epoch 7, train loss 0.045, train accuracy 0.416, val loss 0.235, val accuracy 0.243, and val rmse 0.387\n",
            "Epoch 8, train loss 0.043, train accuracy 0.471, val loss 0.223, val accuracy 0.284, and val rmse 0.387\n",
            "Epoch 9, train loss 0.040, train accuracy 0.549, val loss 0.205, val accuracy 0.350, and val rmse 0.387\n",
            "Epoch 10, train loss 0.037, train accuracy 0.578, val loss 0.199, val accuracy 0.498, and val rmse 0.160\n",
            "Epoch 11, train loss 0.037, train accuracy 0.461, val loss 0.189, val accuracy 0.206, and val rmse 0.400\n",
            "Epoch 12, train loss 0.033, train accuracy 0.562, val loss 0.174, val accuracy 0.441, and val rmse 0.400\n",
            "Epoch 13, train loss 0.033, train accuracy 0.558, val loss 0.177, val accuracy 0.316, and val rmse 0.400\n",
            "Epoch 14, train loss 0.033, train accuracy 0.604, val loss 0.177, val accuracy 0.524, and val rmse 0.133\n",
            "Epoch 15, train loss 0.030, train accuracy 0.675, val loss 0.156, val accuracy 0.559, and val rmse 0.213\n",
            "Epoch 16, train loss 0.028, train accuracy 0.679, val loss 0.144, val accuracy 0.572, and val rmse 0.187\n",
            "Epoch 17, train loss 0.026, train accuracy 0.727, val loss 0.138, val accuracy 0.613, and val rmse 0.133\n",
            "Epoch 18, train loss 0.025, train accuracy 0.750, val loss 0.132, val accuracy 0.638, and val rmse 0.133\n",
            "Epoch 19, train loss 0.024, train accuracy 0.708, val loss 0.122, val accuracy 0.637, and val rmse 0.133\n",
            "Epoch 20, train loss 0.022, train accuracy 0.769, val loss 0.118, val accuracy 0.637, and val rmse 0.133\n",
            "Epoch 21, train loss 0.021, train accuracy 0.753, val loss 0.117, val accuracy 0.636, and val rmse 0.133\n",
            "Epoch 22, train loss 0.020, train accuracy 0.779, val loss 0.112, val accuracy 0.675, and val rmse 0.160\n",
            "Epoch 23, train loss 0.020, train accuracy 0.773, val loss 0.100, val accuracy 0.702, and val rmse 0.107\n",
            "Epoch 24, train loss 0.019, train accuracy 0.792, val loss 0.109, val accuracy 0.691, and val rmse 0.107\n",
            "Epoch 25, train loss 0.018, train accuracy 0.815, val loss 0.107, val accuracy 0.691, and val rmse 0.107\n",
            "Epoch 26, train loss 0.017, train accuracy 0.779, val loss 0.109, val accuracy 0.651, and val rmse 0.107\n",
            "Epoch 27, train loss 0.016, train accuracy 0.828, val loss 0.094, val accuracy 0.728, and val rmse 0.107\n",
            "Epoch 28, train loss 0.015, train accuracy 0.838, val loss 0.081, val accuracy 0.792, and val rmse 0.080\n",
            "Epoch 29, train loss 0.014, train accuracy 0.864, val loss 0.072, val accuracy 0.845, and val rmse 0.080\n",
            "Epoch 30, train loss 0.013, train accuracy 0.873, val loss 0.067, val accuracy 0.908, and val rmse 0.080\n",
            "Epoch 31, train loss 0.012, train accuracy 0.877, val loss 0.063, val accuracy 0.908, and val rmse 0.080\n",
            "Epoch 32, train loss 0.013, train accuracy 0.903, val loss 0.056, val accuracy 0.934, and val rmse 0.053\n",
            "Epoch 33, train loss 0.010, train accuracy 0.903, val loss 0.063, val accuracy 0.858, and val rmse 0.080\n",
            "Epoch 34, train loss 0.010, train accuracy 0.929, val loss 0.047, val accuracy 0.921, and val rmse 0.107\n",
            "Epoch 35, train loss 0.009, train accuracy 0.942, val loss 0.044, val accuracy 0.921, and val rmse 0.107\n",
            "Epoch 36, train loss 0.008, train accuracy 0.951, val loss 0.040, val accuracy 0.934, and val rmse 0.080\n",
            "Epoch 37, train loss 0.008, train accuracy 0.955, val loss 0.037, val accuracy 0.934, and val rmse 0.080\n",
            "Epoch 38, train loss 0.007, train accuracy 0.948, val loss 0.034, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 39, train loss 0.006, train accuracy 0.977, val loss 0.029, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 40, train loss 0.005, train accuracy 0.987, val loss 0.026, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 41, train loss 0.005, train accuracy 0.987, val loss 0.024, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 42, train loss 0.004, train accuracy 0.987, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.004, train accuracy 0.994, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.004, train accuracy 0.981, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.003, train accuracy 0.994, val loss 0.034, val accuracy 0.938, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.994, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.990, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.004, train accuracy 0.981, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 7\n",
            "Epoch 0, train loss 0.054, train accuracy 0.286, val loss 0.282, val accuracy 0.258, and val rmse 0.400\n",
            "Epoch 1, train loss 0.051, train accuracy 0.373, val loss 0.265, val accuracy 0.291, and val rmse 0.240\n",
            "Epoch 2, train loss 0.052, train accuracy 0.429, val loss 0.291, val accuracy 0.387, and val rmse 0.027\n",
            "Epoch 3, train loss 0.049, train accuracy 0.357, val loss 0.256, val accuracy 0.347, and val rmse 0.053\n",
            "Epoch 4, train loss 0.046, train accuracy 0.412, val loss 0.248, val accuracy 0.387, and val rmse 0.013\n",
            "Epoch 5, train loss 0.041, train accuracy 0.604, val loss 0.211, val accuracy 0.621, and val rmse 0.000\n",
            "Epoch 6, train loss 0.037, train accuracy 0.714, val loss 0.202, val accuracy 0.710, and val rmse 0.000\n",
            "Epoch 7, train loss 0.034, train accuracy 0.851, val loss 0.181, val accuracy 0.711, and val rmse 0.000\n",
            "Epoch 8, train loss 0.031, train accuracy 0.919, val loss 0.173, val accuracy 0.762, and val rmse 0.000\n",
            "Epoch 9, train loss 0.027, train accuracy 0.938, val loss 0.134, val accuracy 0.973, and val rmse 0.013\n",
            "Epoch 10, train loss 0.024, train accuracy 0.961, val loss 0.120, val accuracy 0.973, and val rmse 0.013\n",
            "Epoch 11, train loss 0.022, train accuracy 0.971, val loss 0.115, val accuracy 0.973, and val rmse 0.013\n",
            "Epoch 12, train loss 0.020, train accuracy 0.971, val loss 0.100, val accuracy 0.973, and val rmse 0.013\n",
            "Epoch 13, train loss 0.019, train accuracy 0.958, val loss 0.091, val accuracy 0.973, and val rmse 0.013\n",
            "Epoch 14, train loss 0.019, train accuracy 0.964, val loss 0.091, val accuracy 0.973, and val rmse 0.013\n",
            "Epoch 15, train loss 0.015, train accuracy 0.981, val loss 0.082, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 16, train loss 0.014, train accuracy 0.984, val loss 0.071, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 17, train loss 0.013, train accuracy 0.984, val loss 0.066, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 18, train loss 0.012, train accuracy 0.987, val loss 0.056, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 19, train loss 0.011, train accuracy 0.994, val loss 0.051, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 20, train loss 0.010, train accuracy 0.994, val loss 0.054, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 21, train loss 0.010, train accuracy 0.977, val loss 0.042, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 22, train loss 0.009, train accuracy 0.990, val loss 0.040, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 23, train loss 0.008, train accuracy 0.981, val loss 0.037, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.007, train accuracy 0.994, val loss 0.033, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.006, train accuracy 1.000, val loss 0.030, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.007, train accuracy 0.990, val loss 0.037, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 27, train loss 0.006, train accuracy 0.990, val loss 0.027, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.005, train accuracy 0.997, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.004, train accuracy 1.000, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.004, train accuracy 1.000, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.004, train accuracy 0.990, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.003, train accuracy 0.994, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.003, train accuracy 0.987, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.003, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.003, train accuracy 0.994, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.987, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.990, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 0.997, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 0.994, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 0.994, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 8\n",
            "Epoch 0, train loss 0.054, train accuracy 0.198, val loss 0.268, val accuracy 0.257, and val rmse 0.400\n",
            "Epoch 1, train loss 0.052, train accuracy 0.292, val loss 0.280, val accuracy 0.183, and val rmse 0.213\n",
            "Epoch 2, train loss 0.052, train accuracy 0.201, val loss 0.272, val accuracy 0.184, and val rmse 0.227\n",
            "Epoch 3, train loss 0.049, train accuracy 0.360, val loss 0.261, val accuracy 0.247, and val rmse 0.373\n",
            "Epoch 4, train loss 0.047, train accuracy 0.464, val loss 0.252, val accuracy 0.443, and val rmse 0.240\n",
            "Epoch 5, train loss 0.045, train accuracy 0.581, val loss 0.237, val accuracy 0.570, and val rmse 0.173\n",
            "Epoch 6, train loss 0.043, train accuracy 0.640, val loss 0.224, val accuracy 0.637, and val rmse 0.093\n",
            "Epoch 7, train loss 0.042, train accuracy 0.643, val loss 0.221, val accuracy 0.519, and val rmse 0.293\n",
            "Epoch 8, train loss 0.040, train accuracy 0.669, val loss 0.203, val accuracy 0.715, and val rmse 0.053\n",
            "Epoch 9, train loss 0.038, train accuracy 0.708, val loss 0.193, val accuracy 0.742, and val rmse 0.013\n",
            "Epoch 10, train loss 0.036, train accuracy 0.731, val loss 0.187, val accuracy 0.729, and val rmse 0.013\n",
            "Epoch 11, train loss 0.035, train accuracy 0.740, val loss 0.175, val accuracy 0.729, and val rmse 0.013\n",
            "Epoch 12, train loss 0.034, train accuracy 0.705, val loss 0.171, val accuracy 0.703, and val rmse 0.027\n",
            "Epoch 13, train loss 0.032, train accuracy 0.714, val loss 0.167, val accuracy 0.677, and val rmse 0.053\n",
            "Epoch 14, train loss 0.030, train accuracy 0.724, val loss 0.151, val accuracy 0.728, and val rmse 0.040\n",
            "Epoch 15, train loss 0.027, train accuracy 0.773, val loss 0.140, val accuracy 0.768, and val rmse 0.013\n",
            "Epoch 16, train loss 0.025, train accuracy 0.805, val loss 0.126, val accuracy 0.806, and val rmse 0.013\n",
            "Epoch 17, train loss 0.023, train accuracy 0.795, val loss 0.112, val accuracy 0.805, and val rmse 0.013\n",
            "Epoch 18, train loss 0.021, train accuracy 0.799, val loss 0.102, val accuracy 0.805, and val rmse 0.013\n",
            "Epoch 19, train loss 0.019, train accuracy 0.828, val loss 0.094, val accuracy 0.831, and val rmse 0.040\n",
            "Epoch 20, train loss 0.018, train accuracy 0.834, val loss 0.091, val accuracy 0.817, and val rmse 0.067\n",
            "Epoch 21, train loss 0.018, train accuracy 0.854, val loss 0.085, val accuracy 0.829, and val rmse 0.067\n",
            "Epoch 22, train loss 0.015, train accuracy 0.883, val loss 0.077, val accuracy 0.828, and val rmse 0.067\n",
            "Epoch 23, train loss 0.014, train accuracy 0.880, val loss 0.073, val accuracy 0.842, and val rmse 0.067\n",
            "Epoch 24, train loss 0.015, train accuracy 0.870, val loss 0.065, val accuracy 0.908, and val rmse 0.053\n",
            "Epoch 25, train loss 0.014, train accuracy 0.903, val loss 0.067, val accuracy 0.895, and val rmse 0.053\n",
            "Epoch 26, train loss 0.012, train accuracy 0.925, val loss 0.059, val accuracy 0.933, and val rmse 0.053\n",
            "Epoch 27, train loss 0.011, train accuracy 0.929, val loss 0.058, val accuracy 0.880, and val rmse 0.053\n",
            "Epoch 28, train loss 0.010, train accuracy 0.929, val loss 0.056, val accuracy 0.880, and val rmse 0.053\n",
            "Epoch 29, train loss 0.010, train accuracy 0.935, val loss 0.050, val accuracy 0.947, and val rmse 0.053\n",
            "Epoch 30, train loss 0.010, train accuracy 0.942, val loss 0.060, val accuracy 0.882, and val rmse 0.053\n",
            "Epoch 31, train loss 0.009, train accuracy 0.935, val loss 0.043, val accuracy 0.947, and val rmse 0.053\n",
            "Epoch 32, train loss 0.008, train accuracy 0.955, val loss 0.044, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 33, train loss 0.007, train accuracy 0.951, val loss 0.039, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 34, train loss 0.008, train accuracy 0.935, val loss 0.040, val accuracy 0.933, and val rmse 0.027\n",
            "Epoch 35, train loss 0.007, train accuracy 0.955, val loss 0.040, val accuracy 0.921, and val rmse 0.000\n",
            "Epoch 36, train loss 0.007, train accuracy 0.938, val loss 0.033, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 37, train loss 0.006, train accuracy 0.964, val loss 0.029, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 38, train loss 0.005, train accuracy 0.974, val loss 0.029, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 39, train loss 0.005, train accuracy 0.964, val loss 0.027, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 40, train loss 0.009, train accuracy 0.945, val loss 0.029, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 41, train loss 0.005, train accuracy 0.971, val loss 0.025, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 42, train loss 0.004, train accuracy 0.977, val loss 0.024, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 43, train loss 0.005, train accuracy 0.971, val loss 0.022, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 44, train loss 0.004, train accuracy 0.974, val loss 0.020, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 45, train loss 0.004, train accuracy 0.984, val loss 0.019, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.990, val loss 0.018, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.984, val loss 0.016, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.981, val loss 0.015, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 49, train loss 0.004, train accuracy 0.977, val loss 0.013, val accuracy 0.987, and val rmse 0.000\n",
            "\n",
            " Iteration number : 9\n",
            "Epoch 0, train loss 0.054, train accuracy 0.211, val loss 0.280, val accuracy 0.177, and val rmse 0.520\n",
            "Epoch 1, train loss 0.053, train accuracy 0.403, val loss 0.273, val accuracy 0.413, and val rmse 0.000\n",
            "Epoch 2, train loss 0.052, train accuracy 0.312, val loss 0.266, val accuracy 0.347, and val rmse 0.133\n",
            "Epoch 3, train loss 0.051, train accuracy 0.282, val loss 0.264, val accuracy 0.173, and val rmse 0.373\n",
            "Epoch 4, train loss 0.052, train accuracy 0.380, val loss 0.278, val accuracy 0.107, and val rmse 0.387\n",
            "Epoch 5, train loss 0.050, train accuracy 0.370, val loss 0.257, val accuracy 0.267, and val rmse 0.133\n",
            "Epoch 6, train loss 0.048, train accuracy 0.500, val loss 0.255, val accuracy 0.293, and val rmse 0.040\n",
            "Epoch 7, train loss 0.047, train accuracy 0.558, val loss 0.242, val accuracy 0.498, and val rmse 0.013\n",
            "Epoch 8, train loss 0.046, train accuracy 0.575, val loss 0.236, val accuracy 0.562, and val rmse 0.013\n",
            "Epoch 9, train loss 0.044, train accuracy 0.610, val loss 0.225, val accuracy 0.664, and val rmse 0.013\n",
            "Epoch 10, train loss 0.042, train accuracy 0.620, val loss 0.222, val accuracy 0.639, and val rmse 0.013\n",
            "Epoch 11, train loss 0.041, train accuracy 0.617, val loss 0.220, val accuracy 0.575, and val rmse 0.013\n",
            "Epoch 12, train loss 0.039, train accuracy 0.640, val loss 0.203, val accuracy 0.650, and val rmse 0.027\n",
            "Epoch 13, train loss 0.037, train accuracy 0.620, val loss 0.192, val accuracy 0.677, and val rmse 0.027\n",
            "Epoch 14, train loss 0.036, train accuracy 0.643, val loss 0.189, val accuracy 0.691, and val rmse 0.000\n",
            "Epoch 15, train loss 0.035, train accuracy 0.656, val loss 0.181, val accuracy 0.691, and val rmse 0.000\n",
            "Epoch 16, train loss 0.034, train accuracy 0.669, val loss 0.188, val accuracy 0.704, and val rmse 0.000\n",
            "Epoch 17, train loss 0.032, train accuracy 0.672, val loss 0.167, val accuracy 0.717, and val rmse 0.000\n",
            "Epoch 18, train loss 0.032, train accuracy 0.630, val loss 0.169, val accuracy 0.651, and val rmse 0.107\n",
            "Epoch 19, train loss 0.030, train accuracy 0.672, val loss 0.163, val accuracy 0.623, and val rmse 0.187\n",
            "Epoch 20, train loss 0.041, train accuracy 0.448, val loss 0.248, val accuracy 0.360, and val rmse 0.227\n",
            "Epoch 21, train loss 0.026, train accuracy 0.662, val loss 0.138, val accuracy 0.610, and val rmse 0.187\n",
            "Epoch 22, train loss 0.023, train accuracy 0.718, val loss 0.121, val accuracy 0.635, and val rmse 0.160\n",
            "Epoch 23, train loss 0.024, train accuracy 0.688, val loss 0.123, val accuracy 0.623, and val rmse 0.187\n",
            "Epoch 24, train loss 0.023, train accuracy 0.692, val loss 0.118, val accuracy 0.597, and val rmse 0.240\n",
            "Epoch 25, train loss 0.023, train accuracy 0.695, val loss 0.116, val accuracy 0.596, and val rmse 0.240\n",
            "Epoch 26, train loss 0.021, train accuracy 0.711, val loss 0.109, val accuracy 0.596, and val rmse 0.240\n",
            "Epoch 27, train loss 0.020, train accuracy 0.705, val loss 0.105, val accuracy 0.608, and val rmse 0.240\n",
            "Epoch 28, train loss 0.020, train accuracy 0.705, val loss 0.102, val accuracy 0.608, and val rmse 0.240\n",
            "Epoch 29, train loss 0.020, train accuracy 0.721, val loss 0.099, val accuracy 0.608, and val rmse 0.240\n",
            "Epoch 30, train loss 0.020, train accuracy 0.718, val loss 0.114, val accuracy 0.717, and val rmse 0.000\n",
            "Epoch 31, train loss 0.019, train accuracy 0.649, val loss 0.099, val accuracy 0.597, and val rmse 0.240\n",
            "Epoch 32, train loss 0.018, train accuracy 0.679, val loss 0.094, val accuracy 0.450, and val rmse 0.240\n",
            "Epoch 33, train loss 0.018, train accuracy 0.672, val loss 0.091, val accuracy 0.450, and val rmse 0.240\n",
            "Epoch 34, train loss 0.017, train accuracy 0.672, val loss 0.089, val accuracy 0.450, and val rmse 0.240\n",
            "Epoch 35, train loss 0.018, train accuracy 0.666, val loss 0.086, val accuracy 0.463, and val rmse 0.240\n",
            "Epoch 36, train loss 0.017, train accuracy 0.666, val loss 0.085, val accuracy 0.475, and val rmse 0.240\n",
            "Epoch 37, train loss 0.016, train accuracy 0.659, val loss 0.083, val accuracy 0.463, and val rmse 0.240\n",
            "Epoch 38, train loss 0.015, train accuracy 0.692, val loss 0.101, val accuracy 0.525, and val rmse 0.240\n",
            "Epoch 39, train loss 0.014, train accuracy 0.724, val loss 0.073, val accuracy 0.618, and val rmse 0.240\n",
            "Epoch 40, train loss 0.014, train accuracy 0.724, val loss 0.069, val accuracy 0.725, and val rmse 0.240\n",
            "Epoch 41, train loss 0.014, train accuracy 0.744, val loss 0.068, val accuracy 0.752, and val rmse 0.240\n",
            "Epoch 42, train loss 0.013, train accuracy 0.789, val loss 0.063, val accuracy 0.817, and val rmse 0.133\n",
            "Epoch 43, train loss 0.012, train accuracy 0.808, val loss 0.061, val accuracy 0.857, and val rmse 0.053\n",
            "Epoch 44, train loss 0.011, train accuracy 0.847, val loss 0.058, val accuracy 0.871, and val rmse 0.027\n",
            "Epoch 45, train loss 0.011, train accuracy 0.867, val loss 0.056, val accuracy 0.871, and val rmse 0.027\n",
            "Epoch 46, train loss 0.011, train accuracy 0.867, val loss 0.054, val accuracy 0.871, and val rmse 0.027\n",
            "Epoch 47, train loss 0.012, train accuracy 0.864, val loss 0.072, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 48, train loss 0.011, train accuracy 0.873, val loss 0.056, val accuracy 0.871, and val rmse 0.027\n",
            "Epoch 49, train loss 0.010, train accuracy 0.870, val loss 0.052, val accuracy 0.871, and val rmse 0.027\n",
            "\n",
            " Iteration number : 10\n",
            "Epoch 0, train loss 0.053, train accuracy 0.286, val loss 0.279, val accuracy 0.090, and val rmse 0.587\n",
            "Epoch 1, train loss 0.051, train accuracy 0.260, val loss 0.264, val accuracy 0.233, and val rmse 0.507\n",
            "Epoch 2, train loss 0.050, train accuracy 0.188, val loss 0.275, val accuracy 0.163, and val rmse 0.493\n",
            "Epoch 3, train loss 0.050, train accuracy 0.448, val loss 0.264, val accuracy 0.363, and val rmse 0.347\n",
            "Epoch 4, train loss 0.049, train accuracy 0.377, val loss 0.255, val accuracy 0.225, and val rmse 0.267\n",
            "Epoch 5, train loss 0.048, train accuracy 0.338, val loss 0.247, val accuracy 0.343, and val rmse 0.173\n",
            "Epoch 6, train loss 0.046, train accuracy 0.341, val loss 0.239, val accuracy 0.396, and val rmse 0.160\n",
            "Epoch 7, train loss 0.049, train accuracy 0.357, val loss 0.256, val accuracy 0.386, and val rmse 0.093\n",
            "Epoch 8, train loss 0.047, train accuracy 0.292, val loss 0.243, val accuracy 0.186, and val rmse 0.227\n",
            "Epoch 9, train loss 0.045, train accuracy 0.351, val loss 0.230, val accuracy 0.350, and val rmse 0.240\n",
            "Epoch 10, train loss 0.044, train accuracy 0.516, val loss 0.227, val accuracy 0.474, and val rmse 0.293\n",
            "Epoch 11, train loss 0.043, train accuracy 0.523, val loss 0.222, val accuracy 0.384, and val rmse 0.293\n",
            "Epoch 12, train loss 0.042, train accuracy 0.471, val loss 0.210, val accuracy 0.337, and val rmse 0.240\n",
            "Epoch 13, train loss 0.041, train accuracy 0.451, val loss 0.201, val accuracy 0.252, and val rmse 0.253\n",
            "Epoch 14, train loss 0.039, train accuracy 0.451, val loss 0.192, val accuracy 0.390, and val rmse 0.267\n",
            "Epoch 15, train loss 0.038, train accuracy 0.481, val loss 0.191, val accuracy 0.325, and val rmse 0.267\n",
            "Epoch 16, train loss 0.037, train accuracy 0.516, val loss 0.186, val accuracy 0.356, and val rmse 0.267\n",
            "Epoch 17, train loss 0.037, train accuracy 0.575, val loss 0.183, val accuracy 0.381, and val rmse 0.267\n",
            "Epoch 18, train loss 0.035, train accuracy 0.620, val loss 0.183, val accuracy 0.394, and val rmse 0.213\n",
            "Epoch 19, train loss 0.034, train accuracy 0.656, val loss 0.176, val accuracy 0.544, and val rmse 0.213\n",
            "Epoch 20, train loss 0.032, train accuracy 0.724, val loss 0.176, val accuracy 0.544, and val rmse 0.213\n",
            "Epoch 21, train loss 0.031, train accuracy 0.718, val loss 0.163, val accuracy 0.596, and val rmse 0.187\n",
            "Epoch 22, train loss 0.028, train accuracy 0.763, val loss 0.156, val accuracy 0.648, and val rmse 0.107\n",
            "Epoch 23, train loss 0.027, train accuracy 0.763, val loss 0.159, val accuracy 0.728, and val rmse 0.053\n",
            "Epoch 24, train loss 0.025, train accuracy 0.786, val loss 0.133, val accuracy 0.753, and val rmse 0.053\n",
            "Epoch 25, train loss 0.024, train accuracy 0.799, val loss 0.117, val accuracy 0.779, and val rmse 0.053\n",
            "Epoch 26, train loss 0.021, train accuracy 0.825, val loss 0.107, val accuracy 0.793, and val rmse 0.053\n",
            "Epoch 27, train loss 0.021, train accuracy 0.851, val loss 0.097, val accuracy 0.831, and val rmse 0.053\n",
            "Epoch 28, train loss 0.019, train accuracy 0.844, val loss 0.090, val accuracy 0.857, and val rmse 0.053\n",
            "Epoch 29, train loss 0.017, train accuracy 0.880, val loss 0.090, val accuracy 0.883, and val rmse 0.027\n",
            "Epoch 30, train loss 0.015, train accuracy 0.906, val loss 0.075, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 31, train loss 0.014, train accuracy 0.925, val loss 0.067, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 32, train loss 0.013, train accuracy 0.919, val loss 0.069, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 33, train loss 0.012, train accuracy 0.942, val loss 0.059, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 34, train loss 0.012, train accuracy 0.945, val loss 0.055, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 35, train loss 0.011, train accuracy 0.955, val loss 0.054, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 36, train loss 0.010, train accuracy 0.951, val loss 0.043, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 37, train loss 0.008, train accuracy 0.968, val loss 0.042, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 38, train loss 0.011, train accuracy 0.935, val loss 0.042, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 39, train loss 0.007, train accuracy 0.981, val loss 0.037, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 40, train loss 0.007, train accuracy 0.977, val loss 0.036, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 41, train loss 0.006, train accuracy 0.981, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.006, train accuracy 0.971, val loss 0.026, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 43, train loss 0.005, train accuracy 0.997, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.006, train accuracy 0.981, val loss 0.022, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 45, train loss 0.005, train accuracy 0.987, val loss 0.020, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 46, train loss 0.004, train accuracy 0.987, val loss 0.019, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 47, train loss 0.004, train accuracy 0.984, val loss 0.020, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 48, train loss 0.005, train accuracy 0.971, val loss 0.020, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 49, train loss 0.003, train accuracy 0.987, val loss 0.015, val accuracy 0.987, and val rmse 0.000\n",
            "\n",
            " Iteration number : 11\n",
            "Epoch 0, train loss 0.053, train accuracy 0.205, val loss 0.273, val accuracy 0.120, and val rmse 0.400\n",
            "Epoch 1, train loss 0.052, train accuracy 0.227, val loss 0.258, val accuracy 0.227, and val rmse 0.253\n",
            "Epoch 2, train loss 0.050, train accuracy 0.312, val loss 0.256, val accuracy 0.213, and val rmse 0.227\n",
            "Epoch 3, train loss 0.048, train accuracy 0.393, val loss 0.257, val accuracy 0.213, and val rmse 0.213\n",
            "Epoch 4, train loss 0.046, train accuracy 0.370, val loss 0.245, val accuracy 0.303, and val rmse 0.240\n",
            "Epoch 5, train loss 0.044, train accuracy 0.503, val loss 0.238, val accuracy 0.267, and val rmse 0.213\n",
            "Epoch 6, train loss 0.041, train accuracy 0.539, val loss 0.217, val accuracy 0.398, and val rmse 0.107\n",
            "Epoch 7, train loss 0.038, train accuracy 0.656, val loss 0.199, val accuracy 0.602, and val rmse 0.013\n",
            "Epoch 8, train loss 0.035, train accuracy 0.721, val loss 0.183, val accuracy 0.626, and val rmse 0.040\n",
            "Epoch 9, train loss 0.032, train accuracy 0.792, val loss 0.165, val accuracy 0.713, and val rmse 0.067\n",
            "Epoch 10, train loss 0.030, train accuracy 0.789, val loss 0.150, val accuracy 0.764, and val rmse 0.067\n",
            "Epoch 11, train loss 0.028, train accuracy 0.821, val loss 0.140, val accuracy 0.752, and val rmse 0.067\n",
            "Epoch 12, train loss 0.025, train accuracy 0.815, val loss 0.125, val accuracy 0.790, and val rmse 0.053\n",
            "Epoch 13, train loss 0.024, train accuracy 0.831, val loss 0.115, val accuracy 0.830, and val rmse 0.053\n",
            "Epoch 14, train loss 0.022, train accuracy 0.873, val loss 0.105, val accuracy 0.855, and val rmse 0.053\n",
            "Epoch 15, train loss 0.020, train accuracy 0.867, val loss 0.099, val accuracy 0.855, and val rmse 0.053\n",
            "Epoch 16, train loss 0.019, train accuracy 0.873, val loss 0.090, val accuracy 0.894, and val rmse 0.053\n",
            "Epoch 17, train loss 0.017, train accuracy 0.899, val loss 0.090, val accuracy 0.868, and val rmse 0.053\n",
            "Epoch 18, train loss 0.016, train accuracy 0.880, val loss 0.076, val accuracy 0.921, and val rmse 0.053\n",
            "Epoch 19, train loss 0.015, train accuracy 0.867, val loss 0.089, val accuracy 0.845, and val rmse 0.053\n",
            "Epoch 20, train loss 0.013, train accuracy 0.929, val loss 0.065, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 21, train loss 0.012, train accuracy 0.929, val loss 0.065, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 22, train loss 0.013, train accuracy 0.906, val loss 0.057, val accuracy 0.933, and val rmse 0.027\n",
            "Epoch 23, train loss 0.011, train accuracy 0.929, val loss 0.054, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 24, train loss 0.010, train accuracy 0.945, val loss 0.048, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 25, train loss 0.009, train accuracy 0.951, val loss 0.045, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 26, train loss 0.009, train accuracy 0.945, val loss 0.045, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 27, train loss 0.008, train accuracy 0.948, val loss 0.039, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 28, train loss 0.008, train accuracy 0.945, val loss 0.034, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 29, train loss 0.007, train accuracy 0.961, val loss 0.032, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 30, train loss 0.007, train accuracy 0.945, val loss 0.029, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 31, train loss 0.007, train accuracy 0.955, val loss 0.031, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 32, train loss 0.009, train accuracy 0.922, val loss 0.028, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 33, train loss 0.006, train accuracy 0.955, val loss 0.024, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 34, train loss 0.022, train accuracy 0.779, val loss 0.228, val accuracy 0.660, and val rmse 0.000\n",
            "Epoch 35, train loss 0.014, train accuracy 0.916, val loss 0.070, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 36, train loss 0.012, train accuracy 0.919, val loss 0.061, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 37, train loss 0.013, train accuracy 0.880, val loss 0.059, val accuracy 0.909, and val rmse 0.027\n",
            "Epoch 38, train loss 0.011, train accuracy 0.919, val loss 0.053, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 39, train loss 0.010, train accuracy 0.932, val loss 0.045, val accuracy 0.974, and val rmse 0.027\n",
            "Epoch 40, train loss 0.008, train accuracy 0.968, val loss 0.035, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 41, train loss 0.007, train accuracy 0.974, val loss 0.033, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 42, train loss 0.007, train accuracy 0.974, val loss 0.029, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 43, train loss 0.006, train accuracy 0.971, val loss 0.028, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 44, train loss 0.005, train accuracy 0.987, val loss 0.026, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 45, train loss 0.005, train accuracy 0.987, val loss 0.024, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 46, train loss 0.006, train accuracy 0.971, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.005, train accuracy 0.981, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.004, train accuracy 0.994, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.004, train accuracy 0.994, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 12\n",
            "Epoch 0, train loss 0.054, train accuracy 0.234, val loss 0.274, val accuracy 0.213, and val rmse 0.400\n",
            "Epoch 1, train loss 0.053, train accuracy 0.315, val loss 0.281, val accuracy 0.226, and val rmse 0.400\n",
            "Epoch 2, train loss 0.052, train accuracy 0.286, val loss 0.263, val accuracy 0.438, and val rmse 0.000\n",
            "Epoch 3, train loss 0.053, train accuracy 0.205, val loss 0.265, val accuracy 0.213, and val rmse 0.200\n",
            "Epoch 4, train loss 0.052, train accuracy 0.091, val loss 0.268, val accuracy 0.013, and val rmse 0.200\n",
            "Epoch 5, train loss 0.051, train accuracy 0.120, val loss 0.268, val accuracy 0.053, and val rmse 0.200\n",
            "Epoch 6, train loss 0.051, train accuracy 0.146, val loss 0.262, val accuracy 0.040, and val rmse 0.520\n",
            "Epoch 7, train loss 0.051, train accuracy 0.227, val loss 0.255, val accuracy 0.147, and val rmse 0.333\n",
            "Epoch 8, train loss 0.050, train accuracy 0.292, val loss 0.264, val accuracy 0.133, and val rmse 0.387\n",
            "Epoch 9, train loss 0.050, train accuracy 0.334, val loss 0.249, val accuracy 0.213, and val rmse 0.147\n",
            "Epoch 10, train loss 0.048, train accuracy 0.432, val loss 0.254, val accuracy 0.306, and val rmse 0.067\n",
            "Epoch 11, train loss 0.047, train accuracy 0.461, val loss 0.236, val accuracy 0.453, and val rmse 0.053\n",
            "Epoch 12, train loss 0.045, train accuracy 0.571, val loss 0.233, val accuracy 0.416, and val rmse 0.360\n",
            "Epoch 13, train loss 0.044, train accuracy 0.633, val loss 0.232, val accuracy 0.507, and val rmse 0.147\n",
            "Epoch 14, train loss 0.041, train accuracy 0.643, val loss 0.213, val accuracy 0.621, and val rmse 0.107\n",
            "Epoch 15, train loss 0.039, train accuracy 0.695, val loss 0.211, val accuracy 0.573, and val rmse 0.160\n",
            "Epoch 16, train loss 0.039, train accuracy 0.659, val loss 0.205, val accuracy 0.545, and val rmse 0.093\n",
            "Epoch 17, train loss 0.035, train accuracy 0.675, val loss 0.177, val accuracy 0.738, and val rmse 0.093\n",
            "Epoch 18, train loss 0.035, train accuracy 0.659, val loss 0.193, val accuracy 0.623, and val rmse 0.067\n",
            "Epoch 19, train loss 0.032, train accuracy 0.610, val loss 0.168, val accuracy 0.595, and val rmse 0.253\n",
            "Epoch 20, train loss 0.031, train accuracy 0.630, val loss 0.163, val accuracy 0.568, and val rmse 0.307\n",
            "Epoch 21, train loss 0.030, train accuracy 0.640, val loss 0.164, val accuracy 0.543, and val rmse 0.307\n",
            "Epoch 22, train loss 0.029, train accuracy 0.633, val loss 0.155, val accuracy 0.596, and val rmse 0.307\n",
            "Epoch 23, train loss 0.027, train accuracy 0.627, val loss 0.142, val accuracy 0.608, and val rmse 0.307\n",
            "Epoch 24, train loss 0.026, train accuracy 0.640, val loss 0.134, val accuracy 0.608, and val rmse 0.307\n",
            "Epoch 25, train loss 0.025, train accuracy 0.643, val loss 0.126, val accuracy 0.621, and val rmse 0.307\n",
            "Epoch 26, train loss 0.024, train accuracy 0.636, val loss 0.122, val accuracy 0.634, and val rmse 0.280\n",
            "Epoch 27, train loss 0.023, train accuracy 0.633, val loss 0.118, val accuracy 0.634, and val rmse 0.280\n",
            "Epoch 28, train loss 0.022, train accuracy 0.714, val loss 0.112, val accuracy 0.781, and val rmse 0.000\n",
            "Epoch 29, train loss 0.021, train accuracy 0.675, val loss 0.111, val accuracy 0.768, and val rmse 0.000\n",
            "Epoch 30, train loss 0.020, train accuracy 0.662, val loss 0.105, val accuracy 0.768, and val rmse 0.027\n",
            "Epoch 31, train loss 0.020, train accuracy 0.646, val loss 0.109, val accuracy 0.621, and val rmse 0.320\n",
            "Epoch 32, train loss 0.020, train accuracy 0.646, val loss 0.115, val accuracy 0.596, and val rmse 0.320\n",
            "Epoch 33, train loss 0.019, train accuracy 0.643, val loss 0.101, val accuracy 0.582, and val rmse 0.373\n",
            "Epoch 34, train loss 0.020, train accuracy 0.656, val loss 0.102, val accuracy 0.595, and val rmse 0.347\n",
            "Epoch 35, train loss 0.018, train accuracy 0.633, val loss 0.089, val accuracy 0.741, and val rmse 0.080\n",
            "Epoch 36, train loss 0.017, train accuracy 0.666, val loss 0.088, val accuracy 0.741, and val rmse 0.080\n",
            "Epoch 37, train loss 0.017, train accuracy 0.679, val loss 0.086, val accuracy 0.741, and val rmse 0.080\n",
            "Epoch 38, train loss 0.017, train accuracy 0.679, val loss 0.089, val accuracy 0.755, and val rmse 0.027\n",
            "Epoch 39, train loss 0.017, train accuracy 0.718, val loss 0.087, val accuracy 0.768, and val rmse 0.000\n",
            "Epoch 40, train loss 0.017, train accuracy 0.721, val loss 0.082, val accuracy 0.768, and val rmse 0.027\n",
            "Epoch 41, train loss 0.017, train accuracy 0.724, val loss 0.087, val accuracy 0.755, and val rmse 0.027\n",
            "Epoch 42, train loss 0.016, train accuracy 0.737, val loss 0.106, val accuracy 0.705, and val rmse 0.027\n",
            "Epoch 43, train loss 0.015, train accuracy 0.756, val loss 0.075, val accuracy 0.768, and val rmse 0.027\n",
            "Epoch 44, train loss 0.015, train accuracy 0.799, val loss 0.073, val accuracy 0.793, and val rmse 0.027\n",
            "Epoch 45, train loss 0.015, train accuracy 0.825, val loss 0.076, val accuracy 0.793, and val rmse 0.027\n",
            "Epoch 46, train loss 0.014, train accuracy 0.841, val loss 0.076, val accuracy 0.846, and val rmse 0.027\n",
            "Epoch 47, train loss 0.013, train accuracy 0.838, val loss 0.068, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 48, train loss 0.014, train accuracy 0.831, val loss 0.067, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 49, train loss 0.013, train accuracy 0.860, val loss 0.065, val accuracy 0.872, and val rmse 0.027\n",
            "\n",
            " Iteration number : 13\n",
            "Epoch 0, train loss 0.054, train accuracy 0.263, val loss 0.275, val accuracy 0.237, and val rmse 0.573\n",
            "Epoch 1, train loss 0.053, train accuracy 0.234, val loss 0.265, val accuracy 0.038, and val rmse 0.507\n",
            "Epoch 2, train loss 0.050, train accuracy 0.351, val loss 0.260, val accuracy 0.189, and val rmse 0.480\n",
            "Epoch 3, train loss 0.047, train accuracy 0.351, val loss 0.248, val accuracy 0.179, and val rmse 0.480\n",
            "Epoch 4, train loss 0.046, train accuracy 0.438, val loss 0.269, val accuracy 0.231, and val rmse 0.387\n",
            "Epoch 5, train loss 0.045, train accuracy 0.435, val loss 0.263, val accuracy 0.158, and val rmse 0.400\n",
            "Epoch 6, train loss 0.040, train accuracy 0.532, val loss 0.216, val accuracy 0.380, and val rmse 0.053\n",
            "Epoch 7, train loss 0.036, train accuracy 0.594, val loss 0.191, val accuracy 0.490, and val rmse 0.027\n",
            "Epoch 8, train loss 0.033, train accuracy 0.630, val loss 0.159, val accuracy 0.640, and val rmse 0.053\n",
            "Epoch 9, train loss 0.029, train accuracy 0.675, val loss 0.151, val accuracy 0.627, and val rmse 0.053\n",
            "Epoch 10, train loss 0.027, train accuracy 0.692, val loss 0.138, val accuracy 0.638, and val rmse 0.080\n",
            "Epoch 11, train loss 0.025, train accuracy 0.695, val loss 0.128, val accuracy 0.716, and val rmse 0.080\n",
            "Epoch 12, train loss 0.024, train accuracy 0.718, val loss 0.127, val accuracy 0.637, and val rmse 0.107\n",
            "Epoch 13, train loss 0.022, train accuracy 0.753, val loss 0.118, val accuracy 0.663, and val rmse 0.133\n",
            "Epoch 14, train loss 0.022, train accuracy 0.763, val loss 0.108, val accuracy 0.742, and val rmse 0.080\n",
            "Epoch 15, train loss 0.020, train accuracy 0.747, val loss 0.118, val accuracy 0.638, and val rmse 0.133\n",
            "Epoch 16, train loss 0.020, train accuracy 0.769, val loss 0.099, val accuracy 0.726, and val rmse 0.107\n",
            "Epoch 17, train loss 0.017, train accuracy 0.799, val loss 0.092, val accuracy 0.765, and val rmse 0.107\n",
            "Epoch 18, train loss 0.017, train accuracy 0.779, val loss 0.087, val accuracy 0.778, and val rmse 0.107\n",
            "Epoch 19, train loss 0.016, train accuracy 0.815, val loss 0.082, val accuracy 0.791, and val rmse 0.107\n",
            "Epoch 20, train loss 0.015, train accuracy 0.825, val loss 0.075, val accuracy 0.817, and val rmse 0.080\n",
            "Epoch 21, train loss 0.014, train accuracy 0.841, val loss 0.073, val accuracy 0.844, and val rmse 0.080\n",
            "Epoch 22, train loss 0.014, train accuracy 0.857, val loss 0.076, val accuracy 0.791, and val rmse 0.107\n",
            "Epoch 23, train loss 0.013, train accuracy 0.870, val loss 0.066, val accuracy 0.856, and val rmse 0.080\n",
            "Epoch 24, train loss 0.012, train accuracy 0.857, val loss 0.061, val accuracy 0.896, and val rmse 0.053\n",
            "Epoch 25, train loss 0.011, train accuracy 0.890, val loss 0.059, val accuracy 0.908, and val rmse 0.053\n",
            "Epoch 26, train loss 0.011, train accuracy 0.896, val loss 0.052, val accuracy 0.921, and val rmse 0.053\n",
            "Epoch 27, train loss 0.011, train accuracy 0.899, val loss 0.095, val accuracy 0.821, and val rmse 0.053\n",
            "Epoch 28, train loss 0.009, train accuracy 0.916, val loss 0.045, val accuracy 0.947, and val rmse 0.053\n",
            "Epoch 29, train loss 0.009, train accuracy 0.942, val loss 0.053, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 30, train loss 0.008, train accuracy 0.974, val loss 0.040, val accuracy 0.947, and val rmse 0.080\n",
            "Epoch 31, train loss 0.007, train accuracy 0.948, val loss 0.036, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 32, train loss 0.007, train accuracy 0.968, val loss 0.036, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 33, train loss 0.006, train accuracy 0.981, val loss 0.027, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 0.981, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.006, train accuracy 0.958, val loss 0.034, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.997, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.990, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.004, train accuracy 0.987, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.004, train accuracy 0.990, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.004, train accuracy 0.997, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.994, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.994, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 1.000, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.997, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.004, train accuracy 0.987, val loss 0.028, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.984, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 14\n",
            "Epoch 0, train loss 0.053, train accuracy 0.237, val loss 0.262, val accuracy 0.217, and val rmse 0.467\n",
            "Epoch 1, train loss 0.051, train accuracy 0.273, val loss 0.263, val accuracy 0.145, and val rmse 0.227\n",
            "Epoch 2, train loss 0.050, train accuracy 0.266, val loss 0.253, val accuracy 0.144, and val rmse 0.280\n",
            "Epoch 3, train loss 0.048, train accuracy 0.497, val loss 0.249, val accuracy 0.373, and val rmse 0.120\n",
            "Epoch 4, train loss 0.049, train accuracy 0.451, val loss 0.247, val accuracy 0.562, and val rmse 0.080\n",
            "Epoch 5, train loss 0.046, train accuracy 0.552, val loss 0.243, val accuracy 0.458, and val rmse 0.173\n",
            "Epoch 6, train loss 0.043, train accuracy 0.562, val loss 0.229, val accuracy 0.518, and val rmse 0.133\n",
            "Epoch 7, train loss 0.042, train accuracy 0.601, val loss 0.241, val accuracy 0.430, and val rmse 0.133\n",
            "Epoch 8, train loss 0.040, train accuracy 0.506, val loss 0.216, val accuracy 0.398, and val rmse 0.213\n",
            "Epoch 9, train loss 0.037, train accuracy 0.536, val loss 0.198, val accuracy 0.540, and val rmse 0.187\n",
            "Epoch 10, train loss 0.035, train accuracy 0.526, val loss 0.187, val accuracy 0.500, and val rmse 0.213\n",
            "Epoch 11, train loss 0.033, train accuracy 0.578, val loss 0.167, val accuracy 0.578, and val rmse 0.187\n",
            "Epoch 12, train loss 0.031, train accuracy 0.604, val loss 0.159, val accuracy 0.581, and val rmse 0.187\n",
            "Epoch 13, train loss 0.029, train accuracy 0.633, val loss 0.149, val accuracy 0.618, and val rmse 0.173\n",
            "Epoch 14, train loss 0.028, train accuracy 0.649, val loss 0.142, val accuracy 0.659, and val rmse 0.133\n",
            "Epoch 15, train loss 0.027, train accuracy 0.623, val loss 0.134, val accuracy 0.647, and val rmse 0.133\n",
            "Epoch 16, train loss 0.025, train accuracy 0.731, val loss 0.133, val accuracy 0.752, and val rmse 0.040\n",
            "Epoch 17, train loss 0.024, train accuracy 0.773, val loss 0.129, val accuracy 0.791, and val rmse 0.067\n",
            "Epoch 18, train loss 0.022, train accuracy 0.844, val loss 0.113, val accuracy 0.778, and val rmse 0.067\n",
            "Epoch 19, train loss 0.021, train accuracy 0.808, val loss 0.114, val accuracy 0.829, and val rmse 0.067\n",
            "Epoch 20, train loss 0.020, train accuracy 0.828, val loss 0.099, val accuracy 0.829, and val rmse 0.067\n",
            "Epoch 21, train loss 0.020, train accuracy 0.786, val loss 0.102, val accuracy 0.793, and val rmse 0.053\n",
            "Epoch 22, train loss 0.018, train accuracy 0.828, val loss 0.090, val accuracy 0.855, and val rmse 0.053\n",
            "Epoch 23, train loss 0.018, train accuracy 0.847, val loss 0.086, val accuracy 0.868, and val rmse 0.053\n",
            "Epoch 24, train loss 0.017, train accuracy 0.873, val loss 0.084, val accuracy 0.844, and val rmse 0.053\n",
            "Epoch 25, train loss 0.016, train accuracy 0.886, val loss 0.081, val accuracy 0.882, and val rmse 0.053\n",
            "Epoch 26, train loss 0.015, train accuracy 0.880, val loss 0.084, val accuracy 0.857, and val rmse 0.080\n",
            "Epoch 27, train loss 0.014, train accuracy 0.844, val loss 0.072, val accuracy 0.882, and val rmse 0.080\n",
            "Epoch 28, train loss 0.013, train accuracy 0.893, val loss 0.066, val accuracy 0.895, and val rmse 0.053\n",
            "Epoch 29, train loss 0.013, train accuracy 0.890, val loss 0.066, val accuracy 0.869, and val rmse 0.080\n",
            "Epoch 30, train loss 0.012, train accuracy 0.912, val loss 0.060, val accuracy 0.894, and val rmse 0.080\n",
            "Epoch 31, train loss 0.011, train accuracy 0.922, val loss 0.061, val accuracy 0.869, and val rmse 0.080\n",
            "Epoch 32, train loss 0.010, train accuracy 0.935, val loss 0.052, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 33, train loss 0.010, train accuracy 0.925, val loss 0.049, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 34, train loss 0.009, train accuracy 0.951, val loss 0.043, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 35, train loss 0.008, train accuracy 0.945, val loss 0.043, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 36, train loss 0.008, train accuracy 0.951, val loss 0.037, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 37, train loss 0.007, train accuracy 0.968, val loss 0.033, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 38, train loss 0.007, train accuracy 0.968, val loss 0.031, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 39, train loss 0.007, train accuracy 0.955, val loss 0.030, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 40, train loss 0.007, train accuracy 0.951, val loss 0.028, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 41, train loss 0.006, train accuracy 0.971, val loss 0.041, val accuracy 0.937, and val rmse 0.000\n",
            "Epoch 42, train loss 0.005, train accuracy 0.974, val loss 0.025, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 43, train loss 0.005, train accuracy 0.987, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.004, train accuracy 0.987, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.004, train accuracy 0.997, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 1.000, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.005, train accuracy 0.974, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.997, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.012, train accuracy 0.968, val loss 0.049, val accuracy 0.988, and val rmse 0.000\n",
            "\n",
            " Iteration number : 15\n",
            "Epoch 0, train loss 0.054, train accuracy 0.406, val loss 0.291, val accuracy 0.013, and val rmse 0.600\n",
            "Epoch 1, train loss 0.052, train accuracy 0.490, val loss 0.270, val accuracy 0.560, and val rmse 0.080\n",
            "Epoch 2, train loss 0.050, train accuracy 0.545, val loss 0.267, val accuracy 0.451, and val rmse 0.000\n",
            "Epoch 3, train loss 0.049, train accuracy 0.555, val loss 0.273, val accuracy 0.333, and val rmse 0.213\n",
            "Epoch 4, train loss 0.045, train accuracy 0.630, val loss 0.256, val accuracy 0.651, and val rmse 0.000\n",
            "Epoch 5, train loss 0.043, train accuracy 0.627, val loss 0.211, val accuracy 0.553, and val rmse 0.000\n",
            "Epoch 6, train loss 0.039, train accuracy 0.688, val loss 0.193, val accuracy 0.591, and val rmse 0.000\n",
            "Epoch 7, train loss 0.034, train accuracy 0.744, val loss 0.189, val accuracy 0.732, and val rmse 0.000\n",
            "Epoch 8, train loss 0.031, train accuracy 0.789, val loss 0.164, val accuracy 0.681, and val rmse 0.000\n",
            "Epoch 9, train loss 0.026, train accuracy 0.896, val loss 0.131, val accuracy 0.933, and val rmse 0.027\n",
            "Epoch 10, train loss 0.022, train accuracy 0.938, val loss 0.121, val accuracy 0.848, and val rmse 0.000\n",
            "Epoch 11, train loss 0.023, train accuracy 0.860, val loss 0.136, val accuracy 0.743, and val rmse 0.000\n",
            "Epoch 12, train loss 0.018, train accuracy 0.935, val loss 0.091, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 13, train loss 0.024, train accuracy 0.802, val loss 0.119, val accuracy 0.781, and val rmse 0.000\n",
            "Epoch 14, train loss 0.017, train accuracy 0.873, val loss 0.105, val accuracy 0.821, and val rmse 0.000\n",
            "Epoch 15, train loss 0.013, train accuracy 0.971, val loss 0.082, val accuracy 0.862, and val rmse 0.000\n",
            "Epoch 16, train loss 0.016, train accuracy 0.864, val loss 0.108, val accuracy 0.717, and val rmse 0.000\n",
            "Epoch 17, train loss 0.009, train accuracy 0.984, val loss 0.044, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 18, train loss 0.008, train accuracy 0.974, val loss 0.037, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 19, train loss 0.007, train accuracy 0.987, val loss 0.032, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 20, train loss 0.006, train accuracy 0.994, val loss 0.027, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 21, train loss 0.006, train accuracy 0.981, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 22, train loss 0.005, train accuracy 0.987, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 23, train loss 0.004, train accuracy 0.997, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.005, train accuracy 0.984, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.005, train accuracy 0.974, val loss 0.049, val accuracy 0.875, and val rmse 0.000\n",
            "Epoch 26, train loss 0.003, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.007, train accuracy 0.987, val loss 0.026, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 28, train loss 0.003, train accuracy 1.000, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.003, train accuracy 0.997, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.013, train accuracy 0.916, val loss 0.129, val accuracy 0.693, and val rmse 0.000\n",
            "Epoch 31, train loss 0.003, train accuracy 1.000, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.003, train accuracy 1.000, val loss 0.020, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.981, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 0.990, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.984, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.990, val loss 0.009, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 0.994, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.994, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 16\n",
            "Epoch 0, train loss 0.053, train accuracy 0.344, val loss 0.257, val accuracy 0.290, and val rmse 0.520\n",
            "Epoch 1, train loss 0.051, train accuracy 0.419, val loss 0.259, val accuracy 0.481, and val rmse 0.253\n",
            "Epoch 2, train loss 0.049, train accuracy 0.565, val loss 0.239, val accuracy 0.491, and val rmse 0.267\n",
            "Epoch 3, train loss 0.045, train accuracy 0.636, val loss 0.233, val accuracy 0.550, and val rmse 0.027\n",
            "Epoch 4, train loss 0.042, train accuracy 0.653, val loss 0.216, val accuracy 0.586, and val rmse 0.053\n",
            "Epoch 5, train loss 0.039, train accuracy 0.568, val loss 0.207, val accuracy 0.459, and val rmse 0.240\n",
            "Epoch 6, train loss 0.034, train accuracy 0.734, val loss 0.171, val accuracy 0.622, and val rmse 0.213\n",
            "Epoch 7, train loss 0.030, train accuracy 0.792, val loss 0.158, val accuracy 0.753, and val rmse 0.133\n",
            "Epoch 8, train loss 0.027, train accuracy 0.818, val loss 0.139, val accuracy 0.791, and val rmse 0.187\n",
            "Epoch 9, train loss 0.028, train accuracy 0.792, val loss 0.193, val accuracy 0.527, and val rmse 0.160\n",
            "Epoch 10, train loss 0.022, train accuracy 0.877, val loss 0.109, val accuracy 0.830, and val rmse 0.133\n",
            "Epoch 11, train loss 0.018, train accuracy 0.896, val loss 0.092, val accuracy 0.909, and val rmse 0.027\n",
            "Epoch 12, train loss 0.018, train accuracy 0.867, val loss 0.078, val accuracy 0.949, and val rmse 0.000\n",
            "Epoch 13, train loss 0.017, train accuracy 0.873, val loss 0.088, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 14, train loss 0.016, train accuracy 0.864, val loss 0.081, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 15, train loss 0.015, train accuracy 0.906, val loss 0.070, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 16, train loss 0.017, train accuracy 0.893, val loss 0.153, val accuracy 0.647, and val rmse 0.000\n",
            "Epoch 17, train loss 0.014, train accuracy 0.938, val loss 0.071, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 18, train loss 0.013, train accuracy 0.961, val loss 0.064, val accuracy 0.961, and val rmse 0.053\n",
            "Epoch 19, train loss 0.012, train accuracy 0.961, val loss 0.057, val accuracy 0.961, and val rmse 0.053\n",
            "Epoch 20, train loss 0.011, train accuracy 0.958, val loss 0.051, val accuracy 0.961, and val rmse 0.053\n",
            "Epoch 21, train loss 0.009, train accuracy 0.977, val loss 0.045, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 22, train loss 0.009, train accuracy 0.977, val loss 0.043, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 23, train loss 0.008, train accuracy 0.984, val loss 0.036, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.007, train accuracy 0.987, val loss 0.032, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.006, train accuracy 0.997, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.006, train accuracy 0.987, val loss 0.026, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.005, train accuracy 0.997, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.005, train accuracy 0.987, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.004, train accuracy 1.000, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.004, train accuracy 0.990, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.003, train accuracy 1.000, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.003, train accuracy 0.997, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.003, train accuracy 0.990, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.003, train accuracy 0.994, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.003, train accuracy 0.987, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.001, train accuracy 1.000, val loss 0.015, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 0.984, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.001, train accuracy 0.994, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 0.990, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 0.990, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 0.997, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.987, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.997, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 17\n",
            "Epoch 0, train loss 0.056, train accuracy 0.221, val loss 0.264, val accuracy 0.282, and val rmse 0.400\n",
            "Epoch 1, train loss 0.053, train accuracy 0.334, val loss 0.258, val accuracy 0.259, and val rmse 0.240\n",
            "Epoch 2, train loss 0.051, train accuracy 0.377, val loss 0.288, val accuracy 0.126, and val rmse 0.400\n",
            "Epoch 3, train loss 0.053, train accuracy 0.237, val loss 0.269, val accuracy 0.257, and val rmse 0.507\n",
            "Epoch 4, train loss 0.051, train accuracy 0.377, val loss 0.264, val accuracy 0.223, and val rmse 0.267\n",
            "Epoch 5, train loss 0.048, train accuracy 0.442, val loss 0.249, val accuracy 0.297, and val rmse 0.253\n",
            "Epoch 6, train loss 0.046, train accuracy 0.458, val loss 0.231, val accuracy 0.528, and val rmse 0.227\n",
            "Epoch 7, train loss 0.044, train accuracy 0.422, val loss 0.226, val accuracy 0.451, and val rmse 0.253\n",
            "Epoch 8, train loss 0.042, train accuracy 0.383, val loss 0.213, val accuracy 0.288, and val rmse 0.240\n",
            "Epoch 9, train loss 0.040, train accuracy 0.416, val loss 0.203, val accuracy 0.341, and val rmse 0.227\n",
            "Epoch 10, train loss 0.039, train accuracy 0.490, val loss 0.200, val accuracy 0.433, and val rmse 0.280\n",
            "Epoch 11, train loss 0.037, train accuracy 0.481, val loss 0.187, val accuracy 0.483, and val rmse 0.280\n",
            "Epoch 12, train loss 0.035, train accuracy 0.526, val loss 0.177, val accuracy 0.537, and val rmse 0.267\n",
            "Epoch 13, train loss 0.034, train accuracy 0.555, val loss 0.169, val accuracy 0.562, and val rmse 0.267\n",
            "Epoch 14, train loss 0.033, train accuracy 0.565, val loss 0.182, val accuracy 0.564, and val rmse 0.307\n",
            "Epoch 15, train loss 0.031, train accuracy 0.578, val loss 0.157, val accuracy 0.602, and val rmse 0.307\n",
            "Epoch 16, train loss 0.030, train accuracy 0.584, val loss 0.151, val accuracy 0.616, and val rmse 0.293\n",
            "Epoch 17, train loss 0.028, train accuracy 0.617, val loss 0.144, val accuracy 0.629, and val rmse 0.267\n",
            "Epoch 18, train loss 0.028, train accuracy 0.601, val loss 0.179, val accuracy 0.428, and val rmse 0.267\n",
            "Epoch 19, train loss 0.028, train accuracy 0.610, val loss 0.154, val accuracy 0.630, and val rmse 0.267\n",
            "Epoch 20, train loss 0.026, train accuracy 0.630, val loss 0.132, val accuracy 0.628, and val rmse 0.320\n",
            "Epoch 21, train loss 0.025, train accuracy 0.630, val loss 0.127, val accuracy 0.628, and val rmse 0.320\n",
            "Epoch 22, train loss 0.024, train accuracy 0.633, val loss 0.140, val accuracy 0.603, and val rmse 0.320\n",
            "Epoch 23, train loss 0.023, train accuracy 0.633, val loss 0.116, val accuracy 0.667, and val rmse 0.320\n",
            "Epoch 24, train loss 0.026, train accuracy 0.636, val loss 0.144, val accuracy 0.773, and val rmse 0.133\n",
            "Epoch 25, train loss 0.024, train accuracy 0.718, val loss 0.126, val accuracy 0.631, and val rmse 0.307\n",
            "Epoch 26, train loss 0.022, train accuracy 0.714, val loss 0.115, val accuracy 0.655, and val rmse 0.307\n",
            "Epoch 27, train loss 0.021, train accuracy 0.705, val loss 0.110, val accuracy 0.656, and val rmse 0.307\n",
            "Epoch 28, train loss 0.020, train accuracy 0.779, val loss 0.099, val accuracy 0.778, and val rmse 0.013\n",
            "Epoch 29, train loss 0.032, train accuracy 0.513, val loss 0.204, val accuracy 0.231, and val rmse 0.387\n",
            "Epoch 30, train loss 0.024, train accuracy 0.620, val loss 0.119, val accuracy 0.640, and val rmse 0.387\n",
            "Epoch 31, train loss 0.023, train accuracy 0.617, val loss 0.117, val accuracy 0.640, and val rmse 0.387\n",
            "Epoch 32, train loss 0.023, train accuracy 0.630, val loss 0.112, val accuracy 0.640, and val rmse 0.387\n",
            "Epoch 33, train loss 0.022, train accuracy 0.620, val loss 0.109, val accuracy 0.613, and val rmse 0.387\n",
            "Epoch 34, train loss 0.021, train accuracy 0.630, val loss 0.104, val accuracy 0.627, and val rmse 0.387\n",
            "Epoch 35, train loss 0.021, train accuracy 0.601, val loss 0.106, val accuracy 0.613, and val rmse 0.387\n",
            "Epoch 36, train loss 0.021, train accuracy 0.633, val loss 0.109, val accuracy 0.653, and val rmse 0.387\n",
            "Epoch 37, train loss 0.021, train accuracy 0.601, val loss 0.103, val accuracy 0.600, and val rmse 0.387\n",
            "Epoch 38, train loss 0.019, train accuracy 0.604, val loss 0.100, val accuracy 0.600, and val rmse 0.387\n",
            "Epoch 39, train loss 0.020, train accuracy 0.597, val loss 0.107, val accuracy 0.489, and val rmse 0.387\n",
            "Epoch 40, train loss 0.019, train accuracy 0.575, val loss 0.098, val accuracy 0.547, and val rmse 0.387\n",
            "Epoch 41, train loss 0.018, train accuracy 0.695, val loss 0.093, val accuracy 0.632, and val rmse 0.200\n",
            "Epoch 42, train loss 0.018, train accuracy 0.724, val loss 0.087, val accuracy 0.680, and val rmse 0.200\n",
            "Epoch 43, train loss 0.017, train accuracy 0.740, val loss 0.084, val accuracy 0.667, and val rmse 0.200\n",
            "Epoch 44, train loss 0.016, train accuracy 0.750, val loss 0.083, val accuracy 0.640, and val rmse 0.200\n",
            "Epoch 45, train loss 0.016, train accuracy 0.740, val loss 0.082, val accuracy 0.640, and val rmse 0.187\n",
            "Epoch 46, train loss 0.017, train accuracy 0.744, val loss 0.081, val accuracy 0.667, and val rmse 0.160\n",
            "Epoch 47, train loss 0.015, train accuracy 0.744, val loss 0.081, val accuracy 0.667, and val rmse 0.187\n",
            "Epoch 48, train loss 0.015, train accuracy 0.747, val loss 0.079, val accuracy 0.680, and val rmse 0.160\n",
            "Epoch 49, train loss 0.014, train accuracy 0.776, val loss 0.079, val accuracy 0.707, and val rmse 0.133\n",
            "\n",
            " Iteration number : 18\n",
            "Epoch 0, train loss 0.055, train accuracy 0.273, val loss 0.290, val accuracy 0.390, and val rmse 0.400\n",
            "Epoch 1, train loss 0.050, train accuracy 0.412, val loss 0.264, val accuracy 0.260, and val rmse 0.240\n",
            "Epoch 2, train loss 0.046, train accuracy 0.594, val loss 0.255, val accuracy 0.375, and val rmse 0.200\n",
            "Epoch 3, train loss 0.041, train accuracy 0.620, val loss 0.219, val accuracy 0.540, and val rmse 0.133\n",
            "Epoch 4, train loss 0.038, train accuracy 0.584, val loss 0.194, val accuracy 0.542, and val rmse 0.173\n",
            "Epoch 5, train loss 0.037, train accuracy 0.594, val loss 0.216, val accuracy 0.482, and val rmse 0.040\n",
            "Epoch 6, train loss 0.034, train accuracy 0.623, val loss 0.178, val accuracy 0.528, and val rmse 0.187\n",
            "Epoch 7, train loss 0.034, train accuracy 0.633, val loss 0.187, val accuracy 0.473, and val rmse 0.200\n",
            "Epoch 8, train loss 0.031, train accuracy 0.617, val loss 0.163, val accuracy 0.618, and val rmse 0.200\n",
            "Epoch 9, train loss 0.029, train accuracy 0.640, val loss 0.143, val accuracy 0.604, and val rmse 0.200\n",
            "Epoch 10, train loss 0.027, train accuracy 0.649, val loss 0.149, val accuracy 0.567, and val rmse 0.200\n",
            "Epoch 11, train loss 0.025, train accuracy 0.682, val loss 0.139, val accuracy 0.657, and val rmse 0.173\n",
            "Epoch 12, train loss 0.024, train accuracy 0.708, val loss 0.130, val accuracy 0.683, and val rmse 0.173\n",
            "Epoch 13, train loss 0.022, train accuracy 0.724, val loss 0.117, val accuracy 0.696, and val rmse 0.173\n",
            "Epoch 14, train loss 0.021, train accuracy 0.737, val loss 0.104, val accuracy 0.749, and val rmse 0.147\n",
            "Epoch 15, train loss 0.020, train accuracy 0.753, val loss 0.099, val accuracy 0.775, and val rmse 0.147\n",
            "Epoch 16, train loss 0.018, train accuracy 0.782, val loss 0.091, val accuracy 0.827, and val rmse 0.133\n",
            "Epoch 17, train loss 0.017, train accuracy 0.812, val loss 0.085, val accuracy 0.867, and val rmse 0.133\n",
            "Epoch 18, train loss 0.016, train accuracy 0.838, val loss 0.078, val accuracy 0.880, and val rmse 0.107\n",
            "Epoch 19, train loss 0.014, train accuracy 0.857, val loss 0.072, val accuracy 0.880, and val rmse 0.107\n",
            "Epoch 20, train loss 0.013, train accuracy 0.886, val loss 0.064, val accuracy 0.933, and val rmse 0.067\n",
            "Epoch 21, train loss 0.013, train accuracy 0.896, val loss 0.062, val accuracy 0.921, and val rmse 0.067\n",
            "Epoch 22, train loss 0.012, train accuracy 0.912, val loss 0.176, val accuracy 0.747, and val rmse 0.067\n",
            "Epoch 23, train loss 0.011, train accuracy 0.893, val loss 0.067, val accuracy 0.809, and val rmse 0.067\n",
            "Epoch 24, train loss 0.009, train accuracy 0.935, val loss 0.045, val accuracy 0.960, and val rmse 0.040\n",
            "Epoch 25, train loss 0.009, train accuracy 0.942, val loss 0.041, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 26, train loss 0.008, train accuracy 0.958, val loss 0.036, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 27, train loss 0.007, train accuracy 0.964, val loss 0.032, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 28, train loss 0.007, train accuracy 0.968, val loss 0.028, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 29, train loss 0.006, train accuracy 0.977, val loss 0.024, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 30, train loss 0.005, train accuracy 0.984, val loss 0.021, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 31, train loss 0.004, train accuracy 0.987, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.004, train accuracy 0.987, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.984, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.003, train accuracy 0.994, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.003, train accuracy 0.997, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.981, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.004, train accuracy 0.958, val loss 0.022, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.987, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 1.000, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 0.994, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.994, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 19\n",
            "Epoch 0, train loss 0.055, train accuracy 0.263, val loss 0.271, val accuracy 0.250, and val rmse 0.600\n",
            "Epoch 1, train loss 0.052, train accuracy 0.286, val loss 0.269, val accuracy 0.406, and val rmse 0.293\n",
            "Epoch 2, train loss 0.050, train accuracy 0.399, val loss 0.262, val accuracy 0.330, and val rmse 0.093\n",
            "Epoch 3, train loss 0.048, train accuracy 0.503, val loss 0.244, val accuracy 0.527, and val rmse 0.040\n",
            "Epoch 4, train loss 0.047, train accuracy 0.558, val loss 0.238, val accuracy 0.450, and val rmse 0.013\n",
            "Epoch 5, train loss 0.046, train accuracy 0.607, val loss 0.234, val accuracy 0.538, and val rmse 0.000\n",
            "Epoch 6, train loss 0.044, train accuracy 0.636, val loss 0.234, val accuracy 0.574, and val rmse 0.013\n",
            "Epoch 7, train loss 0.040, train accuracy 0.656, val loss 0.207, val accuracy 0.637, and val rmse 0.013\n",
            "Epoch 8, train loss 0.038, train accuracy 0.643, val loss 0.194, val accuracy 0.651, and val rmse 0.013\n",
            "Epoch 9, train loss 0.035, train accuracy 0.640, val loss 0.187, val accuracy 0.650, and val rmse 0.067\n",
            "Epoch 10, train loss 0.035, train accuracy 0.646, val loss 0.176, val accuracy 0.676, and val rmse 0.067\n",
            "Epoch 11, train loss 0.033, train accuracy 0.672, val loss 0.164, val accuracy 0.715, and val rmse 0.053\n",
            "Epoch 12, train loss 0.030, train accuracy 0.747, val loss 0.153, val accuracy 0.715, and val rmse 0.053\n",
            "Epoch 13, train loss 0.030, train accuracy 0.773, val loss 0.155, val accuracy 0.740, and val rmse 0.053\n",
            "Epoch 14, train loss 0.028, train accuracy 0.766, val loss 0.140, val accuracy 0.729, and val rmse 0.027\n",
            "Epoch 15, train loss 0.026, train accuracy 0.828, val loss 0.126, val accuracy 0.755, and val rmse 0.027\n",
            "Epoch 16, train loss 0.024, train accuracy 0.857, val loss 0.154, val accuracy 0.668, and val rmse 0.027\n",
            "Epoch 17, train loss 0.022, train accuracy 0.838, val loss 0.104, val accuracy 0.882, and val rmse 0.027\n",
            "Epoch 18, train loss 0.020, train accuracy 0.873, val loss 0.098, val accuracy 0.882, and val rmse 0.027\n",
            "Epoch 19, train loss 0.019, train accuracy 0.880, val loss 0.093, val accuracy 0.870, and val rmse 0.027\n",
            "Epoch 20, train loss 0.018, train accuracy 0.893, val loss 0.086, val accuracy 0.896, and val rmse 0.027\n",
            "Epoch 21, train loss 0.016, train accuracy 0.903, val loss 0.082, val accuracy 0.922, and val rmse 0.000\n",
            "Epoch 22, train loss 0.017, train accuracy 0.899, val loss 0.079, val accuracy 0.897, and val rmse 0.000\n",
            "Epoch 23, train loss 0.016, train accuracy 0.935, val loss 0.132, val accuracy 0.760, and val rmse 0.000\n",
            "Epoch 24, train loss 0.015, train accuracy 0.916, val loss 0.070, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 25, train loss 0.014, train accuracy 0.912, val loss 0.069, val accuracy 0.897, and val rmse 0.000\n",
            "Epoch 26, train loss 0.013, train accuracy 0.935, val loss 0.064, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 27, train loss 0.012, train accuracy 0.935, val loss 0.077, val accuracy 0.898, and val rmse 0.000\n",
            "Epoch 28, train loss 0.011, train accuracy 0.945, val loss 0.052, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 29, train loss 0.010, train accuracy 0.945, val loss 0.047, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 30, train loss 0.010, train accuracy 0.951, val loss 0.046, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 31, train loss 0.009, train accuracy 0.961, val loss 0.040, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 32, train loss 0.008, train accuracy 0.948, val loss 0.038, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 33, train loss 0.007, train accuracy 0.961, val loss 0.037, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 34, train loss 0.009, train accuracy 0.951, val loss 0.055, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 35, train loss 0.007, train accuracy 0.951, val loss 0.032, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 36, train loss 0.008, train accuracy 0.951, val loss 0.033, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 37, train loss 0.006, train accuracy 0.958, val loss 0.029, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 38, train loss 0.007, train accuracy 0.961, val loss 0.028, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 39, train loss 0.008, train accuracy 0.932, val loss 0.028, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 40, train loss 0.005, train accuracy 0.964, val loss 0.026, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 41, train loss 0.006, train accuracy 0.948, val loss 0.025, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 42, train loss 0.006, train accuracy 0.951, val loss 0.026, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 43, train loss 0.005, train accuracy 0.958, val loss 0.025, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 44, train loss 0.006, train accuracy 0.938, val loss 0.049, val accuracy 0.912, and val rmse 0.000\n",
            "Epoch 45, train loss 0.004, train accuracy 0.974, val loss 0.031, val accuracy 0.949, and val rmse 0.000\n",
            "Epoch 46, train loss 0.004, train accuracy 0.964, val loss 0.022, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 47, train loss 0.005, train accuracy 0.961, val loss 0.020, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 48, train loss 0.004, train accuracy 0.961, val loss 0.018, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 49, train loss 0.004, train accuracy 0.964, val loss 0.017, val accuracy 0.974, and val rmse 0.000\n",
            "\n",
            " Iteration number : 20\n",
            "Epoch 0, train loss 0.053, train accuracy 0.276, val loss 0.269, val accuracy 0.221, and val rmse 0.280\n",
            "Epoch 1, train loss 0.050, train accuracy 0.234, val loss 0.271, val accuracy 0.153, and val rmse 0.320\n",
            "Epoch 2, train loss 0.044, train accuracy 0.435, val loss 0.245, val accuracy 0.317, and val rmse 0.280\n",
            "Epoch 3, train loss 0.038, train accuracy 0.575, val loss 0.185, val accuracy 0.567, and val rmse 0.200\n",
            "Epoch 4, train loss 0.031, train accuracy 0.571, val loss 0.148, val accuracy 0.567, and val rmse 0.333\n",
            "Epoch 5, train loss 0.034, train accuracy 0.471, val loss 0.182, val accuracy 0.394, and val rmse 0.333\n",
            "Epoch 6, train loss 0.032, train accuracy 0.588, val loss 0.209, val accuracy 0.432, and val rmse 0.213\n",
            "Epoch 7, train loss 0.028, train accuracy 0.614, val loss 0.145, val accuracy 0.608, and val rmse 0.213\n",
            "Epoch 8, train loss 0.026, train accuracy 0.636, val loss 0.131, val accuracy 0.636, and val rmse 0.147\n",
            "Epoch 9, train loss 0.024, train accuracy 0.662, val loss 0.121, val accuracy 0.715, and val rmse 0.093\n",
            "Epoch 10, train loss 0.022, train accuracy 0.672, val loss 0.111, val accuracy 0.755, and val rmse 0.067\n",
            "Epoch 11, train loss 0.020, train accuracy 0.731, val loss 0.104, val accuracy 0.768, and val rmse 0.040\n",
            "Epoch 12, train loss 0.020, train accuracy 0.727, val loss 0.098, val accuracy 0.768, and val rmse 0.040\n",
            "Epoch 13, train loss 0.018, train accuracy 0.756, val loss 0.091, val accuracy 0.792, and val rmse 0.067\n",
            "Epoch 14, train loss 0.017, train accuracy 0.760, val loss 0.085, val accuracy 0.819, and val rmse 0.053\n",
            "Epoch 15, train loss 0.017, train accuracy 0.782, val loss 0.079, val accuracy 0.832, and val rmse 0.053\n",
            "Epoch 16, train loss 0.017, train accuracy 0.802, val loss 0.157, val accuracy 0.619, and val rmse 0.080\n",
            "Epoch 17, train loss 0.015, train accuracy 0.808, val loss 0.070, val accuracy 0.859, and val rmse 0.053\n",
            "Epoch 18, train loss 0.014, train accuracy 0.818, val loss 0.066, val accuracy 0.872, and val rmse 0.053\n",
            "Epoch 19, train loss 0.013, train accuracy 0.828, val loss 0.063, val accuracy 0.872, and val rmse 0.080\n",
            "Epoch 20, train loss 0.012, train accuracy 0.870, val loss 0.059, val accuracy 0.872, and val rmse 0.080\n",
            "Epoch 21, train loss 0.011, train accuracy 0.880, val loss 0.055, val accuracy 0.872, and val rmse 0.080\n",
            "Epoch 22, train loss 0.012, train accuracy 0.867, val loss 0.063, val accuracy 0.872, and val rmse 0.080\n",
            "Epoch 23, train loss 0.010, train accuracy 0.877, val loss 0.049, val accuracy 0.872, and val rmse 0.080\n",
            "Epoch 24, train loss 0.009, train accuracy 0.899, val loss 0.045, val accuracy 0.884, and val rmse 0.080\n",
            "Epoch 25, train loss 0.011, train accuracy 0.883, val loss 0.046, val accuracy 0.872, and val rmse 0.080\n",
            "Epoch 26, train loss 0.008, train accuracy 0.919, val loss 0.040, val accuracy 0.897, and val rmse 0.080\n",
            "Epoch 27, train loss 0.008, train accuracy 0.925, val loss 0.037, val accuracy 0.923, and val rmse 0.053\n",
            "Epoch 28, train loss 0.008, train accuracy 0.916, val loss 0.036, val accuracy 0.923, and val rmse 0.053\n",
            "Epoch 29, train loss 0.007, train accuracy 0.925, val loss 0.033, val accuracy 0.962, and val rmse 0.027\n",
            "Epoch 30, train loss 0.007, train accuracy 0.929, val loss 0.032, val accuracy 0.962, and val rmse 0.027\n",
            "Epoch 31, train loss 0.007, train accuracy 0.935, val loss 0.028, val accuracy 0.962, and val rmse 0.027\n",
            "Epoch 32, train loss 0.006, train accuracy 0.945, val loss 0.024, val accuracy 0.962, and val rmse 0.027\n",
            "Epoch 33, train loss 0.005, train accuracy 0.958, val loss 0.022, val accuracy 0.962, and val rmse 0.027\n",
            "Epoch 34, train loss 0.005, train accuracy 0.958, val loss 0.021, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 35, train loss 0.005, train accuracy 0.968, val loss 0.018, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.974, val loss 0.017, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.984, val loss 0.017, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 38, train loss 0.004, train accuracy 0.977, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.987, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.004, train accuracy 0.974, val loss 0.014, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.987, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.004, train accuracy 0.971, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.990, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.987, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.984, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.990, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.990, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.987, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 21\n",
            "Epoch 0, train loss 0.055, train accuracy 0.179, val loss 0.288, val accuracy 0.000, and val rmse 0.573\n",
            "Epoch 1, train loss 0.053, train accuracy 0.282, val loss 0.269, val accuracy 0.088, and val rmse 0.320\n",
            "Epoch 2, train loss 0.051, train accuracy 0.438, val loss 0.269, val accuracy 0.293, and val rmse 0.133\n",
            "Epoch 3, train loss 0.051, train accuracy 0.474, val loss 0.255, val accuracy 0.447, and val rmse 0.067\n",
            "Epoch 4, train loss 0.051, train accuracy 0.393, val loss 0.261, val accuracy 0.422, and val rmse 0.053\n",
            "Epoch 5, train loss 0.048, train accuracy 0.468, val loss 0.239, val accuracy 0.476, and val rmse 0.080\n",
            "Epoch 6, train loss 0.046, train accuracy 0.549, val loss 0.240, val accuracy 0.342, and val rmse 0.093\n",
            "Epoch 7, train loss 0.043, train accuracy 0.539, val loss 0.237, val accuracy 0.408, and val rmse 0.107\n",
            "Epoch 8, train loss 0.040, train accuracy 0.656, val loss 0.207, val accuracy 0.502, and val rmse 0.027\n",
            "Epoch 9, train loss 0.038, train accuracy 0.731, val loss 0.199, val accuracy 0.647, and val rmse 0.080\n",
            "Epoch 10, train loss 0.036, train accuracy 0.773, val loss 0.182, val accuracy 0.712, and val rmse 0.080\n",
            "Epoch 11, train loss 0.032, train accuracy 0.808, val loss 0.169, val accuracy 0.766, and val rmse 0.053\n",
            "Epoch 12, train loss 0.030, train accuracy 0.831, val loss 0.155, val accuracy 0.817, and val rmse 0.027\n",
            "Epoch 13, train loss 0.027, train accuracy 0.854, val loss 0.146, val accuracy 0.843, and val rmse 0.027\n",
            "Epoch 14, train loss 0.026, train accuracy 0.854, val loss 0.128, val accuracy 0.894, and val rmse 0.000\n",
            "Epoch 15, train loss 0.023, train accuracy 0.890, val loss 0.116, val accuracy 0.908, and val rmse 0.000\n",
            "Epoch 16, train loss 0.022, train accuracy 0.893, val loss 0.108, val accuracy 0.922, and val rmse 0.000\n",
            "Epoch 17, train loss 0.019, train accuracy 0.922, val loss 0.099, val accuracy 0.947, and val rmse 0.000\n",
            "Epoch 18, train loss 0.018, train accuracy 0.942, val loss 0.088, val accuracy 0.947, and val rmse 0.000\n",
            "Epoch 19, train loss 0.017, train accuracy 0.945, val loss 0.087, val accuracy 0.947, and val rmse 0.000\n",
            "Epoch 20, train loss 0.016, train accuracy 0.935, val loss 0.077, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 21, train loss 0.014, train accuracy 0.938, val loss 0.069, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 22, train loss 0.012, train accuracy 0.968, val loss 0.062, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 23, train loss 0.011, train accuracy 0.964, val loss 0.055, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 24, train loss 0.011, train accuracy 0.951, val loss 0.051, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 25, train loss 0.009, train accuracy 0.974, val loss 0.045, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 26, train loss 0.009, train accuracy 0.968, val loss 0.041, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 27, train loss 0.008, train accuracy 0.961, val loss 0.038, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 28, train loss 0.007, train accuracy 0.977, val loss 0.033, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 29, train loss 0.008, train accuracy 0.971, val loss 0.033, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 30, train loss 0.006, train accuracy 0.968, val loss 0.027, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 31, train loss 0.005, train accuracy 0.990, val loss 0.024, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 32, train loss 0.005, train accuracy 0.981, val loss 0.022, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.984, val loss 0.020, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 0.987, val loss 0.018, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.990, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.990, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.990, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.987, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.987, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.994, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.002, train accuracy 0.994, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.977, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.994, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.990, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.987, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 22\n",
            "Epoch 0, train loss 0.054, train accuracy 0.237, val loss 0.296, val accuracy 0.190, and val rmse 0.400\n",
            "Epoch 1, train loss 0.052, train accuracy 0.289, val loss 0.281, val accuracy 0.116, and val rmse 0.440\n",
            "Epoch 2, train loss 0.050, train accuracy 0.396, val loss 0.260, val accuracy 0.347, and val rmse 0.147\n",
            "Epoch 3, train loss 0.047, train accuracy 0.425, val loss 0.270, val accuracy 0.092, and val rmse 0.320\n",
            "Epoch 4, train loss 0.048, train accuracy 0.383, val loss 0.274, val accuracy 0.066, and val rmse 0.480\n",
            "Epoch 5, train loss 0.047, train accuracy 0.351, val loss 0.257, val accuracy 0.213, and val rmse 0.267\n",
            "Epoch 6, train loss 0.045, train accuracy 0.442, val loss 0.238, val accuracy 0.304, and val rmse 0.253\n",
            "Epoch 7, train loss 0.043, train accuracy 0.536, val loss 0.229, val accuracy 0.398, and val rmse 0.133\n",
            "Epoch 8, train loss 0.038, train accuracy 0.604, val loss 0.215, val accuracy 0.548, and val rmse 0.253\n",
            "Epoch 9, train loss 0.036, train accuracy 0.623, val loss 0.226, val accuracy 0.477, and val rmse 0.040\n",
            "Epoch 10, train loss 0.032, train accuracy 0.643, val loss 0.167, val accuracy 0.665, and val rmse 0.053\n",
            "Epoch 11, train loss 0.029, train accuracy 0.718, val loss 0.162, val accuracy 0.678, and val rmse 0.027\n",
            "Epoch 12, train loss 0.023, train accuracy 0.805, val loss 0.113, val accuracy 0.780, and val rmse 0.027\n",
            "Epoch 13, train loss 0.022, train accuracy 0.825, val loss 0.115, val accuracy 0.768, and val rmse 0.027\n",
            "Epoch 14, train loss 0.018, train accuracy 0.867, val loss 0.090, val accuracy 0.870, and val rmse 0.027\n",
            "Epoch 15, train loss 0.016, train accuracy 0.919, val loss 0.080, val accuracy 0.922, and val rmse 0.027\n",
            "Epoch 16, train loss 0.014, train accuracy 0.929, val loss 0.068, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 17, train loss 0.016, train accuracy 0.867, val loss 0.095, val accuracy 0.822, and val rmse 0.000\n",
            "Epoch 18, train loss 0.012, train accuracy 0.948, val loss 0.058, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 19, train loss 0.010, train accuracy 0.961, val loss 0.045, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 20, train loss 0.011, train accuracy 0.945, val loss 0.060, val accuracy 0.937, and val rmse 0.000\n",
            "Epoch 21, train loss 0.007, train accuracy 0.968, val loss 0.035, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 22, train loss 0.009, train accuracy 0.951, val loss 0.046, val accuracy 0.949, and val rmse 0.000\n",
            "Epoch 23, train loss 0.006, train accuracy 0.987, val loss 0.027, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.005, train accuracy 0.997, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.005, train accuracy 0.994, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.006, train accuracy 0.981, val loss 0.031, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.005, train accuracy 0.984, val loss 0.022, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 28, train loss 0.003, train accuracy 0.997, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.003, train accuracy 0.994, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.003, train accuracy 0.997, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.003, train accuracy 0.987, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.002, train accuracy 0.997, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.002, train accuracy 0.994, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.002, train accuracy 0.990, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.002, train accuracy 0.984, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 0.997, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.994, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.994, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 23\n",
            "Epoch 0, train loss 0.055, train accuracy 0.273, val loss 0.300, val accuracy 0.150, and val rmse 0.573\n",
            "Epoch 1, train loss 0.052, train accuracy 0.179, val loss 0.264, val accuracy 0.213, and val rmse 0.093\n",
            "Epoch 2, train loss 0.051, train accuracy 0.289, val loss 0.269, val accuracy 0.320, and val rmse 0.040\n",
            "Epoch 3, train loss 0.049, train accuracy 0.286, val loss 0.251, val accuracy 0.280, and val rmse 0.293\n",
            "Epoch 4, train loss 0.048, train accuracy 0.292, val loss 0.243, val accuracy 0.187, and val rmse 0.347\n",
            "Epoch 5, train loss 0.046, train accuracy 0.321, val loss 0.233, val accuracy 0.290, and val rmse 0.333\n",
            "Epoch 6, train loss 0.045, train accuracy 0.429, val loss 0.244, val accuracy 0.227, and val rmse 0.333\n",
            "Epoch 7, train loss 0.043, train accuracy 0.497, val loss 0.211, val accuracy 0.365, and val rmse 0.333\n",
            "Epoch 8, train loss 0.042, train accuracy 0.438, val loss 0.216, val accuracy 0.406, and val rmse 0.333\n",
            "Epoch 9, train loss 0.040, train accuracy 0.565, val loss 0.206, val accuracy 0.318, and val rmse 0.333\n",
            "Epoch 10, train loss 0.039, train accuracy 0.604, val loss 0.207, val accuracy 0.440, and val rmse 0.040\n",
            "Epoch 11, train loss 0.035, train accuracy 0.627, val loss 0.182, val accuracy 0.564, and val rmse 0.120\n",
            "Epoch 12, train loss 0.033, train accuracy 0.711, val loss 0.166, val accuracy 0.652, and val rmse 0.067\n",
            "Epoch 13, train loss 0.031, train accuracy 0.724, val loss 0.160, val accuracy 0.577, and val rmse 0.067\n",
            "Epoch 14, train loss 0.029, train accuracy 0.760, val loss 0.148, val accuracy 0.615, and val rmse 0.040\n",
            "Epoch 15, train loss 0.027, train accuracy 0.753, val loss 0.136, val accuracy 0.702, and val rmse 0.067\n",
            "Epoch 16, train loss 0.024, train accuracy 0.779, val loss 0.126, val accuracy 0.715, and val rmse 0.053\n",
            "Epoch 17, train loss 0.024, train accuracy 0.779, val loss 0.123, val accuracy 0.663, and val rmse 0.107\n",
            "Epoch 18, train loss 0.021, train accuracy 0.831, val loss 0.107, val accuracy 0.830, and val rmse 0.053\n",
            "Epoch 19, train loss 0.021, train accuracy 0.857, val loss 0.113, val accuracy 0.808, and val rmse 0.027\n",
            "Epoch 20, train loss 0.019, train accuracy 0.899, val loss 0.094, val accuracy 0.896, and val rmse 0.027\n",
            "Epoch 21, train loss 0.017, train accuracy 0.896, val loss 0.088, val accuracy 0.882, and val rmse 0.053\n",
            "Epoch 22, train loss 0.017, train accuracy 0.873, val loss 0.086, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 23, train loss 0.015, train accuracy 0.893, val loss 0.080, val accuracy 0.883, and val rmse 0.027\n",
            "Epoch 24, train loss 0.014, train accuracy 0.919, val loss 0.075, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 25, train loss 0.013, train accuracy 0.938, val loss 0.073, val accuracy 0.908, and val rmse 0.080\n",
            "Epoch 26, train loss 0.011, train accuracy 0.971, val loss 0.059, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 27, train loss 0.010, train accuracy 0.964, val loss 0.049, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 28, train loss 0.008, train accuracy 0.987, val loss 0.044, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 29, train loss 0.008, train accuracy 0.971, val loss 0.040, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.007, train accuracy 0.987, val loss 0.036, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.006, train accuracy 0.994, val loss 0.031, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.011, train accuracy 0.958, val loss 0.036, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 33, train loss 0.005, train accuracy 0.997, val loss 0.026, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 0.981, val loss 0.025, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.997, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.005, train accuracy 0.994, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 1.000, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.004, train accuracy 0.994, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.004, train accuracy 0.994, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.997, val loss 0.018, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.994, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.987, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 1.000, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.994, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.994, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 24\n",
            "Epoch 0, train loss 0.053, train accuracy 0.244, val loss 0.264, val accuracy 0.133, and val rmse 0.160\n",
            "Epoch 1, train loss 0.052, train accuracy 0.328, val loss 0.281, val accuracy 0.159, and val rmse 0.347\n",
            "Epoch 2, train loss 0.051, train accuracy 0.380, val loss 0.264, val accuracy 0.319, and val rmse 0.040\n",
            "Epoch 3, train loss 0.049, train accuracy 0.455, val loss 0.269, val accuracy 0.305, and val rmse 0.213\n",
            "Epoch 4, train loss 0.046, train accuracy 0.494, val loss 0.268, val accuracy 0.128, and val rmse 0.427\n",
            "Epoch 5, train loss 0.043, train accuracy 0.494, val loss 0.224, val accuracy 0.329, and val rmse 0.400\n",
            "Epoch 6, train loss 0.039, train accuracy 0.614, val loss 0.204, val accuracy 0.463, and val rmse 0.267\n",
            "Epoch 7, train loss 0.036, train accuracy 0.633, val loss 0.187, val accuracy 0.622, and val rmse 0.213\n",
            "Epoch 8, train loss 0.034, train accuracy 0.662, val loss 0.177, val accuracy 0.714, and val rmse 0.080\n",
            "Epoch 9, train loss 0.032, train accuracy 0.682, val loss 0.170, val accuracy 0.623, and val rmse 0.107\n",
            "Epoch 10, train loss 0.031, train accuracy 0.734, val loss 0.158, val accuracy 0.647, and val rmse 0.107\n",
            "Epoch 11, train loss 0.028, train accuracy 0.792, val loss 0.148, val accuracy 0.702, and val rmse 0.107\n",
            "Epoch 12, train loss 0.039, train accuracy 0.617, val loss 0.237, val accuracy 0.588, and val rmse 0.133\n",
            "Epoch 13, train loss 0.036, train accuracy 0.701, val loss 0.182, val accuracy 0.738, and val rmse 0.133\n",
            "Epoch 14, train loss 0.033, train accuracy 0.769, val loss 0.170, val accuracy 0.752, and val rmse 0.133\n",
            "Epoch 15, train loss 0.031, train accuracy 0.769, val loss 0.157, val accuracy 0.775, and val rmse 0.133\n",
            "Epoch 16, train loss 0.028, train accuracy 0.789, val loss 0.147, val accuracy 0.800, and val rmse 0.120\n",
            "Epoch 17, train loss 0.026, train accuracy 0.821, val loss 0.150, val accuracy 0.748, and val rmse 0.107\n",
            "Epoch 18, train loss 0.023, train accuracy 0.864, val loss 0.124, val accuracy 0.855, and val rmse 0.107\n",
            "Epoch 19, train loss 0.017, train accuracy 0.890, val loss 0.115, val accuracy 0.813, and val rmse 0.107\n",
            "Epoch 20, train loss 0.014, train accuracy 0.883, val loss 0.066, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 21, train loss 0.013, train accuracy 0.899, val loss 0.062, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 22, train loss 0.011, train accuracy 0.903, val loss 0.055, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 23, train loss 0.011, train accuracy 0.925, val loss 0.051, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 24, train loss 0.009, train accuracy 0.932, val loss 0.044, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 25, train loss 0.009, train accuracy 0.925, val loss 0.042, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 26, train loss 0.008, train accuracy 0.958, val loss 0.036, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.007, train accuracy 0.948, val loss 0.030, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.007, train accuracy 0.958, val loss 0.026, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.010, train accuracy 0.948, val loss 0.028, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 30, train loss 0.005, train accuracy 0.981, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.005, train accuracy 0.987, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.004, train accuracy 0.977, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.003, train accuracy 0.990, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.004, train accuracy 0.987, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.003, train accuracy 0.984, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.987, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.974, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.994, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 0.990, val loss 0.026, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.990, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.990, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.994, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 0.990, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.990, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 25\n",
            "Epoch 0, train loss 0.055, train accuracy 0.292, val loss 0.272, val accuracy 0.217, and val rmse 0.400\n",
            "Epoch 1, train loss 0.053, train accuracy 0.260, val loss 0.267, val accuracy 0.283, and val rmse 0.400\n",
            "Epoch 2, train loss 0.051, train accuracy 0.438, val loss 0.263, val accuracy 0.064, and val rmse 0.400\n",
            "Epoch 3, train loss 0.049, train accuracy 0.542, val loss 0.256, val accuracy 0.129, and val rmse 0.373\n",
            "Epoch 4, train loss 0.047, train accuracy 0.552, val loss 0.256, val accuracy 0.183, and val rmse 0.280\n",
            "Epoch 5, train loss 0.046, train accuracy 0.571, val loss 0.237, val accuracy 0.224, and val rmse 0.267\n",
            "Epoch 6, train loss 0.045, train accuracy 0.542, val loss 0.238, val accuracy 0.330, and val rmse 0.107\n",
            "Epoch 7, train loss 0.043, train accuracy 0.516, val loss 0.220, val accuracy 0.386, and val rmse 0.200\n",
            "Epoch 8, train loss 0.040, train accuracy 0.539, val loss 0.205, val accuracy 0.438, and val rmse 0.213\n",
            "Epoch 9, train loss 0.040, train accuracy 0.588, val loss 0.215, val accuracy 0.644, and val rmse 0.160\n",
            "Epoch 10, train loss 0.039, train accuracy 0.607, val loss 0.197, val accuracy 0.564, and val rmse 0.267\n",
            "Epoch 11, train loss 0.037, train accuracy 0.685, val loss 0.192, val accuracy 0.591, and val rmse 0.293\n",
            "Epoch 12, train loss 0.035, train accuracy 0.617, val loss 0.176, val accuracy 0.695, and val rmse 0.293\n",
            "Epoch 13, train loss 0.033, train accuracy 0.620, val loss 0.166, val accuracy 0.602, and val rmse 0.347\n",
            "Epoch 14, train loss 0.031, train accuracy 0.610, val loss 0.160, val accuracy 0.601, and val rmse 0.373\n",
            "Epoch 15, train loss 0.029, train accuracy 0.597, val loss 0.148, val accuracy 0.601, and val rmse 0.373\n",
            "Epoch 16, train loss 0.028, train accuracy 0.552, val loss 0.141, val accuracy 0.640, and val rmse 0.360\n",
            "Epoch 17, train loss 0.027, train accuracy 0.578, val loss 0.134, val accuracy 0.628, and val rmse 0.360\n",
            "Epoch 18, train loss 0.026, train accuracy 0.558, val loss 0.130, val accuracy 0.602, and val rmse 0.360\n",
            "Epoch 19, train loss 0.024, train accuracy 0.620, val loss 0.123, val accuracy 0.595, and val rmse 0.360\n",
            "Epoch 20, train loss 0.023, train accuracy 0.640, val loss 0.118, val accuracy 0.622, and val rmse 0.347\n",
            "Epoch 21, train loss 0.024, train accuracy 0.633, val loss 0.115, val accuracy 0.621, and val rmse 0.347\n",
            "Epoch 22, train loss 0.022, train accuracy 0.666, val loss 0.108, val accuracy 0.634, and val rmse 0.347\n",
            "Epoch 23, train loss 0.021, train accuracy 0.685, val loss 0.104, val accuracy 0.634, and val rmse 0.347\n",
            "Epoch 24, train loss 0.020, train accuracy 0.692, val loss 0.100, val accuracy 0.647, and val rmse 0.320\n",
            "Epoch 25, train loss 0.020, train accuracy 0.675, val loss 0.096, val accuracy 0.688, and val rmse 0.240\n",
            "Epoch 26, train loss 0.019, train accuracy 0.705, val loss 0.093, val accuracy 0.767, and val rmse 0.080\n",
            "Epoch 27, train loss 0.018, train accuracy 0.724, val loss 0.089, val accuracy 0.767, and val rmse 0.080\n",
            "Epoch 28, train loss 0.017, train accuracy 0.737, val loss 0.086, val accuracy 0.781, and val rmse 0.053\n",
            "Epoch 29, train loss 0.017, train accuracy 0.740, val loss 0.084, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 30, train loss 0.016, train accuracy 0.750, val loss 0.081, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 31, train loss 0.016, train accuracy 0.737, val loss 0.080, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 32, train loss 0.016, train accuracy 0.753, val loss 0.077, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 33, train loss 0.015, train accuracy 0.776, val loss 0.076, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 34, train loss 0.015, train accuracy 0.766, val loss 0.074, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 35, train loss 0.014, train accuracy 0.769, val loss 0.072, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 36, train loss 0.014, train accuracy 0.766, val loss 0.071, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 37, train loss 0.014, train accuracy 0.776, val loss 0.070, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 38, train loss 0.014, train accuracy 0.766, val loss 0.069, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 39, train loss 0.015, train accuracy 0.753, val loss 0.070, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 40, train loss 0.013, train accuracy 0.766, val loss 0.067, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 41, train loss 0.013, train accuracy 0.789, val loss 0.066, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 42, train loss 0.013, train accuracy 0.802, val loss 0.065, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 43, train loss 0.013, train accuracy 0.799, val loss 0.065, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 44, train loss 0.012, train accuracy 0.805, val loss 0.064, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 45, train loss 0.012, train accuracy 0.802, val loss 0.064, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 46, train loss 0.012, train accuracy 0.792, val loss 0.063, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 47, train loss 0.012, train accuracy 0.805, val loss 0.062, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 48, train loss 0.012, train accuracy 0.799, val loss 0.062, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 49, train loss 0.012, train accuracy 0.799, val loss 0.062, val accuracy 0.794, and val rmse 0.027\n",
            "\n",
            " Iteration number : 26\n",
            "Epoch 0, train loss 0.055, train accuracy 0.383, val loss 0.274, val accuracy 0.363, and val rmse 0.280\n",
            "Epoch 1, train loss 0.052, train accuracy 0.409, val loss 0.261, val accuracy 0.354, and val rmse 0.200\n",
            "Epoch 2, train loss 0.051, train accuracy 0.448, val loss 0.258, val accuracy 0.291, and val rmse 0.200\n",
            "Epoch 3, train loss 0.049, train accuracy 0.442, val loss 0.251, val accuracy 0.363, and val rmse 0.253\n",
            "Epoch 4, train loss 0.047, train accuracy 0.487, val loss 0.234, val accuracy 0.626, and val rmse 0.067\n",
            "Epoch 5, train loss 0.044, train accuracy 0.617, val loss 0.223, val accuracy 0.612, and val rmse 0.040\n",
            "Epoch 6, train loss 0.041, train accuracy 0.692, val loss 0.218, val accuracy 0.600, and val rmse 0.013\n",
            "Epoch 7, train loss 0.045, train accuracy 0.623, val loss 0.253, val accuracy 0.491, and val rmse 0.000\n",
            "Epoch 8, train loss 0.042, train accuracy 0.711, val loss 0.214, val accuracy 0.728, and val rmse 0.000\n",
            "Epoch 9, train loss 0.040, train accuracy 0.731, val loss 0.203, val accuracy 0.728, and val rmse 0.000\n",
            "Epoch 10, train loss 0.038, train accuracy 0.737, val loss 0.194, val accuracy 0.742, and val rmse 0.000\n",
            "Epoch 11, train loss 0.037, train accuracy 0.766, val loss 0.180, val accuracy 0.768, and val rmse 0.000\n",
            "Epoch 12, train loss 0.035, train accuracy 0.786, val loss 0.173, val accuracy 0.768, and val rmse 0.000\n",
            "Epoch 13, train loss 0.032, train accuracy 0.838, val loss 0.162, val accuracy 0.821, and val rmse 0.000\n",
            "Epoch 14, train loss 0.030, train accuracy 0.825, val loss 0.160, val accuracy 0.770, and val rmse 0.013\n",
            "Epoch 15, train loss 0.028, train accuracy 0.821, val loss 0.143, val accuracy 0.832, and val rmse 0.040\n",
            "Epoch 16, train loss 0.027, train accuracy 0.825, val loss 0.152, val accuracy 0.767, and val rmse 0.067\n",
            "Epoch 17, train loss 0.024, train accuracy 0.818, val loss 0.119, val accuracy 0.871, and val rmse 0.027\n",
            "Epoch 18, train loss 0.022, train accuracy 0.873, val loss 0.119, val accuracy 0.883, and val rmse 0.027\n",
            "Epoch 19, train loss 0.021, train accuracy 0.883, val loss 0.104, val accuracy 0.909, and val rmse 0.027\n",
            "Epoch 20, train loss 0.019, train accuracy 0.896, val loss 0.099, val accuracy 0.922, and val rmse 0.027\n",
            "Epoch 21, train loss 0.018, train accuracy 0.899, val loss 0.100, val accuracy 0.909, and val rmse 0.027\n",
            "Epoch 22, train loss 0.033, train accuracy 0.636, val loss 0.283, val accuracy 0.453, and val rmse 0.000\n",
            "Epoch 23, train loss 0.027, train accuracy 0.708, val loss 0.146, val accuracy 0.691, and val rmse 0.000\n",
            "Epoch 24, train loss 0.021, train accuracy 0.795, val loss 0.114, val accuracy 0.770, and val rmse 0.107\n",
            "Epoch 25, train loss 0.016, train accuracy 0.893, val loss 0.071, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 26, train loss 0.015, train accuracy 0.935, val loss 0.066, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 27, train loss 0.013, train accuracy 0.942, val loss 0.062, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 28, train loss 0.012, train accuracy 0.951, val loss 0.060, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 29, train loss 0.012, train accuracy 0.958, val loss 0.057, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 30, train loss 0.014, train accuracy 0.938, val loss 0.067, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 31, train loss 0.011, train accuracy 0.968, val loss 0.056, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 32, train loss 0.010, train accuracy 0.971, val loss 0.053, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 33, train loss 0.011, train accuracy 0.961, val loss 0.049, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 34, train loss 0.010, train accuracy 0.958, val loss 0.042, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 35, train loss 0.008, train accuracy 0.974, val loss 0.040, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 36, train loss 0.008, train accuracy 0.964, val loss 0.037, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 37, train loss 0.008, train accuracy 0.971, val loss 0.075, val accuracy 0.854, and val rmse 0.000\n",
            "Epoch 38, train loss 0.009, train accuracy 0.932, val loss 0.033, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 39, train loss 0.007, train accuracy 0.974, val loss 0.032, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 40, train loss 0.013, train accuracy 0.912, val loss 0.283, val accuracy 0.717, and val rmse 0.000\n",
            "Epoch 41, train loss 0.010, train accuracy 0.942, val loss 0.029, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 42, train loss 0.007, train accuracy 0.971, val loss 0.029, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 43, train loss 0.006, train accuracy 0.981, val loss 0.042, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 44, train loss 0.007, train accuracy 0.961, val loss 0.027, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 45, train loss 0.006, train accuracy 0.964, val loss 0.025, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 46, train loss 0.007, train accuracy 0.977, val loss 0.034, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 47, train loss 0.007, train accuracy 0.961, val loss 0.024, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 48, train loss 0.006, train accuracy 0.974, val loss 0.027, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 49, train loss 0.005, train accuracy 0.964, val loss 0.023, val accuracy 0.988, and val rmse 0.000\n",
            "\n",
            " Iteration number : 27\n",
            "Epoch 0, train loss 0.055, train accuracy 0.247, val loss 0.287, val accuracy 0.127, and val rmse 0.493\n",
            "Epoch 1, train loss 0.052, train accuracy 0.250, val loss 0.272, val accuracy 0.080, and val rmse 0.467\n",
            "Epoch 2, train loss 0.051, train accuracy 0.386, val loss 0.282, val accuracy 0.187, and val rmse 0.200\n",
            "Epoch 3, train loss 0.047, train accuracy 0.448, val loss 0.253, val accuracy 0.301, and val rmse 0.133\n",
            "Epoch 4, train loss 0.044, train accuracy 0.636, val loss 0.225, val accuracy 0.673, and val rmse 0.040\n",
            "Epoch 5, train loss 0.042, train accuracy 0.532, val loss 0.243, val accuracy 0.395, and val rmse 0.053\n",
            "Epoch 6, train loss 0.037, train accuracy 0.659, val loss 0.194, val accuracy 0.637, and val rmse 0.040\n",
            "Epoch 7, train loss 0.035, train accuracy 0.623, val loss 0.196, val accuracy 0.504, and val rmse 0.227\n",
            "Epoch 8, train loss 0.031, train accuracy 0.640, val loss 0.164, val accuracy 0.663, and val rmse 0.013\n",
            "Epoch 9, train loss 0.029, train accuracy 0.558, val loss 0.150, val accuracy 0.477, and val rmse 0.280\n",
            "Epoch 10, train loss 0.028, train accuracy 0.601, val loss 0.142, val accuracy 0.450, and val rmse 0.280\n",
            "Epoch 11, train loss 0.025, train accuracy 0.597, val loss 0.131, val accuracy 0.557, and val rmse 0.227\n",
            "Epoch 12, train loss 0.023, train accuracy 0.581, val loss 0.121, val accuracy 0.503, and val rmse 0.333\n",
            "Epoch 13, train loss 0.021, train accuracy 0.649, val loss 0.110, val accuracy 0.570, and val rmse 0.227\n",
            "Epoch 14, train loss 0.021, train accuracy 0.643, val loss 0.108, val accuracy 0.477, and val rmse 0.253\n",
            "Epoch 15, train loss 0.019, train accuracy 0.643, val loss 0.098, val accuracy 0.528, and val rmse 0.267\n",
            "Epoch 16, train loss 0.018, train accuracy 0.653, val loss 0.094, val accuracy 0.528, and val rmse 0.267\n",
            "Epoch 17, train loss 0.017, train accuracy 0.688, val loss 0.089, val accuracy 0.582, and val rmse 0.213\n",
            "Epoch 18, train loss 0.017, train accuracy 0.701, val loss 0.086, val accuracy 0.607, and val rmse 0.213\n",
            "Epoch 19, train loss 0.016, train accuracy 0.718, val loss 0.085, val accuracy 0.570, and val rmse 0.213\n",
            "Epoch 20, train loss 0.015, train accuracy 0.753, val loss 0.077, val accuracy 0.699, and val rmse 0.133\n",
            "Epoch 21, train loss 0.014, train accuracy 0.799, val loss 0.072, val accuracy 0.805, and val rmse 0.107\n",
            "Epoch 22, train loss 0.014, train accuracy 0.834, val loss 0.069, val accuracy 0.831, and val rmse 0.107\n",
            "Epoch 23, train loss 0.013, train accuracy 0.838, val loss 0.065, val accuracy 0.869, and val rmse 0.107\n",
            "Epoch 24, train loss 0.012, train accuracy 0.867, val loss 0.060, val accuracy 0.883, and val rmse 0.107\n",
            "Epoch 25, train loss 0.011, train accuracy 0.880, val loss 0.054, val accuracy 0.896, and val rmse 0.080\n",
            "Epoch 26, train loss 0.010, train accuracy 0.893, val loss 0.050, val accuracy 0.908, and val rmse 0.080\n",
            "Epoch 27, train loss 0.010, train accuracy 0.909, val loss 0.046, val accuracy 0.934, and val rmse 0.053\n",
            "Epoch 28, train loss 0.009, train accuracy 0.919, val loss 0.042, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 29, train loss 0.008, train accuracy 0.951, val loss 0.039, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 30, train loss 0.007, train accuracy 0.968, val loss 0.036, val accuracy 0.960, and val rmse 0.053\n",
            "Epoch 31, train loss 0.007, train accuracy 0.981, val loss 0.033, val accuracy 0.960, and val rmse 0.053\n",
            "Epoch 32, train loss 0.006, train accuracy 0.981, val loss 0.030, val accuracy 0.960, and val rmse 0.053\n",
            "Epoch 33, train loss 0.005, train accuracy 0.984, val loss 0.027, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 34, train loss 0.005, train accuracy 0.977, val loss 0.025, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 35, train loss 0.005, train accuracy 0.955, val loss 0.022, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 36, train loss 0.005, train accuracy 0.968, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.990, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.004, train accuracy 0.971, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.004, train accuracy 0.977, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.005, train accuracy 0.971, val loss 0.025, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.984, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.987, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.987, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.987, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.003, train accuracy 0.981, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.987, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.990, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 28\n",
            "Epoch 0, train loss 0.053, train accuracy 0.244, val loss 0.265, val accuracy 0.332, and val rmse 0.133\n",
            "Epoch 1, train loss 0.053, train accuracy 0.286, val loss 0.277, val accuracy 0.093, and val rmse 0.400\n",
            "Epoch 2, train loss 0.051, train accuracy 0.282, val loss 0.264, val accuracy 0.297, and val rmse 0.400\n",
            "Epoch 3, train loss 0.049, train accuracy 0.458, val loss 0.252, val accuracy 0.311, and val rmse 0.267\n",
            "Epoch 4, train loss 0.048, train accuracy 0.458, val loss 0.248, val accuracy 0.451, and val rmse 0.027\n",
            "Epoch 5, train loss 0.044, train accuracy 0.445, val loss 0.252, val accuracy 0.223, and val rmse 0.107\n",
            "Epoch 6, train loss 0.041, train accuracy 0.565, val loss 0.224, val accuracy 0.508, and val rmse 0.067\n",
            "Epoch 7, train loss 0.039, train accuracy 0.545, val loss 0.220, val accuracy 0.398, and val rmse 0.160\n",
            "Epoch 8, train loss 0.036, train accuracy 0.604, val loss 0.196, val accuracy 0.517, and val rmse 0.147\n",
            "Epoch 9, train loss 0.034, train accuracy 0.656, val loss 0.178, val accuracy 0.595, and val rmse 0.107\n",
            "Epoch 10, train loss 0.031, train accuracy 0.705, val loss 0.171, val accuracy 0.635, and val rmse 0.107\n",
            "Epoch 11, train loss 0.029, train accuracy 0.737, val loss 0.158, val accuracy 0.688, and val rmse 0.053\n",
            "Epoch 12, train loss 0.027, train accuracy 0.776, val loss 0.147, val accuracy 0.635, and val rmse 0.107\n",
            "Epoch 13, train loss 0.025, train accuracy 0.760, val loss 0.133, val accuracy 0.688, and val rmse 0.080\n",
            "Epoch 14, train loss 0.023, train accuracy 0.799, val loss 0.121, val accuracy 0.714, and val rmse 0.053\n",
            "Epoch 15, train loss 0.021, train accuracy 0.825, val loss 0.129, val accuracy 0.715, and val rmse 0.053\n",
            "Epoch 16, train loss 0.020, train accuracy 0.838, val loss 0.108, val accuracy 0.778, and val rmse 0.053\n",
            "Epoch 17, train loss 0.019, train accuracy 0.821, val loss 0.098, val accuracy 0.778, and val rmse 0.027\n",
            "Epoch 18, train loss 0.017, train accuracy 0.857, val loss 0.091, val accuracy 0.778, and val rmse 0.053\n",
            "Epoch 19, train loss 0.017, train accuracy 0.867, val loss 0.081, val accuracy 0.817, and val rmse 0.027\n",
            "Epoch 20, train loss 0.016, train accuracy 0.870, val loss 0.076, val accuracy 0.857, and val rmse 0.027\n",
            "Epoch 21, train loss 0.016, train accuracy 0.883, val loss 0.074, val accuracy 0.869, and val rmse 0.027\n",
            "Epoch 22, train loss 0.013, train accuracy 0.916, val loss 0.068, val accuracy 0.895, and val rmse 0.027\n",
            "Epoch 23, train loss 0.013, train accuracy 0.893, val loss 0.065, val accuracy 0.883, and val rmse 0.027\n",
            "Epoch 24, train loss 0.012, train accuracy 0.925, val loss 0.058, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 25, train loss 0.011, train accuracy 0.925, val loss 0.054, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 26, train loss 0.010, train accuracy 0.942, val loss 0.049, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 27, train loss 0.010, train accuracy 0.932, val loss 0.045, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 28, train loss 0.009, train accuracy 0.951, val loss 0.041, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 29, train loss 0.009, train accuracy 0.955, val loss 0.038, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 30, train loss 0.009, train accuracy 0.955, val loss 0.035, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.007, train accuracy 0.990, val loss 0.031, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.006, train accuracy 0.990, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.006, train accuracy 0.977, val loss 0.026, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 0.974, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.005, train accuracy 0.974, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.005, train accuracy 0.977, val loss 0.032, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.984, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.004, train accuracy 0.987, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.994, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.005, train accuracy 0.974, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.990, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.990, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.977, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.987, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.974, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.990, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.003, train accuracy 0.977, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 29\n",
            "Epoch 0, train loss 0.054, train accuracy 0.169, val loss 0.291, val accuracy 0.163, and val rmse 0.400\n",
            "Epoch 1, train loss 0.050, train accuracy 0.429, val loss 0.264, val accuracy 0.292, and val rmse 0.267\n",
            "Epoch 2, train loss 0.046, train accuracy 0.539, val loss 0.238, val accuracy 0.492, and val rmse 0.267\n",
            "Epoch 3, train loss 0.042, train accuracy 0.620, val loss 0.229, val accuracy 0.410, and val rmse 0.173\n",
            "Epoch 4, train loss 0.039, train accuracy 0.604, val loss 0.214, val accuracy 0.477, and val rmse 0.160\n",
            "Epoch 5, train loss 0.036, train accuracy 0.601, val loss 0.193, val accuracy 0.517, and val rmse 0.200\n",
            "Epoch 6, train loss 0.033, train accuracy 0.627, val loss 0.179, val accuracy 0.557, and val rmse 0.200\n",
            "Epoch 7, train loss 0.031, train accuracy 0.636, val loss 0.166, val accuracy 0.583, and val rmse 0.200\n",
            "Epoch 8, train loss 0.029, train accuracy 0.649, val loss 0.153, val accuracy 0.643, and val rmse 0.227\n",
            "Epoch 9, train loss 0.029, train accuracy 0.659, val loss 0.149, val accuracy 0.737, and val rmse 0.093\n",
            "Epoch 10, train loss 0.027, train accuracy 0.672, val loss 0.141, val accuracy 0.637, and val rmse 0.120\n",
            "Epoch 11, train loss 0.024, train accuracy 0.727, val loss 0.126, val accuracy 0.686, and val rmse 0.213\n",
            "Epoch 12, train loss 0.023, train accuracy 0.737, val loss 0.118, val accuracy 0.712, and val rmse 0.253\n",
            "Epoch 13, train loss 0.021, train accuracy 0.769, val loss 0.107, val accuracy 0.803, and val rmse 0.200\n",
            "Epoch 14, train loss 0.019, train accuracy 0.789, val loss 0.099, val accuracy 0.816, and val rmse 0.173\n",
            "Epoch 15, train loss 0.018, train accuracy 0.789, val loss 0.091, val accuracy 0.829, and val rmse 0.147\n",
            "Epoch 16, train loss 0.016, train accuracy 0.844, val loss 0.082, val accuracy 0.842, and val rmse 0.147\n",
            "Epoch 17, train loss 0.015, train accuracy 0.860, val loss 0.077, val accuracy 0.908, and val rmse 0.040\n",
            "Epoch 18, train loss 0.014, train accuracy 0.860, val loss 0.068, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 19, train loss 0.013, train accuracy 0.886, val loss 0.062, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 20, train loss 0.012, train accuracy 0.899, val loss 0.057, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 21, train loss 0.011, train accuracy 0.929, val loss 0.052, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 22, train loss 0.010, train accuracy 0.922, val loss 0.049, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 23, train loss 0.011, train accuracy 0.922, val loss 0.047, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 24, train loss 0.009, train accuracy 0.932, val loss 0.042, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 25, train loss 0.008, train accuracy 0.935, val loss 0.039, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 26, train loss 0.009, train accuracy 0.925, val loss 0.038, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 27, train loss 0.008, train accuracy 0.912, val loss 0.036, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 28, train loss 0.006, train accuracy 0.958, val loss 0.032, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 29, train loss 0.006, train accuracy 0.955, val loss 0.026, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 30, train loss 0.007, train accuracy 0.951, val loss 0.025, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 31, train loss 0.005, train accuracy 0.984, val loss 0.021, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 32, train loss 0.004, train accuracy 0.984, val loss 0.019, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 33, train loss 0.005, train accuracy 0.964, val loss 0.018, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 0.945, val loss 0.018, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.961, val loss 0.015, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.971, val loss 0.015, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.971, val loss 0.013, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.984, val loss 0.013, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.984, val loss 0.012, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.987, val loss 0.011, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.974, val loss 0.010, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.984, val loss 0.010, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.987, val loss 0.009, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.981, val loss 0.007, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.974, val loss 0.007, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.981, val loss 0.016, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.994, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 30\n",
            "Epoch 0, train loss 0.053, train accuracy 0.286, val loss 0.268, val accuracy 0.283, and val rmse 0.400\n",
            "Epoch 1, train loss 0.052, train accuracy 0.318, val loss 0.267, val accuracy 0.252, and val rmse 0.173\n",
            "Epoch 2, train loss 0.051, train accuracy 0.263, val loss 0.272, val accuracy 0.160, and val rmse 0.213\n",
            "Epoch 3, train loss 0.049, train accuracy 0.315, val loss 0.256, val accuracy 0.227, and val rmse 0.173\n",
            "Epoch 4, train loss 0.048, train accuracy 0.403, val loss 0.266, val accuracy 0.213, and val rmse 0.293\n",
            "Epoch 5, train loss 0.047, train accuracy 0.471, val loss 0.254, val accuracy 0.435, and val rmse 0.040\n",
            "Epoch 6, train loss 0.044, train accuracy 0.477, val loss 0.235, val accuracy 0.277, and val rmse 0.133\n",
            "Epoch 7, train loss 0.042, train accuracy 0.474, val loss 0.222, val accuracy 0.499, and val rmse 0.040\n",
            "Epoch 8, train loss 0.040, train accuracy 0.529, val loss 0.204, val accuracy 0.578, and val rmse 0.013\n",
            "Epoch 9, train loss 0.037, train accuracy 0.627, val loss 0.190, val accuracy 0.605, and val rmse 0.000\n",
            "Epoch 10, train loss 0.035, train accuracy 0.669, val loss 0.183, val accuracy 0.643, and val rmse 0.027\n",
            "Epoch 11, train loss 0.034, train accuracy 0.675, val loss 0.167, val accuracy 0.707, and val rmse 0.000\n",
            "Epoch 12, train loss 0.032, train accuracy 0.721, val loss 0.160, val accuracy 0.707, and val rmse 0.000\n",
            "Epoch 13, train loss 0.029, train accuracy 0.799, val loss 0.153, val accuracy 0.732, and val rmse 0.000\n",
            "Epoch 14, train loss 0.027, train accuracy 0.847, val loss 0.137, val accuracy 0.783, and val rmse 0.000\n",
            "Epoch 15, train loss 0.025, train accuracy 0.873, val loss 0.123, val accuracy 0.884, and val rmse 0.000\n",
            "Epoch 16, train loss 0.023, train accuracy 0.890, val loss 0.112, val accuracy 0.886, and val rmse 0.000\n",
            "Epoch 17, train loss 0.021, train accuracy 0.919, val loss 0.103, val accuracy 0.924, and val rmse 0.000\n",
            "Epoch 18, train loss 0.020, train accuracy 0.925, val loss 0.097, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 19, train loss 0.020, train accuracy 0.903, val loss 0.086, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 20, train loss 0.016, train accuracy 0.958, val loss 0.082, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 21, train loss 0.015, train accuracy 0.958, val loss 0.074, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 22, train loss 0.013, train accuracy 0.964, val loss 0.069, val accuracy 0.950, and val rmse 0.000\n",
            "Epoch 23, train loss 0.012, train accuracy 0.964, val loss 0.062, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 24, train loss 0.012, train accuracy 0.977, val loss 0.061, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 25, train loss 0.012, train accuracy 0.977, val loss 0.056, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 26, train loss 0.011, train accuracy 0.968, val loss 0.052, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 27, train loss 0.010, train accuracy 0.984, val loss 0.047, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 28, train loss 0.009, train accuracy 0.977, val loss 0.043, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 29, train loss 0.008, train accuracy 0.977, val loss 0.041, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 30, train loss 0.008, train accuracy 0.971, val loss 0.039, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 31, train loss 0.008, train accuracy 0.984, val loss 0.037, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 32, train loss 0.007, train accuracy 0.984, val loss 0.032, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 33, train loss 0.006, train accuracy 0.984, val loss 0.030, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 34, train loss 0.006, train accuracy 0.981, val loss 0.028, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 35, train loss 0.006, train accuracy 0.984, val loss 0.026, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 36, train loss 0.006, train accuracy 0.981, val loss 0.029, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 37, train loss 0.007, train accuracy 0.964, val loss 0.023, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 38, train loss 0.005, train accuracy 0.981, val loss 0.022, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 39, train loss 0.004, train accuracy 0.987, val loss 0.022, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 40, train loss 0.005, train accuracy 0.977, val loss 0.021, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 41, train loss 0.004, train accuracy 0.984, val loss 0.017, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.987, val loss 0.015, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.981, val loss 0.014, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.987, val loss 0.014, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 45, train loss 0.003, train accuracy 0.987, val loss 0.013, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.987, val loss 0.013, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.984, val loss 0.011, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.981, val loss 0.010, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.984, val loss 0.009, val accuracy 0.988, and val rmse 0.000\n",
            "\n",
            " Iteration number : 31\n",
            "Epoch 0, train loss 0.053, train accuracy 0.179, val loss 0.265, val accuracy 0.187, and val rmse 0.107\n",
            "Epoch 1, train loss 0.051, train accuracy 0.231, val loss 0.258, val accuracy 0.252, and val rmse 0.120\n",
            "Epoch 2, train loss 0.051, train accuracy 0.334, val loss 0.265, val accuracy 0.293, and val rmse 0.213\n",
            "Epoch 3, train loss 0.048, train accuracy 0.529, val loss 0.273, val accuracy 0.280, and val rmse 0.200\n",
            "Epoch 4, train loss 0.042, train accuracy 0.640, val loss 0.218, val accuracy 0.668, and val rmse 0.187\n",
            "Epoch 5, train loss 0.040, train accuracy 0.594, val loss 0.206, val accuracy 0.490, and val rmse 0.173\n",
            "Epoch 6, train loss 0.042, train accuracy 0.695, val loss 0.249, val accuracy 0.476, and val rmse 0.000\n",
            "Epoch 7, train loss 0.040, train accuracy 0.666, val loss 0.222, val accuracy 0.663, and val rmse 0.000\n",
            "Epoch 8, train loss 0.039, train accuracy 0.636, val loss 0.214, val accuracy 0.517, and val rmse 0.293\n",
            "Epoch 9, train loss 0.036, train accuracy 0.481, val loss 0.185, val accuracy 0.357, and val rmse 0.267\n",
            "Epoch 10, train loss 0.034, train accuracy 0.461, val loss 0.172, val accuracy 0.477, and val rmse 0.107\n",
            "Epoch 11, train loss 0.033, train accuracy 0.490, val loss 0.169, val accuracy 0.463, and val rmse 0.147\n",
            "Epoch 12, train loss 0.031, train accuracy 0.581, val loss 0.168, val accuracy 0.501, and val rmse 0.147\n",
            "Epoch 13, train loss 0.029, train accuracy 0.571, val loss 0.159, val accuracy 0.488, and val rmse 0.187\n",
            "Epoch 14, train loss 0.028, train accuracy 0.604, val loss 0.141, val accuracy 0.554, and val rmse 0.173\n",
            "Epoch 15, train loss 0.025, train accuracy 0.649, val loss 0.139, val accuracy 0.490, and val rmse 0.200\n",
            "Epoch 16, train loss 0.024, train accuracy 0.662, val loss 0.125, val accuracy 0.656, and val rmse 0.173\n",
            "Epoch 17, train loss 0.022, train accuracy 0.698, val loss 0.116, val accuracy 0.736, and val rmse 0.120\n",
            "Epoch 18, train loss 0.022, train accuracy 0.731, val loss 0.109, val accuracy 0.673, and val rmse 0.160\n",
            "Epoch 19, train loss 0.020, train accuracy 0.753, val loss 0.103, val accuracy 0.711, and val rmse 0.133\n",
            "Epoch 20, train loss 0.019, train accuracy 0.779, val loss 0.095, val accuracy 0.804, and val rmse 0.053\n",
            "Epoch 21, train loss 0.017, train accuracy 0.841, val loss 0.087, val accuracy 0.843, and val rmse 0.053\n",
            "Epoch 22, train loss 0.017, train accuracy 0.825, val loss 0.081, val accuracy 0.907, and val rmse 0.027\n",
            "Epoch 23, train loss 0.016, train accuracy 0.851, val loss 0.077, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 24, train loss 0.015, train accuracy 0.890, val loss 0.071, val accuracy 0.907, and val rmse 0.027\n",
            "Epoch 25, train loss 0.013, train accuracy 0.890, val loss 0.067, val accuracy 0.921, and val rmse 0.027\n",
            "Epoch 26, train loss 0.013, train accuracy 0.899, val loss 0.063, val accuracy 0.921, and val rmse 0.027\n",
            "Epoch 27, train loss 0.013, train accuracy 0.929, val loss 0.057, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 28, train loss 0.012, train accuracy 0.922, val loss 0.053, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 29, train loss 0.010, train accuracy 0.942, val loss 0.049, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 30, train loss 0.009, train accuracy 0.958, val loss 0.046, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 31, train loss 0.009, train accuracy 0.948, val loss 0.043, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 32, train loss 0.009, train accuracy 0.951, val loss 0.041, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 33, train loss 0.008, train accuracy 0.948, val loss 0.037, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 34, train loss 0.007, train accuracy 0.961, val loss 0.034, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 35, train loss 0.013, train accuracy 0.802, val loss 0.093, val accuracy 0.733, and val rmse 0.213\n",
            "Epoch 36, train loss 0.012, train accuracy 0.776, val loss 0.055, val accuracy 0.800, and val rmse 0.213\n",
            "Epoch 37, train loss 0.010, train accuracy 0.805, val loss 0.055, val accuracy 0.800, and val rmse 0.213\n",
            "Epoch 38, train loss 0.011, train accuracy 0.792, val loss 0.081, val accuracy 0.763, and val rmse 0.213\n",
            "Epoch 39, train loss 0.012, train accuracy 0.786, val loss 0.052, val accuracy 0.800, and val rmse 0.213\n",
            "Epoch 40, train loss 0.010, train accuracy 0.818, val loss 0.051, val accuracy 0.800, and val rmse 0.213\n",
            "Epoch 41, train loss 0.010, train accuracy 0.808, val loss 0.047, val accuracy 0.800, and val rmse 0.213\n",
            "Epoch 42, train loss 0.008, train accuracy 0.906, val loss 0.043, val accuracy 0.853, and val rmse 0.213\n",
            "Epoch 43, train loss 0.008, train accuracy 0.929, val loss 0.040, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 44, train loss 0.008, train accuracy 0.938, val loss 0.038, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 45, train loss 0.007, train accuracy 0.958, val loss 0.037, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 46, train loss 0.008, train accuracy 0.948, val loss 0.036, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 47, train loss 0.007, train accuracy 0.968, val loss 0.035, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 48, train loss 0.006, train accuracy 0.968, val loss 0.033, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 49, train loss 0.006, train accuracy 0.968, val loss 0.031, val accuracy 0.987, and val rmse 0.000\n",
            "\n",
            " Iteration number : 32\n",
            "Epoch 0, train loss 0.053, train accuracy 0.182, val loss 0.279, val accuracy 0.027, and val rmse 0.307\n",
            "Epoch 1, train loss 0.053, train accuracy 0.097, val loss 0.263, val accuracy 0.053, and val rmse 0.200\n",
            "Epoch 2, train loss 0.053, train accuracy 0.117, val loss 0.261, val accuracy 0.053, and val rmse 0.600\n",
            "Epoch 3, train loss 0.052, train accuracy 0.315, val loss 0.262, val accuracy 0.410, and val rmse 0.400\n",
            "Epoch 4, train loss 0.051, train accuracy 0.338, val loss 0.258, val accuracy 0.363, and val rmse 0.267\n",
            "Epoch 5, train loss 0.050, train accuracy 0.357, val loss 0.255, val accuracy 0.251, and val rmse 0.187\n",
            "Epoch 6, train loss 0.049, train accuracy 0.396, val loss 0.252, val accuracy 0.372, and val rmse 0.120\n",
            "Epoch 7, train loss 0.052, train accuracy 0.390, val loss 0.256, val accuracy 0.333, and val rmse 0.093\n",
            "Epoch 8, train loss 0.049, train accuracy 0.286, val loss 0.256, val accuracy 0.333, and val rmse 0.067\n",
            "Epoch 9, train loss 0.049, train accuracy 0.409, val loss 0.259, val accuracy 0.347, and val rmse 0.080\n",
            "Epoch 10, train loss 0.045, train accuracy 0.406, val loss 0.235, val accuracy 0.333, and val rmse 0.213\n",
            "Epoch 11, train loss 0.043, train accuracy 0.429, val loss 0.219, val accuracy 0.360, and val rmse 0.213\n",
            "Epoch 12, train loss 0.041, train accuracy 0.510, val loss 0.212, val accuracy 0.423, and val rmse 0.187\n",
            "Epoch 13, train loss 0.039, train accuracy 0.562, val loss 0.201, val accuracy 0.448, and val rmse 0.173\n",
            "Epoch 14, train loss 0.037, train accuracy 0.571, val loss 0.185, val accuracy 0.612, and val rmse 0.160\n",
            "Epoch 15, train loss 0.035, train accuracy 0.607, val loss 0.176, val accuracy 0.598, and val rmse 0.160\n",
            "Epoch 16, train loss 0.033, train accuracy 0.633, val loss 0.168, val accuracy 0.703, and val rmse 0.027\n",
            "Epoch 17, train loss 0.032, train accuracy 0.656, val loss 0.170, val accuracy 0.625, and val rmse 0.133\n",
            "Epoch 18, train loss 0.029, train accuracy 0.649, val loss 0.147, val accuracy 0.636, and val rmse 0.133\n",
            "Epoch 19, train loss 0.028, train accuracy 0.698, val loss 0.149, val accuracy 0.673, and val rmse 0.160\n",
            "Epoch 20, train loss 0.026, train accuracy 0.705, val loss 0.140, val accuracy 0.697, and val rmse 0.160\n",
            "Epoch 21, train loss 0.025, train accuracy 0.721, val loss 0.123, val accuracy 0.736, and val rmse 0.160\n",
            "Epoch 22, train loss 0.023, train accuracy 0.724, val loss 0.119, val accuracy 0.710, and val rmse 0.160\n",
            "Epoch 23, train loss 0.023, train accuracy 0.744, val loss 0.123, val accuracy 0.697, and val rmse 0.160\n",
            "Epoch 24, train loss 0.021, train accuracy 0.737, val loss 0.273, val accuracy 0.468, and val rmse 0.133\n",
            "Epoch 25, train loss 0.024, train accuracy 0.695, val loss 0.105, val accuracy 0.736, and val rmse 0.160\n",
            "Epoch 26, train loss 0.021, train accuracy 0.763, val loss 0.118, val accuracy 0.673, and val rmse 0.160\n",
            "Epoch 27, train loss 0.020, train accuracy 0.753, val loss 0.099, val accuracy 0.749, and val rmse 0.160\n",
            "Epoch 28, train loss 0.019, train accuracy 0.750, val loss 0.097, val accuracy 0.723, and val rmse 0.160\n",
            "Epoch 29, train loss 0.019, train accuracy 0.766, val loss 0.101, val accuracy 0.710, and val rmse 0.160\n",
            "Epoch 30, train loss 0.017, train accuracy 0.763, val loss 0.088, val accuracy 0.723, and val rmse 0.160\n",
            "Epoch 31, train loss 0.019, train accuracy 0.756, val loss 0.089, val accuracy 0.788, and val rmse 0.160\n",
            "Epoch 32, train loss 0.016, train accuracy 0.795, val loss 0.077, val accuracy 0.762, and val rmse 0.133\n",
            "Epoch 33, train loss 0.014, train accuracy 0.815, val loss 0.076, val accuracy 0.736, and val rmse 0.133\n",
            "Epoch 34, train loss 0.014, train accuracy 0.828, val loss 0.070, val accuracy 0.789, and val rmse 0.133\n",
            "Epoch 35, train loss 0.014, train accuracy 0.802, val loss 0.073, val accuracy 0.763, and val rmse 0.133\n",
            "Epoch 36, train loss 0.013, train accuracy 0.834, val loss 0.065, val accuracy 0.789, and val rmse 0.133\n",
            "Epoch 37, train loss 0.012, train accuracy 0.857, val loss 0.057, val accuracy 0.854, and val rmse 0.107\n",
            "Epoch 38, train loss 0.011, train accuracy 0.877, val loss 0.054, val accuracy 0.854, and val rmse 0.107\n",
            "Epoch 39, train loss 0.012, train accuracy 0.857, val loss 0.094, val accuracy 0.705, and val rmse 0.080\n",
            "Epoch 40, train loss 0.010, train accuracy 0.890, val loss 0.050, val accuracy 0.854, and val rmse 0.080\n",
            "Epoch 41, train loss 0.010, train accuracy 0.883, val loss 0.048, val accuracy 0.907, and val rmse 0.053\n",
            "Epoch 42, train loss 0.009, train accuracy 0.922, val loss 0.055, val accuracy 0.884, and val rmse 0.027\n",
            "Epoch 43, train loss 0.008, train accuracy 0.929, val loss 0.042, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 44, train loss 0.007, train accuracy 0.925, val loss 0.035, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 45, train loss 0.008, train accuracy 0.932, val loss 0.078, val accuracy 0.810, and val rmse 0.027\n",
            "Epoch 46, train loss 0.006, train accuracy 0.961, val loss 0.028, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 47, train loss 0.006, train accuracy 0.958, val loss 0.032, val accuracy 0.974, and val rmse 0.027\n",
            "Epoch 48, train loss 0.009, train accuracy 0.925, val loss 0.033, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 49, train loss 0.006, train accuracy 0.974, val loss 0.026, val accuracy 0.987, and val rmse 0.000\n",
            "\n",
            " Iteration number : 33\n",
            "Epoch 0, train loss 0.053, train accuracy 0.338, val loss 0.266, val accuracy 0.253, and val rmse 0.360\n",
            "Epoch 1, train loss 0.052, train accuracy 0.377, val loss 0.283, val accuracy 0.013, and val rmse 0.400\n",
            "Epoch 2, train loss 0.051, train accuracy 0.325, val loss 0.263, val accuracy 0.384, and val rmse 0.200\n",
            "Epoch 3, train loss 0.049, train accuracy 0.458, val loss 0.253, val accuracy 0.358, and val rmse 0.053\n",
            "Epoch 4, train loss 0.045, train accuracy 0.571, val loss 0.240, val accuracy 0.543, and val rmse 0.013\n",
            "Epoch 5, train loss 0.043, train accuracy 0.604, val loss 0.235, val accuracy 0.501, and val rmse 0.013\n",
            "Epoch 6, train loss 0.039, train accuracy 0.649, val loss 0.224, val accuracy 0.577, and val rmse 0.013\n",
            "Epoch 7, train loss 0.036, train accuracy 0.649, val loss 0.190, val accuracy 0.704, and val rmse 0.013\n",
            "Epoch 8, train loss 0.033, train accuracy 0.688, val loss 0.170, val accuracy 0.768, and val rmse 0.013\n",
            "Epoch 9, train loss 0.031, train accuracy 0.718, val loss 0.158, val accuracy 0.769, and val rmse 0.013\n",
            "Epoch 10, train loss 0.029, train accuracy 0.744, val loss 0.147, val accuracy 0.768, and val rmse 0.013\n",
            "Epoch 11, train loss 0.027, train accuracy 0.779, val loss 0.149, val accuracy 0.782, and val rmse 0.013\n",
            "Epoch 12, train loss 0.026, train accuracy 0.812, val loss 0.141, val accuracy 0.834, and val rmse 0.013\n",
            "Epoch 13, train loss 0.025, train accuracy 0.760, val loss 0.143, val accuracy 0.795, and val rmse 0.013\n",
            "Epoch 14, train loss 0.022, train accuracy 0.834, val loss 0.115, val accuracy 0.833, and val rmse 0.013\n",
            "Epoch 15, train loss 0.021, train accuracy 0.860, val loss 0.101, val accuracy 0.898, and val rmse 0.013\n",
            "Epoch 16, train loss 0.019, train accuracy 0.906, val loss 0.093, val accuracy 0.911, and val rmse 0.013\n",
            "Epoch 17, train loss 0.017, train accuracy 0.929, val loss 0.089, val accuracy 0.911, and val rmse 0.027\n",
            "Epoch 18, train loss 0.016, train accuracy 0.942, val loss 0.079, val accuracy 0.923, and val rmse 0.027\n",
            "Epoch 19, train loss 0.015, train accuracy 0.925, val loss 0.072, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 20, train loss 0.013, train accuracy 0.945, val loss 0.069, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 21, train loss 0.018, train accuracy 0.890, val loss 0.154, val accuracy 0.711, and val rmse 0.027\n",
            "Epoch 22, train loss 0.014, train accuracy 0.951, val loss 0.065, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 23, train loss 0.022, train accuracy 0.864, val loss 0.101, val accuracy 0.922, and val rmse 0.027\n",
            "Epoch 24, train loss 0.016, train accuracy 0.968, val loss 0.080, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 25, train loss 0.014, train accuracy 0.964, val loss 0.071, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 26, train loss 0.014, train accuracy 0.964, val loss 0.066, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 27, train loss 0.012, train accuracy 0.974, val loss 0.054, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 28, train loss 0.011, train accuracy 0.971, val loss 0.047, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 29, train loss 0.010, train accuracy 0.971, val loss 0.073, val accuracy 0.837, and val rmse 0.000\n",
            "Epoch 30, train loss 0.008, train accuracy 0.997, val loss 0.037, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.007, train accuracy 0.990, val loss 0.034, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.007, train accuracy 0.990, val loss 0.029, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.006, train accuracy 0.990, val loss 0.026, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 0.994, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.007, train accuracy 0.971, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 1.000, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.994, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.004, train accuracy 0.987, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 1.000, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.004, train accuracy 0.984, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.994, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.994, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.990, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.990, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 34\n",
            "Epoch 0, train loss 0.054, train accuracy 0.269, val loss 0.269, val accuracy 0.039, and val rmse 0.387\n",
            "Epoch 1, train loss 0.051, train accuracy 0.351, val loss 0.288, val accuracy 0.253, and val rmse 0.320\n",
            "Epoch 2, train loss 0.046, train accuracy 0.610, val loss 0.248, val accuracy 0.543, and val rmse 0.200\n",
            "Epoch 3, train loss 0.043, train accuracy 0.610, val loss 0.231, val accuracy 0.503, and val rmse 0.160\n",
            "Epoch 4, train loss 0.041, train accuracy 0.669, val loss 0.211, val accuracy 0.690, and val rmse 0.000\n",
            "Epoch 5, train loss 0.038, train accuracy 0.688, val loss 0.196, val accuracy 0.702, and val rmse 0.013\n",
            "Epoch 6, train loss 0.036, train accuracy 0.698, val loss 0.181, val accuracy 0.716, and val rmse 0.013\n",
            "Epoch 7, train loss 0.034, train accuracy 0.718, val loss 0.169, val accuracy 0.729, and val rmse 0.000\n",
            "Epoch 8, train loss 0.031, train accuracy 0.731, val loss 0.158, val accuracy 0.743, and val rmse 0.000\n",
            "Epoch 9, train loss 0.030, train accuracy 0.744, val loss 0.146, val accuracy 0.781, and val rmse 0.000\n",
            "Epoch 10, train loss 0.028, train accuracy 0.782, val loss 0.135, val accuracy 0.793, and val rmse 0.000\n",
            "Epoch 11, train loss 0.026, train accuracy 0.808, val loss 0.128, val accuracy 0.807, and val rmse 0.000\n",
            "Epoch 12, train loss 0.024, train accuracy 0.838, val loss 0.114, val accuracy 0.898, and val rmse 0.000\n",
            "Epoch 13, train loss 0.022, train accuracy 0.880, val loss 0.110, val accuracy 0.898, and val rmse 0.000\n",
            "Epoch 14, train loss 0.020, train accuracy 0.909, val loss 0.101, val accuracy 0.911, and val rmse 0.000\n",
            "Epoch 15, train loss 0.018, train accuracy 0.909, val loss 0.089, val accuracy 0.911, and val rmse 0.000\n",
            "Epoch 16, train loss 0.017, train accuracy 0.909, val loss 0.084, val accuracy 0.911, and val rmse 0.000\n",
            "Epoch 17, train loss 0.017, train accuracy 0.880, val loss 0.076, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 18, train loss 0.014, train accuracy 0.903, val loss 0.071, val accuracy 0.911, and val rmse 0.000\n",
            "Epoch 19, train loss 0.013, train accuracy 0.916, val loss 0.066, val accuracy 0.911, and val rmse 0.000\n",
            "Epoch 20, train loss 0.011, train accuracy 0.909, val loss 0.055, val accuracy 0.898, and val rmse 0.027\n",
            "Epoch 21, train loss 0.012, train accuracy 0.890, val loss 0.056, val accuracy 0.898, and val rmse 0.027\n",
            "Epoch 22, train loss 0.010, train accuracy 0.922, val loss 0.052, val accuracy 0.898, and val rmse 0.027\n",
            "Epoch 23, train loss 0.009, train accuracy 0.919, val loss 0.047, val accuracy 0.898, and val rmse 0.027\n",
            "Epoch 24, train loss 0.008, train accuracy 0.945, val loss 0.044, val accuracy 0.910, and val rmse 0.027\n",
            "Epoch 25, train loss 0.008, train accuracy 0.935, val loss 0.039, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 26, train loss 0.007, train accuracy 0.945, val loss 0.038, val accuracy 0.923, and val rmse 0.027\n",
            "Epoch 27, train loss 0.007, train accuracy 0.951, val loss 0.035, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 28, train loss 0.007, train accuracy 0.955, val loss 0.034, val accuracy 0.923, and val rmse 0.027\n",
            "Epoch 29, train loss 0.006, train accuracy 0.971, val loss 0.031, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 30, train loss 0.006, train accuracy 0.961, val loss 0.030, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 31, train loss 0.005, train accuracy 0.964, val loss 0.028, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 32, train loss 0.005, train accuracy 0.968, val loss 0.025, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 33, train loss 0.005, train accuracy 0.977, val loss 0.023, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 0.964, val loss 0.021, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.971, val loss 0.020, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.984, val loss 0.018, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.974, val loss 0.019, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 38, train loss 0.005, train accuracy 0.971, val loss 0.016, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.977, val loss 0.015, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.977, val loss 0.014, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 41, train loss 0.004, train accuracy 0.971, val loss 0.014, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.977, val loss 0.013, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.981, val loss 0.013, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.984, val loss 0.012, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.987, val loss 0.011, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.977, val loss 0.010, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.987, val loss 0.010, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.958, val loss 0.010, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.987, val loss 0.009, val accuracy 0.987, and val rmse 0.000\n",
            "\n",
            " Iteration number : 35\n",
            "Epoch 0, train loss 0.053, train accuracy 0.166, val loss 0.272, val accuracy 0.093, and val rmse 0.453\n",
            "Epoch 1, train loss 0.051, train accuracy 0.263, val loss 0.255, val accuracy 0.147, and val rmse 0.240\n",
            "Epoch 2, train loss 0.050, train accuracy 0.360, val loss 0.258, val accuracy 0.160, and val rmse 0.133\n",
            "Epoch 3, train loss 0.048, train accuracy 0.419, val loss 0.259, val accuracy 0.319, and val rmse 0.093\n",
            "Epoch 4, train loss 0.046, train accuracy 0.500, val loss 0.267, val accuracy 0.397, and val rmse 0.120\n",
            "Epoch 5, train loss 0.042, train accuracy 0.666, val loss 0.237, val accuracy 0.521, and val rmse 0.067\n",
            "Epoch 6, train loss 0.038, train accuracy 0.714, val loss 0.213, val accuracy 0.585, and val rmse 0.067\n",
            "Epoch 7, train loss 0.038, train accuracy 0.669, val loss 0.219, val accuracy 0.425, and val rmse 0.067\n",
            "Epoch 8, train loss 0.034, train accuracy 0.714, val loss 0.187, val accuracy 0.525, and val rmse 0.067\n",
            "Epoch 9, train loss 0.031, train accuracy 0.750, val loss 0.163, val accuracy 0.688, and val rmse 0.067\n",
            "Epoch 10, train loss 0.035, train accuracy 0.659, val loss 0.196, val accuracy 0.465, and val rmse 0.013\n",
            "Epoch 11, train loss 0.032, train accuracy 0.653, val loss 0.163, val accuracy 0.627, and val rmse 0.040\n",
            "Epoch 12, train loss 0.029, train accuracy 0.698, val loss 0.158, val accuracy 0.639, and val rmse 0.040\n",
            "Epoch 13, train loss 0.027, train accuracy 0.737, val loss 0.144, val accuracy 0.676, and val rmse 0.067\n",
            "Epoch 14, train loss 0.027, train accuracy 0.721, val loss 0.145, val accuracy 0.653, and val rmse 0.013\n",
            "Epoch 15, train loss 0.027, train accuracy 0.718, val loss 0.133, val accuracy 0.677, and val rmse 0.040\n",
            "Epoch 16, train loss 0.022, train accuracy 0.773, val loss 0.115, val accuracy 0.701, and val rmse 0.067\n",
            "Epoch 17, train loss 0.021, train accuracy 0.763, val loss 0.103, val accuracy 0.742, and val rmse 0.067\n",
            "Epoch 18, train loss 0.019, train accuracy 0.799, val loss 0.097, val accuracy 0.793, and val rmse 0.067\n",
            "Epoch 19, train loss 0.018, train accuracy 0.831, val loss 0.090, val accuracy 0.820, and val rmse 0.067\n",
            "Epoch 20, train loss 0.019, train accuracy 0.753, val loss 0.110, val accuracy 0.677, and val rmse 0.040\n",
            "Epoch 21, train loss 0.017, train accuracy 0.802, val loss 0.089, val accuracy 0.780, and val rmse 0.040\n",
            "Epoch 22, train loss 0.016, train accuracy 0.812, val loss 0.078, val accuracy 0.807, and val rmse 0.040\n",
            "Epoch 23, train loss 0.015, train accuracy 0.857, val loss 0.077, val accuracy 0.844, and val rmse 0.040\n",
            "Epoch 24, train loss 0.014, train accuracy 0.851, val loss 0.070, val accuracy 0.857, and val rmse 0.040\n",
            "Epoch 25, train loss 0.014, train accuracy 0.903, val loss 0.064, val accuracy 0.870, and val rmse 0.040\n",
            "Epoch 26, train loss 0.012, train accuracy 0.922, val loss 0.060, val accuracy 0.949, and val rmse 0.027\n",
            "Epoch 27, train loss 0.013, train accuracy 0.896, val loss 0.058, val accuracy 0.949, and val rmse 0.027\n",
            "Epoch 28, train loss 0.011, train accuracy 0.942, val loss 0.049, val accuracy 0.974, and val rmse 0.027\n",
            "Epoch 29, train loss 0.009, train accuracy 0.971, val loss 0.046, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 30, train loss 0.009, train accuracy 0.968, val loss 0.041, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 31, train loss 0.008, train accuracy 0.961, val loss 0.042, val accuracy 0.962, and val rmse 0.027\n",
            "Epoch 32, train loss 0.007, train accuracy 0.968, val loss 0.034, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 33, train loss 0.020, train accuracy 0.776, val loss 0.134, val accuracy 0.733, and val rmse 0.027\n",
            "Epoch 34, train loss 0.012, train accuracy 0.916, val loss 0.061, val accuracy 0.922, and val rmse 0.027\n",
            "Epoch 35, train loss 0.010, train accuracy 0.961, val loss 0.055, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 36, train loss 0.010, train accuracy 0.961, val loss 0.048, val accuracy 0.974, and val rmse 0.027\n",
            "Epoch 37, train loss 0.009, train accuracy 0.974, val loss 0.044, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 38, train loss 0.008, train accuracy 0.968, val loss 0.042, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 39, train loss 0.008, train accuracy 0.974, val loss 0.037, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 40, train loss 0.008, train accuracy 0.977, val loss 0.036, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 41, train loss 0.007, train accuracy 0.971, val loss 0.033, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 42, train loss 0.007, train accuracy 0.977, val loss 0.032, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 43, train loss 0.006, train accuracy 0.977, val loss 0.028, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 44, train loss 0.005, train accuracy 0.981, val loss 0.026, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 45, train loss 0.005, train accuracy 0.981, val loss 0.029, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 46, train loss 0.005, train accuracy 0.981, val loss 0.023, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 47, train loss 0.005, train accuracy 0.981, val loss 0.035, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 48, train loss 0.005, train accuracy 0.984, val loss 0.025, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 49, train loss 0.004, train accuracy 0.987, val loss 0.021, val accuracy 0.987, and val rmse 0.027\n",
            "\n",
            " Iteration number : 36\n",
            "Epoch 0, train loss 0.053, train accuracy 0.289, val loss 0.268, val accuracy 0.138, and val rmse 0.400\n",
            "Epoch 1, train loss 0.052, train accuracy 0.321, val loss 0.270, val accuracy 0.117, and val rmse 0.427\n",
            "Epoch 2, train loss 0.049, train accuracy 0.545, val loss 0.255, val accuracy 0.338, and val rmse 0.240\n",
            "Epoch 3, train loss 0.046, train accuracy 0.666, val loss 0.251, val accuracy 0.353, and val rmse 0.187\n",
            "Epoch 4, train loss 0.043, train accuracy 0.708, val loss 0.230, val accuracy 0.553, and val rmse 0.187\n",
            "Epoch 5, train loss 0.041, train accuracy 0.714, val loss 0.223, val accuracy 0.556, and val rmse 0.107\n",
            "Epoch 6, train loss 0.039, train accuracy 0.734, val loss 0.218, val accuracy 0.493, and val rmse 0.107\n",
            "Epoch 7, train loss 0.035, train accuracy 0.756, val loss 0.185, val accuracy 0.583, and val rmse 0.107\n",
            "Epoch 8, train loss 0.032, train accuracy 0.747, val loss 0.174, val accuracy 0.594, and val rmse 0.107\n",
            "Epoch 9, train loss 0.030, train accuracy 0.769, val loss 0.162, val accuracy 0.622, and val rmse 0.080\n",
            "Epoch 10, train loss 0.028, train accuracy 0.815, val loss 0.150, val accuracy 0.623, and val rmse 0.080\n",
            "Epoch 11, train loss 0.026, train accuracy 0.812, val loss 0.140, val accuracy 0.689, and val rmse 0.027\n",
            "Epoch 12, train loss 0.025, train accuracy 0.812, val loss 0.124, val accuracy 0.768, and val rmse 0.027\n",
            "Epoch 13, train loss 0.023, train accuracy 0.818, val loss 0.110, val accuracy 0.910, and val rmse 0.027\n",
            "Epoch 14, train loss 0.021, train accuracy 0.883, val loss 0.106, val accuracy 0.909, and val rmse 0.027\n",
            "Epoch 15, train loss 0.020, train accuracy 0.883, val loss 0.098, val accuracy 0.921, and val rmse 0.053\n",
            "Epoch 16, train loss 0.017, train accuracy 0.893, val loss 0.094, val accuracy 0.908, and val rmse 0.053\n",
            "Epoch 17, train loss 0.016, train accuracy 0.873, val loss 0.085, val accuracy 0.908, and val rmse 0.053\n",
            "Epoch 18, train loss 0.015, train accuracy 0.864, val loss 0.082, val accuracy 0.882, and val rmse 0.053\n",
            "Epoch 19, train loss 0.013, train accuracy 0.867, val loss 0.074, val accuracy 0.921, and val rmse 0.053\n",
            "Epoch 20, train loss 0.012, train accuracy 0.890, val loss 0.065, val accuracy 0.934, and val rmse 0.053\n",
            "Epoch 21, train loss 0.011, train accuracy 0.880, val loss 0.056, val accuracy 0.934, and val rmse 0.053\n",
            "Epoch 22, train loss 0.010, train accuracy 0.906, val loss 0.049, val accuracy 0.934, and val rmse 0.053\n",
            "Epoch 23, train loss 0.009, train accuracy 0.916, val loss 0.045, val accuracy 0.934, and val rmse 0.053\n",
            "Epoch 24, train loss 0.008, train accuracy 0.942, val loss 0.040, val accuracy 0.947, and val rmse 0.053\n",
            "Epoch 25, train loss 0.009, train accuracy 0.932, val loss 0.037, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 26, train loss 0.007, train accuracy 0.955, val loss 0.032, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 27, train loss 0.006, train accuracy 0.951, val loss 0.027, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 28, train loss 0.006, train accuracy 0.961, val loss 0.026, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 29, train loss 0.005, train accuracy 0.981, val loss 0.022, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 30, train loss 0.004, train accuracy 0.977, val loss 0.020, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 31, train loss 0.004, train accuracy 0.977, val loss 0.017, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 32, train loss 0.004, train accuracy 0.974, val loss 0.017, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.974, val loss 0.015, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 34, train loss 0.003, train accuracy 0.984, val loss 0.012, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.977, val loss 0.014, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.990, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.002, train accuracy 0.994, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 0.990, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.990, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.987, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.994, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.990, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.997, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 37\n",
            "Epoch 0, train loss 0.057, train accuracy 0.289, val loss 0.283, val accuracy 0.177, and val rmse 0.493\n",
            "Epoch 1, train loss 0.054, train accuracy 0.354, val loss 0.264, val accuracy 0.350, and val rmse 0.333\n",
            "Epoch 2, train loss 0.051, train accuracy 0.429, val loss 0.259, val accuracy 0.312, and val rmse 0.267\n",
            "Epoch 3, train loss 0.047, train accuracy 0.516, val loss 0.250, val accuracy 0.367, and val rmse 0.173\n",
            "Epoch 4, train loss 0.043, train accuracy 0.542, val loss 0.224, val accuracy 0.438, and val rmse 0.120\n",
            "Epoch 5, train loss 0.039, train accuracy 0.604, val loss 0.204, val accuracy 0.466, and val rmse 0.040\n",
            "Epoch 6, train loss 0.037, train accuracy 0.662, val loss 0.200, val accuracy 0.439, and val rmse 0.067\n",
            "Epoch 7, train loss 0.034, train accuracy 0.718, val loss 0.181, val accuracy 0.553, and val rmse 0.067\n",
            "Epoch 8, train loss 0.032, train accuracy 0.724, val loss 0.158, val accuracy 0.653, and val rmse 0.040\n",
            "Epoch 9, train loss 0.028, train accuracy 0.808, val loss 0.142, val accuracy 0.753, and val rmse 0.040\n",
            "Epoch 10, train loss 0.026, train accuracy 0.851, val loss 0.135, val accuracy 0.719, and val rmse 0.040\n",
            "Epoch 11, train loss 0.024, train accuracy 0.867, val loss 0.111, val accuracy 0.868, and val rmse 0.040\n",
            "Epoch 12, train loss 0.020, train accuracy 0.903, val loss 0.097, val accuracy 0.948, and val rmse 0.040\n",
            "Epoch 13, train loss 0.019, train accuracy 0.912, val loss 0.090, val accuracy 0.948, and val rmse 0.013\n",
            "Epoch 14, train loss 0.018, train accuracy 0.932, val loss 0.078, val accuracy 0.974, and val rmse 0.013\n",
            "Epoch 15, train loss 0.015, train accuracy 0.929, val loss 0.068, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 16, train loss 0.012, train accuracy 0.974, val loss 0.056, val accuracy 0.973, and val rmse 0.040\n",
            "Epoch 17, train loss 0.010, train accuracy 0.971, val loss 0.043, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 18, train loss 0.010, train accuracy 0.964, val loss 0.039, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 19, train loss 0.008, train accuracy 0.990, val loss 0.038, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 20, train loss 0.009, train accuracy 0.974, val loss 0.108, val accuracy 0.775, and val rmse 0.000\n",
            "Epoch 21, train loss 0.007, train accuracy 0.981, val loss 0.029, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 22, train loss 0.005, train accuracy 0.997, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 23, train loss 0.005, train accuracy 0.984, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.004, train accuracy 0.990, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.004, train accuracy 0.994, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.007, train accuracy 0.945, val loss 0.064, val accuracy 0.837, and val rmse 0.000\n",
            "Epoch 27, train loss 0.003, train accuracy 0.994, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.003, train accuracy 0.997, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.004, train accuracy 0.981, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.002, train accuracy 0.997, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.003, train accuracy 0.977, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.003, train accuracy 0.981, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.003, train accuracy 0.981, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.002, train accuracy 0.990, val loss 0.052, val accuracy 0.887, and val rmse 0.000\n",
            "Epoch 36, train loss 0.002, train accuracy 0.994, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.981, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 0.994, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 0.990, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.990, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 0.990, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.987, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.987, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.997, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.981, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.997, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 38\n",
            "Epoch 0, train loss 0.053, train accuracy 0.224, val loss 0.279, val accuracy 0.243, and val rmse 0.520\n",
            "Epoch 1, train loss 0.052, train accuracy 0.406, val loss 0.299, val accuracy 0.187, and val rmse 0.373\n",
            "Epoch 2, train loss 0.047, train accuracy 0.536, val loss 0.253, val accuracy 0.185, and val rmse 0.267\n",
            "Epoch 3, train loss 0.043, train accuracy 0.594, val loss 0.238, val accuracy 0.538, and val rmse 0.160\n",
            "Epoch 4, train loss 0.040, train accuracy 0.610, val loss 0.256, val accuracy 0.370, and val rmse 0.053\n",
            "Epoch 5, train loss 0.037, train accuracy 0.614, val loss 0.192, val accuracy 0.637, and val rmse 0.027\n",
            "Epoch 6, train loss 0.037, train accuracy 0.653, val loss 0.197, val accuracy 0.663, and val rmse 0.000\n",
            "Epoch 7, train loss 0.036, train accuracy 0.617, val loss 0.185, val accuracy 0.650, and val rmse 0.027\n",
            "Epoch 8, train loss 0.035, train accuracy 0.588, val loss 0.180, val accuracy 0.517, and val rmse 0.293\n",
            "Epoch 9, train loss 0.034, train accuracy 0.588, val loss 0.173, val accuracy 0.602, and val rmse 0.293\n",
            "Epoch 10, train loss 0.033, train accuracy 0.584, val loss 0.174, val accuracy 0.490, and val rmse 0.293\n",
            "Epoch 11, train loss 0.033, train accuracy 0.578, val loss 0.178, val accuracy 0.517, and val rmse 0.267\n",
            "Epoch 12, train loss 0.031, train accuracy 0.630, val loss 0.169, val accuracy 0.530, and val rmse 0.133\n",
            "Epoch 13, train loss 0.030, train accuracy 0.666, val loss 0.158, val accuracy 0.637, and val rmse 0.027\n",
            "Epoch 14, train loss 0.029, train accuracy 0.682, val loss 0.147, val accuracy 0.677, and val rmse 0.040\n",
            "Epoch 15, train loss 0.028, train accuracy 0.698, val loss 0.140, val accuracy 0.703, and val rmse 0.027\n",
            "Epoch 16, train loss 0.027, train accuracy 0.688, val loss 0.135, val accuracy 0.730, and val rmse 0.000\n",
            "Epoch 17, train loss 0.026, train accuracy 0.731, val loss 0.130, val accuracy 0.730, and val rmse 0.000\n",
            "Epoch 18, train loss 0.025, train accuracy 0.744, val loss 0.124, val accuracy 0.807, and val rmse 0.000\n",
            "Epoch 19, train loss 0.024, train accuracy 0.756, val loss 0.119, val accuracy 0.793, and val rmse 0.000\n",
            "Epoch 20, train loss 0.023, train accuracy 0.769, val loss 0.115, val accuracy 0.807, and val rmse 0.000\n",
            "Epoch 21, train loss 0.023, train accuracy 0.799, val loss 0.178, val accuracy 0.669, and val rmse 0.000\n",
            "Epoch 22, train loss 0.021, train accuracy 0.776, val loss 0.101, val accuracy 0.819, and val rmse 0.000\n",
            "Epoch 23, train loss 0.020, train accuracy 0.828, val loss 0.096, val accuracy 0.845, and val rmse 0.000\n",
            "Epoch 24, train loss 0.019, train accuracy 0.854, val loss 0.090, val accuracy 0.897, and val rmse 0.000\n",
            "Epoch 25, train loss 0.018, train accuracy 0.890, val loss 0.085, val accuracy 0.922, and val rmse 0.000\n",
            "Epoch 26, train loss 0.016, train accuracy 0.919, val loss 0.080, val accuracy 0.922, and val rmse 0.000\n",
            "Epoch 27, train loss 0.015, train accuracy 0.932, val loss 0.074, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 28, train loss 0.015, train accuracy 0.896, val loss 0.070, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 29, train loss 0.014, train accuracy 0.912, val loss 0.065, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 30, train loss 0.013, train accuracy 0.903, val loss 0.062, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 31, train loss 0.012, train accuracy 0.922, val loss 0.057, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 32, train loss 0.012, train accuracy 0.922, val loss 0.057, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 33, train loss 0.011, train accuracy 0.925, val loss 0.052, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 34, train loss 0.011, train accuracy 0.922, val loss 0.048, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 35, train loss 0.010, train accuracy 0.922, val loss 0.046, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 36, train loss 0.010, train accuracy 0.935, val loss 0.043, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 37, train loss 0.009, train accuracy 0.945, val loss 0.041, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 38, train loss 0.008, train accuracy 0.938, val loss 0.038, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 39, train loss 0.009, train accuracy 0.929, val loss 0.037, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 40, train loss 0.007, train accuracy 0.938, val loss 0.033, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 41, train loss 0.007, train accuracy 0.938, val loss 0.032, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 42, train loss 0.006, train accuracy 0.942, val loss 0.030, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 43, train loss 0.006, train accuracy 0.945, val loss 0.029, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 44, train loss 0.006, train accuracy 0.958, val loss 0.027, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 45, train loss 0.005, train accuracy 0.990, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.005, train accuracy 0.994, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.004, train accuracy 0.997, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.005, train accuracy 0.984, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.004, train accuracy 0.987, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 39\n",
            "Epoch 0, train loss 0.054, train accuracy 0.234, val loss 0.271, val accuracy 0.389, and val rmse 0.400\n",
            "Epoch 1, train loss 0.052, train accuracy 0.289, val loss 0.262, val accuracy 0.291, and val rmse 0.267\n",
            "Epoch 2, train loss 0.051, train accuracy 0.419, val loss 0.263, val accuracy 0.429, and val rmse 0.147\n",
            "Epoch 3, train loss 0.047, train accuracy 0.562, val loss 0.247, val accuracy 0.432, and val rmse 0.093\n",
            "Epoch 4, train loss 0.044, train accuracy 0.601, val loss 0.241, val accuracy 0.610, and val rmse 0.040\n",
            "Epoch 5, train loss 0.046, train accuracy 0.575, val loss 0.256, val accuracy 0.387, and val rmse 0.040\n",
            "Epoch 6, train loss 0.042, train accuracy 0.685, val loss 0.221, val accuracy 0.637, and val rmse 0.013\n",
            "Epoch 7, train loss 0.039, train accuracy 0.653, val loss 0.208, val accuracy 0.597, and val rmse 0.160\n",
            "Epoch 8, train loss 0.034, train accuracy 0.760, val loss 0.188, val accuracy 0.690, and val rmse 0.067\n",
            "Epoch 9, train loss 0.033, train accuracy 0.734, val loss 0.170, val accuracy 0.754, and val rmse 0.040\n",
            "Epoch 10, train loss 0.030, train accuracy 0.740, val loss 0.155, val accuracy 0.714, and val rmse 0.040\n",
            "Epoch 11, train loss 0.028, train accuracy 0.769, val loss 0.144, val accuracy 0.714, and val rmse 0.067\n",
            "Epoch 12, train loss 0.026, train accuracy 0.799, val loss 0.128, val accuracy 0.841, and val rmse 0.067\n",
            "Epoch 13, train loss 0.024, train accuracy 0.799, val loss 0.119, val accuracy 0.842, and val rmse 0.040\n",
            "Epoch 14, train loss 0.023, train accuracy 0.838, val loss 0.119, val accuracy 0.828, and val rmse 0.040\n",
            "Epoch 15, train loss 0.021, train accuracy 0.841, val loss 0.101, val accuracy 0.868, and val rmse 0.040\n",
            "Epoch 16, train loss 0.019, train accuracy 0.867, val loss 0.090, val accuracy 0.907, and val rmse 0.040\n",
            "Epoch 17, train loss 0.017, train accuracy 0.899, val loss 0.082, val accuracy 0.920, and val rmse 0.040\n",
            "Epoch 18, train loss 0.016, train accuracy 0.916, val loss 0.075, val accuracy 0.920, and val rmse 0.040\n",
            "Epoch 19, train loss 0.014, train accuracy 0.922, val loss 0.068, val accuracy 0.947, and val rmse 0.040\n",
            "Epoch 20, train loss 0.013, train accuracy 0.922, val loss 0.061, val accuracy 0.947, and val rmse 0.040\n",
            "Epoch 21, train loss 0.012, train accuracy 0.945, val loss 0.056, val accuracy 0.947, and val rmse 0.040\n",
            "Epoch 22, train loss 0.011, train accuracy 0.958, val loss 0.051, val accuracy 0.947, and val rmse 0.040\n",
            "Epoch 23, train loss 0.010, train accuracy 0.964, val loss 0.047, val accuracy 0.960, and val rmse 0.040\n",
            "Epoch 24, train loss 0.010, train accuracy 0.955, val loss 0.044, val accuracy 0.973, and val rmse 0.040\n",
            "Epoch 25, train loss 0.009, train accuracy 0.945, val loss 0.039, val accuracy 0.973, and val rmse 0.040\n",
            "Epoch 26, train loss 0.008, train accuracy 0.968, val loss 0.036, val accuracy 0.973, and val rmse 0.040\n",
            "Epoch 27, train loss 0.008, train accuracy 0.958, val loss 0.034, val accuracy 0.973, and val rmse 0.040\n",
            "Epoch 28, train loss 0.007, train accuracy 0.964, val loss 0.035, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 29, train loss 0.008, train accuracy 0.955, val loss 0.028, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 30, train loss 0.005, train accuracy 0.981, val loss 0.026, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 31, train loss 0.005, train accuracy 0.987, val loss 0.024, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 32, train loss 0.007, train accuracy 0.948, val loss 0.023, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 33, train loss 0.004, train accuracy 0.984, val loss 0.020, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 34, train loss 0.004, train accuracy 0.987, val loss 0.020, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 35, train loss 0.004, train accuracy 0.971, val loss 0.015, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 36, train loss 0.004, train accuracy 0.981, val loss 0.013, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 37, train loss 0.003, train accuracy 0.990, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 0.997, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 0.994, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 0.994, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 0.990, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.990, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 40\n",
            "Epoch 0, train loss 0.054, train accuracy 0.282, val loss 0.270, val accuracy 0.296, and val rmse 0.347\n",
            "Epoch 1, train loss 0.052, train accuracy 0.276, val loss 0.266, val accuracy 0.187, and val rmse 0.200\n",
            "Epoch 2, train loss 0.049, train accuracy 0.458, val loss 0.258, val accuracy 0.303, and val rmse 0.040\n",
            "Epoch 3, train loss 0.043, train accuracy 0.571, val loss 0.223, val accuracy 0.625, and val rmse 0.013\n",
            "Epoch 4, train loss 0.040, train accuracy 0.617, val loss 0.195, val accuracy 0.654, and val rmse 0.027\n",
            "Epoch 5, train loss 0.036, train accuracy 0.679, val loss 0.187, val accuracy 0.529, and val rmse 0.027\n",
            "Epoch 6, train loss 0.034, train accuracy 0.718, val loss 0.163, val accuracy 0.782, and val rmse 0.000\n",
            "Epoch 7, train loss 0.030, train accuracy 0.776, val loss 0.152, val accuracy 0.782, and val rmse 0.027\n",
            "Epoch 8, train loss 0.029, train accuracy 0.821, val loss 0.146, val accuracy 0.794, and val rmse 0.000\n",
            "Epoch 9, train loss 0.029, train accuracy 0.773, val loss 0.134, val accuracy 0.857, and val rmse 0.000\n",
            "Epoch 10, train loss 0.023, train accuracy 0.925, val loss 0.116, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 11, train loss 0.021, train accuracy 0.932, val loss 0.110, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 12, train loss 0.020, train accuracy 0.938, val loss 0.095, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 13, train loss 0.019, train accuracy 0.945, val loss 0.094, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 14, train loss 0.016, train accuracy 0.971, val loss 0.079, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 15, train loss 0.015, train accuracy 0.971, val loss 0.072, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 16, train loss 0.015, train accuracy 0.945, val loss 0.077, val accuracy 0.949, and val rmse 0.000\n",
            "Epoch 17, train loss 0.012, train accuracy 0.974, val loss 0.060, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 18, train loss 0.011, train accuracy 0.981, val loss 0.055, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 19, train loss 0.010, train accuracy 0.981, val loss 0.055, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 20, train loss 0.009, train accuracy 0.977, val loss 0.044, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 21, train loss 0.012, train accuracy 0.961, val loss 0.129, val accuracy 0.896, and val rmse 0.000\n",
            "Epoch 22, train loss 0.012, train accuracy 0.981, val loss 0.059, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 23, train loss 0.011, train accuracy 0.977, val loss 0.056, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 24, train loss 0.011, train accuracy 0.964, val loss 0.055, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 25, train loss 0.009, train accuracy 0.987, val loss 0.043, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 26, train loss 0.008, train accuracy 0.977, val loss 0.039, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 27, train loss 0.007, train accuracy 0.990, val loss 0.036, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 28, train loss 0.007, train accuracy 0.994, val loss 0.033, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 29, train loss 0.007, train accuracy 0.984, val loss 0.046, val accuracy 0.937, and val rmse 0.000\n",
            "Epoch 30, train loss 0.006, train accuracy 0.990, val loss 0.029, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 31, train loss 0.006, train accuracy 0.990, val loss 0.027, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 32, train loss 0.005, train accuracy 0.994, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.005, train accuracy 0.990, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.004, train accuracy 0.994, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.003, train accuracy 0.994, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.997, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.002, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 0.997, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.994, val loss 0.019, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 40, train loss 0.007, train accuracy 0.951, val loss 0.037, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.997, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 1.000, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 1.000, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.004, train accuracy 0.990, val loss 0.016, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 1.000, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 1.000, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.997, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.990, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 41\n",
            "Epoch 0, train loss 0.053, train accuracy 0.347, val loss 0.286, val accuracy 0.147, and val rmse 0.480\n",
            "Epoch 1, train loss 0.052, train accuracy 0.393, val loss 0.271, val accuracy 0.267, and val rmse 0.400\n",
            "Epoch 2, train loss 0.051, train accuracy 0.464, val loss 0.260, val accuracy 0.436, and val rmse 0.120\n",
            "Epoch 3, train loss 0.050, train accuracy 0.445, val loss 0.255, val accuracy 0.380, and val rmse 0.147\n",
            "Epoch 4, train loss 0.048, train accuracy 0.474, val loss 0.249, val accuracy 0.230, and val rmse 0.213\n",
            "Epoch 5, train loss 0.047, train accuracy 0.516, val loss 0.258, val accuracy 0.387, and val rmse 0.227\n",
            "Epoch 6, train loss 0.046, train accuracy 0.513, val loss 0.235, val accuracy 0.445, and val rmse 0.173\n",
            "Epoch 7, train loss 0.044, train accuracy 0.601, val loss 0.223, val accuracy 0.584, and val rmse 0.133\n",
            "Epoch 8, train loss 0.042, train accuracy 0.643, val loss 0.210, val accuracy 0.662, and val rmse 0.133\n",
            "Epoch 9, train loss 0.039, train accuracy 0.708, val loss 0.201, val accuracy 0.688, and val rmse 0.133\n",
            "Epoch 10, train loss 0.038, train accuracy 0.740, val loss 0.185, val accuracy 0.752, and val rmse 0.147\n",
            "Epoch 11, train loss 0.035, train accuracy 0.776, val loss 0.186, val accuracy 0.660, and val rmse 0.200\n",
            "Epoch 12, train loss 0.032, train accuracy 0.776, val loss 0.169, val accuracy 0.737, and val rmse 0.253\n",
            "Epoch 13, train loss 0.032, train accuracy 0.692, val loss 0.166, val accuracy 0.633, and val rmse 0.227\n",
            "Epoch 14, train loss 0.028, train accuracy 0.834, val loss 0.145, val accuracy 0.856, and val rmse 0.107\n",
            "Epoch 15, train loss 0.025, train accuracy 0.883, val loss 0.130, val accuracy 0.831, and val rmse 0.107\n",
            "Epoch 16, train loss 0.023, train accuracy 0.912, val loss 0.118, val accuracy 0.908, and val rmse 0.107\n",
            "Epoch 17, train loss 0.021, train accuracy 0.899, val loss 0.098, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 18, train loss 0.018, train accuracy 0.945, val loss 0.091, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 19, train loss 0.016, train accuracy 0.958, val loss 0.082, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 20, train loss 0.015, train accuracy 0.951, val loss 0.071, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 21, train loss 0.013, train accuracy 0.968, val loss 0.061, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 22, train loss 0.012, train accuracy 0.971, val loss 0.063, val accuracy 0.974, and val rmse 0.027\n",
            "Epoch 23, train loss 0.010, train accuracy 0.981, val loss 0.052, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 24, train loss 0.009, train accuracy 0.984, val loss 0.046, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.008, train accuracy 0.990, val loss 0.037, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.007, train accuracy 0.990, val loss 0.033, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.006, train accuracy 0.994, val loss 0.027, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.006, train accuracy 0.987, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.006, train accuracy 0.990, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.004, train accuracy 0.990, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.004, train accuracy 0.987, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.004, train accuracy 0.994, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.005, train accuracy 0.981, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.003, train accuracy 1.000, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.003, train accuracy 0.987, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.002, train accuracy 0.997, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.997, val loss 0.032, val accuracy 0.925, and val rmse 0.000\n",
            "Epoch 41, train loss 0.002, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.990, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 0.994, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.994, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.997, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 42\n",
            "Epoch 0, train loss 0.054, train accuracy 0.282, val loss 0.273, val accuracy 0.184, and val rmse 0.400\n",
            "Epoch 1, train loss 0.051, train accuracy 0.409, val loss 0.268, val accuracy 0.237, and val rmse 0.360\n",
            "Epoch 2, train loss 0.050, train accuracy 0.500, val loss 0.258, val accuracy 0.468, and val rmse 0.280\n",
            "Epoch 3, train loss 0.047, train accuracy 0.545, val loss 0.250, val accuracy 0.481, and val rmse 0.213\n",
            "Epoch 4, train loss 0.047, train accuracy 0.497, val loss 0.238, val accuracy 0.398, and val rmse 0.107\n",
            "Epoch 5, train loss 0.044, train accuracy 0.513, val loss 0.233, val accuracy 0.436, and val rmse 0.053\n",
            "Epoch 6, train loss 0.043, train accuracy 0.481, val loss 0.233, val accuracy 0.400, and val rmse 0.027\n",
            "Epoch 7, train loss 0.042, train accuracy 0.494, val loss 0.209, val accuracy 0.478, and val rmse 0.013\n",
            "Epoch 8, train loss 0.042, train accuracy 0.438, val loss 0.218, val accuracy 0.439, and val rmse 0.013\n",
            "Epoch 9, train loss 0.040, train accuracy 0.464, val loss 0.202, val accuracy 0.478, and val rmse 0.013\n",
            "Epoch 10, train loss 0.038, train accuracy 0.523, val loss 0.191, val accuracy 0.464, and val rmse 0.013\n",
            "Epoch 11, train loss 0.038, train accuracy 0.578, val loss 0.194, val accuracy 0.525, and val rmse 0.027\n",
            "Epoch 12, train loss 0.038, train accuracy 0.601, val loss 0.205, val accuracy 0.453, and val rmse 0.027\n",
            "Epoch 13, train loss 0.035, train accuracy 0.610, val loss 0.192, val accuracy 0.475, and val rmse 0.027\n",
            "Epoch 14, train loss 0.033, train accuracy 0.727, val loss 0.169, val accuracy 0.653, and val rmse 0.027\n",
            "Epoch 15, train loss 0.032, train accuracy 0.760, val loss 0.163, val accuracy 0.703, and val rmse 0.000\n",
            "Epoch 16, train loss 0.032, train accuracy 0.708, val loss 0.163, val accuracy 0.668, and val rmse 0.027\n",
            "Epoch 17, train loss 0.030, train accuracy 0.769, val loss 0.150, val accuracy 0.705, and val rmse 0.000\n",
            "Epoch 18, train loss 0.030, train accuracy 0.744, val loss 0.143, val accuracy 0.756, and val rmse 0.000\n",
            "Epoch 19, train loss 0.027, train accuracy 0.789, val loss 0.138, val accuracy 0.744, and val rmse 0.000\n",
            "Epoch 20, train loss 0.027, train accuracy 0.789, val loss 0.130, val accuracy 0.795, and val rmse 0.000\n",
            "Epoch 21, train loss 0.025, train accuracy 0.838, val loss 0.127, val accuracy 0.782, and val rmse 0.000\n",
            "Epoch 22, train loss 0.023, train accuracy 0.877, val loss 0.118, val accuracy 0.870, and val rmse 0.000\n",
            "Epoch 23, train loss 0.024, train accuracy 0.834, val loss 0.121, val accuracy 0.795, and val rmse 0.000\n",
            "Epoch 24, train loss 0.023, train accuracy 0.877, val loss 0.122, val accuracy 0.783, and val rmse 0.000\n",
            "Epoch 25, train loss 0.022, train accuracy 0.857, val loss 0.112, val accuracy 0.821, and val rmse 0.000\n",
            "Epoch 26, train loss 0.020, train accuracy 0.909, val loss 0.104, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 27, train loss 0.020, train accuracy 0.893, val loss 0.103, val accuracy 0.848, and val rmse 0.000\n",
            "Epoch 28, train loss 0.018, train accuracy 0.925, val loss 0.091, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 29, train loss 0.018, train accuracy 0.912, val loss 0.102, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 30, train loss 0.017, train accuracy 0.909, val loss 0.094, val accuracy 0.895, and val rmse 0.080\n",
            "Epoch 31, train loss 0.017, train accuracy 0.916, val loss 0.082, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 32, train loss 0.016, train accuracy 0.925, val loss 0.082, val accuracy 0.910, and val rmse 0.000\n",
            "Epoch 33, train loss 0.015, train accuracy 0.935, val loss 0.123, val accuracy 0.798, and val rmse 0.000\n",
            "Epoch 34, train loss 0.014, train accuracy 0.932, val loss 0.069, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 35, train loss 0.014, train accuracy 0.929, val loss 0.068, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 36, train loss 0.014, train accuracy 0.935, val loss 0.076, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 37, train loss 0.013, train accuracy 0.935, val loss 0.060, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 38, train loss 0.013, train accuracy 0.948, val loss 0.122, val accuracy 0.798, and val rmse 0.000\n",
            "Epoch 39, train loss 0.015, train accuracy 0.929, val loss 0.077, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 40, train loss 0.012, train accuracy 0.945, val loss 0.064, val accuracy 0.898, and val rmse 0.000\n",
            "Epoch 41, train loss 0.011, train accuracy 0.961, val loss 0.054, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 42, train loss 0.010, train accuracy 0.968, val loss 0.051, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 43, train loss 0.009, train accuracy 0.981, val loss 0.045, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 44, train loss 0.008, train accuracy 0.987, val loss 0.042, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 45, train loss 0.010, train accuracy 0.958, val loss 0.050, val accuracy 0.924, and val rmse 0.000\n",
            "Epoch 46, train loss 0.008, train accuracy 0.981, val loss 0.058, val accuracy 0.950, and val rmse 0.000\n",
            "Epoch 47, train loss 0.035, train accuracy 0.708, val loss 0.254, val accuracy 0.463, and val rmse 0.187\n",
            "Epoch 48, train loss 0.021, train accuracy 0.769, val loss 0.098, val accuracy 0.827, and val rmse 0.213\n",
            "Epoch 49, train loss 0.019, train accuracy 0.808, val loss 0.093, val accuracy 0.853, and val rmse 0.187\n",
            "\n",
            " Iteration number : 43\n",
            "Epoch 0, train loss 0.056, train accuracy 0.295, val loss 0.272, val accuracy 0.163, and val rmse 0.467\n",
            "Epoch 1, train loss 0.052, train accuracy 0.308, val loss 0.264, val accuracy 0.270, and val rmse 0.400\n",
            "Epoch 2, train loss 0.052, train accuracy 0.367, val loss 0.273, val accuracy 0.283, and val rmse 0.400\n",
            "Epoch 3, train loss 0.050, train accuracy 0.412, val loss 0.259, val accuracy 0.308, and val rmse 0.400\n",
            "Epoch 4, train loss 0.048, train accuracy 0.455, val loss 0.243, val accuracy 0.538, and val rmse 0.267\n",
            "Epoch 5, train loss 0.046, train accuracy 0.497, val loss 0.240, val accuracy 0.323, and val rmse 0.240\n",
            "Epoch 6, train loss 0.042, train accuracy 0.571, val loss 0.224, val accuracy 0.646, and val rmse 0.000\n",
            "Epoch 7, train loss 0.040, train accuracy 0.545, val loss 0.215, val accuracy 0.558, and val rmse 0.133\n",
            "Epoch 8, train loss 0.037, train accuracy 0.646, val loss 0.201, val accuracy 0.633, and val rmse 0.080\n",
            "Epoch 9, train loss 0.036, train accuracy 0.623, val loss 0.174, val accuracy 0.748, and val rmse 0.080\n",
            "Epoch 10, train loss 0.033, train accuracy 0.724, val loss 0.172, val accuracy 0.699, and val rmse 0.053\n",
            "Epoch 11, train loss 0.031, train accuracy 0.760, val loss 0.162, val accuracy 0.726, and val rmse 0.053\n",
            "Epoch 12, train loss 0.030, train accuracy 0.734, val loss 0.152, val accuracy 0.739, and val rmse 0.027\n",
            "Epoch 13, train loss 0.028, train accuracy 0.750, val loss 0.146, val accuracy 0.686, and val rmse 0.187\n",
            "Epoch 14, train loss 0.027, train accuracy 0.734, val loss 0.135, val accuracy 0.763, and val rmse 0.133\n",
            "Epoch 15, train loss 0.025, train accuracy 0.799, val loss 0.124, val accuracy 0.778, and val rmse 0.053\n",
            "Epoch 16, train loss 0.023, train accuracy 0.792, val loss 0.116, val accuracy 0.752, and val rmse 0.053\n",
            "Epoch 17, train loss 0.021, train accuracy 0.828, val loss 0.111, val accuracy 0.778, and val rmse 0.053\n",
            "Epoch 18, train loss 0.024, train accuracy 0.831, val loss 0.160, val accuracy 0.591, and val rmse 0.080\n",
            "Epoch 19, train loss 0.022, train accuracy 0.864, val loss 0.115, val accuracy 0.803, and val rmse 0.080\n",
            "Epoch 20, train loss 0.020, train accuracy 0.906, val loss 0.126, val accuracy 0.768, and val rmse 0.053\n",
            "Epoch 21, train loss 0.019, train accuracy 0.932, val loss 0.091, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 22, train loss 0.017, train accuracy 0.916, val loss 0.085, val accuracy 0.908, and val rmse 0.000\n",
            "Epoch 23, train loss 0.017, train accuracy 0.873, val loss 0.074, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 24, train loss 0.015, train accuracy 0.958, val loss 0.243, val accuracy 0.787, and val rmse 0.000\n",
            "Epoch 25, train loss 0.013, train accuracy 0.977, val loss 0.064, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 26, train loss 0.011, train accuracy 0.974, val loss 0.053, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 27, train loss 0.010, train accuracy 0.984, val loss 0.050, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 28, train loss 0.009, train accuracy 0.990, val loss 0.046, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.008, train accuracy 0.987, val loss 0.039, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.008, train accuracy 0.981, val loss 0.035, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.007, train accuracy 0.987, val loss 0.036, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.006, train accuracy 1.000, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.006, train accuracy 0.990, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 1.000, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.997, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.994, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.994, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 1.000, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.004, train accuracy 0.990, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.004, train accuracy 0.990, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.004, train accuracy 0.990, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.981, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 1.000, val loss 0.014, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.997, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.984, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.990, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 44\n",
            "Epoch 0, train loss 0.054, train accuracy 0.247, val loss 0.287, val accuracy 0.050, and val rmse 0.413\n",
            "Epoch 1, train loss 0.051, train accuracy 0.263, val loss 0.263, val accuracy 0.130, and val rmse 0.360\n",
            "Epoch 2, train loss 0.047, train accuracy 0.422, val loss 0.254, val accuracy 0.290, and val rmse 0.240\n",
            "Epoch 3, train loss 0.043, train accuracy 0.601, val loss 0.230, val accuracy 0.610, and val rmse 0.053\n",
            "Epoch 4, train loss 0.039, train accuracy 0.594, val loss 0.210, val accuracy 0.558, and val rmse 0.107\n",
            "Epoch 5, train loss 0.035, train accuracy 0.620, val loss 0.172, val accuracy 0.569, and val rmse 0.240\n",
            "Epoch 6, train loss 0.032, train accuracy 0.649, val loss 0.168, val accuracy 0.557, and val rmse 0.187\n",
            "Epoch 7, train loss 0.028, train accuracy 0.649, val loss 0.146, val accuracy 0.579, and val rmse 0.240\n",
            "Epoch 8, train loss 0.027, train accuracy 0.669, val loss 0.133, val accuracy 0.655, and val rmse 0.240\n",
            "Epoch 9, train loss 0.025, train accuracy 0.675, val loss 0.124, val accuracy 0.642, and val rmse 0.240\n",
            "Epoch 10, train loss 0.023, train accuracy 0.688, val loss 0.118, val accuracy 0.667, and val rmse 0.240\n",
            "Epoch 11, train loss 0.024, train accuracy 0.675, val loss 0.135, val accuracy 0.761, and val rmse 0.053\n",
            "Epoch 12, train loss 0.021, train accuracy 0.773, val loss 0.114, val accuracy 0.685, and val rmse 0.080\n",
            "Epoch 13, train loss 0.019, train accuracy 0.795, val loss 0.106, val accuracy 0.751, and val rmse 0.027\n",
            "Epoch 14, train loss 0.016, train accuracy 0.818, val loss 0.077, val accuracy 0.881, and val rmse 0.080\n",
            "Epoch 15, train loss 0.014, train accuracy 0.886, val loss 0.069, val accuracy 0.893, and val rmse 0.080\n",
            "Epoch 16, train loss 0.013, train accuracy 0.899, val loss 0.061, val accuracy 0.947, and val rmse 0.053\n",
            "Epoch 17, train loss 0.011, train accuracy 0.932, val loss 0.056, val accuracy 0.960, and val rmse 0.053\n",
            "Epoch 18, train loss 0.014, train accuracy 0.916, val loss 0.124, val accuracy 0.760, and val rmse 0.053\n",
            "Epoch 19, train loss 0.011, train accuracy 0.955, val loss 0.059, val accuracy 0.960, and val rmse 0.053\n",
            "Epoch 20, train loss 0.009, train accuracy 0.968, val loss 0.048, val accuracy 0.960, and val rmse 0.053\n",
            "Epoch 21, train loss 0.008, train accuracy 0.968, val loss 0.044, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 22, train loss 0.007, train accuracy 0.968, val loss 0.038, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 23, train loss 0.007, train accuracy 0.968, val loss 0.034, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 24, train loss 0.006, train accuracy 0.974, val loss 0.031, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 25, train loss 0.006, train accuracy 0.961, val loss 0.029, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 26, train loss 0.005, train accuracy 0.977, val loss 0.025, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 27, train loss 0.004, train accuracy 0.984, val loss 0.020, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 28, train loss 0.004, train accuracy 0.981, val loss 0.019, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 29, train loss 0.004, train accuracy 0.977, val loss 0.016, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 30, train loss 0.003, train accuracy 0.987, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.002, train accuracy 0.994, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.002, train accuracy 0.990, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.002, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.001, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.002, train accuracy 0.994, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.984, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.994, val loss 0.021, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 0.994, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 45\n",
            "Epoch 0, train loss 0.055, train accuracy 0.250, val loss 0.274, val accuracy 0.075, and val rmse 0.600\n",
            "Epoch 1, train loss 0.052, train accuracy 0.347, val loss 0.269, val accuracy 0.183, and val rmse 0.360\n",
            "Epoch 2, train loss 0.051, train accuracy 0.419, val loss 0.258, val accuracy 0.372, and val rmse 0.307\n",
            "Epoch 3, train loss 0.050, train accuracy 0.409, val loss 0.255, val accuracy 0.399, and val rmse 0.187\n",
            "Epoch 4, train loss 0.049, train accuracy 0.367, val loss 0.269, val accuracy 0.225, and val rmse 0.173\n",
            "Epoch 5, train loss 0.047, train accuracy 0.442, val loss 0.261, val accuracy 0.425, and val rmse 0.053\n",
            "Epoch 6, train loss 0.046, train accuracy 0.477, val loss 0.243, val accuracy 0.465, and val rmse 0.053\n",
            "Epoch 7, train loss 0.043, train accuracy 0.490, val loss 0.228, val accuracy 0.503, and val rmse 0.067\n",
            "Epoch 8, train loss 0.043, train accuracy 0.500, val loss 0.220, val accuracy 0.531, and val rmse 0.040\n",
            "Epoch 9, train loss 0.041, train accuracy 0.519, val loss 0.208, val accuracy 0.557, and val rmse 0.040\n",
            "Epoch 10, train loss 0.040, train accuracy 0.529, val loss 0.200, val accuracy 0.556, and val rmse 0.040\n",
            "Epoch 11, train loss 0.037, train accuracy 0.562, val loss 0.198, val accuracy 0.476, and val rmse 0.147\n",
            "Epoch 12, train loss 0.035, train accuracy 0.581, val loss 0.184, val accuracy 0.539, and val rmse 0.120\n",
            "Epoch 13, train loss 0.033, train accuracy 0.623, val loss 0.168, val accuracy 0.515, and val rmse 0.093\n",
            "Epoch 14, train loss 0.031, train accuracy 0.718, val loss 0.154, val accuracy 0.630, and val rmse 0.027\n",
            "Epoch 15, train loss 0.034, train accuracy 0.666, val loss 0.168, val accuracy 0.616, and val rmse 0.000\n",
            "Epoch 16, train loss 0.034, train accuracy 0.656, val loss 0.170, val accuracy 0.678, and val rmse 0.013\n",
            "Epoch 17, train loss 0.027, train accuracy 0.802, val loss 0.124, val accuracy 0.870, and val rmse 0.053\n",
            "Epoch 18, train loss 0.024, train accuracy 0.851, val loss 0.142, val accuracy 0.869, and val rmse 0.000\n",
            "Epoch 19, train loss 0.022, train accuracy 0.899, val loss 0.112, val accuracy 0.858, and val rmse 0.000\n",
            "Epoch 20, train loss 0.020, train accuracy 0.896, val loss 0.100, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 21, train loss 0.019, train accuracy 0.899, val loss 0.091, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 22, train loss 0.017, train accuracy 0.909, val loss 0.080, val accuracy 0.907, and val rmse 0.000\n",
            "Epoch 23, train loss 0.014, train accuracy 0.951, val loss 0.072, val accuracy 0.933, and val rmse 0.000\n",
            "Epoch 24, train loss 0.014, train accuracy 0.925, val loss 0.068, val accuracy 0.933, and val rmse 0.000\n",
            "Epoch 25, train loss 0.013, train accuracy 0.935, val loss 0.067, val accuracy 0.921, and val rmse 0.000\n",
            "Epoch 26, train loss 0.011, train accuracy 0.948, val loss 0.060, val accuracy 0.933, and val rmse 0.000\n",
            "Epoch 27, train loss 0.010, train accuracy 0.955, val loss 0.059, val accuracy 0.920, and val rmse 0.000\n",
            "Epoch 28, train loss 0.010, train accuracy 0.951, val loss 0.059, val accuracy 0.920, and val rmse 0.000\n",
            "Epoch 29, train loss 0.009, train accuracy 0.968, val loss 0.050, val accuracy 0.947, and val rmse 0.000\n",
            "Epoch 30, train loss 0.009, train accuracy 0.971, val loss 0.042, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 31, train loss 0.007, train accuracy 0.977, val loss 0.034, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.007, train accuracy 0.974, val loss 0.040, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 33, train loss 0.006, train accuracy 0.981, val loss 0.029, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 0.990, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.007, train accuracy 0.968, val loss 0.029, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.005, train accuracy 0.990, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.987, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.004, train accuracy 0.994, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.997, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.990, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.004, train accuracy 0.984, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.004, train accuracy 0.977, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.997, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.990, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.003, train accuracy 0.987, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.987, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.984, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.987, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 46\n",
            "Epoch 0, train loss 0.053, train accuracy 0.224, val loss 0.272, val accuracy 0.280, and val rmse 0.000\n",
            "Epoch 1, train loss 0.050, train accuracy 0.432, val loss 0.267, val accuracy 0.413, and val rmse 0.000\n",
            "Epoch 2, train loss 0.047, train accuracy 0.562, val loss 0.262, val accuracy 0.501, and val rmse 0.000\n",
            "Epoch 3, train loss 0.045, train accuracy 0.604, val loss 0.263, val accuracy 0.463, and val rmse 0.000\n",
            "Epoch 4, train loss 0.042, train accuracy 0.519, val loss 0.221, val accuracy 0.530, and val rmse 0.133\n",
            "Epoch 5, train loss 0.040, train accuracy 0.455, val loss 0.206, val accuracy 0.410, and val rmse 0.133\n",
            "Epoch 6, train loss 0.039, train accuracy 0.494, val loss 0.207, val accuracy 0.503, and val rmse 0.160\n",
            "Epoch 7, train loss 0.038, train accuracy 0.429, val loss 0.190, val accuracy 0.517, and val rmse 0.107\n",
            "Epoch 8, train loss 0.036, train accuracy 0.477, val loss 0.181, val accuracy 0.543, and val rmse 0.187\n",
            "Epoch 9, train loss 0.035, train accuracy 0.552, val loss 0.185, val accuracy 0.437, and val rmse 0.187\n",
            "Epoch 10, train loss 0.033, train accuracy 0.565, val loss 0.172, val accuracy 0.583, and val rmse 0.107\n",
            "Epoch 11, train loss 0.032, train accuracy 0.584, val loss 0.169, val accuracy 0.623, and val rmse 0.027\n",
            "Epoch 12, train loss 0.031, train accuracy 0.552, val loss 0.158, val accuracy 0.543, and val rmse 0.200\n",
            "Epoch 13, train loss 0.030, train accuracy 0.571, val loss 0.151, val accuracy 0.517, and val rmse 0.307\n",
            "Epoch 14, train loss 0.029, train accuracy 0.649, val loss 0.156, val accuracy 0.690, and val rmse 0.013\n",
            "Epoch 15, train loss 0.028, train accuracy 0.591, val loss 0.143, val accuracy 0.570, and val rmse 0.253\n",
            "Epoch 16, train loss 0.031, train accuracy 0.542, val loss 0.161, val accuracy 0.450, and val rmse 0.387\n",
            "Epoch 17, train loss 0.030, train accuracy 0.526, val loss 0.152, val accuracy 0.357, and val rmse 0.387\n",
            "Epoch 18, train loss 0.028, train accuracy 0.513, val loss 0.146, val accuracy 0.357, and val rmse 0.387\n",
            "Epoch 19, train loss 0.027, train accuracy 0.519, val loss 0.140, val accuracy 0.343, and val rmse 0.387\n",
            "Epoch 20, train loss 0.026, train accuracy 0.506, val loss 0.133, val accuracy 0.417, and val rmse 0.387\n",
            "Epoch 21, train loss 0.025, train accuracy 0.523, val loss 0.128, val accuracy 0.317, and val rmse 0.387\n",
            "Epoch 22, train loss 0.024, train accuracy 0.539, val loss 0.123, val accuracy 0.330, and val rmse 0.387\n",
            "Epoch 23, train loss 0.023, train accuracy 0.549, val loss 0.117, val accuracy 0.357, and val rmse 0.387\n",
            "Epoch 24, train loss 0.022, train accuracy 0.575, val loss 0.114, val accuracy 0.517, and val rmse 0.387\n",
            "Epoch 25, train loss 0.022, train accuracy 0.565, val loss 0.111, val accuracy 0.517, and val rmse 0.387\n",
            "Epoch 26, train loss 0.021, train accuracy 0.575, val loss 0.107, val accuracy 0.517, and val rmse 0.387\n",
            "Epoch 27, train loss 0.020, train accuracy 0.562, val loss 0.102, val accuracy 0.370, and val rmse 0.387\n",
            "Epoch 28, train loss 0.019, train accuracy 0.591, val loss 0.101, val accuracy 0.383, and val rmse 0.400\n",
            "Epoch 29, train loss 0.019, train accuracy 0.588, val loss 0.095, val accuracy 0.503, and val rmse 0.400\n",
            "Epoch 30, train loss 0.018, train accuracy 0.604, val loss 0.094, val accuracy 0.397, and val rmse 0.400\n",
            "Epoch 31, train loss 0.017, train accuracy 0.601, val loss 0.091, val accuracy 0.463, and val rmse 0.400\n",
            "Epoch 32, train loss 0.017, train accuracy 0.591, val loss 0.087, val accuracy 0.516, and val rmse 0.400\n",
            "Epoch 33, train loss 0.036, train accuracy 0.383, val loss 0.219, val accuracy 0.296, and val rmse 0.453\n",
            "Epoch 34, train loss 0.035, train accuracy 0.442, val loss 0.172, val accuracy 0.488, and val rmse 0.147\n",
            "Epoch 35, train loss 0.034, train accuracy 0.497, val loss 0.175, val accuracy 0.369, and val rmse 0.453\n",
            "Epoch 36, train loss 0.033, train accuracy 0.513, val loss 0.172, val accuracy 0.516, and val rmse 0.000\n",
            "Epoch 37, train loss 0.031, train accuracy 0.627, val loss 0.165, val accuracy 0.542, and val rmse 0.067\n",
            "Epoch 38, train loss 0.030, train accuracy 0.688, val loss 0.162, val accuracy 0.565, and val rmse 0.040\n",
            "Epoch 39, train loss 0.030, train accuracy 0.633, val loss 0.160, val accuracy 0.591, and val rmse 0.000\n",
            "Epoch 40, train loss 0.026, train accuracy 0.734, val loss 0.137, val accuracy 0.668, and val rmse 0.000\n",
            "Epoch 41, train loss 0.025, train accuracy 0.753, val loss 0.131, val accuracy 0.694, and val rmse 0.000\n",
            "Epoch 42, train loss 0.025, train accuracy 0.789, val loss 0.132, val accuracy 0.784, and val rmse 0.000\n",
            "Epoch 43, train loss 0.022, train accuracy 0.864, val loss 0.111, val accuracy 0.900, and val rmse 0.000\n",
            "Epoch 44, train loss 0.020, train accuracy 0.916, val loss 0.098, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 45, train loss 0.019, train accuracy 0.951, val loss 0.089, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 46, train loss 0.017, train accuracy 0.951, val loss 0.082, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 47, train loss 0.015, train accuracy 0.990, val loss 0.076, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.014, train accuracy 0.974, val loss 0.083, val accuracy 0.925, and val rmse 0.000\n",
            "Epoch 49, train loss 0.012, train accuracy 0.984, val loss 0.065, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 47\n",
            "Epoch 0, train loss 0.053, train accuracy 0.282, val loss 0.260, val accuracy 0.126, and val rmse 0.413\n",
            "Epoch 1, train loss 0.051, train accuracy 0.360, val loss 0.288, val accuracy 0.106, and val rmse 0.253\n",
            "Epoch 2, train loss 0.049, train accuracy 0.338, val loss 0.270, val accuracy 0.133, and val rmse 0.400\n",
            "Epoch 3, train loss 0.047, train accuracy 0.481, val loss 0.248, val accuracy 0.422, and val rmse 0.080\n",
            "Epoch 4, train loss 0.046, train accuracy 0.380, val loss 0.235, val accuracy 0.400, and val rmse 0.000\n",
            "Epoch 5, train loss 0.044, train accuracy 0.416, val loss 0.230, val accuracy 0.427, and val rmse 0.013\n",
            "Epoch 6, train loss 0.042, train accuracy 0.438, val loss 0.219, val accuracy 0.440, and val rmse 0.027\n",
            "Epoch 7, train loss 0.040, train accuracy 0.484, val loss 0.201, val accuracy 0.413, and val rmse 0.080\n",
            "Epoch 8, train loss 0.040, train accuracy 0.364, val loss 0.193, val accuracy 0.453, and val rmse 0.027\n",
            "Epoch 9, train loss 0.036, train accuracy 0.532, val loss 0.185, val accuracy 0.453, and val rmse 0.027\n",
            "Epoch 10, train loss 0.034, train accuracy 0.542, val loss 0.176, val accuracy 0.448, and val rmse 0.160\n",
            "Epoch 11, train loss 0.032, train accuracy 0.659, val loss 0.160, val accuracy 0.651, and val rmse 0.080\n",
            "Epoch 12, train loss 0.030, train accuracy 0.662, val loss 0.152, val accuracy 0.613, and val rmse 0.080\n",
            "Epoch 13, train loss 0.028, train accuracy 0.640, val loss 0.160, val accuracy 0.391, and val rmse 0.400\n",
            "Epoch 14, train loss 0.027, train accuracy 0.558, val loss 0.133, val accuracy 0.520, and val rmse 0.400\n",
            "Epoch 15, train loss 0.025, train accuracy 0.597, val loss 0.124, val accuracy 0.528, and val rmse 0.347\n",
            "Epoch 16, train loss 0.024, train accuracy 0.633, val loss 0.117, val accuracy 0.662, and val rmse 0.080\n",
            "Epoch 17, train loss 0.022, train accuracy 0.646, val loss 0.111, val accuracy 0.648, and val rmse 0.107\n",
            "Epoch 18, train loss 0.023, train accuracy 0.591, val loss 0.111, val accuracy 0.648, and val rmse 0.133\n",
            "Epoch 19, train loss 0.021, train accuracy 0.698, val loss 0.106, val accuracy 0.647, and val rmse 0.107\n",
            "Epoch 20, train loss 0.021, train accuracy 0.666, val loss 0.102, val accuracy 0.634, and val rmse 0.133\n",
            "Epoch 21, train loss 0.019, train accuracy 0.682, val loss 0.099, val accuracy 0.647, and val rmse 0.107\n",
            "Epoch 22, train loss 0.019, train accuracy 0.721, val loss 0.095, val accuracy 0.647, and val rmse 0.080\n",
            "Epoch 23, train loss 0.018, train accuracy 0.737, val loss 0.093, val accuracy 0.712, and val rmse 0.080\n",
            "Epoch 24, train loss 0.017, train accuracy 0.744, val loss 0.090, val accuracy 0.711, and val rmse 0.107\n",
            "Epoch 25, train loss 0.016, train accuracy 0.805, val loss 0.087, val accuracy 0.737, and val rmse 0.080\n",
            "Epoch 26, train loss 0.016, train accuracy 0.795, val loss 0.080, val accuracy 0.763, and val rmse 0.080\n",
            "Epoch 27, train loss 0.015, train accuracy 0.812, val loss 0.081, val accuracy 0.788, and val rmse 0.080\n",
            "Epoch 28, train loss 0.014, train accuracy 0.838, val loss 0.070, val accuracy 0.841, and val rmse 0.080\n",
            "Epoch 29, train loss 0.013, train accuracy 0.857, val loss 0.066, val accuracy 0.854, and val rmse 0.053\n",
            "Epoch 30, train loss 0.013, train accuracy 0.870, val loss 0.066, val accuracy 0.868, and val rmse 0.053\n",
            "Epoch 31, train loss 0.013, train accuracy 0.886, val loss 0.071, val accuracy 0.857, and val rmse 0.053\n",
            "Epoch 32, train loss 0.012, train accuracy 0.877, val loss 0.057, val accuracy 0.907, and val rmse 0.053\n",
            "Epoch 33, train loss 0.011, train accuracy 0.877, val loss 0.051, val accuracy 0.907, and val rmse 0.053\n",
            "Epoch 34, train loss 0.010, train accuracy 0.890, val loss 0.048, val accuracy 0.921, and val rmse 0.027\n",
            "Epoch 35, train loss 0.011, train accuracy 0.903, val loss 0.052, val accuracy 0.921, and val rmse 0.027\n",
            "Epoch 36, train loss 0.009, train accuracy 0.912, val loss 0.042, val accuracy 0.921, and val rmse 0.027\n",
            "Epoch 37, train loss 0.009, train accuracy 0.893, val loss 0.040, val accuracy 0.921, and val rmse 0.027\n",
            "Epoch 38, train loss 0.008, train accuracy 0.916, val loss 0.037, val accuracy 0.921, and val rmse 0.027\n",
            "Epoch 39, train loss 0.008, train accuracy 0.909, val loss 0.033, val accuracy 0.921, and val rmse 0.027\n",
            "Epoch 40, train loss 0.007, train accuracy 0.909, val loss 0.030, val accuracy 0.921, and val rmse 0.027\n",
            "Epoch 41, train loss 0.006, train accuracy 0.909, val loss 0.028, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 42, train loss 0.006, train accuracy 0.942, val loss 0.026, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 43, train loss 0.005, train accuracy 0.961, val loss 0.024, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 44, train loss 0.005, train accuracy 0.971, val loss 0.023, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 45, train loss 0.004, train accuracy 0.984, val loss 0.019, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 46, train loss 0.004, train accuracy 0.968, val loss 0.018, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 47, train loss 0.005, train accuracy 0.955, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.990, val loss 0.024, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 49, train loss 0.004, train accuracy 0.984, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 48\n",
            "Epoch 0, train loss 0.056, train accuracy 0.273, val loss 0.289, val accuracy 0.163, and val rmse 0.533\n",
            "Epoch 1, train loss 0.052, train accuracy 0.357, val loss 0.287, val accuracy 0.170, and val rmse 0.280\n",
            "Epoch 2, train loss 0.050, train accuracy 0.386, val loss 0.261, val accuracy 0.272, and val rmse 0.240\n",
            "Epoch 3, train loss 0.048, train accuracy 0.503, val loss 0.257, val accuracy 0.292, and val rmse 0.160\n",
            "Epoch 4, train loss 0.045, train accuracy 0.575, val loss 0.237, val accuracy 0.344, and val rmse 0.093\n",
            "Epoch 5, train loss 0.043, train accuracy 0.565, val loss 0.238, val accuracy 0.435, and val rmse 0.067\n",
            "Epoch 6, train loss 0.039, train accuracy 0.711, val loss 0.204, val accuracy 0.602, and val rmse 0.027\n",
            "Epoch 7, train loss 0.035, train accuracy 0.792, val loss 0.200, val accuracy 0.625, and val rmse 0.013\n",
            "Epoch 8, train loss 0.031, train accuracy 0.847, val loss 0.153, val accuracy 0.859, and val rmse 0.000\n",
            "Epoch 9, train loss 0.028, train accuracy 0.883, val loss 0.137, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 10, train loss 0.025, train accuracy 0.886, val loss 0.132, val accuracy 0.922, and val rmse 0.000\n",
            "Epoch 11, train loss 0.022, train accuracy 0.890, val loss 0.105, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 12, train loss 0.019, train accuracy 0.935, val loss 0.098, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 13, train loss 0.017, train accuracy 0.964, val loss 0.089, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 14, train loss 0.015, train accuracy 0.974, val loss 0.073, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 15, train loss 0.013, train accuracy 0.981, val loss 0.070, val accuracy 0.949, and val rmse 0.000\n",
            "Epoch 16, train loss 0.012, train accuracy 0.968, val loss 0.078, val accuracy 0.938, and val rmse 0.000\n",
            "Epoch 17, train loss 0.010, train accuracy 0.981, val loss 0.049, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 18, train loss 0.010, train accuracy 0.984, val loss 0.044, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 19, train loss 0.008, train accuracy 0.987, val loss 0.038, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 20, train loss 0.008, train accuracy 0.984, val loss 0.031, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 21, train loss 0.007, train accuracy 0.981, val loss 0.027, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 22, train loss 0.005, train accuracy 0.997, val loss 0.029, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 23, train loss 0.005, train accuracy 0.994, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.004, train accuracy 1.000, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.004, train accuracy 1.000, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.003, train accuracy 1.000, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.004, train accuracy 0.987, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.003, train accuracy 1.000, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.003, train accuracy 0.997, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.002, train accuracy 0.997, val loss 0.019, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 34, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.984, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.001, train accuracy 0.997, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 0.997, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.997, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 49\n",
            "Epoch 0, train loss 0.054, train accuracy 0.263, val loss 0.282, val accuracy 0.193, and val rmse 0.373\n",
            "Epoch 1, train loss 0.053, train accuracy 0.325, val loss 0.280, val accuracy 0.027, and val rmse 0.400\n",
            "Epoch 2, train loss 0.052, train accuracy 0.289, val loss 0.262, val accuracy 0.267, and val rmse 0.080\n",
            "Epoch 3, train loss 0.050, train accuracy 0.390, val loss 0.253, val accuracy 0.372, and val rmse 0.053\n",
            "Epoch 4, train loss 0.047, train accuracy 0.438, val loss 0.241, val accuracy 0.380, and val rmse 0.147\n",
            "Epoch 5, train loss 0.045, train accuracy 0.500, val loss 0.237, val accuracy 0.438, and val rmse 0.080\n",
            "Epoch 6, train loss 0.042, train accuracy 0.591, val loss 0.215, val accuracy 0.550, and val rmse 0.013\n",
            "Epoch 7, train loss 0.039, train accuracy 0.630, val loss 0.191, val accuracy 0.628, and val rmse 0.000\n",
            "Epoch 8, train loss 0.036, train accuracy 0.682, val loss 0.186, val accuracy 0.603, and val rmse 0.000\n",
            "Epoch 9, train loss 0.033, train accuracy 0.692, val loss 0.163, val accuracy 0.678, and val rmse 0.000\n",
            "Epoch 10, train loss 0.031, train accuracy 0.662, val loss 0.154, val accuracy 0.678, and val rmse 0.000\n",
            "Epoch 11, train loss 0.030, train accuracy 0.740, val loss 0.152, val accuracy 0.626, and val rmse 0.053\n",
            "Epoch 12, train loss 0.027, train accuracy 0.799, val loss 0.132, val accuracy 0.768, and val rmse 0.053\n",
            "Epoch 13, train loss 0.025, train accuracy 0.789, val loss 0.125, val accuracy 0.757, and val rmse 0.053\n",
            "Epoch 14, train loss 0.022, train accuracy 0.825, val loss 0.111, val accuracy 0.805, and val rmse 0.107\n",
            "Epoch 15, train loss 0.022, train accuracy 0.805, val loss 0.108, val accuracy 0.832, and val rmse 0.080\n",
            "Epoch 16, train loss 0.019, train accuracy 0.834, val loss 0.094, val accuracy 0.895, and val rmse 0.053\n",
            "Epoch 17, train loss 0.018, train accuracy 0.864, val loss 0.087, val accuracy 0.922, and val rmse 0.053\n",
            "Epoch 18, train loss 0.016, train accuracy 0.870, val loss 0.078, val accuracy 0.935, and val rmse 0.053\n",
            "Epoch 19, train loss 0.015, train accuracy 0.877, val loss 0.073, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 20, train loss 0.014, train accuracy 0.919, val loss 0.067, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 21, train loss 0.013, train accuracy 0.935, val loss 0.061, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 22, train loss 0.012, train accuracy 0.948, val loss 0.057, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 23, train loss 0.011, train accuracy 0.951, val loss 0.053, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 24, train loss 0.010, train accuracy 0.942, val loss 0.048, val accuracy 0.962, and val rmse 0.027\n",
            "Epoch 25, train loss 0.009, train accuracy 0.971, val loss 0.047, val accuracy 0.962, and val rmse 0.027\n",
            "Epoch 26, train loss 0.009, train accuracy 0.961, val loss 0.041, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 27, train loss 0.010, train accuracy 0.929, val loss 0.048, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 28, train loss 0.008, train accuracy 0.955, val loss 0.038, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 29, train loss 0.007, train accuracy 0.961, val loss 0.036, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 30, train loss 0.007, train accuracy 0.964, val loss 0.031, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 31, train loss 0.006, train accuracy 0.984, val loss 0.029, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 32, train loss 0.006, train accuracy 0.990, val loss 0.027, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 33, train loss 0.006, train accuracy 0.977, val loss 0.025, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 0.977, val loss 0.024, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 35, train loss 0.005, train accuracy 0.981, val loss 0.024, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 36, train loss 0.005, train accuracy 0.964, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.984, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.006, train accuracy 0.981, val loss 0.029, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.987, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.997, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.990, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.997, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.994, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.997, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.990, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.994, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 50\n",
            "Epoch 0, train loss 0.053, train accuracy 0.289, val loss 0.284, val accuracy 0.133, and val rmse 0.400\n",
            "Epoch 1, train loss 0.051, train accuracy 0.396, val loss 0.256, val accuracy 0.378, and val rmse 0.240\n",
            "Epoch 2, train loss 0.049, train accuracy 0.549, val loss 0.258, val accuracy 0.173, and val rmse 0.213\n",
            "Epoch 3, train loss 0.043, train accuracy 0.640, val loss 0.233, val accuracy 0.435, and val rmse 0.053\n",
            "Epoch 4, train loss 0.039, train accuracy 0.643, val loss 0.196, val accuracy 0.677, and val rmse 0.040\n",
            "Epoch 5, train loss 0.035, train accuracy 0.669, val loss 0.181, val accuracy 0.677, and val rmse 0.053\n",
            "Epoch 6, train loss 0.033, train accuracy 0.695, val loss 0.169, val accuracy 0.714, and val rmse 0.053\n",
            "Epoch 7, train loss 0.030, train accuracy 0.724, val loss 0.156, val accuracy 0.728, and val rmse 0.040\n",
            "Epoch 8, train loss 0.029, train accuracy 0.727, val loss 0.145, val accuracy 0.793, and val rmse 0.053\n",
            "Epoch 9, train loss 0.027, train accuracy 0.731, val loss 0.136, val accuracy 0.781, and val rmse 0.053\n",
            "Epoch 10, train loss 0.032, train accuracy 0.636, val loss 0.193, val accuracy 0.604, and val rmse 0.107\n",
            "Epoch 11, train loss 0.031, train accuracy 0.737, val loss 0.156, val accuracy 0.793, and val rmse 0.053\n",
            "Epoch 12, train loss 0.029, train accuracy 0.747, val loss 0.146, val accuracy 0.807, and val rmse 0.027\n",
            "Epoch 13, train loss 0.028, train accuracy 0.763, val loss 0.139, val accuracy 0.806, and val rmse 0.027\n",
            "Epoch 14, train loss 0.027, train accuracy 0.815, val loss 0.131, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 15, train loss 0.026, train accuracy 0.841, val loss 0.124, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 16, train loss 0.024, train accuracy 0.831, val loss 0.127, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 17, train loss 0.023, train accuracy 0.795, val loss 0.112, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 18, train loss 0.021, train accuracy 0.857, val loss 0.108, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 19, train loss 0.020, train accuracy 0.860, val loss 0.105, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 20, train loss 0.019, train accuracy 0.844, val loss 0.096, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 21, train loss 0.018, train accuracy 0.825, val loss 0.094, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 22, train loss 0.015, train accuracy 0.834, val loss 0.074, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 23, train loss 0.014, train accuracy 0.844, val loss 0.070, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 24, train loss 0.015, train accuracy 0.851, val loss 0.081, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 25, train loss 0.013, train accuracy 0.857, val loss 0.064, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 26, train loss 0.015, train accuracy 0.834, val loss 0.188, val accuracy 0.672, and val rmse 0.000\n",
            "Epoch 27, train loss 0.012, train accuracy 0.860, val loss 0.059, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 28, train loss 0.012, train accuracy 0.841, val loss 0.058, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 29, train loss 0.011, train accuracy 0.851, val loss 0.056, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 30, train loss 0.011, train accuracy 0.847, val loss 0.056, val accuracy 0.845, and val rmse 0.053\n",
            "Epoch 31, train loss 0.011, train accuracy 0.844, val loss 0.061, val accuracy 0.805, and val rmse 0.133\n",
            "Epoch 32, train loss 0.010, train accuracy 0.864, val loss 0.056, val accuracy 0.857, and val rmse 0.053\n",
            "Epoch 33, train loss 0.010, train accuracy 0.860, val loss 0.053, val accuracy 0.857, and val rmse 0.053\n",
            "Epoch 34, train loss 0.009, train accuracy 0.873, val loss 0.047, val accuracy 0.882, and val rmse 0.053\n",
            "Epoch 35, train loss 0.009, train accuracy 0.883, val loss 0.045, val accuracy 0.870, and val rmse 0.053\n",
            "Epoch 36, train loss 0.008, train accuracy 0.899, val loss 0.042, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 37, train loss 0.008, train accuracy 0.896, val loss 0.041, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 38, train loss 0.007, train accuracy 0.922, val loss 0.038, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 39, train loss 0.007, train accuracy 0.932, val loss 0.034, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 40, train loss 0.006, train accuracy 0.942, val loss 0.031, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 41, train loss 0.006, train accuracy 0.961, val loss 0.030, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 42, train loss 0.006, train accuracy 0.958, val loss 0.026, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 43, train loss 0.005, train accuracy 0.977, val loss 0.022, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 44, train loss 0.004, train accuracy 0.981, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.004, train accuracy 0.981, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.987, val loss 0.037, val accuracy 0.925, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.997, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.997, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 51\n",
            "Epoch 0, train loss 0.054, train accuracy 0.218, val loss 0.264, val accuracy 0.088, and val rmse 0.427\n",
            "Epoch 1, train loss 0.051, train accuracy 0.273, val loss 0.282, val accuracy 0.220, and val rmse 0.200\n",
            "Epoch 2, train loss 0.050, train accuracy 0.266, val loss 0.269, val accuracy 0.240, and val rmse 0.067\n",
            "Epoch 3, train loss 0.049, train accuracy 0.351, val loss 0.280, val accuracy 0.040, and val rmse 0.280\n",
            "Epoch 4, train loss 0.047, train accuracy 0.292, val loss 0.254, val accuracy 0.400, and val rmse 0.000\n",
            "Epoch 5, train loss 0.046, train accuracy 0.253, val loss 0.231, val accuracy 0.413, and val rmse 0.013\n",
            "Epoch 6, train loss 0.043, train accuracy 0.416, val loss 0.234, val accuracy 0.427, and val rmse 0.027\n",
            "Epoch 7, train loss 0.041, train accuracy 0.419, val loss 0.227, val accuracy 0.412, and val rmse 0.080\n",
            "Epoch 8, train loss 0.039, train accuracy 0.477, val loss 0.200, val accuracy 0.491, and val rmse 0.053\n",
            "Epoch 9, train loss 0.036, train accuracy 0.552, val loss 0.193, val accuracy 0.517, and val rmse 0.053\n",
            "Epoch 10, train loss 0.033, train accuracy 0.646, val loss 0.170, val accuracy 0.554, and val rmse 0.053\n",
            "Epoch 11, train loss 0.032, train accuracy 0.731, val loss 0.189, val accuracy 0.518, and val rmse 0.240\n",
            "Epoch 12, train loss 0.029, train accuracy 0.756, val loss 0.150, val accuracy 0.701, and val rmse 0.187\n",
            "Epoch 13, train loss 0.027, train accuracy 0.769, val loss 0.153, val accuracy 0.628, and val rmse 0.133\n",
            "Epoch 14, train loss 0.026, train accuracy 0.792, val loss 0.126, val accuracy 0.805, and val rmse 0.080\n",
            "Epoch 15, train loss 0.024, train accuracy 0.782, val loss 0.152, val accuracy 0.615, and val rmse 0.107\n",
            "Epoch 16, train loss 0.022, train accuracy 0.838, val loss 0.115, val accuracy 0.818, and val rmse 0.053\n",
            "Epoch 17, train loss 0.020, train accuracy 0.831, val loss 0.106, val accuracy 0.818, and val rmse 0.080\n",
            "Epoch 18, train loss 0.020, train accuracy 0.818, val loss 0.099, val accuracy 0.832, and val rmse 0.053\n",
            "Epoch 19, train loss 0.018, train accuracy 0.851, val loss 0.092, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 20, train loss 0.019, train accuracy 0.828, val loss 0.089, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 21, train loss 0.016, train accuracy 0.877, val loss 0.080, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 22, train loss 0.015, train accuracy 0.870, val loss 0.075, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 23, train loss 0.015, train accuracy 0.864, val loss 0.080, val accuracy 0.821, and val rmse 0.027\n",
            "Epoch 24, train loss 0.013, train accuracy 0.877, val loss 0.066, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 25, train loss 0.012, train accuracy 0.880, val loss 0.061, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 26, train loss 0.012, train accuracy 0.877, val loss 0.061, val accuracy 0.846, and val rmse 0.027\n",
            "Epoch 27, train loss 0.011, train accuracy 0.899, val loss 0.053, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 28, train loss 0.010, train accuracy 0.893, val loss 0.052, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 29, train loss 0.010, train accuracy 0.886, val loss 0.049, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 30, train loss 0.009, train accuracy 0.919, val loss 0.045, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 31, train loss 0.008, train accuracy 0.935, val loss 0.049, val accuracy 0.936, and val rmse 0.027\n",
            "Epoch 32, train loss 0.008, train accuracy 0.948, val loss 0.035, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 33, train loss 0.008, train accuracy 0.948, val loss 0.035, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 34, train loss 0.009, train accuracy 0.938, val loss 0.035, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 35, train loss 0.006, train accuracy 0.961, val loss 0.030, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 36, train loss 0.006, train accuracy 0.981, val loss 0.028, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 37, train loss 0.005, train accuracy 0.977, val loss 0.025, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 38, train loss 0.006, train accuracy 0.955, val loss 0.026, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 39, train loss 0.005, train accuracy 0.984, val loss 0.026, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 40, train loss 0.004, train accuracy 0.977, val loss 0.020, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 41, train loss 0.004, train accuracy 0.974, val loss 0.020, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 42, train loss 0.006, train accuracy 0.968, val loss 0.034, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.981, val loss 0.019, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 44, train loss 0.005, train accuracy 0.974, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.003, train accuracy 0.984, val loss 0.019, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.984, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.987, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.981, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.990, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 52\n",
            "Epoch 0, train loss 0.054, train accuracy 0.227, val loss 0.267, val accuracy 0.075, and val rmse 0.600\n",
            "Epoch 1, train loss 0.052, train accuracy 0.289, val loss 0.259, val accuracy 0.466, and val rmse 0.267\n",
            "Epoch 2, train loss 0.051, train accuracy 0.386, val loss 0.261, val accuracy 0.226, and val rmse 0.173\n",
            "Epoch 3, train loss 0.049, train accuracy 0.474, val loss 0.249, val accuracy 0.397, and val rmse 0.120\n",
            "Epoch 4, train loss 0.047, train accuracy 0.519, val loss 0.240, val accuracy 0.476, and val rmse 0.093\n",
            "Epoch 5, train loss 0.045, train accuracy 0.607, val loss 0.227, val accuracy 0.514, and val rmse 0.093\n",
            "Epoch 6, train loss 0.043, train accuracy 0.679, val loss 0.217, val accuracy 0.564, and val rmse 0.093\n",
            "Epoch 7, train loss 0.041, train accuracy 0.740, val loss 0.210, val accuracy 0.626, and val rmse 0.080\n",
            "Epoch 8, train loss 0.040, train accuracy 0.708, val loss 0.204, val accuracy 0.590, and val rmse 0.053\n",
            "Epoch 9, train loss 0.036, train accuracy 0.773, val loss 0.186, val accuracy 0.743, and val rmse 0.053\n",
            "Epoch 10, train loss 0.034, train accuracy 0.776, val loss 0.172, val accuracy 0.768, and val rmse 0.053\n",
            "Epoch 11, train loss 0.032, train accuracy 0.812, val loss 0.162, val accuracy 0.767, and val rmse 0.107\n",
            "Epoch 12, train loss 0.029, train accuracy 0.782, val loss 0.156, val accuracy 0.717, and val rmse 0.107\n",
            "Epoch 13, train loss 0.027, train accuracy 0.808, val loss 0.135, val accuracy 0.843, and val rmse 0.080\n",
            "Epoch 14, train loss 0.025, train accuracy 0.870, val loss 0.123, val accuracy 0.909, and val rmse 0.053\n",
            "Epoch 15, train loss 0.022, train accuracy 0.886, val loss 0.116, val accuracy 0.923, and val rmse 0.053\n",
            "Epoch 16, train loss 0.020, train accuracy 0.877, val loss 0.102, val accuracy 0.936, and val rmse 0.053\n",
            "Epoch 17, train loss 0.019, train accuracy 0.870, val loss 0.100, val accuracy 0.923, and val rmse 0.080\n",
            "Epoch 18, train loss 0.018, train accuracy 0.877, val loss 0.088, val accuracy 0.935, and val rmse 0.080\n",
            "Epoch 19, train loss 0.016, train accuracy 0.896, val loss 0.083, val accuracy 0.923, and val rmse 0.080\n",
            "Epoch 20, train loss 0.015, train accuracy 0.903, val loss 0.073, val accuracy 0.922, and val rmse 0.080\n",
            "Epoch 21, train loss 0.015, train accuracy 0.880, val loss 0.089, val accuracy 0.871, and val rmse 0.080\n",
            "Epoch 22, train loss 0.013, train accuracy 0.903, val loss 0.067, val accuracy 0.908, and val rmse 0.080\n",
            "Epoch 23, train loss 0.012, train accuracy 0.909, val loss 0.060, val accuracy 0.895, and val rmse 0.080\n",
            "Epoch 24, train loss 0.012, train accuracy 0.896, val loss 0.055, val accuracy 0.895, and val rmse 0.080\n",
            "Epoch 25, train loss 0.023, train accuracy 0.760, val loss 0.142, val accuracy 0.854, and val rmse 0.000\n",
            "Epoch 26, train loss 0.021, train accuracy 0.734, val loss 0.107, val accuracy 0.704, and val rmse 0.000\n",
            "Epoch 27, train loss 0.019, train accuracy 0.789, val loss 0.096, val accuracy 0.794, and val rmse 0.000\n",
            "Epoch 28, train loss 0.019, train accuracy 0.786, val loss 0.091, val accuracy 0.807, and val rmse 0.000\n",
            "Epoch 29, train loss 0.019, train accuracy 0.769, val loss 0.087, val accuracy 0.794, and val rmse 0.000\n",
            "Epoch 30, train loss 0.017, train accuracy 0.808, val loss 0.087, val accuracy 0.807, and val rmse 0.000\n",
            "Epoch 31, train loss 0.016, train accuracy 0.799, val loss 0.083, val accuracy 0.819, and val rmse 0.000\n",
            "Epoch 32, train loss 0.016, train accuracy 0.831, val loss 0.080, val accuracy 0.807, and val rmse 0.000\n",
            "Epoch 33, train loss 0.015, train accuracy 0.828, val loss 0.078, val accuracy 0.819, and val rmse 0.000\n",
            "Epoch 34, train loss 0.015, train accuracy 0.831, val loss 0.076, val accuracy 0.819, and val rmse 0.000\n",
            "Epoch 35, train loss 0.015, train accuracy 0.825, val loss 0.075, val accuracy 0.819, and val rmse 0.000\n",
            "Epoch 36, train loss 0.015, train accuracy 0.828, val loss 0.081, val accuracy 0.832, and val rmse 0.000\n",
            "Epoch 37, train loss 0.015, train accuracy 0.831, val loss 0.073, val accuracy 0.819, and val rmse 0.000\n",
            "Epoch 38, train loss 0.014, train accuracy 0.825, val loss 0.070, val accuracy 0.819, and val rmse 0.000\n",
            "Epoch 39, train loss 0.014, train accuracy 0.854, val loss 0.069, val accuracy 0.819, and val rmse 0.000\n",
            "Epoch 40, train loss 0.014, train accuracy 0.844, val loss 0.068, val accuracy 0.820, and val rmse 0.000\n",
            "Epoch 41, train loss 0.014, train accuracy 0.854, val loss 0.067, val accuracy 0.819, and val rmse 0.000\n",
            "Epoch 42, train loss 0.013, train accuracy 0.880, val loss 0.063, val accuracy 0.857, and val rmse 0.000\n",
            "Epoch 43, train loss 0.012, train accuracy 0.883, val loss 0.062, val accuracy 0.871, and val rmse 0.000\n",
            "Epoch 44, train loss 0.015, train accuracy 0.802, val loss 0.086, val accuracy 0.730, and val rmse 0.000\n",
            "Epoch 45, train loss 0.014, train accuracy 0.805, val loss 0.070, val accuracy 0.807, and val rmse 0.000\n",
            "Epoch 46, train loss 0.013, train accuracy 0.851, val loss 0.066, val accuracy 0.820, and val rmse 0.027\n",
            "Epoch 47, train loss 0.012, train accuracy 0.890, val loss 0.059, val accuracy 0.895, and val rmse 0.027\n",
            "Epoch 48, train loss 0.012, train accuracy 0.906, val loss 0.057, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 49, train loss 0.012, train accuracy 0.925, val loss 0.052, val accuracy 0.947, and val rmse 0.027\n",
            "\n",
            " Iteration number : 53\n",
            "Epoch 0, train loss 0.054, train accuracy 0.231, val loss 0.274, val accuracy 0.101, and val rmse 0.507\n",
            "Epoch 1, train loss 0.052, train accuracy 0.175, val loss 0.267, val accuracy 0.027, and val rmse 0.467\n",
            "Epoch 2, train loss 0.051, train accuracy 0.221, val loss 0.276, val accuracy 0.133, and val rmse 0.187\n",
            "Epoch 3, train loss 0.050, train accuracy 0.308, val loss 0.262, val accuracy 0.373, and val rmse 0.093\n",
            "Epoch 4, train loss 0.049, train accuracy 0.276, val loss 0.258, val accuracy 0.253, and val rmse 0.200\n",
            "Epoch 5, train loss 0.048, train accuracy 0.299, val loss 0.248, val accuracy 0.320, and val rmse 0.200\n",
            "Epoch 6, train loss 0.047, train accuracy 0.338, val loss 0.250, val accuracy 0.347, and val rmse 0.040\n",
            "Epoch 7, train loss 0.046, train accuracy 0.351, val loss 0.231, val accuracy 0.387, and val rmse 0.040\n",
            "Epoch 8, train loss 0.044, train accuracy 0.409, val loss 0.236, val accuracy 0.360, and val rmse 0.067\n",
            "Epoch 9, train loss 0.043, train accuracy 0.487, val loss 0.221, val accuracy 0.413, and val rmse 0.013\n",
            "Epoch 10, train loss 0.041, train accuracy 0.558, val loss 0.212, val accuracy 0.451, and val rmse 0.013\n",
            "Epoch 11, train loss 0.039, train accuracy 0.607, val loss 0.204, val accuracy 0.514, and val rmse 0.013\n",
            "Epoch 12, train loss 0.037, train accuracy 0.649, val loss 0.196, val accuracy 0.604, and val rmse 0.040\n",
            "Epoch 13, train loss 0.036, train accuracy 0.653, val loss 0.183, val accuracy 0.716, and val rmse 0.013\n",
            "Epoch 14, train loss 0.035, train accuracy 0.656, val loss 0.180, val accuracy 0.639, and val rmse 0.013\n",
            "Epoch 15, train loss 0.033, train accuracy 0.672, val loss 0.170, val accuracy 0.678, and val rmse 0.013\n",
            "Epoch 16, train loss 0.031, train accuracy 0.714, val loss 0.157, val accuracy 0.729, and val rmse 0.040\n",
            "Epoch 17, train loss 0.030, train accuracy 0.714, val loss 0.154, val accuracy 0.716, and val rmse 0.040\n",
            "Epoch 18, train loss 0.029, train accuracy 0.734, val loss 0.149, val accuracy 0.780, and val rmse 0.013\n",
            "Epoch 19, train loss 0.027, train accuracy 0.779, val loss 0.142, val accuracy 0.793, and val rmse 0.013\n",
            "Epoch 20, train loss 0.027, train accuracy 0.740, val loss 0.135, val accuracy 0.781, and val rmse 0.013\n",
            "Epoch 21, train loss 0.026, train accuracy 0.718, val loss 0.139, val accuracy 0.743, and val rmse 0.013\n",
            "Epoch 22, train loss 0.024, train accuracy 0.782, val loss 0.120, val accuracy 0.806, and val rmse 0.013\n",
            "Epoch 23, train loss 0.023, train accuracy 0.773, val loss 0.113, val accuracy 0.806, and val rmse 0.013\n",
            "Epoch 24, train loss 0.022, train accuracy 0.708, val loss 0.115, val accuracy 0.619, and val rmse 0.387\n",
            "Epoch 25, train loss 0.021, train accuracy 0.756, val loss 0.106, val accuracy 0.766, and val rmse 0.093\n",
            "Epoch 26, train loss 0.020, train accuracy 0.766, val loss 0.099, val accuracy 0.766, and val rmse 0.093\n",
            "Epoch 27, train loss 0.018, train accuracy 0.763, val loss 0.096, val accuracy 0.778, and val rmse 0.093\n",
            "Epoch 28, train loss 0.019, train accuracy 0.737, val loss 0.090, val accuracy 0.792, and val rmse 0.107\n",
            "Epoch 29, train loss 0.017, train accuracy 0.737, val loss 0.083, val accuracy 0.765, and val rmse 0.160\n",
            "Epoch 30, train loss 0.015, train accuracy 0.747, val loss 0.078, val accuracy 0.752, and val rmse 0.187\n",
            "Epoch 31, train loss 0.016, train accuracy 0.744, val loss 0.077, val accuracy 0.738, and val rmse 0.213\n",
            "Epoch 32, train loss 0.015, train accuracy 0.740, val loss 0.072, val accuracy 0.738, and val rmse 0.213\n",
            "Epoch 33, train loss 0.013, train accuracy 0.760, val loss 0.069, val accuracy 0.725, and val rmse 0.213\n",
            "Epoch 34, train loss 0.013, train accuracy 0.750, val loss 0.065, val accuracy 0.752, and val rmse 0.187\n",
            "Epoch 35, train loss 0.014, train accuracy 0.825, val loss 0.074, val accuracy 0.832, and val rmse 0.053\n",
            "Epoch 36, train loss 0.012, train accuracy 0.838, val loss 0.059, val accuracy 0.832, and val rmse 0.053\n",
            "Epoch 37, train loss 0.012, train accuracy 0.834, val loss 0.058, val accuracy 0.845, and val rmse 0.027\n",
            "Epoch 38, train loss 0.012, train accuracy 0.844, val loss 0.058, val accuracy 0.846, and val rmse 0.027\n",
            "Epoch 39, train loss 0.011, train accuracy 0.867, val loss 0.053, val accuracy 0.883, and val rmse 0.027\n",
            "Epoch 40, train loss 0.009, train accuracy 0.896, val loss 0.048, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 41, train loss 0.009, train accuracy 0.886, val loss 0.046, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 42, train loss 0.009, train accuracy 0.906, val loss 0.049, val accuracy 0.884, and val rmse 0.000\n",
            "Epoch 43, train loss 0.009, train accuracy 0.860, val loss 0.050, val accuracy 0.884, and val rmse 0.000\n",
            "Epoch 44, train loss 0.008, train accuracy 0.899, val loss 0.040, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 45, train loss 0.008, train accuracy 0.903, val loss 0.038, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 46, train loss 0.008, train accuracy 0.899, val loss 0.037, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 47, train loss 0.007, train accuracy 0.903, val loss 0.036, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 48, train loss 0.007, train accuracy 0.906, val loss 0.039, val accuracy 0.897, and val rmse 0.000\n",
            "Epoch 49, train loss 0.007, train accuracy 0.903, val loss 0.036, val accuracy 0.909, and val rmse 0.000\n",
            "\n",
            " Iteration number : 54\n",
            "Epoch 0, train loss 0.053, train accuracy 0.305, val loss 0.269, val accuracy 0.117, and val rmse 0.467\n",
            "Epoch 1, train loss 0.052, train accuracy 0.331, val loss 0.268, val accuracy 0.076, and val rmse 0.400\n",
            "Epoch 2, train loss 0.051, train accuracy 0.370, val loss 0.270, val accuracy 0.253, and val rmse 0.200\n",
            "Epoch 3, train loss 0.052, train accuracy 0.269, val loss 0.272, val accuracy 0.413, and val rmse 0.000\n",
            "Epoch 4, train loss 0.049, train accuracy 0.357, val loss 0.258, val accuracy 0.307, and val rmse 0.080\n",
            "Epoch 5, train loss 0.047, train accuracy 0.484, val loss 0.256, val accuracy 0.360, and val rmse 0.080\n",
            "Epoch 6, train loss 0.045, train accuracy 0.584, val loss 0.231, val accuracy 0.448, and val rmse 0.053\n",
            "Epoch 7, train loss 0.042, train accuracy 0.571, val loss 0.225, val accuracy 0.410, and val rmse 0.093\n",
            "Epoch 8, train loss 0.039, train accuracy 0.617, val loss 0.194, val accuracy 0.557, and val rmse 0.293\n",
            "Epoch 9, train loss 0.036, train accuracy 0.630, val loss 0.182, val accuracy 0.543, and val rmse 0.293\n",
            "Epoch 10, train loss 0.034, train accuracy 0.630, val loss 0.173, val accuracy 0.449, and val rmse 0.293\n",
            "Epoch 11, train loss 0.031, train accuracy 0.617, val loss 0.162, val accuracy 0.553, and val rmse 0.227\n",
            "Epoch 12, train loss 0.031, train accuracy 0.617, val loss 0.155, val accuracy 0.642, and val rmse 0.293\n",
            "Epoch 13, train loss 0.028, train accuracy 0.695, val loss 0.148, val accuracy 0.548, and val rmse 0.293\n",
            "Epoch 14, train loss 0.026, train accuracy 0.795, val loss 0.146, val accuracy 0.449, and val rmse 0.293\n",
            "Epoch 15, train loss 0.025, train accuracy 0.789, val loss 0.128, val accuracy 0.697, and val rmse 0.107\n",
            "Epoch 16, train loss 0.025, train accuracy 0.808, val loss 0.117, val accuracy 0.802, and val rmse 0.080\n",
            "Epoch 17, train loss 0.022, train accuracy 0.873, val loss 0.111, val accuracy 0.856, and val rmse 0.027\n",
            "Epoch 18, train loss 0.020, train accuracy 0.873, val loss 0.104, val accuracy 0.856, and val rmse 0.027\n",
            "Epoch 19, train loss 0.019, train accuracy 0.864, val loss 0.095, val accuracy 0.921, and val rmse 0.027\n",
            "Epoch 20, train loss 0.020, train accuracy 0.854, val loss 0.094, val accuracy 0.856, and val rmse 0.027\n",
            "Epoch 21, train loss 0.017, train accuracy 0.899, val loss 0.086, val accuracy 0.882, and val rmse 0.027\n",
            "Epoch 22, train loss 0.016, train accuracy 0.899, val loss 0.080, val accuracy 0.882, and val rmse 0.027\n",
            "Epoch 23, train loss 0.015, train accuracy 0.903, val loss 0.080, val accuracy 0.882, and val rmse 0.053\n",
            "Epoch 24, train loss 0.015, train accuracy 0.896, val loss 0.073, val accuracy 0.882, and val rmse 0.027\n",
            "Epoch 25, train loss 0.013, train accuracy 0.909, val loss 0.067, val accuracy 0.896, and val rmse 0.027\n",
            "Epoch 26, train loss 0.014, train accuracy 0.890, val loss 0.068, val accuracy 0.933, and val rmse 0.027\n",
            "Epoch 27, train loss 0.012, train accuracy 0.929, val loss 0.065, val accuracy 0.896, and val rmse 0.027\n",
            "Epoch 28, train loss 0.012, train accuracy 0.929, val loss 0.060, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 29, train loss 0.011, train accuracy 0.948, val loss 0.057, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 30, train loss 0.011, train accuracy 0.935, val loss 0.049, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 31, train loss 0.010, train accuracy 0.938, val loss 0.045, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 32, train loss 0.008, train accuracy 0.971, val loss 0.041, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 33, train loss 0.009, train accuracy 0.968, val loss 0.040, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 34, train loss 0.008, train accuracy 0.974, val loss 0.036, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 35, train loss 0.007, train accuracy 0.968, val loss 0.033, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 36, train loss 0.007, train accuracy 0.968, val loss 0.031, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.006, train accuracy 0.974, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.006, train accuracy 0.977, val loss 0.027, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.006, train accuracy 0.987, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.005, train accuracy 0.987, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.005, train accuracy 0.981, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.006, train accuracy 0.974, val loss 0.026, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.004, train accuracy 0.990, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.004, train accuracy 0.994, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.004, train accuracy 0.987, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.004, train accuracy 0.987, val loss 0.022, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.990, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.990, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.003, train accuracy 0.987, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 55\n",
            "Epoch 0, train loss 0.054, train accuracy 0.328, val loss 0.280, val accuracy 0.267, and val rmse 0.440\n",
            "Epoch 1, train loss 0.051, train accuracy 0.370, val loss 0.271, val accuracy 0.222, and val rmse 0.173\n",
            "Epoch 2, train loss 0.051, train accuracy 0.360, val loss 0.272, val accuracy 0.347, and val rmse 0.080\n",
            "Epoch 3, train loss 0.048, train accuracy 0.519, val loss 0.261, val accuracy 0.184, and val rmse 0.293\n",
            "Epoch 4, train loss 0.045, train accuracy 0.516, val loss 0.233, val accuracy 0.488, and val rmse 0.040\n",
            "Epoch 5, train loss 0.042, train accuracy 0.497, val loss 0.226, val accuracy 0.462, and val rmse 0.053\n",
            "Epoch 6, train loss 0.039, train accuracy 0.510, val loss 0.200, val accuracy 0.528, and val rmse 0.053\n",
            "Epoch 7, train loss 0.036, train accuracy 0.630, val loss 0.188, val accuracy 0.542, and val rmse 0.053\n",
            "Epoch 8, train loss 0.034, train accuracy 0.688, val loss 0.170, val accuracy 0.579, and val rmse 0.027\n",
            "Epoch 9, train loss 0.030, train accuracy 0.792, val loss 0.160, val accuracy 0.692, and val rmse 0.027\n",
            "Epoch 10, train loss 0.028, train accuracy 0.812, val loss 0.141, val accuracy 0.756, and val rmse 0.027\n",
            "Epoch 11, train loss 0.026, train accuracy 0.860, val loss 0.128, val accuracy 0.832, and val rmse 0.027\n",
            "Epoch 12, train loss 0.023, train accuracy 0.870, val loss 0.120, val accuracy 0.844, and val rmse 0.027\n",
            "Epoch 13, train loss 0.021, train accuracy 0.893, val loss 0.111, val accuracy 0.907, and val rmse 0.027\n",
            "Epoch 14, train loss 0.020, train accuracy 0.903, val loss 0.103, val accuracy 0.884, and val rmse 0.000\n",
            "Epoch 15, train loss 0.017, train accuracy 0.942, val loss 0.086, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 16, train loss 0.016, train accuracy 0.932, val loss 0.082, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 17, train loss 0.014, train accuracy 0.958, val loss 0.070, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 18, train loss 0.013, train accuracy 0.945, val loss 0.060, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 19, train loss 0.013, train accuracy 0.951, val loss 0.055, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 20, train loss 0.010, train accuracy 0.984, val loss 0.049, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 21, train loss 0.012, train accuracy 0.932, val loss 0.060, val accuracy 0.949, and val rmse 0.000\n",
            "Epoch 22, train loss 0.009, train accuracy 0.961, val loss 0.041, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 23, train loss 0.007, train accuracy 0.987, val loss 0.037, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 24, train loss 0.007, train accuracy 0.977, val loss 0.048, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 25, train loss 0.006, train accuracy 0.971, val loss 0.028, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 26, train loss 0.006, train accuracy 0.981, val loss 0.024, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 27, train loss 0.006, train accuracy 0.974, val loss 0.030, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 28, train loss 0.004, train accuracy 0.987, val loss 0.020, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 29, train loss 0.005, train accuracy 0.981, val loss 0.017, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 30, train loss 0.004, train accuracy 0.977, val loss 0.039, val accuracy 0.912, and val rmse 0.000\n",
            "Epoch 31, train loss 0.004, train accuracy 0.984, val loss 0.025, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 32, train loss 0.003, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.003, train accuracy 1.000, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.003, train accuracy 0.987, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.990, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 0.994, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.984, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 0.994, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.974, val loss 0.075, val accuracy 0.800, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 56\n",
            "Epoch 0, train loss 0.054, train accuracy 0.305, val loss 0.277, val accuracy 0.191, and val rmse 0.440\n",
            "Epoch 1, train loss 0.051, train accuracy 0.347, val loss 0.261, val accuracy 0.142, and val rmse 0.427\n",
            "Epoch 2, train loss 0.050, train accuracy 0.344, val loss 0.272, val accuracy 0.142, and val rmse 0.440\n",
            "Epoch 3, train loss 0.051, train accuracy 0.386, val loss 0.278, val accuracy 0.185, and val rmse 0.400\n",
            "Epoch 4, train loss 0.049, train accuracy 0.422, val loss 0.269, val accuracy 0.053, and val rmse 0.440\n",
            "Epoch 5, train loss 0.046, train accuracy 0.523, val loss 0.233, val accuracy 0.558, and val rmse 0.093\n",
            "Epoch 6, train loss 0.045, train accuracy 0.529, val loss 0.238, val accuracy 0.366, and val rmse 0.120\n",
            "Epoch 7, train loss 0.042, train accuracy 0.562, val loss 0.221, val accuracy 0.548, and val rmse 0.040\n",
            "Epoch 8, train loss 0.040, train accuracy 0.594, val loss 0.204, val accuracy 0.587, and val rmse 0.067\n",
            "Epoch 9, train loss 0.038, train accuracy 0.597, val loss 0.201, val accuracy 0.537, and val rmse 0.067\n",
            "Epoch 10, train loss 0.036, train accuracy 0.649, val loss 0.190, val accuracy 0.613, and val rmse 0.067\n",
            "Epoch 11, train loss 0.036, train accuracy 0.653, val loss 0.190, val accuracy 0.602, and val rmse 0.067\n",
            "Epoch 12, train loss 0.034, train accuracy 0.649, val loss 0.173, val accuracy 0.677, and val rmse 0.040\n",
            "Epoch 13, train loss 0.033, train accuracy 0.627, val loss 0.163, val accuracy 0.665, and val rmse 0.040\n",
            "Epoch 14, train loss 0.030, train accuracy 0.640, val loss 0.154, val accuracy 0.665, and val rmse 0.040\n",
            "Epoch 15, train loss 0.029, train accuracy 0.630, val loss 0.146, val accuracy 0.665, and val rmse 0.040\n",
            "Epoch 16, train loss 0.037, train accuracy 0.438, val loss 0.232, val accuracy 0.453, and val rmse 0.013\n",
            "Epoch 17, train loss 0.034, train accuracy 0.399, val loss 0.171, val accuracy 0.466, and val rmse 0.027\n",
            "Epoch 18, train loss 0.033, train accuracy 0.464, val loss 0.167, val accuracy 0.531, and val rmse 0.027\n",
            "Epoch 19, train loss 0.034, train accuracy 0.519, val loss 0.193, val accuracy 0.332, and val rmse 0.200\n",
            "Epoch 20, train loss 0.033, train accuracy 0.591, val loss 0.164, val accuracy 0.506, and val rmse 0.013\n",
            "Epoch 21, train loss 0.032, train accuracy 0.578, val loss 0.163, val accuracy 0.479, and val rmse 0.027\n",
            "Epoch 22, train loss 0.032, train accuracy 0.656, val loss 0.161, val accuracy 0.690, and val rmse 0.013\n",
            "Epoch 23, train loss 0.031, train accuracy 0.649, val loss 0.153, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 24, train loss 0.030, train accuracy 0.662, val loss 0.156, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 25, train loss 0.030, train accuracy 0.675, val loss 0.149, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 26, train loss 0.029, train accuracy 0.685, val loss 0.144, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 27, train loss 0.029, train accuracy 0.714, val loss 0.150, val accuracy 0.689, and val rmse 0.013\n",
            "Epoch 28, train loss 0.028, train accuracy 0.695, val loss 0.142, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 29, train loss 0.027, train accuracy 0.705, val loss 0.138, val accuracy 0.716, and val rmse 0.013\n",
            "Epoch 30, train loss 0.026, train accuracy 0.701, val loss 0.133, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 31, train loss 0.026, train accuracy 0.711, val loss 0.129, val accuracy 0.717, and val rmse 0.013\n",
            "Epoch 32, train loss 0.026, train accuracy 0.708, val loss 0.126, val accuracy 0.717, and val rmse 0.013\n",
            "Epoch 33, train loss 0.024, train accuracy 0.721, val loss 0.125, val accuracy 0.729, and val rmse 0.013\n",
            "Epoch 34, train loss 0.025, train accuracy 0.727, val loss 0.128, val accuracy 0.716, and val rmse 0.013\n",
            "Epoch 35, train loss 0.024, train accuracy 0.685, val loss 0.122, val accuracy 0.729, and val rmse 0.013\n",
            "Epoch 36, train loss 0.023, train accuracy 0.685, val loss 0.117, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 37, train loss 0.023, train accuracy 0.666, val loss 0.115, val accuracy 0.728, and val rmse 0.013\n",
            "Epoch 38, train loss 0.022, train accuracy 0.695, val loss 0.111, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 39, train loss 0.021, train accuracy 0.675, val loss 0.109, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 40, train loss 0.021, train accuracy 0.672, val loss 0.107, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 41, train loss 0.021, train accuracy 0.666, val loss 0.104, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 42, train loss 0.020, train accuracy 0.656, val loss 0.107, val accuracy 0.691, and val rmse 0.027\n",
            "Epoch 43, train loss 0.021, train accuracy 0.594, val loss 0.103, val accuracy 0.703, and val rmse 0.027\n",
            "Epoch 44, train loss 0.021, train accuracy 0.604, val loss 0.099, val accuracy 0.703, and val rmse 0.027\n",
            "Epoch 45, train loss 0.019, train accuracy 0.614, val loss 0.097, val accuracy 0.677, and val rmse 0.080\n",
            "Epoch 46, train loss 0.019, train accuracy 0.627, val loss 0.096, val accuracy 0.637, and val rmse 0.160\n",
            "Epoch 47, train loss 0.018, train accuracy 0.620, val loss 0.094, val accuracy 0.517, and val rmse 0.400\n",
            "Epoch 48, train loss 0.018, train accuracy 0.627, val loss 0.093, val accuracy 0.517, and val rmse 0.400\n",
            "Epoch 49, train loss 0.018, train accuracy 0.623, val loss 0.092, val accuracy 0.517, and val rmse 0.400\n",
            "\n",
            " Iteration number : 57\n",
            "Epoch 0, train loss 0.054, train accuracy 0.331, val loss 0.270, val accuracy 0.413, and val rmse 0.000\n",
            "Epoch 1, train loss 0.052, train accuracy 0.383, val loss 0.262, val accuracy 0.373, and val rmse 0.027\n",
            "Epoch 2, train loss 0.050, train accuracy 0.344, val loss 0.254, val accuracy 0.347, and val rmse 0.027\n",
            "Epoch 3, train loss 0.050, train accuracy 0.370, val loss 0.258, val accuracy 0.387, and val rmse 0.053\n",
            "Epoch 4, train loss 0.051, train accuracy 0.390, val loss 0.273, val accuracy 0.426, and val rmse 0.000\n",
            "Epoch 5, train loss 0.050, train accuracy 0.393, val loss 0.253, val accuracy 0.387, and val rmse 0.053\n",
            "Epoch 6, train loss 0.047, train accuracy 0.513, val loss 0.236, val accuracy 0.360, and val rmse 0.093\n",
            "Epoch 7, train loss 0.041, train accuracy 0.620, val loss 0.215, val accuracy 0.502, and val rmse 0.093\n",
            "Epoch 8, train loss 0.037, train accuracy 0.653, val loss 0.194, val accuracy 0.550, and val rmse 0.040\n",
            "Epoch 9, train loss 0.035, train accuracy 0.656, val loss 0.175, val accuracy 0.598, and val rmse 0.093\n",
            "Epoch 10, train loss 0.032, train accuracy 0.708, val loss 0.168, val accuracy 0.612, and val rmse 0.093\n",
            "Epoch 11, train loss 0.030, train accuracy 0.721, val loss 0.144, val accuracy 0.712, and val rmse 0.093\n",
            "Epoch 12, train loss 0.027, train accuracy 0.782, val loss 0.147, val accuracy 0.753, and val rmse 0.093\n",
            "Epoch 13, train loss 0.024, train accuracy 0.825, val loss 0.124, val accuracy 0.830, and val rmse 0.093\n",
            "Epoch 14, train loss 0.023, train accuracy 0.815, val loss 0.120, val accuracy 0.830, and val rmse 0.093\n",
            "Epoch 15, train loss 0.021, train accuracy 0.805, val loss 0.104, val accuracy 0.843, and val rmse 0.093\n",
            "Epoch 16, train loss 0.019, train accuracy 0.825, val loss 0.096, val accuracy 0.843, and val rmse 0.093\n",
            "Epoch 17, train loss 0.017, train accuracy 0.860, val loss 0.090, val accuracy 0.830, and val rmse 0.093\n",
            "Epoch 18, train loss 0.016, train accuracy 0.851, val loss 0.081, val accuracy 0.868, and val rmse 0.080\n",
            "Epoch 19, train loss 0.015, train accuracy 0.864, val loss 0.074, val accuracy 0.857, and val rmse 0.080\n",
            "Epoch 20, train loss 0.015, train accuracy 0.870, val loss 0.066, val accuracy 0.907, and val rmse 0.080\n",
            "Epoch 21, train loss 0.013, train accuracy 0.886, val loss 0.061, val accuracy 0.920, and val rmse 0.053\n",
            "Epoch 22, train loss 0.013, train accuracy 0.893, val loss 0.060, val accuracy 0.920, and val rmse 0.053\n",
            "Epoch 23, train loss 0.011, train accuracy 0.932, val loss 0.053, val accuracy 0.933, and val rmse 0.027\n",
            "Epoch 24, train loss 0.010, train accuracy 0.929, val loss 0.049, val accuracy 0.933, and val rmse 0.027\n",
            "Epoch 25, train loss 0.009, train accuracy 0.925, val loss 0.044, val accuracy 0.933, and val rmse 0.027\n",
            "Epoch 26, train loss 0.010, train accuracy 0.929, val loss 0.045, val accuracy 0.921, and val rmse 0.027\n",
            "Epoch 27, train loss 0.009, train accuracy 0.916, val loss 0.036, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 28, train loss 0.008, train accuracy 0.938, val loss 0.033, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 29, train loss 0.007, train accuracy 0.964, val loss 0.030, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 30, train loss 0.006, train accuracy 0.964, val loss 0.028, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 31, train loss 0.005, train accuracy 0.971, val loss 0.024, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 32, train loss 0.005, train accuracy 0.971, val loss 0.022, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 33, train loss 0.013, train accuracy 0.909, val loss 0.041, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 34, train loss 0.008, train accuracy 0.945, val loss 0.037, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 35, train loss 0.007, train accuracy 0.945, val loss 0.030, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 36, train loss 0.008, train accuracy 0.922, val loss 0.029, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 37, train loss 0.006, train accuracy 0.961, val loss 0.028, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 38, train loss 0.005, train accuracy 0.971, val loss 0.025, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 39, train loss 0.005, train accuracy 0.987, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.004, train accuracy 0.987, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.005, train accuracy 0.968, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.004, train accuracy 0.987, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.990, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.987, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.003, train accuracy 0.990, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.987, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.984, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.984, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 58\n",
            "Epoch 0, train loss 0.054, train accuracy 0.240, val loss 0.290, val accuracy 0.129, and val rmse 0.573\n",
            "Epoch 1, train loss 0.052, train accuracy 0.266, val loss 0.271, val accuracy 0.080, and val rmse 0.440\n",
            "Epoch 2, train loss 0.050, train accuracy 0.338, val loss 0.267, val accuracy 0.144, and val rmse 0.360\n",
            "Epoch 3, train loss 0.048, train accuracy 0.432, val loss 0.256, val accuracy 0.278, and val rmse 0.160\n",
            "Epoch 4, train loss 0.047, train accuracy 0.419, val loss 0.246, val accuracy 0.385, and val rmse 0.107\n",
            "Epoch 5, train loss 0.044, train accuracy 0.497, val loss 0.211, val accuracy 0.562, and val rmse 0.080\n",
            "Epoch 6, train loss 0.043, train accuracy 0.445, val loss 0.215, val accuracy 0.427, and val rmse 0.080\n",
            "Epoch 7, train loss 0.044, train accuracy 0.432, val loss 0.225, val accuracy 0.479, and val rmse 0.000\n",
            "Epoch 8, train loss 0.048, train accuracy 0.247, val loss 0.244, val accuracy 0.187, and val rmse 0.227\n",
            "Epoch 9, train loss 0.046, train accuracy 0.269, val loss 0.235, val accuracy 0.244, and val rmse 0.320\n",
            "Epoch 10, train loss 0.045, train accuracy 0.380, val loss 0.251, val accuracy 0.129, and val rmse 0.347\n",
            "Epoch 11, train loss 0.044, train accuracy 0.386, val loss 0.226, val accuracy 0.257, and val rmse 0.360\n",
            "Epoch 12, train loss 0.040, train accuracy 0.490, val loss 0.205, val accuracy 0.338, and val rmse 0.360\n",
            "Epoch 13, train loss 0.037, train accuracy 0.633, val loss 0.191, val accuracy 0.488, and val rmse 0.307\n",
            "Epoch 14, train loss 0.036, train accuracy 0.685, val loss 0.201, val accuracy 0.651, and val rmse 0.080\n",
            "Epoch 15, train loss 0.033, train accuracy 0.721, val loss 0.175, val accuracy 0.676, and val rmse 0.080\n",
            "Epoch 16, train loss 0.031, train accuracy 0.679, val loss 0.161, val accuracy 0.702, and val rmse 0.080\n",
            "Epoch 17, train loss 0.027, train accuracy 0.750, val loss 0.142, val accuracy 0.728, and val rmse 0.080\n",
            "Epoch 18, train loss 0.024, train accuracy 0.773, val loss 0.126, val accuracy 0.781, and val rmse 0.000\n",
            "Epoch 19, train loss 0.022, train accuracy 0.792, val loss 0.117, val accuracy 0.807, and val rmse 0.000\n",
            "Epoch 20, train loss 0.021, train accuracy 0.776, val loss 0.109, val accuracy 0.807, and val rmse 0.027\n",
            "Epoch 21, train loss 0.020, train accuracy 0.818, val loss 0.100, val accuracy 0.820, and val rmse 0.000\n",
            "Epoch 22, train loss 0.018, train accuracy 0.841, val loss 0.093, val accuracy 0.847, and val rmse 0.000\n",
            "Epoch 23, train loss 0.017, train accuracy 0.838, val loss 0.088, val accuracy 0.833, and val rmse 0.000\n",
            "Epoch 24, train loss 0.016, train accuracy 0.890, val loss 0.082, val accuracy 0.846, and val rmse 0.000\n",
            "Epoch 25, train loss 0.015, train accuracy 0.886, val loss 0.075, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 26, train loss 0.014, train accuracy 0.903, val loss 0.069, val accuracy 0.898, and val rmse 0.000\n",
            "Epoch 27, train loss 0.013, train accuracy 0.925, val loss 0.063, val accuracy 0.924, and val rmse 0.000\n",
            "Epoch 28, train loss 0.012, train accuracy 0.938, val loss 0.057, val accuracy 0.937, and val rmse 0.000\n",
            "Epoch 29, train loss 0.013, train accuracy 0.912, val loss 0.117, val accuracy 0.762, and val rmse 0.000\n",
            "Epoch 30, train loss 0.011, train accuracy 0.951, val loss 0.047, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 31, train loss 0.010, train accuracy 0.958, val loss 0.043, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 32, train loss 0.008, train accuracy 0.981, val loss 0.037, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 33, train loss 0.009, train accuracy 0.968, val loss 0.037, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 34, train loss 0.007, train accuracy 0.977, val loss 0.032, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 35, train loss 0.006, train accuracy 0.981, val loss 0.026, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 36, train loss 0.005, train accuracy 0.987, val loss 0.024, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 37, train loss 0.005, train accuracy 0.990, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.004, train accuracy 0.990, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.004, train accuracy 0.990, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.994, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.990, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.997, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.990, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.984, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 59\n",
            "Epoch 0, train loss 0.054, train accuracy 0.156, val loss 0.267, val accuracy 0.213, and val rmse 0.147\n",
            "Epoch 1, train loss 0.052, train accuracy 0.292, val loss 0.275, val accuracy 0.320, and val rmse 0.173\n",
            "Epoch 2, train loss 0.051, train accuracy 0.429, val loss 0.279, val accuracy 0.413, and val rmse 0.000\n",
            "Epoch 3, train loss 0.048, train accuracy 0.442, val loss 0.261, val accuracy 0.238, and val rmse 0.280\n",
            "Epoch 4, train loss 0.047, train accuracy 0.364, val loss 0.243, val accuracy 0.305, and val rmse 0.307\n",
            "Epoch 5, train loss 0.043, train accuracy 0.490, val loss 0.221, val accuracy 0.426, and val rmse 0.093\n",
            "Epoch 6, train loss 0.040, train accuracy 0.578, val loss 0.203, val accuracy 0.513, and val rmse 0.107\n",
            "Epoch 7, train loss 0.038, train accuracy 0.604, val loss 0.187, val accuracy 0.615, and val rmse 0.053\n",
            "Epoch 8, train loss 0.035, train accuracy 0.679, val loss 0.178, val accuracy 0.614, and val rmse 0.080\n",
            "Epoch 9, train loss 0.033, train accuracy 0.679, val loss 0.167, val accuracy 0.613, and val rmse 0.107\n",
            "Epoch 10, train loss 0.031, train accuracy 0.692, val loss 0.164, val accuracy 0.663, and val rmse 0.107\n",
            "Epoch 11, train loss 0.028, train accuracy 0.714, val loss 0.149, val accuracy 0.676, and val rmse 0.107\n",
            "Epoch 12, train loss 0.026, train accuracy 0.698, val loss 0.133, val accuracy 0.676, and val rmse 0.107\n",
            "Epoch 13, train loss 0.025, train accuracy 0.688, val loss 0.125, val accuracy 0.688, and val rmse 0.107\n",
            "Epoch 14, train loss 0.023, train accuracy 0.692, val loss 0.115, val accuracy 0.714, and val rmse 0.080\n",
            "Epoch 15, train loss 0.021, train accuracy 0.727, val loss 0.109, val accuracy 0.714, and val rmse 0.080\n",
            "Epoch 16, train loss 0.021, train accuracy 0.727, val loss 0.114, val accuracy 0.716, and val rmse 0.027\n",
            "Epoch 17, train loss 0.022, train accuracy 0.776, val loss 0.109, val accuracy 0.728, and val rmse 0.080\n",
            "Epoch 18, train loss 0.018, train accuracy 0.734, val loss 0.104, val accuracy 0.660, and val rmse 0.213\n",
            "Epoch 19, train loss 0.018, train accuracy 0.711, val loss 0.086, val accuracy 0.713, and val rmse 0.160\n",
            "Epoch 20, train loss 0.016, train accuracy 0.773, val loss 0.085, val accuracy 0.779, and val rmse 0.080\n",
            "Epoch 21, train loss 0.016, train accuracy 0.815, val loss 0.082, val accuracy 0.805, and val rmse 0.053\n",
            "Epoch 22, train loss 0.015, train accuracy 0.815, val loss 0.073, val accuracy 0.818, and val rmse 0.080\n",
            "Epoch 23, train loss 0.014, train accuracy 0.831, val loss 0.069, val accuracy 0.832, and val rmse 0.053\n",
            "Epoch 24, train loss 0.013, train accuracy 0.860, val loss 0.063, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 25, train loss 0.012, train accuracy 0.880, val loss 0.059, val accuracy 0.898, and val rmse 0.000\n",
            "Epoch 26, train loss 0.011, train accuracy 0.909, val loss 0.055, val accuracy 0.911, and val rmse 0.000\n",
            "Epoch 27, train loss 0.010, train accuracy 0.942, val loss 0.051, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 28, train loss 0.011, train accuracy 0.890, val loss 0.049, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 29, train loss 0.010, train accuracy 0.942, val loss 0.043, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 30, train loss 0.009, train accuracy 0.948, val loss 0.041, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 31, train loss 0.008, train accuracy 0.961, val loss 0.037, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 32, train loss 0.023, train accuracy 0.607, val loss 0.212, val accuracy 0.353, and val rmse 0.373\n",
            "Epoch 33, train loss 0.016, train accuracy 0.675, val loss 0.092, val accuracy 0.580, and val rmse 0.293\n",
            "Epoch 34, train loss 0.016, train accuracy 0.675, val loss 0.087, val accuracy 0.501, and val rmse 0.293\n",
            "Epoch 35, train loss 0.014, train accuracy 0.734, val loss 0.082, val accuracy 0.512, and val rmse 0.293\n",
            "Epoch 36, train loss 0.013, train accuracy 0.737, val loss 0.079, val accuracy 0.645, and val rmse 0.213\n",
            "Epoch 37, train loss 0.013, train accuracy 0.779, val loss 0.075, val accuracy 0.713, and val rmse 0.133\n",
            "Epoch 38, train loss 0.013, train accuracy 0.805, val loss 0.074, val accuracy 0.727, and val rmse 0.053\n",
            "Epoch 39, train loss 0.011, train accuracy 0.873, val loss 0.064, val accuracy 0.817, and val rmse 0.053\n",
            "Epoch 40, train loss 0.011, train accuracy 0.903, val loss 0.058, val accuracy 0.894, and val rmse 0.053\n",
            "Epoch 41, train loss 0.011, train accuracy 0.890, val loss 0.052, val accuracy 0.894, and val rmse 0.053\n",
            "Epoch 42, train loss 0.009, train accuracy 0.929, val loss 0.049, val accuracy 0.907, and val rmse 0.053\n",
            "Epoch 43, train loss 0.009, train accuracy 0.935, val loss 0.048, val accuracy 0.907, and val rmse 0.053\n",
            "Epoch 44, train loss 0.010, train accuracy 0.919, val loss 0.044, val accuracy 0.933, and val rmse 0.053\n",
            "Epoch 45, train loss 0.008, train accuracy 0.935, val loss 0.040, val accuracy 0.947, and val rmse 0.053\n",
            "Epoch 46, train loss 0.007, train accuracy 0.951, val loss 0.037, val accuracy 0.960, and val rmse 0.053\n",
            "Epoch 47, train loss 0.007, train accuracy 0.955, val loss 0.056, val accuracy 0.910, and val rmse 0.053\n",
            "Epoch 48, train loss 0.006, train accuracy 0.955, val loss 0.031, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 49, train loss 0.007, train accuracy 0.958, val loss 0.028, val accuracy 0.987, and val rmse 0.027\n",
            "\n",
            " Iteration number : 60\n",
            "Epoch 0, train loss 0.056, train accuracy 0.250, val loss 0.279, val accuracy 0.250, and val rmse 0.493\n",
            "Epoch 1, train loss 0.053, train accuracy 0.195, val loss 0.273, val accuracy 0.160, and val rmse 0.267\n",
            "Epoch 2, train loss 0.051, train accuracy 0.256, val loss 0.269, val accuracy 0.027, and val rmse 0.253\n",
            "Epoch 3, train loss 0.049, train accuracy 0.279, val loss 0.259, val accuracy 0.092, and val rmse 0.253\n",
            "Epoch 4, train loss 0.048, train accuracy 0.308, val loss 0.255, val accuracy 0.197, and val rmse 0.187\n",
            "Epoch 5, train loss 0.046, train accuracy 0.351, val loss 0.249, val accuracy 0.244, and val rmse 0.400\n",
            "Epoch 6, train loss 0.048, train accuracy 0.396, val loss 0.249, val accuracy 0.345, and val rmse 0.120\n",
            "Epoch 7, train loss 0.045, train accuracy 0.558, val loss 0.234, val accuracy 0.382, and val rmse 0.133\n",
            "Epoch 8, train loss 0.044, train accuracy 0.536, val loss 0.225, val accuracy 0.460, and val rmse 0.147\n",
            "Epoch 9, train loss 0.042, train accuracy 0.614, val loss 0.216, val accuracy 0.547, and val rmse 0.147\n",
            "Epoch 10, train loss 0.040, train accuracy 0.675, val loss 0.206, val accuracy 0.585, and val rmse 0.080\n",
            "Epoch 11, train loss 0.038, train accuracy 0.627, val loss 0.197, val accuracy 0.590, and val rmse 0.027\n",
            "Epoch 12, train loss 0.042, train accuracy 0.448, val loss 0.221, val accuracy 0.373, and val rmse 0.027\n",
            "Epoch 13, train loss 0.040, train accuracy 0.471, val loss 0.202, val accuracy 0.425, and val rmse 0.187\n",
            "Epoch 14, train loss 0.038, train accuracy 0.578, val loss 0.190, val accuracy 0.532, and val rmse 0.267\n",
            "Epoch 15, train loss 0.038, train accuracy 0.351, val loss 0.196, val accuracy 0.420, and val rmse 0.213\n",
            "Epoch 16, train loss 0.037, train accuracy 0.458, val loss 0.196, val accuracy 0.342, and val rmse 0.267\n",
            "Epoch 17, train loss 0.035, train accuracy 0.536, val loss 0.177, val accuracy 0.491, and val rmse 0.267\n",
            "Epoch 18, train loss 0.034, train accuracy 0.549, val loss 0.173, val accuracy 0.533, and val rmse 0.120\n",
            "Epoch 19, train loss 0.033, train accuracy 0.565, val loss 0.176, val accuracy 0.462, and val rmse 0.120\n",
            "Epoch 20, train loss 0.030, train accuracy 0.640, val loss 0.160, val accuracy 0.562, and val rmse 0.080\n",
            "Epoch 21, train loss 0.028, train accuracy 0.675, val loss 0.148, val accuracy 0.588, and val rmse 0.080\n",
            "Epoch 22, train loss 0.025, train accuracy 0.705, val loss 0.141, val accuracy 0.602, and val rmse 0.053\n",
            "Epoch 23, train loss 0.026, train accuracy 0.727, val loss 0.147, val accuracy 0.650, and val rmse 0.080\n",
            "Epoch 24, train loss 0.025, train accuracy 0.740, val loss 0.130, val accuracy 0.688, and val rmse 0.080\n",
            "Epoch 25, train loss 0.023, train accuracy 0.760, val loss 0.120, val accuracy 0.715, and val rmse 0.053\n",
            "Epoch 26, train loss 0.022, train accuracy 0.779, val loss 0.111, val accuracy 0.715, and val rmse 0.053\n",
            "Epoch 27, train loss 0.021, train accuracy 0.750, val loss 0.104, val accuracy 0.753, and val rmse 0.053\n",
            "Epoch 28, train loss 0.020, train accuracy 0.792, val loss 0.099, val accuracy 0.780, and val rmse 0.053\n",
            "Epoch 29, train loss 0.019, train accuracy 0.828, val loss 0.094, val accuracy 0.779, and val rmse 0.080\n",
            "Epoch 30, train loss 0.018, train accuracy 0.841, val loss 0.099, val accuracy 0.753, and val rmse 0.080\n",
            "Epoch 31, train loss 0.022, train accuracy 0.821, val loss 0.106, val accuracy 0.817, and val rmse 0.080\n",
            "Epoch 32, train loss 0.019, train accuracy 0.851, val loss 0.096, val accuracy 0.780, and val rmse 0.080\n",
            "Epoch 33, train loss 0.018, train accuracy 0.844, val loss 0.088, val accuracy 0.843, and val rmse 0.080\n",
            "Epoch 34, train loss 0.019, train accuracy 0.841, val loss 0.086, val accuracy 0.843, and val rmse 0.080\n",
            "Epoch 35, train loss 0.016, train accuracy 0.857, val loss 0.080, val accuracy 0.868, and val rmse 0.080\n",
            "Epoch 36, train loss 0.017, train accuracy 0.838, val loss 0.078, val accuracy 0.843, and val rmse 0.080\n",
            "Epoch 37, train loss 0.018, train accuracy 0.873, val loss 0.097, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 38, train loss 0.015, train accuracy 0.886, val loss 0.070, val accuracy 0.894, and val rmse 0.080\n",
            "Epoch 39, train loss 0.014, train accuracy 0.906, val loss 0.067, val accuracy 0.908, and val rmse 0.080\n",
            "Epoch 40, train loss 0.014, train accuracy 0.886, val loss 0.067, val accuracy 0.895, and val rmse 0.080\n",
            "Epoch 41, train loss 0.013, train accuracy 0.903, val loss 0.065, val accuracy 0.894, and val rmse 0.080\n",
            "Epoch 42, train loss 0.012, train accuracy 0.909, val loss 0.061, val accuracy 0.894, and val rmse 0.080\n",
            "Epoch 43, train loss 0.011, train accuracy 0.909, val loss 0.052, val accuracy 0.921, and val rmse 0.080\n",
            "Epoch 44, train loss 0.010, train accuracy 0.912, val loss 0.048, val accuracy 0.921, and val rmse 0.080\n",
            "Epoch 45, train loss 0.010, train accuracy 0.925, val loss 0.047, val accuracy 0.921, and val rmse 0.080\n",
            "Epoch 46, train loss 0.009, train accuracy 0.922, val loss 0.045, val accuracy 0.921, and val rmse 0.080\n",
            "Epoch 47, train loss 0.009, train accuracy 0.916, val loss 0.040, val accuracy 0.921, and val rmse 0.080\n",
            "Epoch 48, train loss 0.008, train accuracy 0.932, val loss 0.036, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 49, train loss 0.010, train accuracy 0.922, val loss 0.035, val accuracy 0.987, and val rmse 0.027\n",
            "\n",
            " Iteration number : 61\n",
            "Epoch 0, train loss 0.056, train accuracy 0.266, val loss 0.299, val accuracy 0.158, and val rmse 0.413\n",
            "Epoch 1, train loss 0.053, train accuracy 0.334, val loss 0.272, val accuracy 0.282, and val rmse 0.467\n",
            "Epoch 2, train loss 0.052, train accuracy 0.367, val loss 0.282, val accuracy 0.483, and val rmse 0.467\n",
            "Epoch 3, train loss 0.052, train accuracy 0.409, val loss 0.255, val accuracy 0.331, and val rmse 0.453\n",
            "Epoch 4, train loss 0.050, train accuracy 0.481, val loss 0.249, val accuracy 0.463, and val rmse 0.347\n",
            "Epoch 5, train loss 0.050, train accuracy 0.422, val loss 0.247, val accuracy 0.314, and val rmse 0.240\n",
            "Epoch 6, train loss 0.050, train accuracy 0.269, val loss 0.275, val accuracy 0.248, and val rmse 0.307\n",
            "Epoch 7, train loss 0.048, train accuracy 0.325, val loss 0.256, val accuracy 0.157, and val rmse 0.267\n",
            "Epoch 8, train loss 0.045, train accuracy 0.403, val loss 0.232, val accuracy 0.196, and val rmse 0.280\n",
            "Epoch 9, train loss 0.043, train accuracy 0.445, val loss 0.210, val accuracy 0.293, and val rmse 0.160\n",
            "Epoch 10, train loss 0.041, train accuracy 0.497, val loss 0.212, val accuracy 0.306, and val rmse 0.187\n",
            "Epoch 11, train loss 0.038, train accuracy 0.562, val loss 0.204, val accuracy 0.319, and val rmse 0.107\n",
            "Epoch 12, train loss 0.037, train accuracy 0.679, val loss 0.187, val accuracy 0.368, and val rmse 0.293\n",
            "Epoch 13, train loss 0.035, train accuracy 0.610, val loss 0.197, val accuracy 0.466, and val rmse 0.053\n",
            "Epoch 14, train loss 0.036, train accuracy 0.617, val loss 0.167, val accuracy 0.492, and val rmse 0.000\n",
            "Epoch 15, train loss 0.034, train accuracy 0.731, val loss 0.160, val accuracy 0.623, and val rmse 0.200\n",
            "Epoch 16, train loss 0.033, train accuracy 0.760, val loss 0.198, val accuracy 0.478, and val rmse 0.027\n",
            "Epoch 17, train loss 0.028, train accuracy 0.756, val loss 0.137, val accuracy 0.718, and val rmse 0.027\n",
            "Epoch 18, train loss 0.025, train accuracy 0.795, val loss 0.127, val accuracy 0.742, and val rmse 0.053\n",
            "Epoch 19, train loss 0.024, train accuracy 0.808, val loss 0.119, val accuracy 0.753, and val rmse 0.107\n",
            "Epoch 20, train loss 0.021, train accuracy 0.818, val loss 0.103, val accuracy 0.791, and val rmse 0.107\n",
            "Epoch 21, train loss 0.018, train accuracy 0.890, val loss 0.093, val accuracy 0.790, and val rmse 0.133\n",
            "Epoch 22, train loss 0.021, train accuracy 0.899, val loss 0.085, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 23, train loss 0.020, train accuracy 0.860, val loss 0.090, val accuracy 0.857, and val rmse 0.027\n",
            "Epoch 24, train loss 0.016, train accuracy 0.906, val loss 0.079, val accuracy 0.909, and val rmse 0.027\n",
            "Epoch 25, train loss 0.015, train accuracy 0.932, val loss 0.070, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 26, train loss 0.014, train accuracy 0.929, val loss 0.064, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 27, train loss 0.018, train accuracy 0.857, val loss 0.086, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 28, train loss 0.013, train accuracy 0.938, val loss 0.070, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 29, train loss 0.012, train accuracy 0.961, val loss 0.061, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 30, train loss 0.010, train accuracy 0.955, val loss 0.052, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 31, train loss 0.011, train accuracy 0.909, val loss 0.055, val accuracy 0.883, and val rmse 0.000\n",
            "Epoch 32, train loss 0.009, train accuracy 0.951, val loss 0.046, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 33, train loss 0.009, train accuracy 0.958, val loss 0.045, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 34, train loss 0.008, train accuracy 0.971, val loss 0.044, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 35, train loss 0.007, train accuracy 0.971, val loss 0.039, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 36, train loss 0.007, train accuracy 0.977, val loss 0.054, val accuracy 0.911, and val rmse 0.000\n",
            "Epoch 37, train loss 0.006, train accuracy 0.974, val loss 0.029, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 38, train loss 0.013, train accuracy 0.877, val loss 0.058, val accuracy 0.897, and val rmse 0.013\n",
            "Epoch 39, train loss 0.007, train accuracy 0.974, val loss 0.034, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 40, train loss 0.006, train accuracy 0.974, val loss 0.026, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 41, train loss 0.005, train accuracy 0.981, val loss 0.025, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 42, train loss 0.005, train accuracy 0.977, val loss 0.023, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 43, train loss 0.005, train accuracy 0.977, val loss 0.021, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 44, train loss 0.004, train accuracy 0.981, val loss 0.021, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 45, train loss 0.004, train accuracy 0.981, val loss 0.029, val accuracy 0.949, and val rmse 0.000\n",
            "Epoch 46, train loss 0.004, train accuracy 0.977, val loss 0.028, val accuracy 0.950, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.987, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.984, val loss 0.015, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 49, train loss 0.003, train accuracy 0.987, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 62\n",
            "Epoch 0, train loss 0.055, train accuracy 0.188, val loss 0.265, val accuracy 0.203, and val rmse 0.253\n",
            "Epoch 1, train loss 0.052, train accuracy 0.117, val loss 0.276, val accuracy 0.053, and val rmse 0.200\n",
            "Epoch 2, train loss 0.052, train accuracy 0.201, val loss 0.266, val accuracy 0.199, and val rmse 0.173\n",
            "Epoch 3, train loss 0.050, train accuracy 0.312, val loss 0.260, val accuracy 0.293, and val rmse 0.067\n",
            "Epoch 4, train loss 0.050, train accuracy 0.370, val loss 0.247, val accuracy 0.412, and val rmse 0.027\n",
            "Epoch 5, train loss 0.047, train accuracy 0.458, val loss 0.241, val accuracy 0.425, and val rmse 0.027\n",
            "Epoch 6, train loss 0.044, train accuracy 0.526, val loss 0.228, val accuracy 0.503, and val rmse 0.027\n",
            "Epoch 7, train loss 0.042, train accuracy 0.636, val loss 0.216, val accuracy 0.603, and val rmse 0.027\n",
            "Epoch 8, train loss 0.044, train accuracy 0.448, val loss 0.221, val accuracy 0.488, and val rmse 0.120\n",
            "Epoch 9, train loss 0.039, train accuracy 0.588, val loss 0.201, val accuracy 0.603, and val rmse 0.027\n",
            "Epoch 10, train loss 0.035, train accuracy 0.695, val loss 0.183, val accuracy 0.716, and val rmse 0.027\n",
            "Epoch 11, train loss 0.031, train accuracy 0.795, val loss 0.161, val accuracy 0.818, and val rmse 0.013\n",
            "Epoch 12, train loss 0.029, train accuracy 0.782, val loss 0.145, val accuracy 0.845, and val rmse 0.013\n",
            "Epoch 13, train loss 0.026, train accuracy 0.851, val loss 0.128, val accuracy 0.870, and val rmse 0.013\n",
            "Epoch 14, train loss 0.023, train accuracy 0.899, val loss 0.116, val accuracy 0.896, and val rmse 0.013\n",
            "Epoch 15, train loss 0.021, train accuracy 0.906, val loss 0.108, val accuracy 0.923, and val rmse 0.013\n",
            "Epoch 16, train loss 0.018, train accuracy 0.958, val loss 0.090, val accuracy 0.961, and val rmse 0.013\n",
            "Epoch 17, train loss 0.016, train accuracy 0.951, val loss 0.078, val accuracy 0.973, and val rmse 0.013\n",
            "Epoch 18, train loss 0.014, train accuracy 0.971, val loss 0.077, val accuracy 0.973, and val rmse 0.013\n",
            "Epoch 19, train loss 0.013, train accuracy 0.977, val loss 0.067, val accuracy 0.961, and val rmse 0.013\n",
            "Epoch 20, train loss 0.011, train accuracy 0.974, val loss 0.052, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 21, train loss 0.011, train accuracy 0.974, val loss 0.051, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 22, train loss 0.009, train accuracy 0.984, val loss 0.041, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 23, train loss 0.008, train accuracy 0.977, val loss 0.036, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.008, train accuracy 0.977, val loss 0.045, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.005, train accuracy 0.994, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.005, train accuracy 0.997, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.005, train accuracy 0.997, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.004, train accuracy 1.000, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.003, train accuracy 0.997, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.003, train accuracy 0.990, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.004, train accuracy 0.990, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.003, train accuracy 0.997, val loss 0.024, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 33, train loss 0.002, train accuracy 0.990, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.002, train accuracy 0.990, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 0.990, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 1.000, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 1.000, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.990, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.990, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 63\n",
            "Epoch 0, train loss 0.055, train accuracy 0.234, val loss 0.282, val accuracy 0.163, and val rmse 0.400\n",
            "Epoch 1, train loss 0.051, train accuracy 0.354, val loss 0.263, val accuracy 0.324, and val rmse 0.267\n",
            "Epoch 2, train loss 0.051, train accuracy 0.422, val loss 0.258, val accuracy 0.490, and val rmse 0.027\n",
            "Epoch 3, train loss 0.049, train accuracy 0.451, val loss 0.265, val accuracy 0.490, and val rmse 0.027\n",
            "Epoch 4, train loss 0.048, train accuracy 0.377, val loss 0.252, val accuracy 0.479, and val rmse 0.027\n",
            "Epoch 5, train loss 0.048, train accuracy 0.471, val loss 0.266, val accuracy 0.503, and val rmse 0.027\n",
            "Epoch 6, train loss 0.047, train accuracy 0.575, val loss 0.233, val accuracy 0.641, and val rmse 0.027\n",
            "Epoch 7, train loss 0.044, train accuracy 0.685, val loss 0.227, val accuracy 0.554, and val rmse 0.027\n",
            "Epoch 8, train loss 0.040, train accuracy 0.763, val loss 0.205, val accuracy 0.706, and val rmse 0.027\n",
            "Epoch 9, train loss 0.040, train accuracy 0.620, val loss 0.183, val accuracy 0.733, and val rmse 0.027\n",
            "Epoch 10, train loss 0.038, train accuracy 0.529, val loss 0.188, val accuracy 0.570, and val rmse 0.027\n",
            "Epoch 11, train loss 0.036, train accuracy 0.594, val loss 0.186, val accuracy 0.570, and val rmse 0.027\n",
            "Epoch 12, train loss 0.035, train accuracy 0.627, val loss 0.176, val accuracy 0.583, and val rmse 0.027\n",
            "Epoch 13, train loss 0.033, train accuracy 0.695, val loss 0.165, val accuracy 0.708, and val rmse 0.027\n",
            "Epoch 14, train loss 0.032, train accuracy 0.711, val loss 0.161, val accuracy 0.733, and val rmse 0.027\n",
            "Epoch 15, train loss 0.028, train accuracy 0.786, val loss 0.151, val accuracy 0.745, and val rmse 0.027\n",
            "Epoch 16, train loss 0.026, train accuracy 0.808, val loss 0.137, val accuracy 0.783, and val rmse 0.027\n",
            "Epoch 17, train loss 0.023, train accuracy 0.851, val loss 0.121, val accuracy 0.834, and val rmse 0.027\n",
            "Epoch 18, train loss 0.021, train accuracy 0.847, val loss 0.108, val accuracy 0.859, and val rmse 0.027\n",
            "Epoch 19, train loss 0.020, train accuracy 0.870, val loss 0.095, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 20, train loss 0.018, train accuracy 0.854, val loss 0.086, val accuracy 0.884, and val rmse 0.027\n",
            "Epoch 21, train loss 0.016, train accuracy 0.883, val loss 0.078, val accuracy 0.884, and val rmse 0.027\n",
            "Epoch 22, train loss 0.015, train accuracy 0.909, val loss 0.072, val accuracy 0.898, and val rmse 0.027\n",
            "Epoch 23, train loss 0.014, train accuracy 0.916, val loss 0.067, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 24, train loss 0.014, train accuracy 0.929, val loss 0.062, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 25, train loss 0.011, train accuracy 0.955, val loss 0.056, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 26, train loss 0.011, train accuracy 0.951, val loss 0.051, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 27, train loss 0.010, train accuracy 0.958, val loss 0.049, val accuracy 0.974, and val rmse 0.027\n",
            "Epoch 28, train loss 0.009, train accuracy 0.964, val loss 0.041, val accuracy 0.974, and val rmse 0.027\n",
            "Epoch 29, train loss 0.008, train accuracy 0.961, val loss 0.039, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 30, train loss 0.007, train accuracy 0.977, val loss 0.034, val accuracy 0.974, and val rmse 0.027\n",
            "Epoch 31, train loss 0.007, train accuracy 0.971, val loss 0.030, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 32, train loss 0.006, train accuracy 0.977, val loss 0.026, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 33, train loss 0.005, train accuracy 0.977, val loss 0.029, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 34, train loss 0.005, train accuracy 0.971, val loss 0.020, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 35, train loss 0.004, train accuracy 0.981, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.005, train accuracy 0.974, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.984, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 1.000, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.981, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.990, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.002, train accuracy 0.997, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.008, train accuracy 0.971, val loss 0.037, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 44, train loss 0.008, train accuracy 0.964, val loss 0.032, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 45, train loss 0.005, train accuracy 0.990, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.005, train accuracy 0.990, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.004, train accuracy 0.997, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.004, train accuracy 0.994, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.003, train accuracy 0.997, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 64\n",
            "Epoch 0, train loss 0.054, train accuracy 0.276, val loss 0.273, val accuracy 0.075, and val rmse 0.600\n",
            "Epoch 1, train loss 0.052, train accuracy 0.331, val loss 0.261, val accuracy 0.343, and val rmse 0.387\n",
            "Epoch 2, train loss 0.052, train accuracy 0.373, val loss 0.261, val accuracy 0.343, and val rmse 0.373\n",
            "Epoch 3, train loss 0.051, train accuracy 0.380, val loss 0.256, val accuracy 0.370, and val rmse 0.347\n",
            "Epoch 4, train loss 0.050, train accuracy 0.386, val loss 0.256, val accuracy 0.438, and val rmse 0.120\n",
            "Epoch 5, train loss 0.051, train accuracy 0.341, val loss 0.279, val accuracy 0.027, and val rmse 0.360\n",
            "Epoch 6, train loss 0.049, train accuracy 0.364, val loss 0.252, val accuracy 0.414, and val rmse 0.227\n",
            "Epoch 7, train loss 0.048, train accuracy 0.455, val loss 0.249, val accuracy 0.519, and val rmse 0.107\n",
            "Epoch 8, train loss 0.047, train accuracy 0.477, val loss 0.242, val accuracy 0.343, and val rmse 0.120\n",
            "Epoch 9, train loss 0.045, train accuracy 0.468, val loss 0.235, val accuracy 0.287, and val rmse 0.120\n",
            "Epoch 10, train loss 0.042, train accuracy 0.552, val loss 0.218, val accuracy 0.443, and val rmse 0.067\n",
            "Epoch 11, train loss 0.040, train accuracy 0.607, val loss 0.202, val accuracy 0.571, and val rmse 0.067\n",
            "Epoch 12, train loss 0.038, train accuracy 0.675, val loss 0.196, val accuracy 0.702, and val rmse 0.040\n",
            "Epoch 13, train loss 0.036, train accuracy 0.679, val loss 0.179, val accuracy 0.728, and val rmse 0.040\n",
            "Epoch 14, train loss 0.033, train accuracy 0.750, val loss 0.170, val accuracy 0.781, and val rmse 0.040\n",
            "Epoch 15, train loss 0.032, train accuracy 0.734, val loss 0.161, val accuracy 0.781, and val rmse 0.040\n",
            "Epoch 16, train loss 0.030, train accuracy 0.795, val loss 0.151, val accuracy 0.833, and val rmse 0.027\n",
            "Epoch 17, train loss 0.028, train accuracy 0.773, val loss 0.143, val accuracy 0.833, and val rmse 0.027\n",
            "Epoch 18, train loss 0.027, train accuracy 0.792, val loss 0.133, val accuracy 0.833, and val rmse 0.027\n",
            "Epoch 19, train loss 0.026, train accuracy 0.818, val loss 0.123, val accuracy 0.873, and val rmse 0.000\n",
            "Epoch 20, train loss 0.024, train accuracy 0.838, val loss 0.123, val accuracy 0.860, and val rmse 0.000\n",
            "Epoch 21, train loss 0.022, train accuracy 0.857, val loss 0.110, val accuracy 0.860, and val rmse 0.000\n",
            "Epoch 22, train loss 0.022, train accuracy 0.844, val loss 0.105, val accuracy 0.912, and val rmse 0.000\n",
            "Epoch 23, train loss 0.020, train accuracy 0.896, val loss 0.099, val accuracy 0.912, and val rmse 0.000\n",
            "Epoch 24, train loss 0.019, train accuracy 0.893, val loss 0.090, val accuracy 0.925, and val rmse 0.000\n",
            "Epoch 25, train loss 0.018, train accuracy 0.890, val loss 0.085, val accuracy 0.938, and val rmse 0.000\n",
            "Epoch 26, train loss 0.017, train accuracy 0.906, val loss 0.079, val accuracy 0.950, and val rmse 0.000\n",
            "Epoch 27, train loss 0.017, train accuracy 0.896, val loss 0.076, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 28, train loss 0.015, train accuracy 0.916, val loss 0.069, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 29, train loss 0.014, train accuracy 0.935, val loss 0.067, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 30, train loss 0.014, train accuracy 0.925, val loss 0.060, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 31, train loss 0.013, train accuracy 0.922, val loss 0.056, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 32, train loss 0.013, train accuracy 0.945, val loss 0.057, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 33, train loss 0.011, train accuracy 0.942, val loss 0.051, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 34, train loss 0.010, train accuracy 0.958, val loss 0.045, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 35, train loss 0.010, train accuracy 0.955, val loss 0.043, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 36, train loss 0.008, train accuracy 0.964, val loss 0.038, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 37, train loss 0.008, train accuracy 0.961, val loss 0.036, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 38, train loss 0.008, train accuracy 0.984, val loss 0.031, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 39, train loss 0.007, train accuracy 0.977, val loss 0.030, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.006, train accuracy 0.964, val loss 0.026, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.006, train accuracy 0.977, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.005, train accuracy 0.984, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.005, train accuracy 0.987, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.005, train accuracy 0.994, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.004, train accuracy 0.981, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.004, train accuracy 0.981, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.004, train accuracy 0.981, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.990, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.003, train accuracy 1.000, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 65\n",
            "Epoch 0, train loss 0.054, train accuracy 0.221, val loss 0.274, val accuracy 0.133, and val rmse 0.347\n",
            "Epoch 1, train loss 0.053, train accuracy 0.195, val loss 0.269, val accuracy 0.118, and val rmse 0.387\n",
            "Epoch 2, train loss 0.052, train accuracy 0.185, val loss 0.271, val accuracy 0.260, and val rmse 0.240\n",
            "Epoch 3, train loss 0.049, train accuracy 0.377, val loss 0.274, val accuracy 0.160, and val rmse 0.213\n",
            "Epoch 4, train loss 0.046, train accuracy 0.422, val loss 0.235, val accuracy 0.280, and val rmse 0.120\n",
            "Epoch 5, train loss 0.043, train accuracy 0.565, val loss 0.221, val accuracy 0.450, and val rmse 0.067\n",
            "Epoch 6, train loss 0.040, train accuracy 0.653, val loss 0.228, val accuracy 0.477, and val rmse 0.027\n",
            "Epoch 7, train loss 0.037, train accuracy 0.675, val loss 0.188, val accuracy 0.728, and val rmse 0.027\n",
            "Epoch 8, train loss 0.034, train accuracy 0.675, val loss 0.180, val accuracy 0.702, and val rmse 0.053\n",
            "Epoch 9, train loss 0.033, train accuracy 0.659, val loss 0.162, val accuracy 0.715, and val rmse 0.053\n",
            "Epoch 10, train loss 0.030, train accuracy 0.701, val loss 0.151, val accuracy 0.728, and val rmse 0.053\n",
            "Epoch 11, train loss 0.029, train accuracy 0.701, val loss 0.142, val accuracy 0.728, and val rmse 0.053\n",
            "Epoch 12, train loss 0.026, train accuracy 0.744, val loss 0.133, val accuracy 0.741, and val rmse 0.053\n",
            "Epoch 13, train loss 0.025, train accuracy 0.744, val loss 0.136, val accuracy 0.753, and val rmse 0.053\n",
            "Epoch 14, train loss 0.023, train accuracy 0.769, val loss 0.118, val accuracy 0.753, and val rmse 0.053\n",
            "Epoch 15, train loss 0.022, train accuracy 0.799, val loss 0.107, val accuracy 0.805, and val rmse 0.040\n",
            "Epoch 16, train loss 0.020, train accuracy 0.854, val loss 0.098, val accuracy 0.857, and val rmse 0.027\n",
            "Epoch 17, train loss 0.018, train accuracy 0.854, val loss 0.089, val accuracy 0.882, and val rmse 0.027\n",
            "Epoch 18, train loss 0.018, train accuracy 0.844, val loss 0.088, val accuracy 0.818, and val rmse 0.027\n",
            "Epoch 19, train loss 0.016, train accuracy 0.903, val loss 0.076, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 20, train loss 0.015, train accuracy 0.912, val loss 0.071, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 21, train loss 0.013, train accuracy 0.938, val loss 0.064, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 22, train loss 0.012, train accuracy 0.951, val loss 0.057, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 23, train loss 0.014, train accuracy 0.903, val loss 0.058, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 24, train loss 0.010, train accuracy 0.971, val loss 0.049, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 25, train loss 0.014, train accuracy 0.916, val loss 0.063, val accuracy 0.860, and val rmse 0.027\n",
            "Epoch 26, train loss 0.009, train accuracy 0.964, val loss 0.042, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 27, train loss 0.008, train accuracy 0.968, val loss 0.040, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 28, train loss 0.009, train accuracy 0.968, val loss 0.036, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 29, train loss 0.007, train accuracy 0.951, val loss 0.032, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 30, train loss 0.006, train accuracy 0.984, val loss 0.031, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 31, train loss 0.006, train accuracy 0.994, val loss 0.028, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 32, train loss 0.008, train accuracy 0.971, val loss 0.028, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 33, train loss 0.006, train accuracy 0.955, val loss 0.028, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 34, train loss 0.004, train accuracy 0.997, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.997, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.994, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.994, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.004, train accuracy 0.984, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.997, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.997, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.004, train accuracy 0.968, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.997, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.977, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.003, train accuracy 0.977, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 66\n",
            "Epoch 0, train loss 0.055, train accuracy 0.234, val loss 0.278, val accuracy 0.120, and val rmse 0.440\n",
            "Epoch 1, train loss 0.053, train accuracy 0.244, val loss 0.270, val accuracy 0.093, and val rmse 0.480\n",
            "Epoch 2, train loss 0.052, train accuracy 0.279, val loss 0.269, val accuracy 0.146, and val rmse 0.293\n",
            "Epoch 3, train loss 0.051, train accuracy 0.373, val loss 0.274, val accuracy 0.107, and val rmse 0.320\n",
            "Epoch 4, train loss 0.049, train accuracy 0.448, val loss 0.255, val accuracy 0.133, and val rmse 0.227\n",
            "Epoch 5, train loss 0.047, train accuracy 0.351, val loss 0.252, val accuracy 0.172, and val rmse 0.160\n",
            "Epoch 6, train loss 0.043, train accuracy 0.458, val loss 0.228, val accuracy 0.363, and val rmse 0.267\n",
            "Epoch 7, train loss 0.040, train accuracy 0.604, val loss 0.214, val accuracy 0.610, and val rmse 0.080\n",
            "Epoch 8, train loss 0.038, train accuracy 0.653, val loss 0.200, val accuracy 0.663, and val rmse 0.000\n",
            "Epoch 9, train loss 0.036, train accuracy 0.675, val loss 0.187, val accuracy 0.703, and val rmse 0.000\n",
            "Epoch 10, train loss 0.034, train accuracy 0.734, val loss 0.173, val accuracy 0.728, and val rmse 0.027\n",
            "Epoch 11, train loss 0.032, train accuracy 0.737, val loss 0.180, val accuracy 0.610, and val rmse 0.107\n",
            "Epoch 12, train loss 0.031, train accuracy 0.753, val loss 0.154, val accuracy 0.674, and val rmse 0.107\n",
            "Epoch 13, train loss 0.029, train accuracy 0.779, val loss 0.147, val accuracy 0.674, and val rmse 0.107\n",
            "Epoch 14, train loss 0.027, train accuracy 0.756, val loss 0.139, val accuracy 0.725, and val rmse 0.107\n",
            "Epoch 15, train loss 0.026, train accuracy 0.786, val loss 0.128, val accuracy 0.831, and val rmse 0.000\n",
            "Epoch 16, train loss 0.025, train accuracy 0.779, val loss 0.126, val accuracy 0.750, and val rmse 0.107\n",
            "Epoch 17, train loss 0.023, train accuracy 0.834, val loss 0.118, val accuracy 0.831, and val rmse 0.000\n",
            "Epoch 18, train loss 0.022, train accuracy 0.857, val loss 0.112, val accuracy 0.831, and val rmse 0.000\n",
            "Epoch 19, train loss 0.019, train accuracy 0.906, val loss 0.098, val accuracy 0.882, and val rmse 0.027\n",
            "Epoch 20, train loss 0.017, train accuracy 0.925, val loss 0.087, val accuracy 0.934, and val rmse 0.000\n",
            "Epoch 21, train loss 0.015, train accuracy 0.964, val loss 0.078, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 22, train loss 0.014, train accuracy 0.958, val loss 0.074, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 23, train loss 0.013, train accuracy 0.964, val loss 0.066, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 24, train loss 0.011, train accuracy 0.974, val loss 0.056, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 25, train loss 0.011, train accuracy 0.964, val loss 0.050, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 26, train loss 0.009, train accuracy 0.981, val loss 0.043, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 27, train loss 0.008, train accuracy 0.994, val loss 0.039, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 28, train loss 0.007, train accuracy 0.987, val loss 0.034, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 29, train loss 0.006, train accuracy 0.997, val loss 0.031, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 30, train loss 0.006, train accuracy 0.994, val loss 0.029, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 31, train loss 0.005, train accuracy 0.990, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.008, train accuracy 0.981, val loss 0.033, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 1.000, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.004, train accuracy 0.997, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.003, train accuracy 0.994, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 1.000, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.994, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.994, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.002, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.990, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 67\n",
            "Epoch 0, train loss 0.053, train accuracy 0.282, val loss 0.263, val accuracy 0.176, and val rmse 0.387\n",
            "Epoch 1, train loss 0.050, train accuracy 0.390, val loss 0.252, val accuracy 0.269, and val rmse 0.320\n",
            "Epoch 2, train loss 0.047, train accuracy 0.516, val loss 0.241, val accuracy 0.421, and val rmse 0.253\n",
            "Epoch 3, train loss 0.047, train accuracy 0.510, val loss 0.253, val accuracy 0.515, and val rmse 0.293\n",
            "Epoch 4, train loss 0.044, train accuracy 0.617, val loss 0.236, val accuracy 0.438, and val rmse 0.280\n",
            "Epoch 5, train loss 0.042, train accuracy 0.614, val loss 0.218, val accuracy 0.491, and val rmse 0.200\n",
            "Epoch 6, train loss 0.038, train accuracy 0.649, val loss 0.201, val accuracy 0.622, and val rmse 0.147\n",
            "Epoch 7, train loss 0.037, train accuracy 0.669, val loss 0.204, val accuracy 0.607, and val rmse 0.147\n",
            "Epoch 8, train loss 0.034, train accuracy 0.727, val loss 0.176, val accuracy 0.698, and val rmse 0.200\n",
            "Epoch 9, train loss 0.032, train accuracy 0.731, val loss 0.164, val accuracy 0.723, and val rmse 0.173\n",
            "Epoch 10, train loss 0.029, train accuracy 0.769, val loss 0.149, val accuracy 0.777, and val rmse 0.160\n",
            "Epoch 11, train loss 0.027, train accuracy 0.776, val loss 0.136, val accuracy 0.803, and val rmse 0.160\n",
            "Epoch 12, train loss 0.025, train accuracy 0.795, val loss 0.128, val accuracy 0.803, and val rmse 0.160\n",
            "Epoch 13, train loss 0.023, train accuracy 0.828, val loss 0.115, val accuracy 0.816, and val rmse 0.133\n",
            "Epoch 14, train loss 0.023, train accuracy 0.831, val loss 0.129, val accuracy 0.751, and val rmse 0.173\n",
            "Epoch 15, train loss 0.020, train accuracy 0.870, val loss 0.111, val accuracy 0.855, and val rmse 0.133\n",
            "Epoch 16, train loss 0.019, train accuracy 0.893, val loss 0.100, val accuracy 0.855, and val rmse 0.133\n",
            "Epoch 17, train loss 0.028, train accuracy 0.695, val loss 0.121, val accuracy 0.555, and val rmse 0.120\n",
            "Epoch 18, train loss 0.018, train accuracy 0.825, val loss 0.116, val accuracy 0.735, and val rmse 0.147\n",
            "Epoch 19, train loss 0.016, train accuracy 0.909, val loss 0.073, val accuracy 0.935, and val rmse 0.053\n",
            "Epoch 20, train loss 0.013, train accuracy 0.945, val loss 0.065, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 21, train loss 0.012, train accuracy 0.945, val loss 0.060, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 22, train loss 0.011, train accuracy 0.945, val loss 0.054, val accuracy 0.974, and val rmse 0.027\n",
            "Epoch 23, train loss 0.010, train accuracy 0.951, val loss 0.049, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.011, train accuracy 0.912, val loss 0.044, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.009, train accuracy 0.977, val loss 0.039, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.008, train accuracy 0.977, val loss 0.037, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.008, train accuracy 0.968, val loss 0.040, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.006, train accuracy 0.994, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.005, train accuracy 0.990, val loss 0.026, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.005, train accuracy 0.987, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.007, train accuracy 0.968, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.005, train accuracy 0.987, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.997, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.004, train accuracy 0.997, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.990, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.984, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.994, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 1.000, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.994, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.004, train accuracy 0.987, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.994, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.987, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 68\n",
            "Epoch 0, train loss 0.053, train accuracy 0.218, val loss 0.265, val accuracy 0.283, and val rmse 0.400\n",
            "Epoch 1, train loss 0.051, train accuracy 0.302, val loss 0.262, val accuracy 0.192, and val rmse 0.400\n",
            "Epoch 2, train loss 0.049, train accuracy 0.539, val loss 0.252, val accuracy 0.404, and val rmse 0.253\n",
            "Epoch 3, train loss 0.047, train accuracy 0.487, val loss 0.255, val accuracy 0.372, and val rmse 0.133\n",
            "Epoch 4, train loss 0.044, train accuracy 0.500, val loss 0.244, val accuracy 0.285, and val rmse 0.227\n",
            "Epoch 5, train loss 0.043, train accuracy 0.513, val loss 0.239, val accuracy 0.343, and val rmse 0.093\n",
            "Epoch 6, train loss 0.040, train accuracy 0.597, val loss 0.206, val accuracy 0.624, and val rmse 0.013\n",
            "Epoch 7, train loss 0.037, train accuracy 0.633, val loss 0.201, val accuracy 0.575, and val rmse 0.040\n",
            "Epoch 8, train loss 0.035, train accuracy 0.633, val loss 0.181, val accuracy 0.677, and val rmse 0.013\n",
            "Epoch 9, train loss 0.032, train accuracy 0.659, val loss 0.166, val accuracy 0.677, and val rmse 0.013\n",
            "Epoch 10, train loss 0.030, train accuracy 0.649, val loss 0.154, val accuracy 0.663, and val rmse 0.040\n",
            "Epoch 11, train loss 0.028, train accuracy 0.649, val loss 0.143, val accuracy 0.610, and val rmse 0.147\n",
            "Epoch 12, train loss 0.026, train accuracy 0.640, val loss 0.137, val accuracy 0.610, and val rmse 0.147\n",
            "Epoch 13, train loss 0.025, train accuracy 0.669, val loss 0.127, val accuracy 0.623, and val rmse 0.173\n",
            "Epoch 14, train loss 0.023, train accuracy 0.675, val loss 0.125, val accuracy 0.623, and val rmse 0.173\n",
            "Epoch 15, train loss 0.022, train accuracy 0.711, val loss 0.119, val accuracy 0.650, and val rmse 0.147\n",
            "Epoch 16, train loss 0.020, train accuracy 0.744, val loss 0.115, val accuracy 0.570, and val rmse 0.133\n",
            "Epoch 17, train loss 0.019, train accuracy 0.789, val loss 0.104, val accuracy 0.595, and val rmse 0.133\n",
            "Epoch 18, train loss 0.018, train accuracy 0.779, val loss 0.094, val accuracy 0.728, and val rmse 0.107\n",
            "Epoch 19, train loss 0.017, train accuracy 0.802, val loss 0.118, val accuracy 0.653, and val rmse 0.107\n",
            "Epoch 20, train loss 0.016, train accuracy 0.802, val loss 0.083, val accuracy 0.741, and val rmse 0.080\n",
            "Epoch 21, train loss 0.015, train accuracy 0.860, val loss 0.077, val accuracy 0.844, and val rmse 0.080\n",
            "Epoch 22, train loss 0.014, train accuracy 0.886, val loss 0.070, val accuracy 0.870, and val rmse 0.053\n",
            "Epoch 23, train loss 0.013, train accuracy 0.870, val loss 0.065, val accuracy 0.896, and val rmse 0.027\n",
            "Epoch 24, train loss 0.013, train accuracy 0.916, val loss 0.062, val accuracy 0.910, and val rmse 0.027\n",
            "Epoch 25, train loss 0.012, train accuracy 0.899, val loss 0.063, val accuracy 0.897, and val rmse 0.027\n",
            "Epoch 26, train loss 0.011, train accuracy 0.925, val loss 0.056, val accuracy 0.923, and val rmse 0.027\n",
            "Epoch 27, train loss 0.010, train accuracy 0.925, val loss 0.053, val accuracy 0.923, and val rmse 0.027\n",
            "Epoch 28, train loss 0.010, train accuracy 0.932, val loss 0.059, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 29, train loss 0.009, train accuracy 0.958, val loss 0.043, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 30, train loss 0.008, train accuracy 0.964, val loss 0.035, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 31, train loss 0.007, train accuracy 0.945, val loss 0.030, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 32, train loss 0.009, train accuracy 0.929, val loss 0.033, val accuracy 0.974, and val rmse 0.027\n",
            "Epoch 33, train loss 0.005, train accuracy 0.981, val loss 0.024, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 34, train loss 0.005, train accuracy 0.961, val loss 0.021, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 35, train loss 0.004, train accuracy 0.987, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.994, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.997, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.994, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.004, train accuracy 0.987, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.004, train accuracy 0.987, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.987, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.987, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.990, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 69\n",
            "Epoch 0, train loss 0.054, train accuracy 0.315, val loss 0.283, val accuracy 0.147, and val rmse 0.373\n",
            "Epoch 1, train loss 0.051, train accuracy 0.341, val loss 0.277, val accuracy 0.267, and val rmse 0.053\n",
            "Epoch 2, train loss 0.048, train accuracy 0.380, val loss 0.249, val accuracy 0.333, and val rmse 0.027\n",
            "Epoch 3, train loss 0.044, train accuracy 0.581, val loss 0.239, val accuracy 0.463, and val rmse 0.000\n",
            "Epoch 4, train loss 0.041, train accuracy 0.679, val loss 0.208, val accuracy 0.663, and val rmse 0.000\n",
            "Epoch 5, train loss 0.037, train accuracy 0.718, val loss 0.193, val accuracy 0.690, and val rmse 0.027\n",
            "Epoch 6, train loss 0.034, train accuracy 0.740, val loss 0.177, val accuracy 0.743, and val rmse 0.013\n",
            "Epoch 7, train loss 0.032, train accuracy 0.750, val loss 0.169, val accuracy 0.783, and val rmse 0.013\n",
            "Epoch 8, train loss 0.029, train accuracy 0.760, val loss 0.149, val accuracy 0.782, and val rmse 0.013\n",
            "Epoch 9, train loss 0.026, train accuracy 0.795, val loss 0.128, val accuracy 0.808, and val rmse 0.013\n",
            "Epoch 10, train loss 0.024, train accuracy 0.812, val loss 0.115, val accuracy 0.832, and val rmse 0.013\n",
            "Epoch 11, train loss 0.021, train accuracy 0.854, val loss 0.107, val accuracy 0.859, and val rmse 0.000\n",
            "Epoch 12, train loss 0.019, train accuracy 0.834, val loss 0.096, val accuracy 0.884, and val rmse 0.000\n",
            "Epoch 13, train loss 0.017, train accuracy 0.828, val loss 0.087, val accuracy 0.857, and val rmse 0.053\n",
            "Epoch 14, train loss 0.016, train accuracy 0.867, val loss 0.080, val accuracy 0.896, and val rmse 0.053\n",
            "Epoch 15, train loss 0.015, train accuracy 0.890, val loss 0.076, val accuracy 0.921, and val rmse 0.053\n",
            "Epoch 16, train loss 0.014, train accuracy 0.909, val loss 0.064, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 17, train loss 0.013, train accuracy 0.925, val loss 0.058, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 18, train loss 0.012, train accuracy 0.925, val loss 0.053, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 19, train loss 0.010, train accuracy 0.958, val loss 0.046, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 20, train loss 0.009, train accuracy 0.968, val loss 0.041, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 21, train loss 0.008, train accuracy 0.968, val loss 0.051, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 22, train loss 0.007, train accuracy 0.964, val loss 0.032, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 23, train loss 0.006, train accuracy 0.984, val loss 0.029, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 24, train loss 0.006, train accuracy 0.984, val loss 0.025, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 25, train loss 0.005, train accuracy 0.987, val loss 0.022, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 26, train loss 0.004, train accuracy 0.981, val loss 0.019, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 27, train loss 0.004, train accuracy 0.981, val loss 0.017, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 28, train loss 0.004, train accuracy 0.977, val loss 0.015, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 29, train loss 0.003, train accuracy 0.981, val loss 0.013, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 30, train loss 0.003, train accuracy 0.984, val loss 0.012, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 31, train loss 0.002, train accuracy 0.994, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.003, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.001, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.005, train accuracy 0.984, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.997, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 1.000, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.994, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 0.997, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.990, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.990, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.990, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 70\n",
            "Epoch 0, train loss 0.054, train accuracy 0.172, val loss 0.270, val accuracy 0.038, and val rmse 0.227\n",
            "Epoch 1, train loss 0.053, train accuracy 0.185, val loss 0.270, val accuracy 0.347, and val rmse 0.027\n",
            "Epoch 2, train loss 0.052, train accuracy 0.347, val loss 0.264, val accuracy 0.170, and val rmse 0.240\n",
            "Epoch 3, train loss 0.048, train accuracy 0.390, val loss 0.267, val accuracy 0.320, and val rmse 0.053\n",
            "Epoch 4, train loss 0.044, train accuracy 0.513, val loss 0.230, val accuracy 0.497, and val rmse 0.053\n",
            "Epoch 5, train loss 0.041, train accuracy 0.617, val loss 0.238, val accuracy 0.368, and val rmse 0.027\n",
            "Epoch 6, train loss 0.041, train accuracy 0.604, val loss 0.245, val accuracy 0.252, and val rmse 0.267\n",
            "Epoch 7, train loss 0.034, train accuracy 0.692, val loss 0.179, val accuracy 0.673, and val rmse 0.187\n",
            "Epoch 8, train loss 0.031, train accuracy 0.705, val loss 0.178, val accuracy 0.563, and val rmse 0.160\n",
            "Epoch 9, train loss 0.027, train accuracy 0.744, val loss 0.149, val accuracy 0.728, and val rmse 0.133\n",
            "Epoch 10, train loss 0.024, train accuracy 0.786, val loss 0.121, val accuracy 0.818, and val rmse 0.080\n",
            "Epoch 11, train loss 0.022, train accuracy 0.828, val loss 0.139, val accuracy 0.707, and val rmse 0.053\n",
            "Epoch 12, train loss 0.019, train accuracy 0.860, val loss 0.096, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 13, train loss 0.019, train accuracy 0.834, val loss 0.130, val accuracy 0.697, and val rmse 0.000\n",
            "Epoch 14, train loss 0.016, train accuracy 0.883, val loss 0.079, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 15, train loss 0.016, train accuracy 0.890, val loss 0.074, val accuracy 0.898, and val rmse 0.000\n",
            "Epoch 16, train loss 0.014, train accuracy 0.909, val loss 0.065, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 17, train loss 0.012, train accuracy 0.938, val loss 0.059, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 18, train loss 0.011, train accuracy 0.961, val loss 0.054, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 19, train loss 0.015, train accuracy 0.880, val loss 0.118, val accuracy 0.748, and val rmse 0.000\n",
            "Epoch 20, train loss 0.014, train accuracy 0.864, val loss 0.065, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 21, train loss 0.013, train accuracy 0.880, val loss 0.061, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 22, train loss 0.013, train accuracy 0.877, val loss 0.059, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 23, train loss 0.012, train accuracy 0.877, val loss 0.076, val accuracy 0.848, and val rmse 0.000\n",
            "Epoch 24, train loss 0.011, train accuracy 0.880, val loss 0.054, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 25, train loss 0.011, train accuracy 0.877, val loss 0.053, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 26, train loss 0.010, train accuracy 0.883, val loss 0.054, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 27, train loss 0.010, train accuracy 0.877, val loss 0.068, val accuracy 0.848, and val rmse 0.000\n",
            "Epoch 28, train loss 0.011, train accuracy 0.870, val loss 0.049, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 29, train loss 0.010, train accuracy 0.883, val loss 0.047, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 30, train loss 0.011, train accuracy 0.854, val loss 0.090, val accuracy 0.722, and val rmse 0.000\n",
            "Epoch 31, train loss 0.010, train accuracy 0.870, val loss 0.060, val accuracy 0.848, and val rmse 0.000\n",
            "Epoch 32, train loss 0.009, train accuracy 0.883, val loss 0.046, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 33, train loss 0.010, train accuracy 0.873, val loss 0.047, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 34, train loss 0.010, train accuracy 0.873, val loss 0.046, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 35, train loss 0.009, train accuracy 0.880, val loss 0.043, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 36, train loss 0.008, train accuracy 0.883, val loss 0.042, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 37, train loss 0.008, train accuracy 0.883, val loss 0.042, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 38, train loss 0.009, train accuracy 0.883, val loss 0.041, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 39, train loss 0.008, train accuracy 0.880, val loss 0.041, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 40, train loss 0.008, train accuracy 0.873, val loss 0.041, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 41, train loss 0.008, train accuracy 0.880, val loss 0.040, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 42, train loss 0.007, train accuracy 0.883, val loss 0.037, val accuracy 0.885, and val rmse 0.000\n",
            "Epoch 43, train loss 0.007, train accuracy 0.903, val loss 0.037, val accuracy 0.884, and val rmse 0.027\n",
            "Epoch 44, train loss 0.007, train accuracy 0.899, val loss 0.033, val accuracy 0.910, and val rmse 0.000\n",
            "Epoch 45, train loss 0.006, train accuracy 0.919, val loss 0.029, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 46, train loss 0.008, train accuracy 0.922, val loss 0.031, val accuracy 0.909, and val rmse 0.027\n",
            "Epoch 47, train loss 0.005, train accuracy 0.945, val loss 0.024, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 48, train loss 0.005, train accuracy 0.932, val loss 0.026, val accuracy 0.910, and val rmse 0.000\n",
            "Epoch 49, train loss 0.004, train accuracy 0.958, val loss 0.018, val accuracy 0.962, and val rmse 0.000\n",
            "\n",
            " Iteration number : 71\n",
            "Epoch 0, train loss 0.053, train accuracy 0.205, val loss 0.283, val accuracy 0.013, and val rmse 0.280\n",
            "Epoch 1, train loss 0.050, train accuracy 0.308, val loss 0.265, val accuracy 0.065, and val rmse 0.267\n",
            "Epoch 2, train loss 0.051, train accuracy 0.308, val loss 0.293, val accuracy 0.175, and val rmse 0.600\n",
            "Epoch 3, train loss 0.046, train accuracy 0.425, val loss 0.223, val accuracy 0.463, and val rmse 0.120\n",
            "Epoch 4, train loss 0.041, train accuracy 0.539, val loss 0.213, val accuracy 0.583, and val rmse 0.107\n",
            "Epoch 5, train loss 0.037, train accuracy 0.601, val loss 0.194, val accuracy 0.583, and val rmse 0.107\n",
            "Epoch 6, train loss 0.034, train accuracy 0.591, val loss 0.175, val accuracy 0.650, and val rmse 0.053\n",
            "Epoch 7, train loss 0.031, train accuracy 0.627, val loss 0.166, val accuracy 0.570, and val rmse 0.093\n",
            "Epoch 8, train loss 0.028, train accuracy 0.656, val loss 0.144, val accuracy 0.677, and val rmse 0.027\n",
            "Epoch 9, train loss 0.027, train accuracy 0.669, val loss 0.137, val accuracy 0.637, and val rmse 0.080\n",
            "Epoch 10, train loss 0.028, train accuracy 0.649, val loss 0.207, val accuracy 0.477, and val rmse 0.027\n",
            "Epoch 11, train loss 0.024, train accuracy 0.675, val loss 0.122, val accuracy 0.663, and val rmse 0.053\n",
            "Epoch 12, train loss 0.023, train accuracy 0.688, val loss 0.114, val accuracy 0.690, and val rmse 0.013\n",
            "Epoch 13, train loss 0.024, train accuracy 0.669, val loss 0.111, val accuracy 0.703, and val rmse 0.013\n",
            "Epoch 14, train loss 0.021, train accuracy 0.601, val loss 0.104, val accuracy 0.597, and val rmse 0.240\n",
            "Epoch 15, train loss 0.021, train accuracy 0.610, val loss 0.102, val accuracy 0.609, and val rmse 0.240\n",
            "Epoch 16, train loss 0.019, train accuracy 0.672, val loss 0.094, val accuracy 0.622, and val rmse 0.240\n",
            "Epoch 17, train loss 0.018, train accuracy 0.659, val loss 0.092, val accuracy 0.476, and val rmse 0.240\n",
            "Epoch 18, train loss 0.018, train accuracy 0.666, val loss 0.086, val accuracy 0.502, and val rmse 0.240\n",
            "Epoch 19, train loss 0.019, train accuracy 0.610, val loss 0.096, val accuracy 0.501, and val rmse 0.227\n",
            "Epoch 20, train loss 0.017, train accuracy 0.640, val loss 0.084, val accuracy 0.463, and val rmse 0.240\n",
            "Epoch 21, train loss 0.017, train accuracy 0.653, val loss 0.082, val accuracy 0.529, and val rmse 0.240\n",
            "Epoch 22, train loss 0.016, train accuracy 0.646, val loss 0.079, val accuracy 0.630, and val rmse 0.240\n",
            "Epoch 23, train loss 0.015, train accuracy 0.679, val loss 0.076, val accuracy 0.641, and val rmse 0.240\n",
            "Epoch 24, train loss 0.015, train accuracy 0.682, val loss 0.073, val accuracy 0.613, and val rmse 0.240\n",
            "Epoch 25, train loss 0.022, train accuracy 0.662, val loss 0.157, val accuracy 0.535, and val rmse 0.240\n",
            "Epoch 26, train loss 0.022, train accuracy 0.685, val loss 0.107, val accuracy 0.602, and val rmse 0.240\n",
            "Epoch 27, train loss 0.018, train accuracy 0.724, val loss 0.097, val accuracy 0.708, and val rmse 0.240\n",
            "Epoch 28, train loss 0.018, train accuracy 0.747, val loss 0.089, val accuracy 0.733, and val rmse 0.240\n",
            "Epoch 29, train loss 0.018, train accuracy 0.750, val loss 0.088, val accuracy 0.733, and val rmse 0.240\n",
            "Epoch 30, train loss 0.016, train accuracy 0.744, val loss 0.082, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 31, train loss 0.017, train accuracy 0.740, val loss 0.082, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 32, train loss 0.016, train accuracy 0.737, val loss 0.079, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 33, train loss 0.029, train accuracy 0.526, val loss 0.286, val accuracy 0.288, and val rmse 0.120\n",
            "Epoch 34, train loss 0.020, train accuracy 0.640, val loss 0.090, val accuracy 0.734, and val rmse 0.240\n",
            "Epoch 35, train loss 0.016, train accuracy 0.753, val loss 0.081, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 36, train loss 0.016, train accuracy 0.744, val loss 0.077, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 37, train loss 0.015, train accuracy 0.750, val loss 0.075, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 38, train loss 0.014, train accuracy 0.750, val loss 0.074, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 39, train loss 0.014, train accuracy 0.753, val loss 0.074, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 40, train loss 0.014, train accuracy 0.753, val loss 0.073, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 41, train loss 0.013, train accuracy 0.753, val loss 0.070, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 42, train loss 0.014, train accuracy 0.692, val loss 0.067, val accuracy 0.593, and val rmse 0.240\n",
            "Epoch 43, train loss 0.012, train accuracy 0.750, val loss 0.060, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 44, train loss 0.011, train accuracy 0.753, val loss 0.063, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 45, train loss 0.011, train accuracy 0.750, val loss 0.058, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 46, train loss 0.011, train accuracy 0.753, val loss 0.056, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 47, train loss 0.012, train accuracy 0.750, val loss 0.055, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 48, train loss 0.010, train accuracy 0.753, val loss 0.054, val accuracy 0.747, and val rmse 0.240\n",
            "Epoch 49, train loss 0.010, train accuracy 0.753, val loss 0.053, val accuracy 0.747, and val rmse 0.240\n",
            "\n",
            " Iteration number : 72\n",
            "Epoch 0, train loss 0.052, train accuracy 0.354, val loss 0.269, val accuracy 0.102, and val rmse 0.347\n",
            "Epoch 1, train loss 0.046, train accuracy 0.552, val loss 0.244, val accuracy 0.581, and val rmse 0.133\n",
            "Epoch 2, train loss 0.040, train accuracy 0.623, val loss 0.233, val accuracy 0.461, and val rmse 0.240\n",
            "Epoch 3, train loss 0.036, train accuracy 0.708, val loss 0.195, val accuracy 0.573, and val rmse 0.093\n",
            "Epoch 4, train loss 0.034, train accuracy 0.659, val loss 0.203, val accuracy 0.503, and val rmse 0.080\n",
            "Epoch 5, train loss 0.028, train accuracy 0.792, val loss 0.131, val accuracy 0.893, and val rmse 0.080\n",
            "Epoch 6, train loss 0.023, train accuracy 0.857, val loss 0.128, val accuracy 0.894, and val rmse 0.067\n",
            "Epoch 7, train loss 0.019, train accuracy 0.951, val loss 0.107, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 8, train loss 0.016, train accuracy 0.961, val loss 0.076, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 9, train loss 0.012, train accuracy 0.987, val loss 0.067, val accuracy 0.987, and val rmse 0.013\n",
            "Epoch 10, train loss 0.010, train accuracy 0.977, val loss 0.071, val accuracy 0.912, and val rmse 0.013\n",
            "Epoch 11, train loss 0.010, train accuracy 0.961, val loss 0.043, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 12, train loss 0.007, train accuracy 0.981, val loss 0.035, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 13, train loss 0.006, train accuracy 0.984, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 14, train loss 0.005, train accuracy 0.990, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 15, train loss 0.006, train accuracy 0.981, val loss 0.110, val accuracy 0.812, and val rmse 0.000\n",
            "Epoch 16, train loss 0.004, train accuracy 0.997, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 17, train loss 0.004, train accuracy 0.997, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 18, train loss 0.003, train accuracy 1.000, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 19, train loss 0.005, train accuracy 0.977, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 20, train loss 0.003, train accuracy 0.994, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 21, train loss 0.002, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 22, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 23, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.001, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.000, train accuracy 0.997, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.004, train accuracy 0.981, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 0.994, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.000, train accuracy 0.997, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.000, train accuracy 0.997, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 73\n",
            "Epoch 0, train loss 0.054, train accuracy 0.266, val loss 0.274, val accuracy 0.283, and val rmse 0.373\n",
            "Epoch 1, train loss 0.052, train accuracy 0.308, val loss 0.291, val accuracy 0.088, and val rmse 0.507\n",
            "Epoch 2, train loss 0.050, train accuracy 0.334, val loss 0.265, val accuracy 0.171, and val rmse 0.320\n",
            "Epoch 3, train loss 0.046, train accuracy 0.422, val loss 0.239, val accuracy 0.384, and val rmse 0.160\n",
            "Epoch 4, train loss 0.044, train accuracy 0.506, val loss 0.233, val accuracy 0.410, and val rmse 0.200\n",
            "Epoch 5, train loss 0.038, train accuracy 0.620, val loss 0.227, val accuracy 0.425, and val rmse 0.000\n",
            "Epoch 6, train loss 0.033, train accuracy 0.659, val loss 0.175, val accuracy 0.628, and val rmse 0.000\n",
            "Epoch 7, train loss 0.030, train accuracy 0.708, val loss 0.150, val accuracy 0.702, and val rmse 0.027\n",
            "Epoch 8, train loss 0.025, train accuracy 0.682, val loss 0.125, val accuracy 0.691, and val rmse 0.027\n",
            "Epoch 9, train loss 0.022, train accuracy 0.708, val loss 0.115, val accuracy 0.636, and val rmse 0.133\n",
            "Epoch 10, train loss 0.019, train accuracy 0.734, val loss 0.098, val accuracy 0.714, and val rmse 0.053\n",
            "Epoch 11, train loss 0.018, train accuracy 0.760, val loss 0.091, val accuracy 0.673, and val rmse 0.160\n",
            "Epoch 12, train loss 0.018, train accuracy 0.779, val loss 0.087, val accuracy 0.647, and val rmse 0.213\n",
            "Epoch 13, train loss 0.016, train accuracy 0.779, val loss 0.082, val accuracy 0.697, and val rmse 0.240\n",
            "Epoch 14, train loss 0.016, train accuracy 0.782, val loss 0.078, val accuracy 0.723, and val rmse 0.213\n",
            "Epoch 15, train loss 0.014, train accuracy 0.808, val loss 0.070, val accuracy 0.763, and val rmse 0.133\n",
            "Epoch 16, train loss 0.013, train accuracy 0.838, val loss 0.066, val accuracy 0.803, and val rmse 0.133\n",
            "Epoch 17, train loss 0.013, train accuracy 0.831, val loss 0.065, val accuracy 0.856, and val rmse 0.053\n",
            "Epoch 18, train loss 0.012, train accuracy 0.886, val loss 0.059, val accuracy 0.908, and val rmse 0.000\n",
            "Epoch 19, train loss 0.011, train accuracy 0.886, val loss 0.056, val accuracy 0.934, and val rmse 0.000\n",
            "Epoch 20, train loss 0.010, train accuracy 0.912, val loss 0.050, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 21, train loss 0.010, train accuracy 0.922, val loss 0.047, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 22, train loss 0.008, train accuracy 0.945, val loss 0.039, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 23, train loss 0.007, train accuracy 0.958, val loss 0.035, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.008, train accuracy 0.951, val loss 0.032, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.007, train accuracy 0.971, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.007, train accuracy 0.971, val loss 0.041, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.006, train accuracy 0.990, val loss 0.029, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.006, train accuracy 0.984, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.005, train accuracy 0.977, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.005, train accuracy 0.994, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.004, train accuracy 0.990, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.004, train accuracy 0.984, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.981, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.003, train accuracy 0.994, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.003, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.994, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.990, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.994, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.997, val loss 0.013, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.990, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.997, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 74\n",
            "Epoch 0, train loss 0.054, train accuracy 0.256, val loss 0.274, val accuracy 0.188, and val rmse 0.560\n",
            "Epoch 1, train loss 0.052, train accuracy 0.383, val loss 0.273, val accuracy 0.253, and val rmse 0.120\n",
            "Epoch 2, train loss 0.052, train accuracy 0.149, val loss 0.268, val accuracy 0.200, and val rmse 0.120\n",
            "Epoch 3, train loss 0.050, train accuracy 0.354, val loss 0.278, val accuracy 0.051, and val rmse 0.200\n",
            "Epoch 4, train loss 0.047, train accuracy 0.519, val loss 0.263, val accuracy 0.386, and val rmse 0.053\n",
            "Epoch 5, train loss 0.042, train accuracy 0.617, val loss 0.237, val accuracy 0.562, and val rmse 0.013\n",
            "Epoch 6, train loss 0.036, train accuracy 0.646, val loss 0.193, val accuracy 0.614, and val rmse 0.053\n",
            "Epoch 7, train loss 0.034, train accuracy 0.692, val loss 0.174, val accuracy 0.703, and val rmse 0.053\n",
            "Epoch 8, train loss 0.032, train accuracy 0.737, val loss 0.165, val accuracy 0.755, and val rmse 0.013\n",
            "Epoch 9, train loss 0.030, train accuracy 0.737, val loss 0.156, val accuracy 0.692, and val rmse 0.027\n",
            "Epoch 10, train loss 0.025, train accuracy 0.857, val loss 0.122, val accuracy 0.833, and val rmse 0.040\n",
            "Epoch 11, train loss 0.021, train accuracy 0.919, val loss 0.113, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 12, train loss 0.018, train accuracy 0.922, val loss 0.089, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 13, train loss 0.021, train accuracy 0.896, val loss 0.088, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 14, train loss 0.016, train accuracy 0.961, val loss 0.080, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 15, train loss 0.013, train accuracy 0.961, val loss 0.063, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 16, train loss 0.014, train accuracy 0.942, val loss 0.101, val accuracy 0.824, and val rmse 0.027\n",
            "Epoch 17, train loss 0.013, train accuracy 0.919, val loss 0.070, val accuracy 0.899, and val rmse 0.027\n",
            "Epoch 18, train loss 0.009, train accuracy 0.974, val loss 0.044, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 19, train loss 0.012, train accuracy 0.925, val loss 0.074, val accuracy 0.887, and val rmse 0.027\n",
            "Epoch 20, train loss 0.007, train accuracy 0.977, val loss 0.036, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 21, train loss 0.006, train accuracy 0.981, val loss 0.031, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 22, train loss 0.006, train accuracy 0.977, val loss 0.029, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 23, train loss 0.006, train accuracy 0.974, val loss 0.025, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 24, train loss 0.004, train accuracy 0.987, val loss 0.021, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 25, train loss 0.004, train accuracy 0.987, val loss 0.017, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 26, train loss 0.004, train accuracy 0.984, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.003, train accuracy 0.990, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.013, train accuracy 0.955, val loss 0.058, val accuracy 0.911, and val rmse 0.027\n",
            "Epoch 29, train loss 0.009, train accuracy 0.955, val loss 0.031, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 30, train loss 0.005, train accuracy 0.984, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.004, train accuracy 0.987, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.004, train accuracy 1.000, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.994, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.003, train accuracy 1.000, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.002, train accuracy 1.000, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.990, val loss 0.037, val accuracy 0.900, and val rmse 0.000\n",
            "Epoch 37, train loss 0.002, train accuracy 0.997, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 0.994, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.997, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 75\n",
            "Epoch 0, train loss 0.053, train accuracy 0.357, val loss 0.274, val accuracy 0.172, and val rmse 0.400\n",
            "Epoch 1, train loss 0.052, train accuracy 0.442, val loss 0.270, val accuracy 0.354, and val rmse 0.307\n",
            "Epoch 2, train loss 0.049, train accuracy 0.523, val loss 0.259, val accuracy 0.307, and val rmse 0.253\n",
            "Epoch 3, train loss 0.047, train accuracy 0.597, val loss 0.249, val accuracy 0.291, and val rmse 0.240\n",
            "Epoch 4, train loss 0.044, train accuracy 0.659, val loss 0.244, val accuracy 0.509, and val rmse 0.160\n",
            "Epoch 5, train loss 0.042, train accuracy 0.721, val loss 0.228, val accuracy 0.623, and val rmse 0.160\n",
            "Epoch 6, train loss 0.038, train accuracy 0.731, val loss 0.217, val accuracy 0.583, and val rmse 0.160\n",
            "Epoch 7, train loss 0.035, train accuracy 0.731, val loss 0.190, val accuracy 0.660, and val rmse 0.133\n",
            "Epoch 8, train loss 0.032, train accuracy 0.779, val loss 0.174, val accuracy 0.725, and val rmse 0.107\n",
            "Epoch 9, train loss 0.030, train accuracy 0.769, val loss 0.164, val accuracy 0.737, and val rmse 0.133\n",
            "Epoch 10, train loss 0.028, train accuracy 0.808, val loss 0.153, val accuracy 0.738, and val rmse 0.160\n",
            "Epoch 11, train loss 0.026, train accuracy 0.825, val loss 0.138, val accuracy 0.816, and val rmse 0.160\n",
            "Epoch 12, train loss 0.024, train accuracy 0.857, val loss 0.125, val accuracy 0.855, and val rmse 0.133\n",
            "Epoch 13, train loss 0.022, train accuracy 0.893, val loss 0.115, val accuracy 0.895, and val rmse 0.053\n",
            "Epoch 14, train loss 0.029, train accuracy 0.731, val loss 0.190, val accuracy 0.646, and val rmse 0.053\n",
            "Epoch 15, train loss 0.025, train accuracy 0.854, val loss 0.126, val accuracy 0.869, and val rmse 0.053\n",
            "Epoch 16, train loss 0.022, train accuracy 0.899, val loss 0.108, val accuracy 0.921, and val rmse 0.053\n",
            "Epoch 17, train loss 0.020, train accuracy 0.906, val loss 0.103, val accuracy 0.897, and val rmse 0.027\n",
            "Epoch 18, train loss 0.017, train accuracy 0.929, val loss 0.086, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 19, train loss 0.016, train accuracy 0.942, val loss 0.078, val accuracy 0.962, and val rmse 0.027\n",
            "Epoch 20, train loss 0.016, train accuracy 0.945, val loss 0.068, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 21, train loss 0.014, train accuracy 0.968, val loss 0.066, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 22, train loss 0.013, train accuracy 0.955, val loss 0.058, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 23, train loss 0.011, train accuracy 0.971, val loss 0.052, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 24, train loss 0.011, train accuracy 0.968, val loss 0.047, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 25, train loss 0.009, train accuracy 0.981, val loss 0.042, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 26, train loss 0.008, train accuracy 0.977, val loss 0.037, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 27, train loss 0.008, train accuracy 0.977, val loss 0.033, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.007, train accuracy 0.984, val loss 0.029, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.006, train accuracy 0.994, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.005, train accuracy 0.997, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.009, train accuracy 0.981, val loss 0.038, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.007, train accuracy 0.974, val loss 0.029, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.006, train accuracy 0.981, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.004, train accuracy 0.994, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.005, train accuracy 0.984, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.990, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.984, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 1.000, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.997, val loss 0.031, val accuracy 0.900, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.997, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.987, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.997, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.990, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.994, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 76\n",
            "Epoch 0, train loss 0.054, train accuracy 0.351, val loss 0.262, val accuracy 0.391, and val rmse 0.320\n",
            "Epoch 1, train loss 0.051, train accuracy 0.419, val loss 0.267, val accuracy 0.372, and val rmse 0.600\n",
            "Epoch 2, train loss 0.047, train accuracy 0.591, val loss 0.265, val accuracy 0.442, and val rmse 0.213\n",
            "Epoch 3, train loss 0.043, train accuracy 0.662, val loss 0.228, val accuracy 0.531, and val rmse 0.187\n",
            "Epoch 4, train loss 0.040, train accuracy 0.679, val loss 0.212, val accuracy 0.593, and val rmse 0.120\n",
            "Epoch 5, train loss 0.039, train accuracy 0.688, val loss 0.217, val accuracy 0.583, and val rmse 0.067\n",
            "Epoch 6, train loss 0.038, train accuracy 0.662, val loss 0.223, val accuracy 0.508, and val rmse 0.067\n",
            "Epoch 7, train loss 0.036, train accuracy 0.705, val loss 0.192, val accuracy 0.570, and val rmse 0.080\n",
            "Epoch 8, train loss 0.034, train accuracy 0.708, val loss 0.172, val accuracy 0.663, and val rmse 0.067\n",
            "Epoch 9, train loss 0.031, train accuracy 0.763, val loss 0.164, val accuracy 0.712, and val rmse 0.067\n",
            "Epoch 10, train loss 0.030, train accuracy 0.760, val loss 0.156, val accuracy 0.740, and val rmse 0.067\n",
            "Epoch 11, train loss 0.028, train accuracy 0.769, val loss 0.146, val accuracy 0.727, and val rmse 0.067\n",
            "Epoch 12, train loss 0.028, train accuracy 0.766, val loss 0.142, val accuracy 0.714, and val rmse 0.067\n",
            "Epoch 13, train loss 0.026, train accuracy 0.805, val loss 0.131, val accuracy 0.739, and val rmse 0.067\n",
            "Epoch 14, train loss 0.024, train accuracy 0.805, val loss 0.124, val accuracy 0.765, and val rmse 0.040\n",
            "Epoch 15, train loss 0.023, train accuracy 0.831, val loss 0.114, val accuracy 0.829, and val rmse 0.027\n",
            "Epoch 16, train loss 0.022, train accuracy 0.828, val loss 0.107, val accuracy 0.856, and val rmse 0.027\n",
            "Epoch 17, train loss 0.020, train accuracy 0.854, val loss 0.100, val accuracy 0.869, and val rmse 0.027\n",
            "Epoch 18, train loss 0.019, train accuracy 0.886, val loss 0.103, val accuracy 0.869, and val rmse 0.027\n",
            "Epoch 19, train loss 0.018, train accuracy 0.873, val loss 0.086, val accuracy 0.895, and val rmse 0.027\n",
            "Epoch 20, train loss 0.016, train accuracy 0.883, val loss 0.090, val accuracy 0.857, and val rmse 0.027\n",
            "Epoch 21, train loss 0.015, train accuracy 0.896, val loss 0.068, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 22, train loss 0.014, train accuracy 0.896, val loss 0.063, val accuracy 0.922, and val rmse 0.027\n",
            "Epoch 23, train loss 0.013, train accuracy 0.912, val loss 0.181, val accuracy 0.734, and val rmse 0.027\n",
            "Epoch 24, train loss 0.011, train accuracy 0.922, val loss 0.051, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 25, train loss 0.009, train accuracy 0.938, val loss 0.046, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 26, train loss 0.009, train accuracy 0.951, val loss 0.042, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 27, train loss 0.009, train accuracy 0.945, val loss 0.041, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 28, train loss 0.007, train accuracy 0.971, val loss 0.037, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 29, train loss 0.007, train accuracy 0.984, val loss 0.031, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.007, train accuracy 0.974, val loss 0.033, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 31, train loss 0.005, train accuracy 0.984, val loss 0.029, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.006, train accuracy 0.974, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.990, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.004, train accuracy 0.990, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.990, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.994, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.984, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.004, train accuracy 0.981, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.990, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 0.990, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.005, train accuracy 0.981, val loss 0.014, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.990, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.005, train accuracy 0.964, val loss 0.025, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 49, train loss 0.003, train accuracy 0.997, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 77\n",
            "Epoch 0, train loss 0.054, train accuracy 0.244, val loss 0.268, val accuracy 0.297, and val rmse 0.360\n",
            "Epoch 1, train loss 0.052, train accuracy 0.260, val loss 0.263, val accuracy 0.156, and val rmse 0.320\n",
            "Epoch 2, train loss 0.052, train accuracy 0.328, val loss 0.264, val accuracy 0.253, and val rmse 0.160\n",
            "Epoch 3, train loss 0.051, train accuracy 0.341, val loss 0.262, val accuracy 0.173, and val rmse 0.160\n",
            "Epoch 4, train loss 0.049, train accuracy 0.380, val loss 0.260, val accuracy 0.330, and val rmse 0.160\n",
            "Epoch 5, train loss 0.047, train accuracy 0.490, val loss 0.243, val accuracy 0.328, and val rmse 0.147\n",
            "Epoch 6, train loss 0.044, train accuracy 0.584, val loss 0.230, val accuracy 0.443, and val rmse 0.133\n",
            "Epoch 7, train loss 0.043, train accuracy 0.581, val loss 0.215, val accuracy 0.477, and val rmse 0.160\n",
            "Epoch 8, train loss 0.040, train accuracy 0.682, val loss 0.214, val accuracy 0.648, and val rmse 0.120\n",
            "Epoch 9, train loss 0.037, train accuracy 0.714, val loss 0.197, val accuracy 0.698, and val rmse 0.147\n",
            "Epoch 10, train loss 0.035, train accuracy 0.731, val loss 0.179, val accuracy 0.698, and val rmse 0.173\n",
            "Epoch 11, train loss 0.032, train accuracy 0.773, val loss 0.163, val accuracy 0.763, and val rmse 0.107\n",
            "Epoch 12, train loss 0.030, train accuracy 0.802, val loss 0.159, val accuracy 0.763, and val rmse 0.080\n",
            "Epoch 13, train loss 0.028, train accuracy 0.763, val loss 0.146, val accuracy 0.802, and val rmse 0.093\n",
            "Epoch 14, train loss 0.025, train accuracy 0.854, val loss 0.129, val accuracy 0.854, and val rmse 0.067\n",
            "Epoch 15, train loss 0.024, train accuracy 0.825, val loss 0.117, val accuracy 0.881, and val rmse 0.040\n",
            "Epoch 16, train loss 0.022, train accuracy 0.851, val loss 0.110, val accuracy 0.894, and val rmse 0.013\n",
            "Epoch 17, train loss 0.021, train accuracy 0.854, val loss 0.104, val accuracy 0.841, and val rmse 0.093\n",
            "Epoch 18, train loss 0.021, train accuracy 0.838, val loss 0.111, val accuracy 0.748, and val rmse 0.227\n",
            "Epoch 19, train loss 0.021, train accuracy 0.731, val loss 0.099, val accuracy 0.761, and val rmse 0.187\n",
            "Epoch 20, train loss 0.019, train accuracy 0.773, val loss 0.091, val accuracy 0.828, and val rmse 0.120\n",
            "Epoch 21, train loss 0.019, train accuracy 0.815, val loss 0.086, val accuracy 0.841, and val rmse 0.120\n",
            "Epoch 22, train loss 0.017, train accuracy 0.844, val loss 0.081, val accuracy 0.868, and val rmse 0.067\n",
            "Epoch 23, train loss 0.016, train accuracy 0.873, val loss 0.077, val accuracy 0.894, and val rmse 0.040\n",
            "Epoch 24, train loss 0.016, train accuracy 0.899, val loss 0.075, val accuracy 0.933, and val rmse 0.027\n",
            "Epoch 25, train loss 0.015, train accuracy 0.906, val loss 0.070, val accuracy 0.920, and val rmse 0.027\n",
            "Epoch 26, train loss 0.014, train accuracy 0.919, val loss 0.066, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 27, train loss 0.013, train accuracy 0.925, val loss 0.064, val accuracy 0.947, and val rmse 0.000\n",
            "Epoch 28, train loss 0.012, train accuracy 0.938, val loss 0.060, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 29, train loss 0.013, train accuracy 0.909, val loss 0.057, val accuracy 0.947, and val rmse 0.000\n",
            "Epoch 30, train loss 0.011, train accuracy 0.938, val loss 0.055, val accuracy 0.947, and val rmse 0.000\n",
            "Epoch 31, train loss 0.011, train accuracy 0.932, val loss 0.053, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 32, train loss 0.010, train accuracy 0.932, val loss 0.049, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 33, train loss 0.011, train accuracy 0.951, val loss 0.052, val accuracy 0.947, and val rmse 0.000\n",
            "Epoch 34, train loss 0.009, train accuracy 0.981, val loss 0.042, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.008, train accuracy 0.971, val loss 0.039, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.008, train accuracy 0.968, val loss 0.036, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.007, train accuracy 0.971, val loss 0.032, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.006, train accuracy 0.990, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.005, train accuracy 0.994, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.006, train accuracy 0.981, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.004, train accuracy 0.997, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 1.000, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.994, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.994, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.003, train accuracy 0.990, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.987, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.984, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.990, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 78\n",
            "Epoch 0, train loss 0.057, train accuracy 0.269, val loss 0.283, val accuracy 0.263, and val rmse 0.600\n",
            "Epoch 1, train loss 0.053, train accuracy 0.347, val loss 0.268, val accuracy 0.227, and val rmse 0.227\n",
            "Epoch 2, train loss 0.049, train accuracy 0.464, val loss 0.255, val accuracy 0.409, and val rmse 0.027\n",
            "Epoch 3, train loss 0.047, train accuracy 0.571, val loss 0.243, val accuracy 0.435, and val rmse 0.040\n",
            "Epoch 4, train loss 0.045, train accuracy 0.506, val loss 0.234, val accuracy 0.369, and val rmse 0.067\n",
            "Epoch 5, train loss 0.043, train accuracy 0.536, val loss 0.235, val accuracy 0.289, and val rmse 0.027\n",
            "Epoch 6, train loss 0.041, train accuracy 0.555, val loss 0.226, val accuracy 0.486, and val rmse 0.027\n",
            "Epoch 7, train loss 0.039, train accuracy 0.588, val loss 0.221, val accuracy 0.433, and val rmse 0.053\n",
            "Epoch 8, train loss 0.037, train accuracy 0.659, val loss 0.198, val accuracy 0.701, and val rmse 0.027\n",
            "Epoch 9, train loss 0.035, train accuracy 0.685, val loss 0.185, val accuracy 0.688, and val rmse 0.027\n",
            "Epoch 10, train loss 0.034, train accuracy 0.666, val loss 0.173, val accuracy 0.688, and val rmse 0.027\n",
            "Epoch 11, train loss 0.031, train accuracy 0.724, val loss 0.168, val accuracy 0.702, and val rmse 0.027\n",
            "Epoch 12, train loss 0.029, train accuracy 0.747, val loss 0.154, val accuracy 0.741, and val rmse 0.013\n",
            "Epoch 13, train loss 0.027, train accuracy 0.795, val loss 0.144, val accuracy 0.793, and val rmse 0.000\n",
            "Epoch 14, train loss 0.026, train accuracy 0.825, val loss 0.135, val accuracy 0.817, and val rmse 0.000\n",
            "Epoch 15, train loss 0.023, train accuracy 0.893, val loss 0.123, val accuracy 0.870, and val rmse 0.000\n",
            "Epoch 16, train loss 0.022, train accuracy 0.922, val loss 0.108, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 17, train loss 0.019, train accuracy 0.961, val loss 0.098, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 18, train loss 0.018, train accuracy 0.968, val loss 0.090, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 19, train loss 0.017, train accuracy 0.981, val loss 0.084, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 20, train loss 0.015, train accuracy 0.984, val loss 0.077, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 21, train loss 0.015, train accuracy 0.994, val loss 0.069, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 22, train loss 0.014, train accuracy 0.997, val loss 0.065, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 23, train loss 0.013, train accuracy 0.987, val loss 0.063, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 24, train loss 0.011, train accuracy 0.997, val loss 0.057, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.010, train accuracy 0.994, val loss 0.049, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.009, train accuracy 0.997, val loss 0.048, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.008, train accuracy 0.990, val loss 0.041, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.008, train accuracy 0.997, val loss 0.037, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.007, train accuracy 0.994, val loss 0.032, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.006, train accuracy 0.997, val loss 0.029, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.006, train accuracy 0.997, val loss 0.028, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.005, train accuracy 0.997, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.005, train accuracy 0.997, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.004, train accuracy 1.000, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 1.000, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.994, val loss 0.028, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.990, val loss 0.020, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.994, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.004, train accuracy 0.984, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 1.000, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.002, train accuracy 0.990, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.997, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 79\n",
            "Epoch 0, train loss 0.054, train accuracy 0.354, val loss 0.278, val accuracy 0.234, and val rmse 0.347\n",
            "Epoch 1, train loss 0.050, train accuracy 0.416, val loss 0.253, val accuracy 0.587, and val rmse 0.133\n",
            "Epoch 2, train loss 0.047, train accuracy 0.468, val loss 0.243, val accuracy 0.447, and val rmse 0.227\n",
            "Epoch 3, train loss 0.047, train accuracy 0.458, val loss 0.241, val accuracy 0.464, and val rmse 0.040\n",
            "Epoch 4, train loss 0.042, train accuracy 0.688, val loss 0.218, val accuracy 0.690, and val rmse 0.120\n",
            "Epoch 5, train loss 0.039, train accuracy 0.666, val loss 0.195, val accuracy 0.673, and val rmse 0.227\n",
            "Epoch 6, train loss 0.037, train accuracy 0.597, val loss 0.204, val accuracy 0.558, and val rmse 0.253\n",
            "Epoch 7, train loss 0.033, train accuracy 0.675, val loss 0.169, val accuracy 0.737, and val rmse 0.253\n",
            "Epoch 8, train loss 0.047, train accuracy 0.334, val loss 0.252, val accuracy 0.304, and val rmse 0.200\n",
            "Epoch 9, train loss 0.043, train accuracy 0.403, val loss 0.232, val accuracy 0.435, and val rmse 0.227\n",
            "Epoch 10, train loss 0.040, train accuracy 0.487, val loss 0.201, val accuracy 0.422, and val rmse 0.253\n",
            "Epoch 11, train loss 0.029, train accuracy 0.747, val loss 0.159, val accuracy 0.751, and val rmse 0.173\n",
            "Epoch 12, train loss 0.026, train accuracy 0.851, val loss 0.128, val accuracy 0.920, and val rmse 0.053\n",
            "Epoch 13, train loss 0.023, train accuracy 0.893, val loss 0.112, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 14, train loss 0.021, train accuracy 0.886, val loss 0.107, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 15, train loss 0.020, train accuracy 0.912, val loss 0.095, val accuracy 0.947, and val rmse 0.053\n",
            "Epoch 16, train loss 0.018, train accuracy 0.919, val loss 0.087, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 17, train loss 0.016, train accuracy 0.938, val loss 0.075, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 18, train loss 0.014, train accuracy 0.958, val loss 0.066, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 19, train loss 0.013, train accuracy 0.974, val loss 0.064, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 20, train loss 0.013, train accuracy 0.955, val loss 0.069, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 21, train loss 0.012, train accuracy 0.958, val loss 0.051, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 22, train loss 0.010, train accuracy 0.977, val loss 0.048, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 23, train loss 0.009, train accuracy 0.971, val loss 0.043, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.008, train accuracy 0.981, val loss 0.046, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 25, train loss 0.010, train accuracy 0.951, val loss 0.035, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.006, train accuracy 1.000, val loss 0.030, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.007, train accuracy 0.981, val loss 0.030, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.006, train accuracy 0.990, val loss 0.027, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.005, train accuracy 0.997, val loss 0.025, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.006, train accuracy 0.987, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.005, train accuracy 0.984, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.004, train accuracy 0.984, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.987, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.004, train accuracy 0.981, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.003, train accuracy 0.997, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.984, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.977, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.994, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.002, train accuracy 0.987, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.987, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.974, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.990, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.994, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 80\n",
            "Epoch 0, train loss 0.054, train accuracy 0.253, val loss 0.268, val accuracy 0.310, and val rmse 0.347\n",
            "Epoch 1, train loss 0.052, train accuracy 0.360, val loss 0.280, val accuracy 0.147, and val rmse 0.253\n",
            "Epoch 2, train loss 0.051, train accuracy 0.357, val loss 0.258, val accuracy 0.133, and val rmse 0.267\n",
            "Epoch 3, train loss 0.048, train accuracy 0.565, val loss 0.247, val accuracy 0.412, and val rmse 0.027\n",
            "Epoch 4, train loss 0.045, train accuracy 0.562, val loss 0.231, val accuracy 0.451, and val rmse 0.027\n",
            "Epoch 5, train loss 0.039, train accuracy 0.802, val loss 0.192, val accuracy 0.818, and val rmse 0.027\n",
            "Epoch 6, train loss 0.038, train accuracy 0.818, val loss 0.176, val accuracy 0.884, and val rmse 0.027\n",
            "Epoch 7, train loss 0.041, train accuracy 0.607, val loss 0.218, val accuracy 0.410, and val rmse 0.027\n",
            "Epoch 8, train loss 0.038, train accuracy 0.552, val loss 0.189, val accuracy 0.453, and val rmse 0.013\n",
            "Epoch 9, train loss 0.034, train accuracy 0.649, val loss 0.169, val accuracy 0.590, and val rmse 0.013\n",
            "Epoch 10, train loss 0.030, train accuracy 0.705, val loss 0.154, val accuracy 0.678, and val rmse 0.013\n",
            "Epoch 11, train loss 0.028, train accuracy 0.799, val loss 0.141, val accuracy 0.782, and val rmse 0.027\n",
            "Epoch 12, train loss 0.026, train accuracy 0.873, val loss 0.124, val accuracy 0.897, and val rmse 0.000\n",
            "Epoch 13, train loss 0.024, train accuracy 0.896, val loss 0.134, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 14, train loss 0.022, train accuracy 0.942, val loss 0.128, val accuracy 0.908, and val rmse 0.027\n",
            "Epoch 15, train loss 0.021, train accuracy 0.938, val loss 0.110, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 16, train loss 0.020, train accuracy 0.938, val loss 0.106, val accuracy 0.898, and val rmse 0.027\n",
            "Epoch 17, train loss 0.018, train accuracy 0.951, val loss 0.094, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 18, train loss 0.016, train accuracy 0.968, val loss 0.073, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 19, train loss 0.013, train accuracy 0.987, val loss 0.066, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 20, train loss 0.015, train accuracy 0.951, val loss 0.070, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 21, train loss 0.013, train accuracy 0.968, val loss 0.066, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 22, train loss 0.011, train accuracy 0.987, val loss 0.056, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 23, train loss 0.010, train accuracy 0.974, val loss 0.047, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 24, train loss 0.009, train accuracy 0.984, val loss 0.045, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 25, train loss 0.008, train accuracy 0.987, val loss 0.037, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 26, train loss 0.007, train accuracy 0.987, val loss 0.036, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 27, train loss 0.006, train accuracy 0.984, val loss 0.031, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 28, train loss 0.006, train accuracy 0.987, val loss 0.028, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 29, train loss 0.010, train accuracy 0.912, val loss 0.034, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 30, train loss 0.005, train accuracy 0.977, val loss 0.026, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 31, train loss 0.005, train accuracy 0.971, val loss 0.025, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 32, train loss 0.004, train accuracy 0.987, val loss 0.021, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.987, val loss 0.019, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 34, train loss 0.004, train accuracy 0.987, val loss 0.018, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.977, val loss 0.017, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.977, val loss 0.015, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.987, val loss 0.017, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.987, val loss 0.012, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 0.987, val loss 0.011, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 40, train loss 0.005, train accuracy 0.968, val loss 0.039, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 41, train loss 0.003, train accuracy 0.981, val loss 0.015, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.987, val loss 0.010, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 43, train loss 0.005, train accuracy 0.958, val loss 0.012, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.990, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.990, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.994, val loss 0.043, val accuracy 0.800, and val rmse 0.000\n",
            "\n",
            " Iteration number : 81\n",
            "Epoch 0, train loss 0.052, train accuracy 0.286, val loss 0.262, val accuracy 0.258, and val rmse 0.413\n",
            "Epoch 1, train loss 0.050, train accuracy 0.231, val loss 0.257, val accuracy 0.315, and val rmse 0.160\n",
            "Epoch 2, train loss 0.049, train accuracy 0.328, val loss 0.261, val accuracy 0.160, and val rmse 0.133\n",
            "Epoch 3, train loss 0.048, train accuracy 0.321, val loss 0.255, val accuracy 0.373, and val rmse 0.053\n",
            "Epoch 4, train loss 0.047, train accuracy 0.445, val loss 0.257, val accuracy 0.360, and val rmse 0.200\n",
            "Epoch 5, train loss 0.041, train accuracy 0.571, val loss 0.222, val accuracy 0.437, and val rmse 0.053\n",
            "Epoch 6, train loss 0.036, train accuracy 0.643, val loss 0.186, val accuracy 0.664, and val rmse 0.053\n",
            "Epoch 7, train loss 0.032, train accuracy 0.685, val loss 0.178, val accuracy 0.652, and val rmse 0.053\n",
            "Epoch 8, train loss 0.029, train accuracy 0.682, val loss 0.158, val accuracy 0.652, and val rmse 0.027\n",
            "Epoch 9, train loss 0.027, train accuracy 0.701, val loss 0.142, val accuracy 0.717, and val rmse 0.000\n",
            "Epoch 10, train loss 0.025, train accuracy 0.669, val loss 0.126, val accuracy 0.717, and val rmse 0.000\n",
            "Epoch 11, train loss 0.024, train accuracy 0.653, val loss 0.121, val accuracy 0.583, and val rmse 0.187\n",
            "Epoch 12, train loss 0.023, train accuracy 0.675, val loss 0.112, val accuracy 0.677, and val rmse 0.080\n",
            "Epoch 13, train loss 0.021, train accuracy 0.718, val loss 0.103, val accuracy 0.677, and val rmse 0.080\n",
            "Epoch 14, train loss 0.031, train accuracy 0.682, val loss 0.190, val accuracy 0.615, and val rmse 0.000\n",
            "Epoch 15, train loss 0.027, train accuracy 0.721, val loss 0.135, val accuracy 0.728, and val rmse 0.000\n",
            "Epoch 16, train loss 0.025, train accuracy 0.698, val loss 0.135, val accuracy 0.715, and val rmse 0.000\n",
            "Epoch 17, train loss 0.023, train accuracy 0.769, val loss 0.114, val accuracy 0.742, and val rmse 0.000\n",
            "Epoch 18, train loss 0.021, train accuracy 0.812, val loss 0.101, val accuracy 0.768, and val rmse 0.027\n",
            "Epoch 19, train loss 0.019, train accuracy 0.854, val loss 0.093, val accuracy 0.780, and val rmse 0.080\n",
            "Epoch 20, train loss 0.017, train accuracy 0.870, val loss 0.090, val accuracy 0.844, and val rmse 0.053\n",
            "Epoch 21, train loss 0.017, train accuracy 0.844, val loss 0.079, val accuracy 0.898, and val rmse 0.053\n",
            "Epoch 22, train loss 0.015, train accuracy 0.880, val loss 0.074, val accuracy 0.898, and val rmse 0.053\n",
            "Epoch 23, train loss 0.015, train accuracy 0.805, val loss 0.078, val accuracy 0.755, and val rmse 0.027\n",
            "Epoch 24, train loss 0.014, train accuracy 0.838, val loss 0.072, val accuracy 0.768, and val rmse 0.053\n",
            "Epoch 25, train loss 0.013, train accuracy 0.844, val loss 0.062, val accuracy 0.883, and val rmse 0.053\n",
            "Epoch 26, train loss 0.011, train accuracy 0.912, val loss 0.059, val accuracy 0.897, and val rmse 0.053\n",
            "Epoch 27, train loss 0.011, train accuracy 0.903, val loss 0.055, val accuracy 0.909, and val rmse 0.053\n",
            "Epoch 28, train loss 0.011, train accuracy 0.916, val loss 0.051, val accuracy 0.923, and val rmse 0.053\n",
            "Epoch 29, train loss 0.010, train accuracy 0.906, val loss 0.049, val accuracy 0.923, and val rmse 0.053\n",
            "Epoch 30, train loss 0.010, train accuracy 0.948, val loss 0.046, val accuracy 0.923, and val rmse 0.053\n",
            "Epoch 31, train loss 0.009, train accuracy 0.942, val loss 0.044, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 32, train loss 0.008, train accuracy 0.938, val loss 0.042, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 33, train loss 0.008, train accuracy 0.964, val loss 0.045, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 34, train loss 0.007, train accuracy 0.968, val loss 0.038, val accuracy 0.961, and val rmse 0.027\n",
            "Epoch 35, train loss 0.007, train accuracy 0.955, val loss 0.033, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 36, train loss 0.006, train accuracy 0.977, val loss 0.030, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 37, train loss 0.006, train accuracy 0.971, val loss 0.027, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 38, train loss 0.005, train accuracy 0.977, val loss 0.021, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 39, train loss 0.006, train accuracy 0.964, val loss 0.054, val accuracy 0.887, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.981, val loss 0.017, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.990, val loss 0.015, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.987, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.990, val loss 0.012, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.994, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.977, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 82\n",
            "Epoch 0, train loss 0.050, train accuracy 0.367, val loss 0.263, val accuracy 0.283, and val rmse 0.400\n",
            "Epoch 1, train loss 0.043, train accuracy 0.497, val loss 0.241, val accuracy 0.357, and val rmse 0.320\n",
            "Epoch 2, train loss 0.039, train accuracy 0.506, val loss 0.203, val accuracy 0.463, and val rmse 0.200\n",
            "Epoch 3, train loss 0.037, train accuracy 0.529, val loss 0.191, val accuracy 0.530, and val rmse 0.187\n",
            "Epoch 4, train loss 0.035, train accuracy 0.591, val loss 0.183, val accuracy 0.623, and val rmse 0.027\n",
            "Epoch 5, train loss 0.033, train accuracy 0.653, val loss 0.166, val accuracy 0.677, and val rmse 0.027\n",
            "Epoch 6, train loss 0.031, train accuracy 0.610, val loss 0.157, val accuracy 0.637, and val rmse 0.053\n",
            "Epoch 7, train loss 0.029, train accuracy 0.623, val loss 0.147, val accuracy 0.663, and val rmse 0.027\n",
            "Epoch 8, train loss 0.027, train accuracy 0.610, val loss 0.141, val accuracy 0.623, and val rmse 0.093\n",
            "Epoch 9, train loss 0.026, train accuracy 0.640, val loss 0.136, val accuracy 0.650, and val rmse 0.040\n",
            "Epoch 10, train loss 0.026, train accuracy 0.633, val loss 0.142, val accuracy 0.677, and val rmse 0.027\n",
            "Epoch 11, train loss 0.023, train accuracy 0.688, val loss 0.124, val accuracy 0.650, and val rmse 0.080\n",
            "Epoch 12, train loss 0.022, train accuracy 0.623, val loss 0.116, val accuracy 0.635, and val rmse 0.160\n",
            "Epoch 13, train loss 0.022, train accuracy 0.630, val loss 0.108, val accuracy 0.543, and val rmse 0.360\n",
            "Epoch 14, train loss 0.021, train accuracy 0.630, val loss 0.104, val accuracy 0.529, and val rmse 0.360\n",
            "Epoch 15, train loss 0.019, train accuracy 0.653, val loss 0.096, val accuracy 0.754, and val rmse 0.000\n",
            "Epoch 16, train loss 0.020, train accuracy 0.646, val loss 0.095, val accuracy 0.594, and val rmse 0.320\n",
            "Epoch 17, train loss 0.018, train accuracy 0.653, val loss 0.091, val accuracy 0.594, and val rmse 0.320\n",
            "Epoch 18, train loss 0.019, train accuracy 0.653, val loss 0.150, val accuracy 0.457, and val rmse 0.320\n",
            "Epoch 19, train loss 0.017, train accuracy 0.679, val loss 0.085, val accuracy 0.608, and val rmse 0.320\n",
            "Epoch 20, train loss 0.019, train accuracy 0.666, val loss 0.083, val accuracy 0.728, and val rmse 0.080\n",
            "Epoch 21, train loss 0.016, train accuracy 0.682, val loss 0.081, val accuracy 0.608, and val rmse 0.347\n",
            "Epoch 22, train loss 0.015, train accuracy 0.679, val loss 0.079, val accuracy 0.608, and val rmse 0.347\n",
            "Epoch 23, train loss 0.016, train accuracy 0.672, val loss 0.077, val accuracy 0.608, and val rmse 0.347\n",
            "Epoch 24, train loss 0.015, train accuracy 0.685, val loss 0.076, val accuracy 0.608, and val rmse 0.347\n",
            "Epoch 25, train loss 0.015, train accuracy 0.711, val loss 0.074, val accuracy 0.608, and val rmse 0.347\n",
            "Epoch 26, train loss 0.014, train accuracy 0.701, val loss 0.071, val accuracy 0.674, and val rmse 0.267\n",
            "Epoch 27, train loss 0.014, train accuracy 0.724, val loss 0.070, val accuracy 0.767, and val rmse 0.080\n",
            "Epoch 28, train loss 0.015, train accuracy 0.666, val loss 0.069, val accuracy 0.621, and val rmse 0.373\n",
            "Epoch 29, train loss 0.014, train accuracy 0.721, val loss 0.068, val accuracy 0.674, and val rmse 0.267\n",
            "Epoch 30, train loss 0.013, train accuracy 0.737, val loss 0.068, val accuracy 0.754, and val rmse 0.107\n",
            "Epoch 31, train loss 0.013, train accuracy 0.763, val loss 0.066, val accuracy 0.794, and val rmse 0.027\n",
            "Epoch 32, train loss 0.012, train accuracy 0.795, val loss 0.063, val accuracy 0.808, and val rmse 0.027\n",
            "Epoch 33, train loss 0.012, train accuracy 0.789, val loss 0.062, val accuracy 0.781, and val rmse 0.080\n",
            "Epoch 34, train loss 0.012, train accuracy 0.789, val loss 0.063, val accuracy 0.781, and val rmse 0.053\n",
            "Epoch 35, train loss 0.012, train accuracy 0.828, val loss 0.057, val accuracy 0.845, and val rmse 0.053\n",
            "Epoch 36, train loss 0.011, train accuracy 0.834, val loss 0.055, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 37, train loss 0.010, train accuracy 0.851, val loss 0.052, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 38, train loss 0.010, train accuracy 0.867, val loss 0.050, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 39, train loss 0.010, train accuracy 0.867, val loss 0.046, val accuracy 0.910, and val rmse 0.000\n",
            "Epoch 40, train loss 0.008, train accuracy 0.886, val loss 0.043, val accuracy 0.910, and val rmse 0.000\n",
            "Epoch 41, train loss 0.008, train accuracy 0.896, val loss 0.040, val accuracy 0.910, and val rmse 0.000\n",
            "Epoch 42, train loss 0.008, train accuracy 0.899, val loss 0.038, val accuracy 0.910, and val rmse 0.000\n",
            "Epoch 43, train loss 0.008, train accuracy 0.886, val loss 0.037, val accuracy 0.910, and val rmse 0.000\n",
            "Epoch 44, train loss 0.007, train accuracy 0.912, val loss 0.034, val accuracy 0.910, and val rmse 0.000\n",
            "Epoch 45, train loss 0.010, train accuracy 0.857, val loss 0.081, val accuracy 0.817, and val rmse 0.027\n",
            "Epoch 46, train loss 0.006, train accuracy 0.929, val loss 0.029, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 47, train loss 0.006, train accuracy 0.932, val loss 0.028, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 48, train loss 0.007, train accuracy 0.912, val loss 0.025, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 49, train loss 0.005, train accuracy 0.929, val loss 0.025, val accuracy 0.923, and val rmse 0.000\n",
            "\n",
            " Iteration number : 83\n",
            "Epoch 0, train loss 0.054, train accuracy 0.260, val loss 0.276, val accuracy 0.283, and val rmse 0.400\n",
            "Epoch 1, train loss 0.050, train accuracy 0.302, val loss 0.256, val accuracy 0.283, and val rmse 0.400\n",
            "Epoch 2, train loss 0.044, train accuracy 0.451, val loss 0.219, val accuracy 0.310, and val rmse 0.400\n",
            "Epoch 3, train loss 0.040, train accuracy 0.552, val loss 0.207, val accuracy 0.525, and val rmse 0.160\n",
            "Epoch 4, train loss 0.037, train accuracy 0.669, val loss 0.183, val accuracy 0.626, and val rmse 0.133\n",
            "Epoch 5, train loss 0.033, train accuracy 0.705, val loss 0.164, val accuracy 0.715, and val rmse 0.133\n",
            "Epoch 6, train loss 0.032, train accuracy 0.701, val loss 0.158, val accuracy 0.678, and val rmse 0.133\n",
            "Epoch 7, train loss 0.028, train accuracy 0.747, val loss 0.139, val accuracy 0.817, and val rmse 0.133\n",
            "Epoch 8, train loss 0.027, train accuracy 0.769, val loss 0.137, val accuracy 0.816, and val rmse 0.133\n",
            "Epoch 9, train loss 0.024, train accuracy 0.756, val loss 0.123, val accuracy 0.727, and val rmse 0.133\n",
            "Epoch 10, train loss 0.024, train accuracy 0.714, val loss 0.146, val accuracy 0.539, and val rmse 0.133\n",
            "Epoch 11, train loss 0.019, train accuracy 0.792, val loss 0.099, val accuracy 0.764, and val rmse 0.133\n",
            "Epoch 12, train loss 0.018, train accuracy 0.812, val loss 0.093, val accuracy 0.789, and val rmse 0.133\n",
            "Epoch 13, train loss 0.017, train accuracy 0.831, val loss 0.089, val accuracy 0.776, and val rmse 0.133\n",
            "Epoch 14, train loss 0.017, train accuracy 0.841, val loss 0.093, val accuracy 0.816, and val rmse 0.133\n",
            "Epoch 15, train loss 0.015, train accuracy 0.834, val loss 0.077, val accuracy 0.816, and val rmse 0.133\n",
            "Epoch 16, train loss 0.015, train accuracy 0.828, val loss 0.080, val accuracy 0.792, and val rmse 0.133\n",
            "Epoch 17, train loss 0.014, train accuracy 0.844, val loss 0.069, val accuracy 0.829, and val rmse 0.133\n",
            "Epoch 18, train loss 0.014, train accuracy 0.854, val loss 0.073, val accuracy 0.843, and val rmse 0.133\n",
            "Epoch 19, train loss 0.011, train accuracy 0.886, val loss 0.057, val accuracy 0.882, and val rmse 0.107\n",
            "Epoch 20, train loss 0.010, train accuracy 0.925, val loss 0.050, val accuracy 0.894, and val rmse 0.107\n",
            "Epoch 21, train loss 0.010, train accuracy 0.942, val loss 0.047, val accuracy 0.894, and val rmse 0.107\n",
            "Epoch 22, train loss 0.008, train accuracy 0.935, val loss 0.041, val accuracy 0.907, and val rmse 0.080\n",
            "Epoch 23, train loss 0.007, train accuracy 0.951, val loss 0.037, val accuracy 0.933, and val rmse 0.053\n",
            "Epoch 24, train loss 0.007, train accuracy 0.961, val loss 0.033, val accuracy 0.960, and val rmse 0.053\n",
            "Epoch 25, train loss 0.006, train accuracy 0.981, val loss 0.029, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 26, train loss 0.006, train accuracy 0.984, val loss 0.026, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 27, train loss 0.005, train accuracy 0.994, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.004, train accuracy 0.987, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.004, train accuracy 0.997, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.004, train accuracy 0.987, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.005, train accuracy 0.981, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.003, train accuracy 0.994, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.002, train accuracy 1.000, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.002, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.002, train accuracy 0.994, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 0.994, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.004, train accuracy 0.968, val loss 0.025, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.987, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 0.997, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 84\n",
            "Epoch 0, train loss 0.054, train accuracy 0.312, val loss 0.267, val accuracy 0.155, and val rmse 0.293\n",
            "Epoch 1, train loss 0.052, train accuracy 0.299, val loss 0.290, val accuracy 0.013, and val rmse 0.387\n",
            "Epoch 2, train loss 0.053, train accuracy 0.136, val loss 0.281, val accuracy 0.067, and val rmse 0.293\n",
            "Epoch 3, train loss 0.051, train accuracy 0.282, val loss 0.273, val accuracy 0.000, and val rmse 0.573\n",
            "Epoch 4, train loss 0.052, train accuracy 0.175, val loss 0.250, val accuracy 0.192, and val rmse 0.253\n",
            "Epoch 5, train loss 0.049, train accuracy 0.299, val loss 0.258, val accuracy 0.145, and val rmse 0.253\n",
            "Epoch 6, train loss 0.047, train accuracy 0.419, val loss 0.239, val accuracy 0.487, and val rmse 0.120\n",
            "Epoch 7, train loss 0.044, train accuracy 0.497, val loss 0.230, val accuracy 0.564, and val rmse 0.067\n",
            "Epoch 8, train loss 0.043, train accuracy 0.633, val loss 0.219, val accuracy 0.590, and val rmse 0.027\n",
            "Epoch 9, train loss 0.040, train accuracy 0.708, val loss 0.201, val accuracy 0.732, and val rmse 0.027\n",
            "Epoch 10, train loss 0.037, train accuracy 0.769, val loss 0.193, val accuracy 0.734, and val rmse 0.027\n",
            "Epoch 11, train loss 0.035, train accuracy 0.815, val loss 0.183, val accuracy 0.760, and val rmse 0.027\n",
            "Epoch 12, train loss 0.033, train accuracy 0.750, val loss 0.180, val accuracy 0.733, and val rmse 0.027\n",
            "Epoch 13, train loss 0.030, train accuracy 0.912, val loss 0.151, val accuracy 0.873, and val rmse 0.013\n",
            "Epoch 14, train loss 0.026, train accuracy 0.922, val loss 0.141, val accuracy 0.836, and val rmse 0.013\n",
            "Epoch 15, train loss 0.024, train accuracy 0.945, val loss 0.118, val accuracy 0.935, and val rmse 0.013\n",
            "Epoch 16, train loss 0.021, train accuracy 0.958, val loss 0.107, val accuracy 0.974, and val rmse 0.013\n",
            "Epoch 17, train loss 0.018, train accuracy 0.974, val loss 0.103, val accuracy 0.921, and val rmse 0.013\n",
            "Epoch 18, train loss 0.016, train accuracy 0.961, val loss 0.085, val accuracy 0.949, and val rmse 0.013\n",
            "Epoch 19, train loss 0.014, train accuracy 0.977, val loss 0.081, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 20, train loss 0.013, train accuracy 0.974, val loss 0.066, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 21, train loss 0.011, train accuracy 0.984, val loss 0.063, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 22, train loss 0.010, train accuracy 0.968, val loss 0.049, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 23, train loss 0.009, train accuracy 0.977, val loss 0.043, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 24, train loss 0.009, train accuracy 0.968, val loss 0.041, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 25, train loss 0.008, train accuracy 0.974, val loss 0.034, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 26, train loss 0.007, train accuracy 0.981, val loss 0.031, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 27, train loss 0.006, train accuracy 0.984, val loss 0.029, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 28, train loss 0.005, train accuracy 0.987, val loss 0.026, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 29, train loss 0.005, train accuracy 0.987, val loss 0.023, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 30, train loss 0.005, train accuracy 0.984, val loss 0.022, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 31, train loss 0.004, train accuracy 0.984, val loss 0.020, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 32, train loss 0.004, train accuracy 0.987, val loss 0.019, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 0.984, val loss 0.017, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 34, train loss 0.003, train accuracy 0.987, val loss 0.016, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 35, train loss 0.003, train accuracy 0.987, val loss 0.015, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.984, val loss 0.014, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.987, val loss 0.013, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.981, val loss 0.012, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 39, train loss 0.002, train accuracy 0.987, val loss 0.011, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.984, val loss 0.011, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.981, val loss 0.013, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.987, val loss 0.009, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 0.987, val loss 0.008, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 0.987, val loss 0.010, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.977, val loss 0.009, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 0.987, val loss 0.007, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.987, val loss 0.007, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.987, val loss 0.006, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.984, val loss 0.006, val accuracy 0.988, and val rmse 0.000\n",
            "\n",
            " Iteration number : 85\n",
            "Epoch 0, train loss 0.057, train accuracy 0.250, val loss 0.289, val accuracy 0.290, and val rmse 0.520\n",
            "Epoch 1, train loss 0.048, train accuracy 0.588, val loss 0.239, val accuracy 0.663, and val rmse 0.000\n",
            "Epoch 2, train loss 0.044, train accuracy 0.617, val loss 0.222, val accuracy 0.626, and val rmse 0.000\n",
            "Epoch 3, train loss 0.051, train accuracy 0.532, val loss 0.253, val accuracy 0.651, and val rmse 0.000\n",
            "Epoch 4, train loss 0.048, train accuracy 0.627, val loss 0.249, val accuracy 0.663, and val rmse 0.000\n",
            "Epoch 5, train loss 0.043, train accuracy 0.617, val loss 0.220, val accuracy 0.637, and val rmse 0.000\n",
            "Epoch 6, train loss 0.038, train accuracy 0.581, val loss 0.188, val accuracy 0.610, and val rmse 0.107\n",
            "Epoch 7, train loss 0.038, train accuracy 0.604, val loss 0.188, val accuracy 0.663, and val rmse 0.000\n",
            "Epoch 8, train loss 0.036, train accuracy 0.630, val loss 0.174, val accuracy 0.663, and val rmse 0.000\n",
            "Epoch 9, train loss 0.034, train accuracy 0.630, val loss 0.167, val accuracy 0.663, and val rmse 0.027\n",
            "Epoch 10, train loss 0.031, train accuracy 0.623, val loss 0.160, val accuracy 0.636, and val rmse 0.080\n",
            "Epoch 11, train loss 0.031, train accuracy 0.620, val loss 0.155, val accuracy 0.648, and val rmse 0.133\n",
            "Epoch 12, train loss 0.030, train accuracy 0.666, val loss 0.152, val accuracy 0.637, and val rmse 0.133\n",
            "Epoch 13, train loss 0.029, train accuracy 0.695, val loss 0.146, val accuracy 0.728, and val rmse 0.053\n",
            "Epoch 14, train loss 0.028, train accuracy 0.698, val loss 0.142, val accuracy 0.717, and val rmse 0.053\n",
            "Epoch 15, train loss 0.026, train accuracy 0.705, val loss 0.135, val accuracy 0.768, and val rmse 0.027\n",
            "Epoch 16, train loss 0.027, train accuracy 0.705, val loss 0.134, val accuracy 0.742, and val rmse 0.080\n",
            "Epoch 17, train loss 0.026, train accuracy 0.688, val loss 0.131, val accuracy 0.692, and val rmse 0.053\n",
            "Epoch 18, train loss 0.024, train accuracy 0.744, val loss 0.122, val accuracy 0.782, and val rmse 0.000\n",
            "Epoch 19, train loss 0.023, train accuracy 0.756, val loss 0.117, val accuracy 0.794, and val rmse 0.000\n",
            "Epoch 20, train loss 0.022, train accuracy 0.766, val loss 0.114, val accuracy 0.808, and val rmse 0.000\n",
            "Epoch 21, train loss 0.021, train accuracy 0.799, val loss 0.108, val accuracy 0.833, and val rmse 0.000\n",
            "Epoch 22, train loss 0.021, train accuracy 0.799, val loss 0.104, val accuracy 0.833, and val rmse 0.000\n",
            "Epoch 23, train loss 0.020, train accuracy 0.802, val loss 0.101, val accuracy 0.847, and val rmse 0.000\n",
            "Epoch 24, train loss 0.019, train accuracy 0.786, val loss 0.097, val accuracy 0.847, and val rmse 0.000\n",
            "Epoch 25, train loss 0.018, train accuracy 0.818, val loss 0.093, val accuracy 0.847, and val rmse 0.000\n",
            "Epoch 26, train loss 0.022, train accuracy 0.789, val loss 0.166, val accuracy 0.756, and val rmse 0.107\n",
            "Epoch 27, train loss 0.017, train accuracy 0.844, val loss 0.085, val accuracy 0.846, and val rmse 0.027\n",
            "Epoch 28, train loss 0.016, train accuracy 0.847, val loss 0.082, val accuracy 0.858, and val rmse 0.027\n",
            "Epoch 29, train loss 0.016, train accuracy 0.831, val loss 0.092, val accuracy 0.847, and val rmse 0.000\n",
            "Epoch 30, train loss 0.017, train accuracy 0.857, val loss 0.079, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 31, train loss 0.015, train accuracy 0.906, val loss 0.073, val accuracy 0.922, and val rmse 0.000\n",
            "Epoch 32, train loss 0.014, train accuracy 0.903, val loss 0.068, val accuracy 0.922, and val rmse 0.000\n",
            "Epoch 33, train loss 0.013, train accuracy 0.935, val loss 0.063, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 34, train loss 0.013, train accuracy 0.916, val loss 0.060, val accuracy 0.936, and val rmse 0.000\n",
            "Epoch 35, train loss 0.011, train accuracy 0.951, val loss 0.054, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 36, train loss 0.011, train accuracy 0.958, val loss 0.049, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 37, train loss 0.010, train accuracy 0.968, val loss 0.046, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 38, train loss 0.009, train accuracy 0.951, val loss 0.043, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 39, train loss 0.011, train accuracy 0.955, val loss 0.040, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 40, train loss 0.008, train accuracy 0.974, val loss 0.037, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 41, train loss 0.008, train accuracy 0.981, val loss 0.037, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.007, train accuracy 0.981, val loss 0.030, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.007, train accuracy 0.974, val loss 0.035, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 44, train loss 0.006, train accuracy 0.987, val loss 0.026, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.005, train accuracy 0.990, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.006, train accuracy 0.964, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.005, train accuracy 0.977, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.004, train accuracy 0.984, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.004, train accuracy 0.997, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 86\n",
            "Epoch 0, train loss 0.049, train accuracy 0.451, val loss 0.265, val accuracy 0.197, and val rmse 0.360\n",
            "Epoch 1, train loss 0.045, train accuracy 0.390, val loss 0.230, val accuracy 0.427, and val rmse 0.013\n",
            "Epoch 2, train loss 0.041, train accuracy 0.412, val loss 0.216, val accuracy 0.187, and val rmse 0.413\n",
            "Epoch 3, train loss 0.042, train accuracy 0.409, val loss 0.208, val accuracy 0.333, and val rmse 0.093\n",
            "Epoch 4, train loss 0.038, train accuracy 0.328, val loss 0.200, val accuracy 0.358, and val rmse 0.120\n",
            "Epoch 5, train loss 0.037, train accuracy 0.403, val loss 0.181, val accuracy 0.318, and val rmse 0.147\n",
            "Epoch 6, train loss 0.035, train accuracy 0.429, val loss 0.198, val accuracy 0.160, and val rmse 0.387\n",
            "Epoch 7, train loss 0.032, train accuracy 0.429, val loss 0.171, val accuracy 0.316, and val rmse 0.227\n",
            "Epoch 8, train loss 0.030, train accuracy 0.510, val loss 0.159, val accuracy 0.437, and val rmse 0.120\n",
            "Epoch 9, train loss 0.027, train accuracy 0.636, val loss 0.150, val accuracy 0.372, and val rmse 0.200\n",
            "Epoch 10, train loss 0.025, train accuracy 0.675, val loss 0.139, val accuracy 0.545, and val rmse 0.213\n",
            "Epoch 11, train loss 0.024, train accuracy 0.679, val loss 0.133, val accuracy 0.611, and val rmse 0.173\n",
            "Epoch 12, train loss 0.021, train accuracy 0.769, val loss 0.117, val accuracy 0.593, and val rmse 0.160\n",
            "Epoch 13, train loss 0.019, train accuracy 0.744, val loss 0.111, val accuracy 0.648, and val rmse 0.160\n",
            "Epoch 14, train loss 0.017, train accuracy 0.805, val loss 0.101, val accuracy 0.648, and val rmse 0.160\n",
            "Epoch 15, train loss 0.019, train accuracy 0.744, val loss 0.100, val accuracy 0.688, and val rmse 0.133\n",
            "Epoch 16, train loss 0.017, train accuracy 0.750, val loss 0.096, val accuracy 0.712, and val rmse 0.160\n",
            "Epoch 17, train loss 0.016, train accuracy 0.763, val loss 0.092, val accuracy 0.712, and val rmse 0.160\n",
            "Epoch 18, train loss 0.014, train accuracy 0.786, val loss 0.085, val accuracy 0.750, and val rmse 0.133\n",
            "Epoch 19, train loss 0.016, train accuracy 0.841, val loss 0.087, val accuracy 0.752, and val rmse 0.080\n",
            "Epoch 20, train loss 0.014, train accuracy 0.847, val loss 0.075, val accuracy 0.802, and val rmse 0.080\n",
            "Epoch 21, train loss 0.013, train accuracy 0.899, val loss 0.077, val accuracy 0.790, and val rmse 0.080\n",
            "Epoch 22, train loss 0.012, train accuracy 0.903, val loss 0.063, val accuracy 0.853, and val rmse 0.080\n",
            "Epoch 23, train loss 0.011, train accuracy 0.896, val loss 0.056, val accuracy 0.867, and val rmse 0.080\n",
            "Epoch 24, train loss 0.009, train accuracy 0.912, val loss 0.045, val accuracy 0.960, and val rmse 0.053\n",
            "Epoch 25, train loss 0.006, train accuracy 0.951, val loss 0.034, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 26, train loss 0.008, train accuracy 0.938, val loss 0.036, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 27, train loss 0.006, train accuracy 0.942, val loss 0.028, val accuracy 0.947, and val rmse 0.000\n",
            "Epoch 28, train loss 0.005, train accuracy 0.945, val loss 0.017, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 29, train loss 0.003, train accuracy 0.974, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.003, train accuracy 0.981, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.002, train accuracy 0.997, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.003, train accuracy 0.981, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.002, train accuracy 0.981, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.002, train accuracy 0.987, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.002, train accuracy 0.984, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 0.984, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 0.994, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 0.990, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.000, train accuracy 0.997, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.000, train accuracy 1.000, val loss 0.001, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 87\n",
            "Epoch 0, train loss 0.052, train accuracy 0.234, val loss 0.293, val accuracy 0.102, and val rmse 0.373\n",
            "Epoch 1, train loss 0.048, train accuracy 0.422, val loss 0.258, val accuracy 0.285, and val rmse 0.227\n",
            "Epoch 2, train loss 0.049, train accuracy 0.282, val loss 0.258, val accuracy 0.250, and val rmse 0.187\n",
            "Epoch 3, train loss 0.048, train accuracy 0.282, val loss 0.262, val accuracy 0.160, and val rmse 0.240\n",
            "Epoch 4, train loss 0.046, train accuracy 0.354, val loss 0.256, val accuracy 0.159, and val rmse 0.240\n",
            "Epoch 5, train loss 0.044, train accuracy 0.481, val loss 0.256, val accuracy 0.297, and val rmse 0.307\n",
            "Epoch 6, train loss 0.040, train accuracy 0.581, val loss 0.230, val accuracy 0.402, and val rmse 0.267\n",
            "Epoch 7, train loss 0.039, train accuracy 0.584, val loss 0.224, val accuracy 0.331, and val rmse 0.240\n",
            "Epoch 8, train loss 0.035, train accuracy 0.698, val loss 0.200, val accuracy 0.570, and val rmse 0.187\n",
            "Epoch 9, train loss 0.033, train accuracy 0.753, val loss 0.165, val accuracy 0.728, and val rmse 0.080\n",
            "Epoch 10, train loss 0.029, train accuracy 0.802, val loss 0.161, val accuracy 0.739, and val rmse 0.080\n",
            "Epoch 11, train loss 0.029, train accuracy 0.789, val loss 0.144, val accuracy 0.803, and val rmse 0.080\n",
            "Epoch 12, train loss 0.027, train accuracy 0.705, val loss 0.143, val accuracy 0.650, and val rmse 0.107\n",
            "Epoch 13, train loss 0.025, train accuracy 0.744, val loss 0.128, val accuracy 0.738, and val rmse 0.133\n",
            "Epoch 14, train loss 0.022, train accuracy 0.786, val loss 0.122, val accuracy 0.723, and val rmse 0.133\n",
            "Epoch 15, train loss 0.028, train accuracy 0.692, val loss 0.193, val accuracy 0.562, and val rmse 0.107\n",
            "Epoch 16, train loss 0.020, train accuracy 0.818, val loss 0.110, val accuracy 0.775, and val rmse 0.053\n",
            "Epoch 17, train loss 0.018, train accuracy 0.860, val loss 0.096, val accuracy 0.841, and val rmse 0.053\n",
            "Epoch 18, train loss 0.015, train accuracy 0.896, val loss 0.078, val accuracy 0.828, and val rmse 0.053\n",
            "Epoch 19, train loss 0.014, train accuracy 0.893, val loss 0.070, val accuracy 0.854, and val rmse 0.053\n",
            "Epoch 20, train loss 0.012, train accuracy 0.896, val loss 0.065, val accuracy 0.881, and val rmse 0.027\n",
            "Epoch 21, train loss 0.014, train accuracy 0.873, val loss 0.065, val accuracy 0.895, and val rmse 0.027\n",
            "Epoch 22, train loss 0.015, train accuracy 0.870, val loss 0.080, val accuracy 0.793, and val rmse 0.027\n",
            "Epoch 23, train loss 0.013, train accuracy 0.948, val loss 0.065, val accuracy 0.893, and val rmse 0.080\n",
            "Epoch 24, train loss 0.042, train accuracy 0.568, val loss 0.255, val accuracy 0.427, and val rmse 0.107\n",
            "Epoch 25, train loss 0.034, train accuracy 0.558, val loss 0.179, val accuracy 0.551, and val rmse 0.107\n",
            "Epoch 26, train loss 0.028, train accuracy 0.679, val loss 0.154, val accuracy 0.563, and val rmse 0.107\n",
            "Epoch 27, train loss 0.024, train accuracy 0.818, val loss 0.132, val accuracy 0.651, and val rmse 0.107\n",
            "Epoch 28, train loss 0.022, train accuracy 0.860, val loss 0.118, val accuracy 0.778, and val rmse 0.053\n",
            "Epoch 29, train loss 0.019, train accuracy 0.873, val loss 0.103, val accuracy 0.828, and val rmse 0.053\n",
            "Epoch 30, train loss 0.020, train accuracy 0.854, val loss 0.105, val accuracy 0.803, and val rmse 0.027\n",
            "Epoch 31, train loss 0.017, train accuracy 0.912, val loss 0.100, val accuracy 0.803, and val rmse 0.027\n",
            "Epoch 32, train loss 0.015, train accuracy 0.935, val loss 0.077, val accuracy 0.893, and val rmse 0.027\n",
            "Epoch 33, train loss 0.014, train accuracy 0.922, val loss 0.084, val accuracy 0.882, and val rmse 0.027\n",
            "Epoch 34, train loss 0.015, train accuracy 0.929, val loss 0.087, val accuracy 0.833, and val rmse 0.027\n",
            "Epoch 35, train loss 0.010, train accuracy 0.945, val loss 0.048, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 36, train loss 0.009, train accuracy 0.964, val loss 0.044, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 37, train loss 0.009, train accuracy 0.948, val loss 0.042, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 38, train loss 0.008, train accuracy 0.955, val loss 0.038, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 39, train loss 0.007, train accuracy 0.955, val loss 0.035, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 40, train loss 0.007, train accuracy 0.968, val loss 0.032, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 41, train loss 0.007, train accuracy 0.964, val loss 0.032, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 42, train loss 0.006, train accuracy 0.948, val loss 0.029, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 43, train loss 0.006, train accuracy 0.951, val loss 0.026, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 44, train loss 0.005, train accuracy 0.964, val loss 0.024, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 45, train loss 0.005, train accuracy 0.971, val loss 0.022, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 46, train loss 0.005, train accuracy 0.968, val loss 0.020, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 47, train loss 0.005, train accuracy 0.977, val loss 0.018, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 48, train loss 0.004, train accuracy 0.974, val loss 0.018, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 49, train loss 0.004, train accuracy 0.964, val loss 0.016, val accuracy 0.987, and val rmse 0.027\n",
            "\n",
            " Iteration number : 88\n",
            "Epoch 0, train loss 0.054, train accuracy 0.269, val loss 0.274, val accuracy 0.237, and val rmse 0.573\n",
            "Epoch 1, train loss 0.052, train accuracy 0.266, val loss 0.268, val accuracy 0.089, and val rmse 0.400\n",
            "Epoch 2, train loss 0.051, train accuracy 0.386, val loss 0.278, val accuracy 0.387, and val rmse 0.027\n",
            "Epoch 3, train loss 0.049, train accuracy 0.409, val loss 0.252, val accuracy 0.333, and val rmse 0.040\n",
            "Epoch 4, train loss 0.046, train accuracy 0.490, val loss 0.241, val accuracy 0.412, and val rmse 0.013\n",
            "Epoch 5, train loss 0.043, train accuracy 0.562, val loss 0.224, val accuracy 0.539, and val rmse 0.013\n",
            "Epoch 6, train loss 0.040, train accuracy 0.649, val loss 0.208, val accuracy 0.668, and val rmse 0.013\n",
            "Epoch 7, train loss 0.038, train accuracy 0.653, val loss 0.206, val accuracy 0.580, and val rmse 0.040\n",
            "Epoch 8, train loss 0.036, train accuracy 0.682, val loss 0.187, val accuracy 0.681, and val rmse 0.013\n",
            "Epoch 9, train loss 0.034, train accuracy 0.705, val loss 0.174, val accuracy 0.746, and val rmse 0.013\n",
            "Epoch 10, train loss 0.031, train accuracy 0.792, val loss 0.161, val accuracy 0.808, and val rmse 0.027\n",
            "Epoch 11, train loss 0.029, train accuracy 0.805, val loss 0.152, val accuracy 0.859, and val rmse 0.027\n",
            "Epoch 12, train loss 0.027, train accuracy 0.841, val loss 0.138, val accuracy 0.847, and val rmse 0.027\n",
            "Epoch 13, train loss 0.025, train accuracy 0.841, val loss 0.128, val accuracy 0.822, and val rmse 0.027\n",
            "Epoch 14, train loss 0.023, train accuracy 0.854, val loss 0.115, val accuracy 0.859, and val rmse 0.027\n",
            "Epoch 15, train loss 0.022, train accuracy 0.857, val loss 0.105, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 16, train loss 0.020, train accuracy 0.873, val loss 0.098, val accuracy 0.872, and val rmse 0.027\n",
            "Epoch 17, train loss 0.018, train accuracy 0.883, val loss 0.089, val accuracy 0.859, and val rmse 0.027\n",
            "Epoch 18, train loss 0.017, train accuracy 0.880, val loss 0.080, val accuracy 0.898, and val rmse 0.027\n",
            "Epoch 19, train loss 0.019, train accuracy 0.841, val loss 0.134, val accuracy 0.817, and val rmse 0.027\n",
            "Epoch 20, train loss 0.018, train accuracy 0.912, val loss 0.088, val accuracy 0.897, and val rmse 0.027\n",
            "Epoch 21, train loss 0.017, train accuracy 0.932, val loss 0.078, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 22, train loss 0.016, train accuracy 0.945, val loss 0.082, val accuracy 0.947, and val rmse 0.027\n",
            "Epoch 23, train loss 0.015, train accuracy 0.951, val loss 0.068, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 24, train loss 0.013, train accuracy 0.955, val loss 0.064, val accuracy 0.962, and val rmse 0.027\n",
            "Epoch 25, train loss 0.011, train accuracy 0.948, val loss 0.053, val accuracy 0.962, and val rmse 0.027\n",
            "Epoch 26, train loss 0.010, train accuracy 0.951, val loss 0.044, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 27, train loss 0.010, train accuracy 0.958, val loss 0.043, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 28, train loss 0.008, train accuracy 0.974, val loss 0.039, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 29, train loss 0.007, train accuracy 0.968, val loss 0.033, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 30, train loss 0.007, train accuracy 0.964, val loss 0.032, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 31, train loss 0.006, train accuracy 0.974, val loss 0.026, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 32, train loss 0.006, train accuracy 0.968, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.004, train accuracy 1.000, val loss 0.021, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.005, train accuracy 0.984, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.974, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.994, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.004, train accuracy 0.987, val loss 0.021, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.990, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.981, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.997, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.987, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.002, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.003, train accuracy 0.990, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.990, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.002, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.994, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 89\n",
            "Epoch 0, train loss 0.054, train accuracy 0.344, val loss 0.285, val accuracy 0.147, and val rmse 0.467\n",
            "Epoch 1, train loss 0.052, train accuracy 0.474, val loss 0.258, val accuracy 0.462, and val rmse 0.040\n",
            "Epoch 2, train loss 0.049, train accuracy 0.539, val loss 0.247, val accuracy 0.422, and val rmse 0.080\n",
            "Epoch 3, train loss 0.046, train accuracy 0.604, val loss 0.258, val accuracy 0.522, and val rmse 0.093\n",
            "Epoch 4, train loss 0.043, train accuracy 0.679, val loss 0.255, val accuracy 0.437, and val rmse 0.040\n",
            "Epoch 5, train loss 0.042, train accuracy 0.604, val loss 0.213, val accuracy 0.492, and val rmse 0.027\n",
            "Epoch 6, train loss 0.039, train accuracy 0.653, val loss 0.205, val accuracy 0.540, and val rmse 0.133\n",
            "Epoch 7, train loss 0.036, train accuracy 0.727, val loss 0.182, val accuracy 0.697, and val rmse 0.000\n",
            "Epoch 8, train loss 0.033, train accuracy 0.718, val loss 0.169, val accuracy 0.547, and val rmse 0.000\n",
            "Epoch 9, train loss 0.031, train accuracy 0.841, val loss 0.155, val accuracy 0.787, and val rmse 0.000\n",
            "Epoch 10, train loss 0.028, train accuracy 0.912, val loss 0.141, val accuracy 0.913, and val rmse 0.000\n",
            "Epoch 11, train loss 0.026, train accuracy 0.925, val loss 0.130, val accuracy 0.938, and val rmse 0.000\n",
            "Epoch 12, train loss 0.022, train accuracy 0.971, val loss 0.113, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 13, train loss 0.023, train accuracy 0.935, val loss 0.113, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 14, train loss 0.019, train accuracy 0.977, val loss 0.095, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 15, train loss 0.017, train accuracy 0.981, val loss 0.089, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 16, train loss 0.015, train accuracy 0.981, val loss 0.078, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 17, train loss 0.014, train accuracy 0.977, val loss 0.067, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 18, train loss 0.012, train accuracy 0.990, val loss 0.060, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 19, train loss 0.022, train accuracy 0.883, val loss 0.105, val accuracy 0.796, and val rmse 0.000\n",
            "Epoch 20, train loss 0.011, train accuracy 0.974, val loss 0.054, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 21, train loss 0.014, train accuracy 0.899, val loss 0.096, val accuracy 0.887, and val rmse 0.000\n",
            "Epoch 22, train loss 0.013, train accuracy 0.990, val loss 0.058, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 23, train loss 0.011, train accuracy 0.990, val loss 0.051, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.011, train accuracy 0.961, val loss 0.077, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 25, train loss 0.008, train accuracy 0.994, val loss 0.051, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 26, train loss 0.007, train accuracy 0.990, val loss 0.035, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.006, train accuracy 0.997, val loss 0.030, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.006, train accuracy 0.987, val loss 0.029, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.005, train accuracy 1.000, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.003, train accuracy 1.000, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.003, train accuracy 0.997, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.003, train accuracy 0.987, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.002, train accuracy 0.997, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.002, train accuracy 0.997, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.002, train accuracy 0.987, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.981, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.002, train accuracy 0.990, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.002, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.984, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 0.997, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.997, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 90\n",
            "Epoch 0, train loss 0.053, train accuracy 0.282, val loss 0.261, val accuracy 0.283, and val rmse 0.400\n",
            "Epoch 1, train loss 0.044, train accuracy 0.549, val loss 0.248, val accuracy 0.308, and val rmse 0.427\n",
            "Epoch 2, train loss 0.041, train accuracy 0.568, val loss 0.212, val accuracy 0.330, and val rmse 0.387\n",
            "Epoch 3, train loss 0.038, train accuracy 0.555, val loss 0.188, val accuracy 0.466, and val rmse 0.000\n",
            "Epoch 4, train loss 0.035, train accuracy 0.666, val loss 0.178, val accuracy 0.558, and val rmse 0.147\n",
            "Epoch 5, train loss 0.033, train accuracy 0.604, val loss 0.188, val accuracy 0.342, and val rmse 0.320\n",
            "Epoch 6, train loss 0.030, train accuracy 0.669, val loss 0.165, val accuracy 0.486, and val rmse 0.147\n",
            "Epoch 7, train loss 0.032, train accuracy 0.597, val loss 0.158, val accuracy 0.547, and val rmse 0.227\n",
            "Epoch 8, train loss 0.027, train accuracy 0.607, val loss 0.136, val accuracy 0.569, and val rmse 0.307\n",
            "Epoch 9, train loss 0.025, train accuracy 0.636, val loss 0.131, val accuracy 0.623, and val rmse 0.267\n",
            "Epoch 10, train loss 0.024, train accuracy 0.672, val loss 0.131, val accuracy 0.583, and val rmse 0.267\n",
            "Epoch 11, train loss 0.024, train accuracy 0.711, val loss 0.121, val accuracy 0.660, and val rmse 0.267\n",
            "Epoch 12, train loss 0.026, train accuracy 0.701, val loss 0.130, val accuracy 0.672, and val rmse 0.280\n",
            "Epoch 13, train loss 0.024, train accuracy 0.750, val loss 0.117, val accuracy 0.764, and val rmse 0.253\n",
            "Epoch 14, train loss 0.022, train accuracy 0.779, val loss 0.111, val accuracy 0.778, and val rmse 0.240\n",
            "Epoch 15, train loss 0.021, train accuracy 0.753, val loss 0.102, val accuracy 0.790, and val rmse 0.240\n",
            "Epoch 16, train loss 0.021, train accuracy 0.763, val loss 0.096, val accuracy 0.750, and val rmse 0.267\n",
            "Epoch 17, train loss 0.017, train accuracy 0.812, val loss 0.087, val accuracy 0.829, and val rmse 0.187\n",
            "Epoch 18, train loss 0.015, train accuracy 0.864, val loss 0.079, val accuracy 0.868, and val rmse 0.160\n",
            "Epoch 19, train loss 0.014, train accuracy 0.844, val loss 0.069, val accuracy 0.869, and val rmse 0.133\n",
            "Epoch 20, train loss 0.013, train accuracy 0.890, val loss 0.072, val accuracy 0.868, and val rmse 0.133\n",
            "Epoch 21, train loss 0.012, train accuracy 0.860, val loss 0.060, val accuracy 0.895, and val rmse 0.107\n",
            "Epoch 22, train loss 0.011, train accuracy 0.886, val loss 0.056, val accuracy 0.895, and val rmse 0.107\n",
            "Epoch 23, train loss 0.012, train accuracy 0.890, val loss 0.058, val accuracy 0.922, and val rmse 0.080\n",
            "Epoch 24, train loss 0.012, train accuracy 0.860, val loss 0.059, val accuracy 0.909, and val rmse 0.080\n",
            "Epoch 25, train loss 0.011, train accuracy 0.873, val loss 0.058, val accuracy 0.907, and val rmse 0.093\n",
            "Epoch 26, train loss 0.009, train accuracy 0.893, val loss 0.045, val accuracy 0.895, and val rmse 0.107\n",
            "Epoch 27, train loss 0.009, train accuracy 0.896, val loss 0.044, val accuracy 0.921, and val rmse 0.080\n",
            "Epoch 28, train loss 0.008, train accuracy 0.899, val loss 0.042, val accuracy 0.934, and val rmse 0.093\n",
            "Epoch 29, train loss 0.007, train accuracy 0.919, val loss 0.036, val accuracy 0.961, and val rmse 0.053\n",
            "Epoch 30, train loss 0.007, train accuracy 0.932, val loss 0.034, val accuracy 0.948, and val rmse 0.053\n",
            "Epoch 31, train loss 0.007, train accuracy 0.922, val loss 0.031, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 32, train loss 0.007, train accuracy 0.945, val loss 0.030, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 33, train loss 0.006, train accuracy 0.932, val loss 0.027, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 34, train loss 0.006, train accuracy 0.951, val loss 0.025, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 35, train loss 0.006, train accuracy 0.958, val loss 0.024, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 36, train loss 0.005, train accuracy 0.964, val loss 0.023, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 37, train loss 0.005, train accuracy 0.968, val loss 0.021, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 38, train loss 0.004, train accuracy 0.974, val loss 0.022, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 39, train loss 0.004, train accuracy 0.968, val loss 0.018, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 40, train loss 0.004, train accuracy 0.981, val loss 0.017, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 41, train loss 0.005, train accuracy 0.971, val loss 0.051, val accuracy 0.887, and val rmse 0.027\n",
            "Epoch 42, train loss 0.004, train accuracy 0.971, val loss 0.016, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 43, train loss 0.004, train accuracy 0.968, val loss 0.015, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 44, train loss 0.004, train accuracy 0.961, val loss 0.015, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 45, train loss 0.004, train accuracy 0.971, val loss 0.014, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 46, train loss 0.003, train accuracy 0.987, val loss 0.013, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 47, train loss 0.003, train accuracy 0.977, val loss 0.012, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 48, train loss 0.003, train accuracy 0.971, val loss 0.011, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 49, train loss 0.003, train accuracy 0.984, val loss 0.014, val accuracy 0.987, and val rmse 0.027\n",
            "\n",
            " Iteration number : 91\n",
            "Epoch 0, train loss 0.053, train accuracy 0.211, val loss 0.278, val accuracy 0.270, and val rmse 0.400\n",
            "Epoch 1, train loss 0.051, train accuracy 0.396, val loss 0.279, val accuracy 0.296, and val rmse 0.400\n",
            "Epoch 2, train loss 0.053, train accuracy 0.344, val loss 0.281, val accuracy 0.088, and val rmse 0.453\n",
            "Epoch 3, train loss 0.052, train accuracy 0.253, val loss 0.275, val accuracy 0.158, and val rmse 0.400\n",
            "Epoch 4, train loss 0.049, train accuracy 0.383, val loss 0.254, val accuracy 0.327, and val rmse 0.200\n",
            "Epoch 5, train loss 0.048, train accuracy 0.539, val loss 0.259, val accuracy 0.313, and val rmse 0.387\n",
            "Epoch 6, train loss 0.047, train accuracy 0.386, val loss 0.269, val accuracy 0.237, and val rmse 0.600\n",
            "Epoch 7, train loss 0.045, train accuracy 0.584, val loss 0.227, val accuracy 0.627, and val rmse 0.013\n",
            "Epoch 8, train loss 0.044, train accuracy 0.620, val loss 0.227, val accuracy 0.652, and val rmse 0.013\n",
            "Epoch 9, train loss 0.042, train accuracy 0.636, val loss 0.215, val accuracy 0.638, and val rmse 0.040\n",
            "Epoch 10, train loss 0.040, train accuracy 0.588, val loss 0.203, val accuracy 0.663, and val rmse 0.067\n",
            "Epoch 11, train loss 0.038, train accuracy 0.620, val loss 0.194, val accuracy 0.662, and val rmse 0.067\n",
            "Epoch 12, train loss 0.036, train accuracy 0.698, val loss 0.186, val accuracy 0.686, and val rmse 0.093\n",
            "Epoch 13, train loss 0.035, train accuracy 0.721, val loss 0.179, val accuracy 0.726, and val rmse 0.093\n",
            "Epoch 14, train loss 0.034, train accuracy 0.734, val loss 0.170, val accuracy 0.750, and val rmse 0.120\n",
            "Epoch 15, train loss 0.033, train accuracy 0.708, val loss 0.169, val accuracy 0.637, and val rmse 0.080\n",
            "Epoch 16, train loss 0.031, train accuracy 0.792, val loss 0.161, val accuracy 0.777, and val rmse 0.080\n",
            "Epoch 17, train loss 0.030, train accuracy 0.834, val loss 0.152, val accuracy 0.842, and val rmse 0.133\n",
            "Epoch 18, train loss 0.029, train accuracy 0.838, val loss 0.148, val accuracy 0.855, and val rmse 0.133\n",
            "Epoch 19, train loss 0.027, train accuracy 0.831, val loss 0.138, val accuracy 0.855, and val rmse 0.133\n",
            "Epoch 20, train loss 0.026, train accuracy 0.841, val loss 0.134, val accuracy 0.855, and val rmse 0.133\n",
            "Epoch 21, train loss 0.026, train accuracy 0.854, val loss 0.129, val accuracy 0.855, and val rmse 0.133\n",
            "Epoch 22, train loss 0.025, train accuracy 0.860, val loss 0.125, val accuracy 0.855, and val rmse 0.133\n",
            "Epoch 23, train loss 0.025, train accuracy 0.860, val loss 0.123, val accuracy 0.882, and val rmse 0.080\n",
            "Epoch 24, train loss 0.023, train accuracy 0.851, val loss 0.116, val accuracy 0.828, and val rmse 0.080\n",
            "Epoch 25, train loss 0.021, train accuracy 0.893, val loss 0.108, val accuracy 0.908, and val rmse 0.080\n",
            "Epoch 26, train loss 0.020, train accuracy 0.890, val loss 0.101, val accuracy 0.908, and val rmse 0.080\n",
            "Epoch 27, train loss 0.019, train accuracy 0.912, val loss 0.093, val accuracy 0.922, and val rmse 0.053\n",
            "Epoch 28, train loss 0.018, train accuracy 0.912, val loss 0.089, val accuracy 0.922, and val rmse 0.053\n",
            "Epoch 29, train loss 0.017, train accuracy 0.912, val loss 0.088, val accuracy 0.908, and val rmse 0.053\n",
            "Epoch 30, train loss 0.016, train accuracy 0.909, val loss 0.078, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 31, train loss 0.015, train accuracy 0.929, val loss 0.073, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 32, train loss 0.014, train accuracy 0.919, val loss 0.070, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 33, train loss 0.014, train accuracy 0.916, val loss 0.069, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 34, train loss 0.013, train accuracy 0.919, val loss 0.067, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 35, train loss 0.012, train accuracy 0.922, val loss 0.062, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 36, train loss 0.012, train accuracy 0.916, val loss 0.058, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 37, train loss 0.011, train accuracy 0.932, val loss 0.057, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 38, train loss 0.011, train accuracy 0.932, val loss 0.054, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 39, train loss 0.010, train accuracy 0.938, val loss 0.049, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 40, train loss 0.009, train accuracy 0.948, val loss 0.043, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 41, train loss 0.008, train accuracy 0.942, val loss 0.039, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 42, train loss 0.008, train accuracy 0.942, val loss 0.036, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 43, train loss 0.007, train accuracy 0.948, val loss 0.033, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 44, train loss 0.006, train accuracy 0.955, val loss 0.030, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 45, train loss 0.006, train accuracy 0.955, val loss 0.028, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 46, train loss 0.006, train accuracy 0.951, val loss 0.025, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 47, train loss 0.005, train accuracy 0.955, val loss 0.023, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 48, train loss 0.005, train accuracy 0.958, val loss 0.022, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 49, train loss 0.004, train accuracy 0.961, val loss 0.019, val accuracy 0.962, and val rmse 0.000\n",
            "\n",
            " Iteration number : 92\n",
            "Epoch 0, train loss 0.053, train accuracy 0.292, val loss 0.284, val accuracy 0.270, and val rmse 0.400\n",
            "Epoch 1, train loss 0.046, train accuracy 0.458, val loss 0.242, val accuracy 0.233, and val rmse 0.400\n",
            "Epoch 2, train loss 0.040, train accuracy 0.532, val loss 0.209, val accuracy 0.554, and val rmse 0.267\n",
            "Epoch 3, train loss 0.037, train accuracy 0.614, val loss 0.201, val accuracy 0.513, and val rmse 0.213\n",
            "Epoch 4, train loss 0.032, train accuracy 0.656, val loss 0.184, val accuracy 0.567, and val rmse 0.187\n",
            "Epoch 5, train loss 0.029, train accuracy 0.688, val loss 0.155, val accuracy 0.727, and val rmse 0.080\n",
            "Epoch 6, train loss 0.033, train accuracy 0.627, val loss 0.221, val accuracy 0.529, and val rmse 0.027\n",
            "Epoch 7, train loss 0.023, train accuracy 0.815, val loss 0.118, val accuracy 0.859, and val rmse 0.000\n",
            "Epoch 8, train loss 0.021, train accuracy 0.841, val loss 0.104, val accuracy 0.833, and val rmse 0.000\n",
            "Epoch 9, train loss 0.019, train accuracy 0.844, val loss 0.090, val accuracy 0.898, and val rmse 0.000\n",
            "Epoch 10, train loss 0.017, train accuracy 0.867, val loss 0.083, val accuracy 0.910, and val rmse 0.000\n",
            "Epoch 11, train loss 0.015, train accuracy 0.912, val loss 0.071, val accuracy 0.911, and val rmse 0.000\n",
            "Epoch 12, train loss 0.012, train accuracy 0.974, val loss 0.051, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 13, train loss 0.010, train accuracy 0.984, val loss 0.043, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 14, train loss 0.008, train accuracy 0.994, val loss 0.038, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 15, train loss 0.007, train accuracy 0.981, val loss 0.033, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 16, train loss 0.007, train accuracy 0.990, val loss 0.030, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 17, train loss 0.005, train accuracy 0.994, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 18, train loss 0.005, train accuracy 0.994, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 19, train loss 0.004, train accuracy 1.000, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 20, train loss 0.003, train accuracy 1.000, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 21, train loss 0.003, train accuracy 0.987, val loss 0.017, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 22, train loss 0.003, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 23, train loss 0.003, train accuracy 0.997, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 25, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 26, train loss 0.003, train accuracy 0.990, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 27, train loss 0.005, train accuracy 0.990, val loss 0.026, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 28, train loss 0.003, train accuracy 1.000, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 29, train loss 0.002, train accuracy 1.000, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 30, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 31, train loss 0.001, train accuracy 1.000, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 32, train loss 0.001, train accuracy 1.000, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 33, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.001, train accuracy 1.000, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.001, train accuracy 0.997, val loss 0.005, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 39, train loss 0.001, train accuracy 1.000, val loss 0.004, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.001, train accuracy 0.997, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.001, train accuracy 0.990, val loss 0.006, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 42, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.001, train accuracy 1.000, val loss 0.003, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.001, train accuracy 0.990, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.001, train accuracy 0.997, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.001, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.001, train accuracy 0.990, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.000, train accuracy 1.000, val loss 0.002, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 93\n",
            "Epoch 0, train loss 0.054, train accuracy 0.260, val loss 0.271, val accuracy 0.143, and val rmse 0.547\n",
            "Epoch 1, train loss 0.052, train accuracy 0.286, val loss 0.275, val accuracy 0.080, and val rmse 0.600\n",
            "Epoch 2, train loss 0.052, train accuracy 0.273, val loss 0.264, val accuracy 0.384, and val rmse 0.120\n",
            "Epoch 3, train loss 0.049, train accuracy 0.477, val loss 0.248, val accuracy 0.420, and val rmse 0.147\n",
            "Epoch 4, train loss 0.046, train accuracy 0.581, val loss 0.232, val accuracy 0.573, and val rmse 0.000\n",
            "Epoch 5, train loss 0.043, train accuracy 0.617, val loss 0.219, val accuracy 0.613, and val rmse 0.013\n",
            "Epoch 6, train loss 0.040, train accuracy 0.682, val loss 0.218, val accuracy 0.639, and val rmse 0.013\n",
            "Epoch 7, train loss 0.038, train accuracy 0.679, val loss 0.202, val accuracy 0.692, and val rmse 0.000\n",
            "Epoch 8, train loss 0.036, train accuracy 0.705, val loss 0.185, val accuracy 0.690, and val rmse 0.000\n",
            "Epoch 9, train loss 0.033, train accuracy 0.705, val loss 0.176, val accuracy 0.650, and val rmse 0.053\n",
            "Epoch 10, train loss 0.030, train accuracy 0.734, val loss 0.155, val accuracy 0.728, and val rmse 0.053\n",
            "Epoch 11, train loss 0.027, train accuracy 0.786, val loss 0.140, val accuracy 0.768, and val rmse 0.053\n",
            "Epoch 12, train loss 0.024, train accuracy 0.799, val loss 0.121, val accuracy 0.782, and val rmse 0.027\n",
            "Epoch 13, train loss 0.026, train accuracy 0.753, val loss 0.135, val accuracy 0.768, and val rmse 0.027\n",
            "Epoch 14, train loss 0.020, train accuracy 0.864, val loss 0.098, val accuracy 0.871, and val rmse 0.000\n",
            "Epoch 15, train loss 0.018, train accuracy 0.867, val loss 0.087, val accuracy 0.897, and val rmse 0.000\n",
            "Epoch 16, train loss 0.017, train accuracy 0.899, val loss 0.080, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 17, train loss 0.015, train accuracy 0.925, val loss 0.069, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 18, train loss 0.013, train accuracy 0.942, val loss 0.064, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 19, train loss 0.016, train accuracy 0.912, val loss 0.074, val accuracy 0.922, and val rmse 0.000\n",
            "Epoch 20, train loss 0.012, train accuracy 0.951, val loss 0.052, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 21, train loss 0.011, train accuracy 0.948, val loss 0.048, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 22, train loss 0.009, train accuracy 0.984, val loss 0.041, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 23, train loss 0.008, train accuracy 0.984, val loss 0.037, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 24, train loss 0.011, train accuracy 0.925, val loss 0.064, val accuracy 0.871, and val rmse 0.000\n",
            "Epoch 25, train loss 0.011, train accuracy 0.909, val loss 0.048, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 26, train loss 0.021, train accuracy 0.779, val loss 0.176, val accuracy 0.659, and val rmse 0.000\n",
            "Epoch 27, train loss 0.013, train accuracy 0.880, val loss 0.059, val accuracy 0.909, and val rmse 0.000\n",
            "Epoch 28, train loss 0.011, train accuracy 0.903, val loss 0.049, val accuracy 0.922, and val rmse 0.000\n",
            "Epoch 29, train loss 0.013, train accuracy 0.916, val loss 0.051, val accuracy 0.922, and val rmse 0.000\n",
            "Epoch 30, train loss 0.010, train accuracy 0.942, val loss 0.043, val accuracy 0.947, and val rmse 0.000\n",
            "Epoch 31, train loss 0.009, train accuracy 0.951, val loss 0.038, val accuracy 0.960, and val rmse 0.000\n",
            "Epoch 32, train loss 0.008, train accuracy 0.951, val loss 0.034, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 33, train loss 0.008, train accuracy 0.948, val loss 0.040, val accuracy 0.934, and val rmse 0.000\n",
            "Epoch 34, train loss 0.006, train accuracy 0.974, val loss 0.029, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 35, train loss 0.006, train accuracy 0.971, val loss 0.024, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 36, train loss 0.007, train accuracy 0.961, val loss 0.033, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 37, train loss 0.006, train accuracy 0.964, val loss 0.026, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 38, train loss 0.005, train accuracy 0.971, val loss 0.025, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 39, train loss 0.005, train accuracy 0.958, val loss 0.023, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 40, train loss 0.006, train accuracy 0.948, val loss 0.039, val accuracy 0.874, and val rmse 0.000\n",
            "Epoch 41, train loss 0.005, train accuracy 0.971, val loss 0.017, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 42, train loss 0.004, train accuracy 0.964, val loss 0.015, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 43, train loss 0.007, train accuracy 0.945, val loss 0.018, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 44, train loss 0.003, train accuracy 0.981, val loss 0.014, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 45, train loss 0.004, train accuracy 0.958, val loss 0.015, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.984, val loss 0.013, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 47, train loss 0.003, train accuracy 0.984, val loss 0.012, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.974, val loss 0.013, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.984, val loss 0.011, val accuracy 0.987, and val rmse 0.000\n",
            "\n",
            " Iteration number : 94\n",
            "Epoch 0, train loss 0.054, train accuracy 0.244, val loss 0.278, val accuracy 0.125, and val rmse 0.227\n",
            "Epoch 1, train loss 0.049, train accuracy 0.448, val loss 0.271, val accuracy 0.189, and val rmse 0.200\n",
            "Epoch 2, train loss 0.045, train accuracy 0.516, val loss 0.243, val accuracy 0.479, and val rmse 0.107\n",
            "Epoch 3, train loss 0.037, train accuracy 0.539, val loss 0.207, val accuracy 0.477, and val rmse 0.053\n",
            "Epoch 4, train loss 0.034, train accuracy 0.623, val loss 0.196, val accuracy 0.558, and val rmse 0.013\n",
            "Epoch 5, train loss 0.032, train accuracy 0.685, val loss 0.172, val accuracy 0.650, and val rmse 0.027\n",
            "Epoch 6, train loss 0.028, train accuracy 0.636, val loss 0.146, val accuracy 0.597, and val rmse 0.133\n",
            "Epoch 7, train loss 0.029, train accuracy 0.701, val loss 0.173, val accuracy 0.637, and val rmse 0.013\n",
            "Epoch 8, train loss 0.031, train accuracy 0.633, val loss 0.232, val accuracy 0.503, and val rmse 0.000\n",
            "Epoch 9, train loss 0.024, train accuracy 0.633, val loss 0.119, val accuracy 0.570, and val rmse 0.293\n",
            "Epoch 10, train loss 0.022, train accuracy 0.636, val loss 0.106, val accuracy 0.649, and val rmse 0.133\n",
            "Epoch 11, train loss 0.021, train accuracy 0.649, val loss 0.103, val accuracy 0.583, and val rmse 0.267\n",
            "Epoch 12, train loss 0.019, train accuracy 0.623, val loss 0.098, val accuracy 0.595, and val rmse 0.293\n",
            "Epoch 13, train loss 0.021, train accuracy 0.714, val loss 0.110, val accuracy 0.490, and val rmse 0.400\n",
            "Epoch 14, train loss 0.018, train accuracy 0.656, val loss 0.092, val accuracy 0.450, and val rmse 0.400\n",
            "Epoch 15, train loss 0.016, train accuracy 0.698, val loss 0.085, val accuracy 0.567, and val rmse 0.267\n",
            "Epoch 16, train loss 0.015, train accuracy 0.688, val loss 0.074, val accuracy 0.689, and val rmse 0.213\n",
            "Epoch 17, train loss 0.015, train accuracy 0.737, val loss 0.072, val accuracy 0.690, and val rmse 0.213\n",
            "Epoch 18, train loss 0.014, train accuracy 0.740, val loss 0.068, val accuracy 0.768, and val rmse 0.133\n",
            "Epoch 19, train loss 0.016, train accuracy 0.763, val loss 0.182, val accuracy 0.353, and val rmse 0.187\n",
            "Epoch 20, train loss 0.013, train accuracy 0.763, val loss 0.060, val accuracy 0.844, and val rmse 0.080\n",
            "Epoch 21, train loss 0.013, train accuracy 0.782, val loss 0.062, val accuracy 0.821, and val rmse 0.027\n",
            "Epoch 22, train loss 0.012, train accuracy 0.828, val loss 0.054, val accuracy 0.870, and val rmse 0.053\n",
            "Epoch 23, train loss 0.011, train accuracy 0.870, val loss 0.051, val accuracy 0.870, and val rmse 0.053\n",
            "Epoch 24, train loss 0.010, train accuracy 0.903, val loss 0.045, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 25, train loss 0.009, train accuracy 0.906, val loss 0.042, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 26, train loss 0.008, train accuracy 0.932, val loss 0.038, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 27, train loss 0.008, train accuracy 0.935, val loss 0.037, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 28, train loss 0.006, train accuracy 0.958, val loss 0.029, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 29, train loss 0.006, train accuracy 0.958, val loss 0.026, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 30, train loss 0.005, train accuracy 0.951, val loss 0.023, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 31, train loss 0.005, train accuracy 0.971, val loss 0.021, val accuracy 0.973, and val rmse 0.000\n",
            "Epoch 32, train loss 0.010, train accuracy 0.916, val loss 0.063, val accuracy 0.860, and val rmse 0.000\n",
            "Epoch 33, train loss 0.005, train accuracy 0.964, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.004, train accuracy 0.984, val loss 0.017, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.004, train accuracy 0.984, val loss 0.021, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 36, train loss 0.003, train accuracy 0.984, val loss 0.013, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 37, train loss 0.003, train accuracy 0.974, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.005, train accuracy 0.951, val loss 0.020, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 39, train loss 0.005, train accuracy 0.981, val loss 0.043, val accuracy 0.947, and val rmse 0.000\n",
            "Epoch 40, train loss 0.004, train accuracy 0.987, val loss 0.022, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 41, train loss 0.003, train accuracy 0.997, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.004, train accuracy 0.971, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.005, train accuracy 0.961, val loss 0.024, val accuracy 0.962, and val rmse 0.000\n",
            "Epoch 44, train loss 0.002, train accuracy 1.000, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.994, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.984, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.987, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.964, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.002, train accuracy 0.990, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 95\n",
            "Epoch 0, train loss 0.056, train accuracy 0.263, val loss 0.294, val accuracy 0.225, and val rmse 0.600\n",
            "Epoch 1, train loss 0.054, train accuracy 0.256, val loss 0.274, val accuracy 0.288, and val rmse 0.480\n",
            "Epoch 2, train loss 0.050, train accuracy 0.321, val loss 0.253, val accuracy 0.267, and val rmse 0.520\n",
            "Epoch 3, train loss 0.048, train accuracy 0.231, val loss 0.245, val accuracy 0.155, and val rmse 0.547\n",
            "Epoch 4, train loss 0.048, train accuracy 0.331, val loss 0.249, val accuracy 0.131, and val rmse 0.533\n",
            "Epoch 5, train loss 0.045, train accuracy 0.321, val loss 0.232, val accuracy 0.483, and val rmse 0.053\n",
            "Epoch 6, train loss 0.044, train accuracy 0.419, val loss 0.227, val accuracy 0.453, and val rmse 0.013\n",
            "Epoch 7, train loss 0.043, train accuracy 0.412, val loss 0.224, val accuracy 0.464, and val rmse 0.093\n",
            "Epoch 8, train loss 0.040, train accuracy 0.448, val loss 0.205, val accuracy 0.450, and val rmse 0.240\n",
            "Epoch 9, train loss 0.038, train accuracy 0.448, val loss 0.199, val accuracy 0.368, and val rmse 0.320\n",
            "Epoch 10, train loss 0.037, train accuracy 0.425, val loss 0.190, val accuracy 0.315, and val rmse 0.320\n",
            "Epoch 11, train loss 0.039, train accuracy 0.432, val loss 0.212, val accuracy 0.250, and val rmse 0.280\n",
            "Epoch 12, train loss 0.034, train accuracy 0.597, val loss 0.169, val accuracy 0.543, and val rmse 0.173\n",
            "Epoch 13, train loss 0.033, train accuracy 0.633, val loss 0.169, val accuracy 0.643, and val rmse 0.000\n",
            "Epoch 14, train loss 0.031, train accuracy 0.763, val loss 0.156, val accuracy 0.620, and val rmse 0.000\n",
            "Epoch 15, train loss 0.029, train accuracy 0.782, val loss 0.149, val accuracy 0.747, and val rmse 0.000\n",
            "Epoch 16, train loss 0.030, train accuracy 0.773, val loss 0.138, val accuracy 0.784, and val rmse 0.000\n",
            "Epoch 17, train loss 0.031, train accuracy 0.685, val loss 0.132, val accuracy 0.844, and val rmse 0.053\n",
            "Epoch 18, train loss 0.029, train accuracy 0.646, val loss 0.174, val accuracy 0.553, and val rmse 0.080\n",
            "Epoch 19, train loss 0.021, train accuracy 0.844, val loss 0.105, val accuracy 0.897, and val rmse 0.000\n",
            "Epoch 20, train loss 0.029, train accuracy 0.851, val loss 0.101, val accuracy 0.897, and val rmse 0.000\n",
            "Epoch 21, train loss 0.032, train accuracy 0.828, val loss 0.162, val accuracy 0.843, and val rmse 0.000\n",
            "Epoch 22, train loss 0.029, train accuracy 0.828, val loss 0.144, val accuracy 0.830, and val rmse 0.000\n",
            "Epoch 23, train loss 0.027, train accuracy 0.786, val loss 0.139, val accuracy 0.743, and val rmse 0.000\n",
            "Epoch 24, train loss 0.022, train accuracy 0.718, val loss 0.100, val accuracy 0.717, and val rmse 0.000\n",
            "Epoch 25, train loss 0.019, train accuracy 0.802, val loss 0.091, val accuracy 0.755, and val rmse 0.000\n",
            "Epoch 26, train loss 0.019, train accuracy 0.828, val loss 0.096, val accuracy 0.872, and val rmse 0.000\n",
            "Epoch 27, train loss 0.015, train accuracy 0.883, val loss 0.073, val accuracy 0.897, and val rmse 0.000\n",
            "Epoch 28, train loss 0.015, train accuracy 0.877, val loss 0.072, val accuracy 0.897, and val rmse 0.000\n",
            "Epoch 29, train loss 0.013, train accuracy 0.909, val loss 0.067, val accuracy 0.910, and val rmse 0.000\n",
            "Epoch 30, train loss 0.013, train accuracy 0.912, val loss 0.061, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 31, train loss 0.011, train accuracy 0.929, val loss 0.056, val accuracy 0.935, and val rmse 0.000\n",
            "Epoch 32, train loss 0.011, train accuracy 0.935, val loss 0.056, val accuracy 0.923, and val rmse 0.000\n",
            "Epoch 33, train loss 0.010, train accuracy 0.932, val loss 0.051, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 34, train loss 0.011, train accuracy 0.922, val loss 0.048, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 35, train loss 0.011, train accuracy 0.938, val loss 0.048, val accuracy 0.948, and val rmse 0.000\n",
            "Epoch 36, train loss 0.009, train accuracy 0.945, val loss 0.053, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 37, train loss 0.009, train accuracy 0.951, val loss 0.042, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 38, train loss 0.009, train accuracy 0.955, val loss 0.040, val accuracy 0.961, and val rmse 0.000\n",
            "Epoch 39, train loss 0.008, train accuracy 0.951, val loss 0.036, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 40, train loss 0.009, train accuracy 0.942, val loss 0.040, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 41, train loss 0.008, train accuracy 0.938, val loss 0.033, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 42, train loss 0.006, train accuracy 0.971, val loss 0.029, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 43, train loss 0.007, train accuracy 0.961, val loss 0.028, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 44, train loss 0.006, train accuracy 0.981, val loss 0.038, val accuracy 0.937, and val rmse 0.000\n",
            "Epoch 45, train loss 0.006, train accuracy 0.977, val loss 0.025, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 46, train loss 0.005, train accuracy 0.990, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.005, train accuracy 0.990, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.004, train accuracy 0.994, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.004, train accuracy 0.997, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 96\n",
            "Epoch 0, train loss 0.054, train accuracy 0.166, val loss 0.274, val accuracy 0.387, and val rmse 0.053\n",
            "Epoch 1, train loss 0.052, train accuracy 0.256, val loss 0.269, val accuracy 0.257, and val rmse 0.453\n",
            "Epoch 2, train loss 0.052, train accuracy 0.302, val loss 0.267, val accuracy 0.204, and val rmse 0.440\n",
            "Epoch 3, train loss 0.051, train accuracy 0.318, val loss 0.267, val accuracy 0.147, and val rmse 0.160\n",
            "Epoch 4, train loss 0.050, train accuracy 0.354, val loss 0.271, val accuracy 0.147, and val rmse 0.267\n",
            "Epoch 5, train loss 0.049, train accuracy 0.422, val loss 0.262, val accuracy 0.210, and val rmse 0.173\n",
            "Epoch 6, train loss 0.046, train accuracy 0.481, val loss 0.250, val accuracy 0.253, and val rmse 0.120\n",
            "Epoch 7, train loss 0.043, train accuracy 0.578, val loss 0.226, val accuracy 0.484, and val rmse 0.120\n",
            "Epoch 8, train loss 0.040, train accuracy 0.568, val loss 0.218, val accuracy 0.376, and val rmse 0.253\n",
            "Epoch 9, train loss 0.042, train accuracy 0.591, val loss 0.226, val accuracy 0.431, and val rmse 0.240\n",
            "Epoch 10, train loss 0.039, train accuracy 0.607, val loss 0.204, val accuracy 0.469, and val rmse 0.253\n",
            "Epoch 11, train loss 0.036, train accuracy 0.679, val loss 0.187, val accuracy 0.611, and val rmse 0.147\n",
            "Epoch 12, train loss 0.033, train accuracy 0.643, val loss 0.172, val accuracy 0.634, and val rmse 0.227\n",
            "Epoch 13, train loss 0.031, train accuracy 0.682, val loss 0.161, val accuracy 0.635, and val rmse 0.227\n",
            "Epoch 14, train loss 0.030, train accuracy 0.688, val loss 0.153, val accuracy 0.674, and val rmse 0.200\n",
            "Epoch 15, train loss 0.028, train accuracy 0.698, val loss 0.150, val accuracy 0.701, and val rmse 0.147\n",
            "Epoch 16, train loss 0.032, train accuracy 0.662, val loss 0.191, val accuracy 0.620, and val rmse 0.267\n",
            "Epoch 17, train loss 0.029, train accuracy 0.714, val loss 0.155, val accuracy 0.686, and val rmse 0.160\n",
            "Epoch 18, train loss 0.027, train accuracy 0.705, val loss 0.137, val accuracy 0.725, and val rmse 0.133\n",
            "Epoch 19, train loss 0.026, train accuracy 0.705, val loss 0.133, val accuracy 0.699, and val rmse 0.160\n",
            "Epoch 20, train loss 0.024, train accuracy 0.727, val loss 0.122, val accuracy 0.739, and val rmse 0.160\n",
            "Epoch 21, train loss 0.024, train accuracy 0.724, val loss 0.116, val accuracy 0.752, and val rmse 0.160\n",
            "Epoch 22, train loss 0.024, train accuracy 0.753, val loss 0.119, val accuracy 0.806, and val rmse 0.053\n",
            "Epoch 23, train loss 0.022, train accuracy 0.773, val loss 0.111, val accuracy 0.819, and val rmse 0.053\n",
            "Epoch 24, train loss 0.021, train accuracy 0.786, val loss 0.105, val accuracy 0.832, and val rmse 0.053\n",
            "Epoch 25, train loss 0.020, train accuracy 0.779, val loss 0.101, val accuracy 0.818, and val rmse 0.080\n",
            "Epoch 26, train loss 0.020, train accuracy 0.812, val loss 0.097, val accuracy 0.832, and val rmse 0.053\n",
            "Epoch 27, train loss 0.019, train accuracy 0.802, val loss 0.095, val accuracy 0.805, and val rmse 0.107\n",
            "Epoch 28, train loss 0.019, train accuracy 0.795, val loss 0.094, val accuracy 0.818, and val rmse 0.080\n",
            "Epoch 29, train loss 0.017, train accuracy 0.795, val loss 0.088, val accuracy 0.845, and val rmse 0.027\n",
            "Epoch 30, train loss 0.016, train accuracy 0.818, val loss 0.084, val accuracy 0.845, and val rmse 0.027\n",
            "Epoch 31, train loss 0.016, train accuracy 0.821, val loss 0.082, val accuracy 0.845, and val rmse 0.027\n",
            "Epoch 32, train loss 0.017, train accuracy 0.825, val loss 0.079, val accuracy 0.845, and val rmse 0.027\n",
            "Epoch 33, train loss 0.016, train accuracy 0.812, val loss 0.077, val accuracy 0.845, and val rmse 0.027\n",
            "Epoch 34, train loss 0.015, train accuracy 0.828, val loss 0.074, val accuracy 0.845, and val rmse 0.027\n",
            "Epoch 35, train loss 0.015, train accuracy 0.825, val loss 0.072, val accuracy 0.845, and val rmse 0.027\n",
            "Epoch 36, train loss 0.015, train accuracy 0.831, val loss 0.070, val accuracy 0.845, and val rmse 0.027\n",
            "Epoch 37, train loss 0.014, train accuracy 0.818, val loss 0.069, val accuracy 0.845, and val rmse 0.027\n",
            "Epoch 38, train loss 0.013, train accuracy 0.851, val loss 0.065, val accuracy 0.845, and val rmse 0.027\n",
            "Epoch 39, train loss 0.013, train accuracy 0.844, val loss 0.063, val accuracy 0.871, and val rmse 0.000\n",
            "Epoch 40, train loss 0.013, train accuracy 0.847, val loss 0.063, val accuracy 0.858, and val rmse 0.000\n",
            "Epoch 41, train loss 0.012, train accuracy 0.854, val loss 0.060, val accuracy 0.871, and val rmse 0.000\n",
            "Epoch 42, train loss 0.012, train accuracy 0.854, val loss 0.059, val accuracy 0.871, and val rmse 0.000\n",
            "Epoch 43, train loss 0.011, train accuracy 0.857, val loss 0.057, val accuracy 0.871, and val rmse 0.000\n",
            "Epoch 44, train loss 0.011, train accuracy 0.847, val loss 0.056, val accuracy 0.871, and val rmse 0.000\n",
            "Epoch 45, train loss 0.012, train accuracy 0.857, val loss 0.054, val accuracy 0.871, and val rmse 0.000\n",
            "Epoch 46, train loss 0.011, train accuracy 0.877, val loss 0.054, val accuracy 0.871, and val rmse 0.000\n",
            "Epoch 47, train loss 0.010, train accuracy 0.870, val loss 0.053, val accuracy 0.884, and val rmse 0.000\n",
            "Epoch 48, train loss 0.010, train accuracy 0.860, val loss 0.052, val accuracy 0.884, and val rmse 0.000\n",
            "Epoch 49, train loss 0.010, train accuracy 0.870, val loss 0.050, val accuracy 0.884, and val rmse 0.000\n",
            "\n",
            " Iteration number : 97\n",
            "Epoch 0, train loss 0.053, train accuracy 0.260, val loss 0.266, val accuracy 0.250, and val rmse 0.600\n",
            "Epoch 1, train loss 0.053, train accuracy 0.237, val loss 0.250, val accuracy 0.277, and val rmse 0.373\n",
            "Epoch 2, train loss 0.051, train accuracy 0.302, val loss 0.255, val accuracy 0.363, and val rmse 0.440\n",
            "Epoch 3, train loss 0.050, train accuracy 0.286, val loss 0.292, val accuracy 0.297, and val rmse 0.227\n",
            "Epoch 4, train loss 0.046, train accuracy 0.256, val loss 0.234, val accuracy 0.310, and val rmse 0.387\n",
            "Epoch 5, train loss 0.039, train accuracy 0.338, val loss 0.209, val accuracy 0.353, and val rmse 0.373\n",
            "Epoch 6, train loss 0.038, train accuracy 0.419, val loss 0.189, val accuracy 0.358, and val rmse 0.213\n",
            "Epoch 7, train loss 0.036, train accuracy 0.429, val loss 0.189, val accuracy 0.398, and val rmse 0.147\n",
            "Epoch 8, train loss 0.034, train accuracy 0.539, val loss 0.179, val accuracy 0.157, and val rmse 0.427\n",
            "Epoch 9, train loss 0.034, train accuracy 0.578, val loss 0.165, val accuracy 0.569, and val rmse 0.240\n",
            "Epoch 10, train loss 0.032, train accuracy 0.571, val loss 0.160, val accuracy 0.534, and val rmse 0.267\n",
            "Epoch 11, train loss 0.031, train accuracy 0.529, val loss 0.162, val accuracy 0.446, and val rmse 0.027\n",
            "Epoch 12, train loss 0.031, train accuracy 0.584, val loss 0.150, val accuracy 0.512, and val rmse 0.240\n",
            "Epoch 13, train loss 0.026, train accuracy 0.627, val loss 0.141, val accuracy 0.494, and val rmse 0.267\n",
            "Epoch 14, train loss 0.025, train accuracy 0.653, val loss 0.130, val accuracy 0.522, and val rmse 0.267\n",
            "Epoch 15, train loss 0.023, train accuracy 0.701, val loss 0.125, val accuracy 0.568, and val rmse 0.267\n",
            "Epoch 16, train loss 0.026, train accuracy 0.682, val loss 0.123, val accuracy 0.633, and val rmse 0.253\n",
            "Epoch 17, train loss 0.021, train accuracy 0.714, val loss 0.114, val accuracy 0.593, and val rmse 0.320\n",
            "Epoch 18, train loss 0.020, train accuracy 0.705, val loss 0.106, val accuracy 0.593, and val rmse 0.320\n",
            "Epoch 19, train loss 0.019, train accuracy 0.714, val loss 0.102, val accuracy 0.593, and val rmse 0.320\n",
            "Epoch 20, train loss 0.018, train accuracy 0.718, val loss 0.096, val accuracy 0.593, and val rmse 0.320\n",
            "Epoch 21, train loss 0.018, train accuracy 0.724, val loss 0.099, val accuracy 0.568, and val rmse 0.320\n",
            "Epoch 22, train loss 0.018, train accuracy 0.633, val loss 0.091, val accuracy 0.513, and val rmse 0.400\n",
            "Epoch 23, train loss 0.017, train accuracy 0.685, val loss 0.088, val accuracy 0.580, and val rmse 0.320\n",
            "Epoch 24, train loss 0.016, train accuracy 0.701, val loss 0.086, val accuracy 0.634, and val rmse 0.320\n",
            "Epoch 25, train loss 0.015, train accuracy 0.711, val loss 0.080, val accuracy 0.647, and val rmse 0.320\n",
            "Epoch 26, train loss 0.015, train accuracy 0.724, val loss 0.080, val accuracy 0.647, and val rmse 0.320\n",
            "Epoch 27, train loss 0.015, train accuracy 0.721, val loss 0.075, val accuracy 0.673, and val rmse 0.293\n",
            "Epoch 28, train loss 0.014, train accuracy 0.740, val loss 0.074, val accuracy 0.687, and val rmse 0.267\n",
            "Epoch 29, train loss 0.015, train accuracy 0.737, val loss 0.077, val accuracy 0.687, and val rmse 0.267\n",
            "Epoch 30, train loss 0.014, train accuracy 0.760, val loss 0.075, val accuracy 0.781, and val rmse 0.027\n",
            "Epoch 31, train loss 0.013, train accuracy 0.753, val loss 0.070, val accuracy 0.727, and val rmse 0.187\n",
            "Epoch 32, train loss 0.013, train accuracy 0.740, val loss 0.068, val accuracy 0.673, and val rmse 0.293\n",
            "Epoch 33, train loss 0.013, train accuracy 0.753, val loss 0.066, val accuracy 0.673, and val rmse 0.293\n",
            "Epoch 34, train loss 0.013, train accuracy 0.789, val loss 0.065, val accuracy 0.673, and val rmse 0.293\n",
            "Epoch 35, train loss 0.013, train accuracy 0.747, val loss 0.065, val accuracy 0.673, and val rmse 0.293\n",
            "Epoch 36, train loss 0.012, train accuracy 0.753, val loss 0.063, val accuracy 0.700, and val rmse 0.240\n",
            "Epoch 37, train loss 0.012, train accuracy 0.769, val loss 0.063, val accuracy 0.700, and val rmse 0.240\n",
            "Epoch 38, train loss 0.011, train accuracy 0.844, val loss 0.053, val accuracy 0.807, and val rmse 0.027\n",
            "Epoch 39, train loss 0.009, train accuracy 0.945, val loss 0.046, val accuracy 0.973, and val rmse 0.053\n",
            "Epoch 40, train loss 0.008, train accuracy 0.955, val loss 0.037, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 41, train loss 0.007, train accuracy 0.964, val loss 0.033, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 42, train loss 0.006, train accuracy 0.977, val loss 0.028, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 43, train loss 0.007, train accuracy 0.961, val loss 0.027, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.005, train accuracy 0.997, val loss 0.023, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.004, train accuracy 0.994, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.004, train accuracy 0.994, val loss 0.018, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.004, train accuracy 0.994, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.003, train accuracy 0.994, val loss 0.015, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.003, train accuracy 0.997, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 98\n",
            "Epoch 0, train loss 0.053, train accuracy 0.094, val loss 0.268, val accuracy 0.160, and val rmse 0.240\n",
            "Epoch 1, train loss 0.050, train accuracy 0.201, val loss 0.269, val accuracy 0.199, and val rmse 0.227\n",
            "Epoch 2, train loss 0.049, train accuracy 0.416, val loss 0.270, val accuracy 0.387, and val rmse 0.027\n",
            "Epoch 3, train loss 0.046, train accuracy 0.438, val loss 0.242, val accuracy 0.267, and val rmse 0.373\n",
            "Epoch 4, train loss 0.044, train accuracy 0.487, val loss 0.245, val accuracy 0.413, and val rmse 0.053\n",
            "Epoch 5, train loss 0.041, train accuracy 0.607, val loss 0.210, val accuracy 0.627, and val rmse 0.053\n",
            "Epoch 6, train loss 0.037, train accuracy 0.659, val loss 0.195, val accuracy 0.690, and val rmse 0.027\n",
            "Epoch 7, train loss 0.035, train accuracy 0.692, val loss 0.197, val accuracy 0.528, and val rmse 0.013\n",
            "Epoch 8, train loss 0.032, train accuracy 0.747, val loss 0.171, val accuracy 0.718, and val rmse 0.000\n",
            "Epoch 9, train loss 0.029, train accuracy 0.753, val loss 0.155, val accuracy 0.781, and val rmse 0.000\n",
            "Epoch 10, train loss 0.028, train accuracy 0.786, val loss 0.146, val accuracy 0.781, and val rmse 0.000\n",
            "Epoch 11, train loss 0.024, train accuracy 0.799, val loss 0.126, val accuracy 0.818, and val rmse 0.000\n",
            "Epoch 12, train loss 0.022, train accuracy 0.854, val loss 0.122, val accuracy 0.819, and val rmse 0.000\n",
            "Epoch 13, train loss 0.021, train accuracy 0.854, val loss 0.111, val accuracy 0.857, and val rmse 0.027\n",
            "Epoch 14, train loss 0.020, train accuracy 0.880, val loss 0.100, val accuracy 0.883, and val rmse 0.000\n",
            "Epoch 15, train loss 0.018, train accuracy 0.873, val loss 0.090, val accuracy 0.883, and val rmse 0.027\n",
            "Epoch 16, train loss 0.017, train accuracy 0.877, val loss 0.084, val accuracy 0.896, and val rmse 0.027\n",
            "Epoch 17, train loss 0.016, train accuracy 0.886, val loss 0.083, val accuracy 0.896, and val rmse 0.027\n",
            "Epoch 18, train loss 0.017, train accuracy 0.877, val loss 0.075, val accuracy 0.909, and val rmse 0.027\n",
            "Epoch 19, train loss 0.014, train accuracy 0.919, val loss 0.078, val accuracy 0.897, and val rmse 0.027\n",
            "Epoch 20, train loss 0.013, train accuracy 0.899, val loss 0.066, val accuracy 0.922, and val rmse 0.027\n",
            "Epoch 21, train loss 0.012, train accuracy 0.925, val loss 0.064, val accuracy 0.922, and val rmse 0.027\n",
            "Epoch 22, train loss 0.011, train accuracy 0.932, val loss 0.059, val accuracy 0.935, and val rmse 0.027\n",
            "Epoch 23, train loss 0.015, train accuracy 0.867, val loss 0.147, val accuracy 0.610, and val rmse 0.027\n",
            "Epoch 24, train loss 0.013, train accuracy 0.899, val loss 0.053, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 25, train loss 0.010, train accuracy 0.942, val loss 0.045, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 26, train loss 0.010, train accuracy 0.912, val loss 0.047, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 27, train loss 0.009, train accuracy 0.929, val loss 0.040, val accuracy 0.948, and val rmse 0.027\n",
            "Epoch 28, train loss 0.008, train accuracy 0.955, val loss 0.038, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 29, train loss 0.007, train accuracy 0.955, val loss 0.034, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 30, train loss 0.007, train accuracy 0.961, val loss 0.031, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 31, train loss 0.006, train accuracy 0.981, val loss 0.027, val accuracy 0.973, and val rmse 0.027\n",
            "Epoch 32, train loss 0.005, train accuracy 0.990, val loss 0.023, val accuracy 0.987, and val rmse 0.027\n",
            "Epoch 33, train loss 0.005, train accuracy 0.984, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 34, train loss 0.006, train accuracy 0.971, val loss 0.020, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 35, train loss 0.005, train accuracy 0.977, val loss 0.016, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 36, train loss 0.004, train accuracy 0.990, val loss 0.022, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 37, train loss 0.005, train accuracy 0.977, val loss 0.014, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 38, train loss 0.003, train accuracy 0.997, val loss 0.018, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 39, train loss 0.003, train accuracy 0.994, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 40, train loss 0.003, train accuracy 0.994, val loss 0.011, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 41, train loss 0.007, train accuracy 0.961, val loss 0.012, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 42, train loss 0.003, train accuracy 0.981, val loss 0.010, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.002, train accuracy 1.000, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 44, train loss 0.004, train accuracy 0.977, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 45, train loss 0.002, train accuracy 0.981, val loss 0.013, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 46, train loss 0.003, train accuracy 0.968, val loss 0.008, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.002, train accuracy 0.990, val loss 0.007, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.002, train accuracy 0.994, val loss 0.009, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 49, train loss 0.001, train accuracy 0.997, val loss 0.006, val accuracy 1.000, and val rmse 0.000\n",
            "\n",
            " Iteration number : 99\n",
            "Epoch 0, train loss 0.053, train accuracy 0.198, val loss 0.274, val accuracy 0.270, and val rmse 0.387\n",
            "Epoch 1, train loss 0.051, train accuracy 0.299, val loss 0.263, val accuracy 0.290, and val rmse 0.267\n",
            "Epoch 2, train loss 0.050, train accuracy 0.373, val loss 0.270, val accuracy 0.312, and val rmse 0.227\n",
            "Epoch 3, train loss 0.049, train accuracy 0.354, val loss 0.253, val accuracy 0.160, and val rmse 0.147\n",
            "Epoch 4, train loss 0.047, train accuracy 0.276, val loss 0.241, val accuracy 0.253, and val rmse 0.173\n",
            "Epoch 5, train loss 0.044, train accuracy 0.393, val loss 0.225, val accuracy 0.400, and val rmse 0.040\n",
            "Epoch 6, train loss 0.042, train accuracy 0.416, val loss 0.225, val accuracy 0.360, and val rmse 0.040\n",
            "Epoch 7, train loss 0.039, train accuracy 0.503, val loss 0.199, val accuracy 0.386, and val rmse 0.093\n",
            "Epoch 8, train loss 0.037, train accuracy 0.584, val loss 0.193, val accuracy 0.473, and val rmse 0.040\n",
            "Epoch 9, train loss 0.035, train accuracy 0.630, val loss 0.177, val accuracy 0.588, and val rmse 0.040\n",
            "Epoch 10, train loss 0.031, train accuracy 0.679, val loss 0.162, val accuracy 0.597, and val rmse 0.227\n",
            "Epoch 11, train loss 0.031, train accuracy 0.614, val loss 0.161, val accuracy 0.418, and val rmse 0.227\n",
            "Epoch 12, train loss 0.027, train accuracy 0.711, val loss 0.136, val accuracy 0.702, and val rmse 0.093\n",
            "Epoch 13, train loss 0.025, train accuracy 0.744, val loss 0.126, val accuracy 0.729, and val rmse 0.067\n",
            "Epoch 14, train loss 0.024, train accuracy 0.744, val loss 0.108, val accuracy 0.854, and val rmse 0.067\n",
            "Epoch 15, train loss 0.021, train accuracy 0.812, val loss 0.106, val accuracy 0.818, and val rmse 0.027\n",
            "Epoch 16, train loss 0.022, train accuracy 0.744, val loss 0.108, val accuracy 0.856, and val rmse 0.027\n",
            "Epoch 17, train loss 0.019, train accuracy 0.821, val loss 0.094, val accuracy 0.794, and val rmse 0.027\n",
            "Epoch 18, train loss 0.020, train accuracy 0.821, val loss 0.094, val accuracy 0.818, and val rmse 0.053\n",
            "Epoch 19, train loss 0.015, train accuracy 0.870, val loss 0.076, val accuracy 0.882, and val rmse 0.027\n",
            "Epoch 20, train loss 0.020, train accuracy 0.734, val loss 0.151, val accuracy 0.356, and val rmse 0.400\n",
            "Epoch 21, train loss 0.022, train accuracy 0.601, val loss 0.149, val accuracy 0.492, and val rmse 0.293\n",
            "Epoch 22, train loss 0.018, train accuracy 0.721, val loss 0.087, val accuracy 0.721, and val rmse 0.213\n",
            "Epoch 23, train loss 0.018, train accuracy 0.727, val loss 0.095, val accuracy 0.671, and val rmse 0.213\n",
            "Epoch 24, train loss 0.017, train accuracy 0.727, val loss 0.083, val accuracy 0.734, and val rmse 0.213\n",
            "Epoch 25, train loss 0.017, train accuracy 0.708, val loss 0.092, val accuracy 0.708, and val rmse 0.187\n",
            "Epoch 26, train loss 0.016, train accuracy 0.769, val loss 0.091, val accuracy 0.722, and val rmse 0.187\n",
            "Epoch 27, train loss 0.018, train accuracy 0.773, val loss 0.186, val accuracy 0.498, and val rmse 0.187\n",
            "Epoch 28, train loss 0.015, train accuracy 0.769, val loss 0.092, val accuracy 0.768, and val rmse 0.053\n",
            "Epoch 29, train loss 0.015, train accuracy 0.821, val loss 0.108, val accuracy 0.729, and val rmse 0.093\n",
            "Epoch 30, train loss 0.014, train accuracy 0.821, val loss 0.067, val accuracy 0.843, and val rmse 0.093\n",
            "Epoch 31, train loss 0.012, train accuracy 0.834, val loss 0.057, val accuracy 0.882, and val rmse 0.093\n",
            "Epoch 32, train loss 0.013, train accuracy 0.870, val loss 0.052, val accuracy 0.908, and val rmse 0.080\n",
            "Epoch 33, train loss 0.011, train accuracy 0.883, val loss 0.048, val accuracy 0.934, and val rmse 0.027\n",
            "Epoch 34, train loss 0.012, train accuracy 0.886, val loss 0.059, val accuracy 0.883, and val rmse 0.040\n",
            "Epoch 35, train loss 0.009, train accuracy 0.916, val loss 0.041, val accuracy 0.960, and val rmse 0.013\n",
            "Epoch 36, train loss 0.008, train accuracy 0.932, val loss 0.037, val accuracy 0.973, and val rmse 0.013\n",
            "Epoch 37, train loss 0.011, train accuracy 0.925, val loss 0.036, val accuracy 0.973, and val rmse 0.013\n",
            "Epoch 38, train loss 0.008, train accuracy 0.942, val loss 0.040, val accuracy 0.961, and val rmse 0.013\n",
            "Epoch 39, train loss 0.008, train accuracy 0.932, val loss 0.031, val accuracy 0.960, and val rmse 0.027\n",
            "Epoch 40, train loss 0.009, train accuracy 0.938, val loss 0.056, val accuracy 0.886, and val rmse 0.013\n",
            "Epoch 41, train loss 0.007, train accuracy 0.961, val loss 0.026, val accuracy 0.987, and val rmse 0.000\n",
            "Epoch 42, train loss 0.006, train accuracy 0.961, val loss 0.024, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 43, train loss 0.006, train accuracy 0.971, val loss 0.026, val accuracy 0.974, and val rmse 0.000\n",
            "Epoch 44, train loss 0.008, train accuracy 0.932, val loss 0.049, val accuracy 0.913, and val rmse 0.000\n",
            "Epoch 45, train loss 0.005, train accuracy 0.981, val loss 0.025, val accuracy 0.988, and val rmse 0.000\n",
            "Epoch 46, train loss 0.005, train accuracy 0.974, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 47, train loss 0.005, train accuracy 0.974, val loss 0.019, val accuracy 1.000, and val rmse 0.000\n",
            "Epoch 48, train loss 0.007, train accuracy 0.945, val loss 0.024, val accuracy 0.975, and val rmse 0.000\n",
            "Epoch 49, train loss 0.004, train accuracy 0.955, val loss 0.018, val accuracy 0.973, and val rmse 0.027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cabwv7apZXcn"
      },
      "source": [
        "# path = pwd+'/Results/'+Nest_analysis+'_'+dt_string+'.csv'\n",
        "df_loss_accuracy.to_csv(base_path+'/Results/'+Nest_analysis+'_'+dt_string+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "b48TwzFVZox6",
        "outputId": "37c350c7-dc6a-406b-a498-ec7ce3905725"
      },
      "source": [
        "df_loss_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Loss</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Val Loss</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Test Loss</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.262133</td>\n",
              "      <td>0.3181818</td>\n",
              "      <td>1.340543</td>\n",
              "      <td>0.21333334</td>\n",
              "      <td>1.263984</td>\n",
              "      <td>0.2820513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.253577</td>\n",
              "      <td>0.3961039</td>\n",
              "      <td>1.308524</td>\n",
              "      <td>0.41333333</td>\n",
              "      <td>1.186756</td>\n",
              "      <td>0.41025642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Train Loss Train Accuracy  Val Loss Val Accuracy  Test Loss Test Accuracy\n",
              "0    0.262133      0.3181818  1.340543   0.21333334   1.263984     0.2820513\n",
              "1    0.253577      0.3961039  1.308524   0.41333333   1.186756    0.41025642"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "3yuH22w6-9Zz",
        "outputId": "c799d0b9-d4e6-42bf-a2ec-5073cebedf91"
      },
      "source": [
        "df_loss_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Loss</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Val Loss</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Test Loss</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.262133</td>\n",
              "      <td>0.3181818</td>\n",
              "      <td>1.340543</td>\n",
              "      <td>0.21333334</td>\n",
              "      <td>1.263984</td>\n",
              "      <td>0.2820513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.253577</td>\n",
              "      <td>0.3961039</td>\n",
              "      <td>1.308524</td>\n",
              "      <td>0.41333333</td>\n",
              "      <td>1.186756</td>\n",
              "      <td>0.41025642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Train Loss Train Accuracy  Val Loss Val Accuracy  Test Loss Test Accuracy\n",
              "0    0.262133      0.3181818  1.340543   0.21333334   1.263984     0.2820513\n",
              "1    0.253577      0.3961039  1.308524   0.41333333   1.186756    0.41025642"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCW_ta1IAvRZ",
        "outputId": "ba7fc581-e2fe-4fff-f6af-091937c3321f"
      },
      "source": [
        "train_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3312)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP2fsHVMxmlp"
      },
      "source": [
        "# model_fixed(torch.randn(24, 153, 1024))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcCjwwa9zxKg"
      },
      "source": [
        "# model_fixed(x.float())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "oswTmTX1suz2",
        "outputId": "94d5c628-d43c-42a2-b255-710ed675aecc"
      },
      "source": [
        "for x, y, l in valid_ds:\n",
        "  x = x.float()\n",
        "  x.resize_((1,x.shape[0],x.shape[1]))\n",
        "  y = torch.tensor(y).long().resize_((1))\n",
        "  # y_hat = model(x, l)\n",
        "  y_hat = model_fixed(x)\n",
        "  # loss = F.cross_entropy(y_hat, y)\n",
        "  pred = torch.max(y_hat, 1)[1]\n",
        "  print(y, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-b31c41fe6517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# y_hat = model(x, l)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'valid_ds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKC1ct11iR5F"
      },
      "source": [
        "Hidden_layer =[]\n",
        "Hidden_layer_labels = []\n",
        "\n",
        "for x, y, l in train_ds:\n",
        "  x = x.float()\n",
        "  x.resize_((1,x.shape[0],x.shape[1]))\n",
        "  lstm_out, (ht, ct) = model_fixed.lstm(x)\n",
        "  Hidden_layer.append(ht[-1].detach().numpy().reshape(10, ))\n",
        "  Hidden_layer_labels.append(y)\n",
        "\n",
        "for x, y, l in test_ds:\n",
        "  x = x.float()\n",
        "  x.resize_((1,x.shape[0],x.shape[1]))\n",
        "  lstm_out, (ht, ct) = model_fixed.lstm(x)\n",
        "  Hidden_layer.append(ht[-1].detach().numpy().reshape(10, ))\n",
        "  Hidden_layer_labels.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiq2mdo1L5Zw",
        "outputId": "7e8fc145-0cec-4e96-826b-97f67ce46c8f"
      },
      "source": [
        "ht"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-9.9999e-01,  1.0147e-08, -9.9955e-01,  6.4942e-04,  3.7315e-01,\n",
              "           4.5323e-08, -7.9513e-04,  1.0000e+00,  1.0000e+00, -1.0000e+00]]],\n",
              "       grad_fn=<StackBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7zRwHr3_gJ2",
        "outputId": "4c2aafdc-76b5-419f-a7f5-2888fb6754a7"
      },
      "source": [
        "Hidden_layer[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.9911277 , -0.9362339 , -0.7752966 ,  0.50072587,  0.9896477 ,\n",
              "        0.9077447 ,  0.9980349 ,  0.9107824 ,  0.9619196 ,  0.9484187 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5kXdYyPlbB-",
        "outputId": "b328b0c8-0b76-4b37-8394-9844d5c51fe7"
      },
      "source": [
        "len(Hidden_layer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwx-OODw5nIE",
        "outputId": "6f58a04b-d951-4f70-9018-4fecfc28f2be"
      },
      "source": [
        "len(Hidden_layer_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GuE1rmJ-8ez"
      },
      "source": [
        "hover_data = pd.DataFrame(le.inverse_transform((Hidden_layer_labels)), columns=['key'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzLKn8-X_TwX",
        "outputId": "91ecdd79-68ab-4e2b-8fa0-74f7a32470b2"
      },
      "source": [
        "pip install umap-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting umap-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/69/85e7f950bb75792ad5d666d86c5f3e62eedbb942848e7e3126513af9999c/umap-learn-0.5.1.tar.gz (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/65/8189298dd3a05bbad716ee8e249764ff8800e365d8dc652ad2192ca01b4a/pynndescent-0.5.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (56.0.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-cp37-none-any.whl size=76569 sha256=6dc5c8dff4b64c64464445774d9fc842aacf7f6cdb835c3aab563f6ed4618a3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/df/d5/a3691296ff779f25cd1cf415a3af954b987fb53111e3392cf4\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.2-cp37-none-any.whl size=51351 sha256=5b4c82bb46fd848d386121cb00487da386ff653248801f5097b38859c4778049\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/52/4e/4c28d04d144a28f89e2575fb63628df6e6d49b56c5ddd0c74e\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.2 umap-learn-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSzpIBYi_Usj"
      },
      "source": [
        "import umap.umap_ as umap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaW56ivr_Yd6"
      },
      "source": [
        "embedding = umap.UMAP(n_neighbors = 100, min_dist=0.05,  densmap=True).fit(Hidden_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wxG-ok5_O_1",
        "outputId": "afe6efc8-f843-456c-d648-0731f9c6a1b6"
      },
      "source": [
        "pip install umap-learn[plot]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: umap-learn[plot] in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (1.19.5)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (0.51.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (0.5.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (1.4.1)\n",
            "Requirement already satisfied: bokeh; extra == \"plot\" in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (2.3.1)\n",
            "Requirement already satisfied: holoviews; extra == \"plot\" in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (1.14.3)\n",
            "Requirement already satisfied: matplotlib; extra == \"plot\" in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (3.2.2)\n",
            "Collecting datashader; extra == \"plot\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/24/22f96084785d9cc424f1e70541a2803eec807c82e6bdab87c4b71fd96d10/datashader-0.12.1-py2.py3-none-any.whl (15.8MB)\n",
            "\u001b[K     |████████████████████████████████| 15.8MB 428kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image; extra == \"plot\" in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (0.16.2)\n",
            "Requirement already satisfied: seaborn; extra == \"plot\" in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (0.11.1)\n",
            "Requirement already satisfied: pandas; extra == \"plot\" in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (1.1.5)\n",
            "Requirement already satisfied: colorcet; extra == \"plot\" in /usr/local/lib/python3.7/dist-packages (from umap-learn[plot]) (2.0.6)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn[plot]) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn[plot]) (56.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn[plot]) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh; extra == \"plot\"->umap-learn[plot]) (2.11.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh; extra == \"plot\"->umap-learn[plot]) (3.13)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh; extra == \"plot\"->umap-learn[plot]) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh; extra == \"plot\"->umap-learn[plot]) (3.7.4.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh; extra == \"plot\"->umap-learn[plot]) (20.9)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh; extra == \"plot\"->umap-learn[plot]) (5.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh; extra == \"plot\"->umap-learn[plot]) (2.8.1)\n",
            "Requirement already satisfied: panel>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from holoviews; extra == \"plot\"->umap-learn[plot]) (0.11.2)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.7/dist-packages (from holoviews; extra == \"plot\"->umap-learn[plot]) (2.0.1)\n",
            "Requirement already satisfied: param<2.0,>=1.9.3 in /usr/local/lib/python3.7/dist-packages (from holoviews; extra == \"plot\"->umap-learn[plot]) (1.10.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib; extra == \"plot\"->umap-learn[plot]) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib; extra == \"plot\"->umap-learn[plot]) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib; extra == \"plot\"->umap-learn[plot]) (0.10.0)\n",
            "Requirement already satisfied: toolz>=0.7.4 in /usr/local/lib/python3.7/dist-packages (from datashader; extra == \"plot\"->umap-learn[plot]) (0.11.1)\n",
            "Collecting datashape>=0.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/5b/95b2ed56b61e649b69c9a5b1ecb32ff0a5cd68b9f69f5aa7774540e6b444/datashape-0.5.2.tar.gz (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyct>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from datashader; extra == \"plot\"->umap-learn[plot]) (0.4.8)\n",
            "Requirement already satisfied: dask[complete]>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from datashader; extra == \"plot\"->umap-learn[plot]) (2.12.0)\n",
            "Requirement already satisfied: xarray>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from datashader; extra == \"plot\"->umap-learn[plot]) (0.15.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image; extra == \"plot\"->umap-learn[plot]) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image; extra == \"plot\"->umap-learn[plot]) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image; extra == \"plot\"->umap-learn[plot]) (1.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas; extra == \"plot\"->umap-learn[plot]) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh; extra == \"plot\"->umap-learn[plot]) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh; extra == \"plot\"->umap-learn[plot]) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews; extra == \"plot\"->umap-learn[plot]) (2.23.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews; extra == \"plot\"->umap-learn[plot]) (3.3.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from panel>=0.8.0->holoviews; extra == \"plot\"->umap-learn[plot]) (4.41.1)\n",
            "Collecting multipledispatch>=0.4.7\n",
            "  Downloading https://files.pythonhosted.org/packages/89/79/429ecef45fd5e4504f7474d4c3c3c4668c267be3370e4c2fd33e61506833/multipledispatch-0.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: cloudpickle>=0.2.1; extra == \"complete\" in /usr/local/lib/python3.7/dist-packages (from dask[complete]>=0.18.0->datashader; extra == \"plot\"->umap-learn[plot]) (1.3.0)\n",
            "Collecting distributed>=2.0; extra == \"complete\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/f8/ac2c18adde6477bca3881c4d3cfa74c7f4da7ee82f3c83c201aa3b9ca5ee/distributed-2021.4.1-py3-none-any.whl (696kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 43.8MB/s \n",
            "\u001b[?25hCollecting fsspec>=0.6.0; extra == \"complete\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 35.2MB/s \n",
            "\u001b[?25hCollecting partd>=0.3.10; extra == \"complete\"\n",
            "  Downloading https://files.pythonhosted.org/packages/41/94/360258a68b55f47859d72b2d0b2b3cfe0ca4fbbcb81b78812bd00ae86b7c/partd-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image; extra == \"plot\"->umap-learn[plot]) (4.4.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews; extra == \"plot\"->umap-learn[plot]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews; extra == \"plot\"->umap-learn[plot]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews; extra == \"plot\"->umap-learn[plot]) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->panel>=0.8.0->holoviews; extra == \"plot\"->umap-learn[plot]) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown->panel>=0.8.0->holoviews; extra == \"plot\"->umap-learn[plot]) (3.10.1)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader; extra == \"plot\"->umap-learn[plot]) (1.7.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader; extra == \"plot\"->umap-learn[plot]) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader; extra == \"plot\"->umap-learn[plot]) (5.4.8)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader; extra == \"plot\"->umap-learn[plot]) (2.0.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader; extra == \"plot\"->umap-learn[plot]) (2.3.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader; extra == \"plot\"->umap-learn[plot]) (1.0.2)\n",
            "Collecting locket\n",
            "  Downloading https://files.pythonhosted.org/packages/50/b8/e789e45b9b9c2db75e9d9e6ceb022c8d1d7e49b2c085ce8c05600f90a96b/locket-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown->panel>=0.8.0->holoviews; extra == \"plot\"->umap-learn[plot]) (3.4.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.0; extra == \"complete\"->dask[complete]>=0.18.0->datashader; extra == \"plot\"->umap-learn[plot]) (1.0.1)\n",
            "Building wheels for collected packages: datashape\n",
            "  Building wheel for datashape (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for datashape: filename=datashape-0.5.2-cp37-none-any.whl size=59430 sha256=55efdcedf42cd46915b5467590e8452b258e290cf5407bbde27abf9510ebbcdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/06/05/c1cba3d57bdcfd3960e3f60a9fdc97e4baef2ef09af0ad1ef8\n",
            "Successfully built datashape\n",
            "\u001b[31mERROR: distributed 2021.4.1 has requirement cloudpickle>=1.5.0, but you'll have cloudpickle 1.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: distributed 2021.4.1 has requirement dask>=2021.03.0, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: multipledispatch, datashape, datashader, distributed, fsspec, locket, partd\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "Successfully installed datashader-0.12.1 datashape-0.5.2 distributed-2021.4.1 fsspec-2021.4.0 locket-0.2.1 multipledispatch-0.6.0 partd-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU4OhQvkA3E1"
      },
      "source": [
        "import umap.plot\n",
        "umap.plot.output_notebook()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "KTuVBIS3AiDu",
        "outputId": "24fa4dd9-a7c7-43da-e3c4-6f670834ec7c"
      },
      "source": [
        "p = umap.plot.interactive(embedding, labels=Hidden_layer_labels, hover_data=hover_data, point_size=4) #title ='Nest1')\n",
        "umap.plot.show(p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error(url) {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (let i = 0; i < css_urls.length; i++) {\n",
              "      const url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.1.min.js\": \"YF85VygJKMVnHE+lLv2AM93Vbstr0yo2TbIu5v8se5Rq3UQAUmcuh4aaJwNlpKwa\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.1.min.js\": \"KKuas3gevv3PvrlkyCMzffFeaMq5we/a2QsP5AUoS3mJ0jmaCL7jirFJN3GoE/lM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.1.min.js\": \"MK/uFc3YT18pkvvXRl66tTHjP0/dxoSH2e/eiNMFIguKlun2+WVqaPTWmUy/zvh4\"};\n",
              "\n",
              "    for (let i = 0; i < js_urls.length; i++) {\n",
              "      const url = js_urls[i];\n",
              "      const element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error.bind(null, url);\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      if (url in hashes) {\n",
              "        element.crossOrigin = \"anonymous\";\n",
              "        element.integrity = \"sha384-\" + hashes[url];\n",
              "      }\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  \n",
              "  var js_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator.js\", \"https://unpkg.com/moment@2.27.0/moment.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.1.min.js\", \"https://unpkg.com/@holoviz/panel@^0.11.2/dist/panel.min.js\"];\n",
              "  var css_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/css/tabulator_simple.min.css\"];\n",
              "  \n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    function(Bokeh) {\n",
              "    \n",
              "    \n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      \n",
              "    for (var i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.1.min.js\": \"YF85VygJKMVnHE+lLv2AM93Vbstr0yo2TbIu5v8se5Rq3UQAUmcuh4aaJwNlpKwa\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.1.min.js\": \"KKuas3gevv3PvrlkyCMzffFeaMq5we/a2QsP5AUoS3mJ0jmaCL7jirFJN3GoE/lM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.1.min.js\": \"MK/uFc3YT18pkvvXRl66tTHjP0/dxoSH2e/eiNMFIguKlun2+WVqaPTWmUy/zvh4\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/js/tabulator.js\", \"https://unpkg.com/moment@2.27.0/moment.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.1.min.js\", \"https://unpkg.com/@holoviz/panel@^0.11.2/dist/panel.min.js\"];\n  var css_urls = [\"https://unpkg.com/tabulator-tables@4.9.3/dist/css/tabulator_simple.min.css\"];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"35a8c5bc-c415-4816-8fbf-a93252b90368\" data-root-id=\"1003\"></div>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"3def8094-6106-4721-8ace-10d60fe6557b\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"background_fill_color\":\"white\",\"below\":[{\"id\":\"1012\"}],\"center\":[{\"id\":\"1015\"},{\"id\":\"1019\"}],\"height\":800,\"left\":[{\"id\":\"1016\"}],\"renderers\":[{\"id\":\"1039\"}],\"title\":{\"id\":\"1042\"},\"toolbar\":{\"id\":\"1028\"},\"width\":800,\"x_range\":{\"id\":\"1004\"},\"x_scale\":{\"id\":\"1008\"},\"y_range\":{\"id\":\"1006\"},\"y_scale\":{\"id\":\"1010\"}},\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1008\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data\":{\"alpha\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"color\":[\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#9e0142\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#fdbf6f\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#bfe5a0\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\",\"#5e4fa2\"],\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138],\"key\":[\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"gthh\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"kcos\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"tbfk\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\",\"ttog\"],\"label\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3],\"x\":{\"__ndarray__\":\"bP+6QDHM50BwedBAyQ7cQK6Z0kB+/AlBSQe1QJBZDUFvn/JANUTaQG0L3EAcRwdBFO7NQPLmC0EIMQ1Bxq/XQPk8D0H4Id5BfxXvQVqU4EEChdtB/a7ZQS8t3UFSWdxBd3zXQYwq30GXht9BC7zbQbB63UF9DN5BYJ7eQUmo10F+RUvBmf1MwWyTScGJ/VjBoCFGwQG/ScFRCjrBApRDwQkpWsH+WErBkpJOwVnESsFOaE7BoV9IwcwTQcF/U0fBBVdFwcxHSMFTk07BuKu+QNUnvEAjO7NAmma0QFKCukDplKhAvLGJQNbduUDA8apADW68QDbpuUD25bNAFHe0QLJWpUCcUqhA4O6oQP2IrUAPkp9AgXkIQT81pUAy1wRB8D/VQPdU5EECSdNApZThQHuMC0H7KPVA/kTNQHK57kDlhQ5BKv4LQcXuDUF81wxBGv8LQcTk1EDQXNtBCMbdQfoO3EFFuulBH7/lQVaT3EEIvN1BVAXeQTKW3EHQrNdBvL/gQROt3EGpTd5BN2vYQTrA3EEd6thBeihKwbztV8F2KUrBSNFYwQF/SMGcV03BqABFwbnVKcH8REnBXz1MweCAUMEgnUXBn1hFwRPvS8GZC07BY6FGwRfxScEyWD3BMr5JwVaxsEAFXpxAKM66QFv7gEBhpKFAzWicQGhItUDyYbZAka62QMGbrUBN2bZAY9uyQNLjpUCbUrZAeMy5QBqDskDNbaNAcWSlQA==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[139]},\"y\":{\"__ndarray__\":\"kaF+QZaUgEH56oBBmxKBQRVzfUEmhIFBuRB7QUMyg0EL2YFBm6OAQRq+fkFf2YBB4Jh9Qc+yg0FhVYJBiZuAQbejg0FKD+5A9zfwQHycwUAzk91AYk/jQMjJ4kA+ueBAF4bcQLJN3EC80rxAEAjZQFUP4UD+L8JALLvdQL864EATCCBB7toeQUciHkHl0BtBU0cKQYanDkGGmt5ABasbQXgtD0FnmRRBLTQVQbJU/0ARbRpBVlgEQfHNFUFN1BdBayoaQRNc9UCxxR1B9zinwcpXpsFt0qTBMC6lwTjppsF/kKDBmwewwdqBpsEyQanBn6+mwZlvpcHCyqbB4/2owQzcpcEwZajBCyenwV0FpcGNG6jBZBeBQVsgfkG3W4JB3BGAQeK25EB3935BuX9/QZJjgkE+DoFBwbuBQRZWgEEnUYNB/x6BQUimgkEv94JBj4eCQXZAgEG6S91AW3zVQJCh1EBP7uVARwYAQWHl2UA7W9lAhfnVQDTD2UBwdNlA2jTLQNzk4EBsr91AF27cQH3h10AUPtRANykRQZjpGUF7RCBBOKUKQQrQ7UBO5BFBp7jTQAxZaEF1W/lA5Z4QQcz2GUHJ8+dANDYSQY/HFkFrUepAl6X2QPwiLUEUQtNAT/gFQYGPpcFI26bBZCCrwaZrqsHVQ6fBZnWlweSYpcGO0KTBH1ilwdxdpMFr4afBC7qkwe/MqMHj5KbBwHymweEFp8G3bafBzUmmwQ==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[139]}},\"selected\":{\"id\":\"1050\"},\"selection_policy\":{\"id\":\"1051\"}},\"id\":\"1002\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"formatter\":{\"id\":\"1047\"},\"major_label_policy\":{\"id\":\"1048\"},\"ticker\":{\"id\":\"1013\"},\"visible\":false},\"id\":\"1012\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"1002\"}},\"id\":\"1040\",\"type\":\"CDSView\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"1020\"},{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1027\"}]},\"id\":\"1028\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1006\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1047\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data_source\":{\"id\":\"1002\"},\"glyph\":{\"id\":\"1037\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1038\"},\"view\":{\"id\":\"1040\"}},\"id\":\"1039\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"key\",\"@{key}\"]]},\"id\":\"1027\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"LinearScale\"},{\"attributes\":{\"overlay\":{\"id\":\"1026\"}},\"id\":\"1022\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1044\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1004\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1050\",\"type\":\"Selection\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"color\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1038\",\"type\":\"Circle\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"1026\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"AllLabels\"},{\"attributes\":{\"fill_alpha\":{\"field\":\"alpha\"},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"field\":\"alpha\"},\"line_color\":{\"field\":\"color\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1037\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"1051\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"axis\":{\"id\":\"1012\"},\"ticker\":null,\"visible\":false},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"1044\"},\"major_label_policy\":{\"id\":\"1045\"},\"ticker\":{\"id\":\"1017\"},\"visible\":false},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1013\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1020\",\"type\":\"PanTool\"},{\"attributes\":{\"axis\":{\"id\":\"1016\"},\"dimension\":1,\"ticker\":null,\"visible\":false},\"id\":\"1019\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"ResetTool\"}],\"root_ids\":[\"1003\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.1\"}};\n",
              "  var render_items = [{\"docid\":\"3def8094-6106-4721-8ace-10d60fe6557b\",\"root_ids\":[\"1003\"],\"roots\":{\"1003\":\"35a8c5bc-c415-4816-8fbf-a93252b90368\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1003"
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-hMnM1rldSv",
        "outputId": "dbd85bb3-f11e-41c9-d8cb-386b8d7b1594"
      },
      "source": [
        "model_fixed.linear(ht[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.6353, -0.1723,  0.8973,  2.1575]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yu-i151lz43",
        "outputId": "1263d636-fa22-400a-acf7-7fa5e24252b2"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV_ScS4uiWGN",
        "outputId": "cba5f49d-6777-4fc8-80dd-e40b931b1bf6"
      },
      "source": [
        "h"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.0000e+00,  4.5915e-02, -1.4943e-04, -1.0000e+00, -8.0883e-08,\n",
              "          -1.0000e+00, -1.0972e+01,  9.7265e-10, -1.0990e+01,  1.0000e+00]],\n",
              "\n",
              "        [[-3.3179e+00, -3.9732e-01, -3.3076e-01, -6.4713e-01, -1.0976e+00,\n",
              "          -6.7902e-02, -1.1187e+00,  1.1220e+00,  2.8348e+00,  5.2127e-01]]],\n",
              "       grad_fn=<StackBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbtCh3dVsa5k"
      },
      "source": [
        "embeddings = nn.Embedding(1024, 4, padding_idx = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGwJnukes6-r"
      },
      "source": [
        "temp = embeddings(torch.tensor(np.zeros((10,1024))).long())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW0YiLy_ts3W",
        "outputId": "3f2fbda5-cee0-46d8-a2b0-7fdf6b20dd5b"
      },
      "source": [
        "temp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TFqT4gnTqhca",
        "outputId": "cb1807ce-9e97-418d-a60e-2957b0610df8"
      },
      "source": [
        "model_fixed(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.]]], grad_fn=<EmbeddingBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-86239191e024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_fixed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-0a7169e84753>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;31m# See torch/nn/modules/module.py::_forward_unimplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[1;32m    607\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    202\u001b[0m             raise RuntimeError(\n\u001b[1;32m    203\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 204\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 1024, got 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgwoLiEAMRzM"
      },
      "source": [
        "current_songfile = syllable_df_Nest_Total.loc[syllable_df_Nest_Total['key']=='cyea_0000']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsm7XG-w1VMV"
      },
      "source": [
        "sequence_length = current_songfile['indvi'].values[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5TV6CGW1cTH"
      },
      "source": [
        "temp_list = current_songfile['densenet121_features'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5y4BWxQ35Rv",
        "outputId": "7e6be2bf-a4d3-49a6-f88f-c4dc68b86cd8"
      },
      "source": [
        "temp_list.append()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([3.6964213e-04, 6.1388216e-03, 2.3623325e-03, ..., 5.9952104e-01,\n",
              "        4.7096276e-01, 6.7699389e-03], dtype=float32),\n",
              " array([3.9546576e-04, 4.2689457e-03, 2.1646945e-03, ..., 1.0832235e+00,\n",
              "        5.0408190e-01, 8.0454396e-04], dtype=float32),\n",
              " array([4.3923515e-04, 3.5873966e-03, 2.3025582e-03, ..., 4.5419684e-01,\n",
              "        9.9826270e-01, 5.8748936e-03], dtype=float32),\n",
              " array([4.8858119e-04, 5.5127405e-03, 1.7675881e-03, ..., 2.6316303e-01,\n",
              "        6.5507305e-01, 0.0000000e+00], dtype=float32),\n",
              " array([4.0706727e-04, 4.3425970e-03, 1.8088806e-03, ..., 6.8255633e-02,\n",
              "        9.7876644e-01, 0.0000000e+00], dtype=float32),\n",
              " array([3.6909830e-04, 7.3469197e-03, 2.3746886e-03, ..., 5.4688144e-01,\n",
              "        7.2352040e-01, 7.7279314e-02], dtype=float32),\n",
              " array([4.8456003e-04, 3.6201791e-03, 2.1676929e-03, ..., 1.2960277e-01,\n",
              "        9.3385494e-01, 4.3036998e-03], dtype=float32),\n",
              " array([0.00049007, 0.00513859, 0.00200676, ..., 0.47218606, 0.48447147,\n",
              "        0.        ], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwska5uM2vvR"
      },
      "source": [
        "for k in range(sequence_length,20):\n",
        "  temp_list.append(np.zeros(len(temp_list[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmRNB9Yd3TLx",
        "outputId": "d8dd4725-5a56-4ad2-c200-a27985ddfaac"
      },
      "source": [
        "torch.tensor(temp_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.6964e-04, 6.1388e-03, 2.3623e-03,  ..., 5.9952e-01, 4.7096e-01,\n",
              "         6.7699e-03],\n",
              "        [3.9547e-04, 4.2689e-03, 2.1647e-03,  ..., 1.0832e+00, 5.0408e-01,\n",
              "         8.0454e-04],\n",
              "        [4.3924e-04, 3.5874e-03, 2.3026e-03,  ..., 4.5420e-01, 9.9826e-01,\n",
              "         5.8749e-03],\n",
              "        ...,\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0c0XRBw3xI1",
        "outputId": "1a8bcca1-078c-4427-958e-3ec86e588e5c"
      },
      "source": [
        "np.zeros((2, len(temp_list[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "h-jzjSqSEzhb",
        "outputId": "183d752a-6a42-4f38-a9d6-1a1a25496a68"
      },
      "source": [
        "feature_set = []\n",
        "for feat in current_songfile['densenet121_features']:\n",
        "  feature_set.append(create_sequence_feature(feat))\n",
        "# current_songfile['densenet121_features'].to_list()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-49b85223f10f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeature_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_songfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'densenet121_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mfeature_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_sequence_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# current_songfile['densenet121_features'].to_list()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: create_sequence_feature() missing 1 required positional argument: 'given_key'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpakzniXE0w7",
        "outputId": "7a4f0fa6-e667-4628-e2bb-2e80ae9f593c"
      },
      "source": [
        "torch.tensor(current_songfile['densenet121_features'].to_list())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.6964e-04, 6.1388e-03, 2.3623e-03,  ..., 5.9952e-01, 4.7096e-01,\n",
              "         6.7699e-03],\n",
              "        [3.9547e-04, 4.2689e-03, 2.1647e-03,  ..., 1.0832e+00, 5.0408e-01,\n",
              "         8.0454e-04],\n",
              "        [4.3924e-04, 3.5874e-03, 2.3026e-03,  ..., 4.5420e-01, 9.9826e-01,\n",
              "         5.8749e-03],\n",
              "        ...,\n",
              "        [3.6910e-04, 7.3469e-03, 2.3747e-03,  ..., 5.4688e-01, 7.2352e-01,\n",
              "         7.7279e-02],\n",
              "        [4.8456e-04, 3.6202e-03, 2.1677e-03,  ..., 1.2960e-01, 9.3385e-01,\n",
              "         4.3037e-03],\n",
              "        [4.9007e-04, 5.1386e-03, 2.0068e-03,  ..., 4.7219e-01, 4.8447e-01,\n",
              "         0.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4Yo8lCvGkUV"
      },
      "source": [
        "l = current_songfile['indvi'].values[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iy1zG8lHHHE",
        "outputId": "11a9f4da-dd3f-4ad6-cc99-d4b1c01abff6"
      },
      "source": [
        "l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKG1kt1sHIJE"
      },
      "source": [
        "y = current_songfile['indv'].values[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jrw37y4hIcot",
        "outputId": "a9722813-e514-4dc1-c749-c9a72b71db7b"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cyea'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLDxcrYeIdRu"
      },
      "source": [
        "syllable_df_Nest_RNN = pd.DataFrame({'X' : [], 'y' : [], 'l' : []})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "-zGrMdhCJsuf",
        "outputId": "33b12b6c-ba65-4177-b9a8-442f86d5d4f1"
      },
      "source": [
        "syllable_df_Nest_RNN['X'].idx[0] = current_songfile['densenet121_features'].to_list()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-9197d74dffff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msyllable_df_Nest_RNN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_songfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'densenet121_features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'idx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "QCPfd8stJ0N9",
        "outputId": "2a543b68-e5c8-4fc8-c50c-37dc5b997a83"
      },
      "source": [
        "syllable_df_Nest_RNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>y</th>\n",
              "      <th>l</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.00036964213, 0.0061388216, 0.0023623325, 0....</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.00039546576, 0.0042689457, 0.0021646945, 0....</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.00043923515, 0.0035873966, 0.0023025582, 0....</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.0004885812, 0.0055127405, 0.0017675881, 0.0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.00040706727, 0.004342597, 0.0018088806, 0.0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[0.0003690983, 0.0073469197, 0.0023746886, 0.0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[0.00048456003, 0.0036201791, 0.0021676929, 0....</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[0.00049007137, 0.005138587, 0.0020067566, 0.0...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   X   y   l\n",
              "0  [0.00036964213, 0.0061388216, 0.0023623325, 0.... NaN NaN\n",
              "1  [0.00039546576, 0.0042689457, 0.0021646945, 0.... NaN NaN\n",
              "2  [0.00043923515, 0.0035873966, 0.0023025582, 0.... NaN NaN\n",
              "3  [0.0004885812, 0.0055127405, 0.0017675881, 0.0... NaN NaN\n",
              "4  [0.00040706727, 0.004342597, 0.0018088806, 0.0... NaN NaN\n",
              "5  [0.0003690983, 0.0073469197, 0.0023746886, 0.0... NaN NaN\n",
              "6  [0.00048456003, 0.0036201791, 0.0021676929, 0.... NaN NaN\n",
              "7  [0.00049007137, 0.005138587, 0.0020067566, 0.0... NaN NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQKGRJb5K18u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}